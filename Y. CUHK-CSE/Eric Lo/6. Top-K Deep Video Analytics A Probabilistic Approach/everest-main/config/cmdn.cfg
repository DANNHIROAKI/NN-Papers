[net]
# Testing
batch=1
subdivisions=1
# Training
# batch=64
# subdivisions=2
width=128
height=128
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.001
burn_in=1000
max_batches = 500200
policy=steps
steps=400000,450000
scales=.1,.1

# 0
[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=leaky

# 1
[maxpool]
size=2
stride=2

# 2
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
activation=leaky

# 3
[maxpool]
size=2
stride=2

# 4
[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=leaky

# 5
[maxpool]
size=2
stride=2

# 6
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=leaky

# 6
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=leaky


# mdn
[hmdn]
filters=128
M=5,8,10,15
num_h=20,30,40
# larger clamp, larger variance
clamp=6
# larger eps, smaller variance
eps=0.1

