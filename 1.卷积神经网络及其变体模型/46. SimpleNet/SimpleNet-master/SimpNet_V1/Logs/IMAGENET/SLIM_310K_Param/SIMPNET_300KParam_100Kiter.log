I0316 09:15:02.067752 11765 caffe.cpp:185] Using GPUs 0, 1
I0316 09:15:02.123103 11765 caffe.cpp:190] GPU 0: GeForce GTX TITAN X
I0316 09:15:02.123809 11765 caffe.cpp:190] GPU 1: GeForce GTX TITAN X 
I0316 09:15:02.442777 11765 solver.cpp:48] Initializing solver from parameters: 
test_iter: 1000
test_interval: 1000
base_lr: 0.2
display: 100
max_iter: 1000000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 20000
snapshot_prefix: "snapshots/imageNet_slim"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "imagenet.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 125000
stepvalue: 193000
stepvalue: 225000
stepvalue: 280000
stepvalue: 350000
type: "AdaDelta"
I0316 09:15:02.442945 11765 solver.cpp:91] Creating training net from net file: imagenet.prototxt
I0316 09:15:02.444142 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I0316 09:15:02.444166 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0316 09:15:02.444186 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0316 09:15:02.444196 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0316 09:15:02.444213 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0316 09:15:02.444231 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0316 09:15:02.444244 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0316 09:15:02.444262 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0316 09:15:02.444273 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0316 09:15:02.444283 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0316 09:15:02.444294 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0316 09:15:02.444310 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top-1
I0316 09:15:02.444317 11765 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy_top-5
I0316 09:15:02.444568 11765 net.cpp:49] Initializing net from parameters: 
name: "ImageNet_SlimNet_300K_NoDrp"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ali/dataset/train_IMDB"
    batch_size: 128
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 7
    stride: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0316 09:15:02.444841 11765 layer_factory.hpp:77] Creating layer data
I0316 09:15:02.445053 11765 net.cpp:91] Creating Layer data
I0316 09:15:02.445067 11765 net.cpp:399] data -> data
I0316 09:15:02.445102 11765 net.cpp:399] data -> label
I0316 09:15:02.445124 11765 data_transformer.cpp:25] Loading mean file from: imagenet_mean.binaryproto
I0316 09:15:02.446650 11771 db_lmdb.cpp:38] Opened lmdb /home/ali/dataset/train_IMDB
I0316 09:15:02.463418 11765 data_layer.cpp:41] output data size: 128,3,227,227
I0316 09:15:02.586946 11765 net.cpp:141] Setting up data
I0316 09:15:02.586980 11765 net.cpp:148] Top shape: 128 3 227 227 (19787136)
I0316 09:15:02.586989 11765 net.cpp:148] Top shape: 128 (128)
I0316 09:15:02.586994 11765 net.cpp:156] Memory required for data: 79149056
I0316 09:15:02.587018 11765 layer_factory.hpp:77] Creating layer conv1
I0316 09:15:02.587045 11765 net.cpp:91] Creating Layer conv1
I0316 09:15:02.587056 11765 net.cpp:425] conv1 <- data
I0316 09:15:02.587074 11765 net.cpp:399] conv1 -> conv1
I0316 09:15:02.588028 11765 net.cpp:141] Setting up conv1
I0316 09:15:02.588044 11765 net.cpp:148] Top shape: 128 64 75 75 (46080000)
I0316 09:15:02.588050 11765 net.cpp:156] Memory required for data: 263469056
I0316 09:15:02.588079 11765 layer_factory.hpp:77] Creating layer bn1
I0316 09:15:02.588100 11765 net.cpp:91] Creating Layer bn1
I0316 09:15:02.588109 11765 net.cpp:425] bn1 <- conv1
I0316 09:15:02.588126 11765 net.cpp:399] bn1 -> bn1
I0316 09:15:02.588274 11765 net.cpp:141] Setting up bn1
I0316 09:15:02.588284 11765 net.cpp:148] Top shape: 128 64 75 75 (46080000)
I0316 09:15:02.588289 11765 net.cpp:156] Memory required for data: 447789056
I0316 09:15:02.588310 11765 layer_factory.hpp:77] Creating layer scale1
I0316 09:15:02.588325 11765 net.cpp:91] Creating Layer scale1
I0316 09:15:02.588333 11765 net.cpp:425] scale1 <- bn1
I0316 09:15:02.588341 11765 net.cpp:399] scale1 -> scale1
I0316 09:15:02.588392 11765 layer_factory.hpp:77] Creating layer scale1
I0316 09:15:02.588506 11765 net.cpp:141] Setting up scale1
I0316 09:15:02.588517 11765 net.cpp:148] Top shape: 128 64 75 75 (46080000)
I0316 09:15:02.588523 11765 net.cpp:156] Memory required for data: 632109056
I0316 09:15:02.588534 11765 layer_factory.hpp:77] Creating layer relu1
I0316 09:15:02.588546 11765 net.cpp:91] Creating Layer relu1
I0316 09:15:02.588551 11765 net.cpp:425] relu1 <- scale1
I0316 09:15:02.588559 11765 net.cpp:399] relu1 -> relu1
I0316 09:15:02.588583 11765 net.cpp:141] Setting up relu1
I0316 09:15:02.588594 11765 net.cpp:148] Top shape: 128 64 75 75 (46080000)
I0316 09:15:02.588599 11765 net.cpp:156] Memory required for data: 816429056
I0316 09:15:02.588605 11765 layer_factory.hpp:77] Creating layer conv1_0
I0316 09:15:02.588624 11765 net.cpp:91] Creating Layer conv1_0
I0316 09:15:02.588630 11765 net.cpp:425] conv1_0 <- relu1
I0316 09:15:02.588639 11765 net.cpp:399] conv1_0 -> conv1_0
I0316 09:15:02.589344 11765 net.cpp:141] Setting up conv1_0
I0316 09:15:02.589359 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.589363 11765 net.cpp:156] Memory required for data: 908589056
I0316 09:15:02.589385 11765 layer_factory.hpp:77] Creating layer bn1_0
I0316 09:15:02.589403 11765 net.cpp:91] Creating Layer bn1_0
I0316 09:15:02.589429 11765 net.cpp:425] bn1_0 <- conv1_0
I0316 09:15:02.589447 11765 net.cpp:399] bn1_0 -> bn1_0
I0316 09:15:02.589604 11765 net.cpp:141] Setting up bn1_0
I0316 09:15:02.589613 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.589619 11765 net.cpp:156] Memory required for data: 1000749056
I0316 09:15:02.589638 11765 layer_factory.hpp:77] Creating layer scale1_0
I0316 09:15:02.589656 11765 net.cpp:91] Creating Layer scale1_0
I0316 09:15:02.589663 11765 net.cpp:425] scale1_0 <- bn1_0
I0316 09:15:02.589679 11765 net.cpp:399] scale1_0 -> scale1_0
I0316 09:15:02.589726 11765 layer_factory.hpp:77] Creating layer scale1_0
I0316 09:15:02.589836 11765 net.cpp:141] Setting up scale1_0
I0316 09:15:02.589846 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.589851 11765 net.cpp:156] Memory required for data: 1092909056
I0316 09:15:02.589869 11765 layer_factory.hpp:77] Creating layer relu1_0
I0316 09:15:02.589879 11765 net.cpp:91] Creating Layer relu1_0
I0316 09:15:02.589886 11765 net.cpp:425] relu1_0 <- scale1_0
I0316 09:15:02.589898 11765 net.cpp:399] relu1_0 -> relu1_0
I0316 09:15:02.601979 11765 net.cpp:141] Setting up relu1_0
I0316 09:15:02.602007 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.602015 11765 net.cpp:156] Memory required for data: 1185069056
I0316 09:15:02.602025 11765 layer_factory.hpp:77] Creating layer conv2
I0316 09:15:02.602042 11765 net.cpp:91] Creating Layer conv2
I0316 09:15:02.602054 11765 net.cpp:425] conv2 <- relu1_0
I0316 09:15:02.602066 11765 net.cpp:399] conv2 -> conv2
I0316 09:15:02.602967 11765 net.cpp:141] Setting up conv2
I0316 09:15:02.602991 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.602998 11765 net.cpp:156] Memory required for data: 1277229056
I0316 09:15:02.603019 11765 layer_factory.hpp:77] Creating layer bn2
I0316 09:15:02.603042 11765 net.cpp:91] Creating Layer bn2
I0316 09:15:02.603051 11765 net.cpp:425] bn2 <- conv2
I0316 09:15:02.603062 11765 net.cpp:399] bn2 -> bn2
I0316 09:15:02.603315 11774 blocking_queue.cpp:50] Waiting for data
I0316 09:15:02.603349 11765 net.cpp:141] Setting up bn2
I0316 09:15:02.603361 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.603370 11765 net.cpp:156] Memory required for data: 1369389056
I0316 09:15:02.603389 11765 layer_factory.hpp:77] Creating layer scale2
I0316 09:15:02.603402 11765 net.cpp:91] Creating Layer scale2
I0316 09:15:02.603411 11765 net.cpp:425] scale2 <- bn2
I0316 09:15:02.603421 11765 net.cpp:399] scale2 -> scale2
I0316 09:15:02.603477 11765 layer_factory.hpp:77] Creating layer scale2
I0316 09:15:02.603652 11765 net.cpp:141] Setting up scale2
I0316 09:15:02.603665 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.603672 11765 net.cpp:156] Memory required for data: 1461549056
I0316 09:15:02.603682 11765 layer_factory.hpp:77] Creating layer relu2
I0316 09:15:02.603699 11765 net.cpp:91] Creating Layer relu2
I0316 09:15:02.603708 11765 net.cpp:425] relu2 <- scale2
I0316 09:15:02.603718 11765 net.cpp:399] relu2 -> relu2
I0316 09:15:02.603749 11765 net.cpp:141] Setting up relu2
I0316 09:15:02.603760 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.603766 11765 net.cpp:156] Memory required for data: 1553709056
I0316 09:15:02.603772 11765 layer_factory.hpp:77] Creating layer conv2_1
I0316 09:15:02.603785 11765 net.cpp:91] Creating Layer conv2_1
I0316 09:15:02.603795 11765 net.cpp:425] conv2_1 <- relu2
I0316 09:15:02.603804 11765 net.cpp:399] conv2_1 -> conv2_1
I0316 09:15:02.604651 11765 net.cpp:141] Setting up conv2_1
I0316 09:15:02.604665 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.604671 11765 net.cpp:156] Memory required for data: 1645869056
I0316 09:15:02.604712 11765 layer_factory.hpp:77] Creating layer bn2_1
I0316 09:15:02.604733 11765 net.cpp:91] Creating Layer bn2_1
I0316 09:15:02.604743 11765 net.cpp:425] bn2_1 <- conv2_1
I0316 09:15:02.604753 11765 net.cpp:399] bn2_1 -> bn2_1
I0316 09:15:02.605036 11765 net.cpp:141] Setting up bn2_1
I0316 09:15:02.605048 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.605056 11765 net.cpp:156] Memory required for data: 1738029056
I0316 09:15:02.605077 11765 layer_factory.hpp:77] Creating layer scale2_1
I0316 09:15:02.605088 11765 net.cpp:91] Creating Layer scale2_1
I0316 09:15:02.605098 11765 net.cpp:425] scale2_1 <- bn2_1
I0316 09:15:02.605114 11765 net.cpp:399] scale2_1 -> scale2_1
I0316 09:15:02.605166 11765 layer_factory.hpp:77] Creating layer scale2_1
I0316 09:15:02.605343 11765 net.cpp:141] Setting up scale2_1
I0316 09:15:02.605356 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.605365 11765 net.cpp:156] Memory required for data: 1830189056
I0316 09:15:02.605376 11765 layer_factory.hpp:77] Creating layer relu2_1
I0316 09:15:02.605389 11765 net.cpp:91] Creating Layer relu2_1
I0316 09:15:02.605398 11765 net.cpp:425] relu2_1 <- scale2_1
I0316 09:15:02.605408 11765 net.cpp:399] relu2_1 -> relu2_1
I0316 09:15:02.605480 11765 net.cpp:141] Setting up relu2_1
I0316 09:15:02.605499 11765 net.cpp:148] Top shape: 128 32 75 75 (23040000)
I0316 09:15:02.605515 11765 net.cpp:156] Memory required for data: 1922349056
I0316 09:15:02.605526 11765 layer_factory.hpp:77] Creating layer pool2_1
I0316 09:15:02.605538 11765 net.cpp:91] Creating Layer pool2_1
I0316 09:15:02.605546 11765 net.cpp:425] pool2_1 <- relu2_1
I0316 09:15:02.605556 11765 net.cpp:399] pool2_1 -> pool2_1
I0316 09:15:02.605621 11765 net.cpp:141] Setting up pool2_1
I0316 09:15:02.605633 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.605639 11765 net.cpp:156] Memory required for data: 1946007552
I0316 09:15:02.605648 11765 layer_factory.hpp:77] Creating layer conv2_2
I0316 09:15:02.605666 11765 net.cpp:91] Creating Layer conv2_2
I0316 09:15:02.605675 11765 net.cpp:425] conv2_2 <- pool2_1
I0316 09:15:02.605685 11765 net.cpp:399] conv2_2 -> conv2_2
I0316 09:15:02.607580 11765 net.cpp:141] Setting up conv2_2
I0316 09:15:02.607615 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.607625 11765 net.cpp:156] Memory required for data: 1969666048
I0316 09:15:02.607648 11765 layer_factory.hpp:77] Creating layer bn2_2
I0316 09:15:02.607673 11765 net.cpp:91] Creating Layer bn2_2
I0316 09:15:02.607683 11765 net.cpp:425] bn2_2 <- conv2_2
I0316 09:15:02.607707 11765 net.cpp:399] bn2_2 -> bn2_2
I0316 09:15:02.608100 11765 net.cpp:141] Setting up bn2_2
I0316 09:15:02.608124 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.608134 11765 net.cpp:156] Memory required for data: 1993324544
I0316 09:15:02.608170 11765 layer_factory.hpp:77] Creating layer scale2_2
I0316 09:15:02.608186 11765 net.cpp:91] Creating Layer scale2_2
I0316 09:15:02.608196 11765 net.cpp:425] scale2_2 <- bn2_2
I0316 09:15:02.608209 11765 net.cpp:399] scale2_2 -> scale2_2
I0316 09:15:02.608274 11765 layer_factory.hpp:77] Creating layer scale2_2
I0316 09:15:02.608482 11765 net.cpp:141] Setting up scale2_2
I0316 09:15:02.608506 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.608515 11765 net.cpp:156] Memory required for data: 2016983040
I0316 09:15:02.608536 11765 layer_factory.hpp:77] Creating layer relu2_2
I0316 09:15:02.608548 11765 net.cpp:91] Creating Layer relu2_2
I0316 09:15:02.608559 11765 net.cpp:425] relu2_2 <- scale2_2
I0316 09:15:02.608579 11765 net.cpp:399] relu2_2 -> relu2_2
I0316 09:15:02.608619 11765 net.cpp:141] Setting up relu2_2
I0316 09:15:02.608633 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.608644 11765 net.cpp:156] Memory required for data: 2040641536
I0316 09:15:02.608650 11765 layer_factory.hpp:77] Creating layer conv3
I0316 09:15:02.608669 11765 net.cpp:91] Creating Layer conv3
I0316 09:15:02.608680 11765 net.cpp:425] conv3 <- relu2_2
I0316 09:15:02.608716 11765 net.cpp:399] conv3 -> conv3
I0316 09:15:02.609262 11765 net.cpp:141] Setting up conv3
I0316 09:15:02.609294 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.609305 11765 net.cpp:156] Memory required for data: 2064300032
I0316 09:15:02.609325 11765 layer_factory.hpp:77] Creating layer bn3
I0316 09:15:02.609342 11765 net.cpp:91] Creating Layer bn3
I0316 09:15:02.609352 11765 net.cpp:425] bn3 <- conv3
I0316 09:15:02.609364 11765 net.cpp:399] bn3 -> bn3
I0316 09:15:02.609730 11765 net.cpp:141] Setting up bn3
I0316 09:15:02.609760 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.609771 11765 net.cpp:156] Memory required for data: 2087958528
I0316 09:15:02.609786 11765 layer_factory.hpp:77] Creating layer scale3
I0316 09:15:02.609800 11765 net.cpp:91] Creating Layer scale3
I0316 09:15:02.609812 11765 net.cpp:425] scale3 <- bn3
I0316 09:15:02.609823 11765 net.cpp:399] scale3 -> scale3
I0316 09:15:02.609892 11765 layer_factory.hpp:77] Creating layer scale3
I0316 09:15:02.610102 11765 net.cpp:141] Setting up scale3
I0316 09:15:02.610117 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.610127 11765 net.cpp:156] Memory required for data: 2111617024
I0316 09:15:02.610141 11765 layer_factory.hpp:77] Creating layer relu3
I0316 09:15:02.610153 11765 net.cpp:91] Creating Layer relu3
I0316 09:15:02.610164 11765 net.cpp:425] relu3 <- scale3
I0316 09:15:02.610177 11765 net.cpp:399] relu3 -> relu3
I0316 09:15:02.610216 11765 net.cpp:141] Setting up relu3
I0316 09:15:02.610230 11765 net.cpp:148] Top shape: 128 32 38 38 (5914624)
I0316 09:15:02.610240 11765 net.cpp:156] Memory required for data: 2135275520
I0316 09:15:02.610249 11765 layer_factory.hpp:77] Creating layer conv4
I0316 09:15:02.610270 11765 net.cpp:91] Creating Layer conv4
I0316 09:15:02.610280 11765 net.cpp:425] conv4 <- relu3
I0316 09:15:02.610292 11765 net.cpp:399] conv4 -> conv4
I0316 09:15:02.610986 11765 net.cpp:141] Setting up conv4
I0316 09:15:02.611011 11765 net.cpp:148] Top shape: 128 64 38 38 (11829248)
I0316 09:15:02.611027 11765 net.cpp:156] Memory required for data: 2182592512
I0316 09:15:02.611042 11765 layer_factory.hpp:77] Creating layer pool4
I0316 09:15:02.611057 11765 net.cpp:91] Creating Layer pool4
I0316 09:15:02.611066 11765 net.cpp:425] pool4 <- conv4
I0316 09:15:02.611079 11765 net.cpp:399] pool4 -> pool4
I0316 09:15:02.611151 11765 net.cpp:141] Setting up pool4
I0316 09:15:02.611165 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.611174 11765 net.cpp:156] Memory required for data: 2194421760
I0316 09:15:02.611184 11765 layer_factory.hpp:77] Creating layer bn4
I0316 09:15:02.611199 11765 net.cpp:91] Creating Layer bn4
I0316 09:15:02.611209 11765 net.cpp:425] bn4 <- pool4
I0316 09:15:02.611222 11765 net.cpp:399] bn4 -> bn4
I0316 09:15:02.612382 11765 net.cpp:141] Setting up bn4
I0316 09:15:02.612416 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.612424 11765 net.cpp:156] Memory required for data: 2206251008
I0316 09:15:02.612444 11765 layer_factory.hpp:77] Creating layer scale4
I0316 09:15:02.612460 11765 net.cpp:91] Creating Layer scale4
I0316 09:15:02.612471 11765 net.cpp:425] scale4 <- bn4
I0316 09:15:02.612486 11765 net.cpp:399] scale4 -> scale4
I0316 09:15:02.612562 11765 layer_factory.hpp:77] Creating layer scale4
I0316 09:15:02.612771 11765 net.cpp:141] Setting up scale4
I0316 09:15:02.612785 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.612795 11765 net.cpp:156] Memory required for data: 2218080256
I0316 09:15:02.612813 11765 layer_factory.hpp:77] Creating layer relu4
I0316 09:15:02.612828 11765 net.cpp:91] Creating Layer relu4
I0316 09:15:02.612838 11765 net.cpp:425] relu4 <- scale4
I0316 09:15:02.612855 11765 net.cpp:399] relu4 -> relu4
I0316 09:15:02.612902 11765 net.cpp:141] Setting up relu4
I0316 09:15:02.612916 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.612926 11765 net.cpp:156] Memory required for data: 2229909504
I0316 09:15:02.612933 11765 layer_factory.hpp:77] Creating layer conv4_1
I0316 09:15:02.612982 11765 net.cpp:91] Creating Layer conv4_1
I0316 09:15:02.612993 11765 net.cpp:425] conv4_1 <- relu4
I0316 09:15:02.613004 11765 net.cpp:399] conv4_1 -> conv4_1
I0316 09:15:02.614034 11765 net.cpp:141] Setting up conv4_1
I0316 09:15:02.614065 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.614073 11765 net.cpp:156] Memory required for data: 2241738752
I0316 09:15:02.614094 11765 layer_factory.hpp:77] Creating layer bn4_1
I0316 09:15:02.614122 11765 net.cpp:91] Creating Layer bn4_1
I0316 09:15:02.614133 11765 net.cpp:425] bn4_1 <- conv4_1
I0316 09:15:02.614153 11765 net.cpp:399] bn4_1 -> bn4_1
I0316 09:15:02.614512 11765 net.cpp:141] Setting up bn4_1
I0316 09:15:02.614527 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.614537 11765 net.cpp:156] Memory required for data: 2253568000
I0316 09:15:02.614555 11765 layer_factory.hpp:77] Creating layer scale4_1
I0316 09:15:02.614569 11765 net.cpp:91] Creating Layer scale4_1
I0316 09:15:02.614579 11765 net.cpp:425] scale4_1 <- bn4_1
I0316 09:15:02.614600 11765 net.cpp:399] scale4_1 -> scale4_1
I0316 09:15:02.614675 11765 layer_factory.hpp:77] Creating layer scale4_1
I0316 09:15:02.614900 11765 net.cpp:141] Setting up scale4_1
I0316 09:15:02.614923 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.614933 11765 net.cpp:156] Memory required for data: 2265397248
I0316 09:15:02.614951 11765 layer_factory.hpp:77] Creating layer relu4_1
I0316 09:15:02.614974 11765 net.cpp:91] Creating Layer relu4_1
I0316 09:15:02.614985 11765 net.cpp:425] relu4_1 <- scale4_1
I0316 09:15:02.614998 11765 net.cpp:399] relu4_1 -> relu4_1
I0316 09:15:02.615047 11765 net.cpp:141] Setting up relu4_1
I0316 09:15:02.615061 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.615070 11765 net.cpp:156] Memory required for data: 2277226496
I0316 09:15:02.615078 11765 layer_factory.hpp:77] Creating layer conv4_2
I0316 09:15:02.615101 11765 net.cpp:91] Creating Layer conv4_2
I0316 09:15:02.615113 11765 net.cpp:425] conv4_2 <- relu4_1
I0316 09:15:02.615133 11765 net.cpp:399] conv4_2 -> conv4_2
I0316 09:15:02.616127 11765 net.cpp:141] Setting up conv4_2
I0316 09:15:02.616154 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.616163 11765 net.cpp:156] Memory required for data: 2289055744
I0316 09:15:02.616185 11765 layer_factory.hpp:77] Creating layer bn4_2
I0316 09:15:02.616209 11765 net.cpp:91] Creating Layer bn4_2
I0316 09:15:02.616219 11765 net.cpp:425] bn4_2 <- conv4_2
I0316 09:15:02.616242 11765 net.cpp:399] bn4_2 -> bn4_2
I0316 09:15:02.616614 11765 net.cpp:141] Setting up bn4_2
I0316 09:15:02.616629 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.616647 11765 net.cpp:156] Memory required for data: 2300884992
I0316 09:15:02.616665 11765 layer_factory.hpp:77] Creating layer scale4_2
I0316 09:15:02.616678 11765 net.cpp:91] Creating Layer scale4_2
I0316 09:15:02.616689 11765 net.cpp:425] scale4_2 <- bn4_2
I0316 09:15:02.616703 11765 net.cpp:399] scale4_2 -> scale4_2
I0316 09:15:02.616786 11765 layer_factory.hpp:77] Creating layer scale4_2
I0316 09:15:02.617022 11765 net.cpp:141] Setting up scale4_2
I0316 09:15:02.617038 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.617046 11765 net.cpp:156] Memory required for data: 2312714240
I0316 09:15:02.617065 11765 layer_factory.hpp:77] Creating layer relu4_2
I0316 09:15:02.617079 11765 net.cpp:91] Creating Layer relu4_2
I0316 09:15:02.617089 11765 net.cpp:425] relu4_2 <- scale4_2
I0316 09:15:02.617101 11765 net.cpp:399] relu4_2 -> relu4_2
I0316 09:15:02.617152 11765 net.cpp:141] Setting up relu4_2
I0316 09:15:02.617166 11765 net.cpp:148] Top shape: 128 64 19 19 (2957312)
I0316 09:15:02.617175 11765 net.cpp:156] Memory required for data: 2324543488
I0316 09:15:02.617183 11765 layer_factory.hpp:77] Creating layer pool4_2
I0316 09:15:02.617207 11765 net.cpp:91] Creating Layer pool4_2
I0316 09:15:02.617216 11765 net.cpp:425] pool4_2 <- relu4_2
I0316 09:15:02.617235 11765 net.cpp:399] pool4_2 -> pool4_2
I0316 09:15:02.617336 11765 net.cpp:141] Setting up pool4_2
I0316 09:15:02.617358 11765 net.cpp:148] Top shape: 128 64 10 10 (819200)
I0316 09:15:02.617368 11765 net.cpp:156] Memory required for data: 2327820288
I0316 09:15:02.617375 11765 layer_factory.hpp:77] Creating layer conv4_0
I0316 09:15:02.617395 11765 net.cpp:91] Creating Layer conv4_0
I0316 09:15:02.617406 11765 net.cpp:425] conv4_0 <- pool4_2
I0316 09:15:02.617449 11765 net.cpp:399] conv4_0 -> conv4_0
I0316 09:15:02.619719 11765 net.cpp:141] Setting up conv4_0
I0316 09:15:02.619751 11765 net.cpp:148] Top shape: 128 128 10 10 (1638400)
I0316 09:15:02.619760 11765 net.cpp:156] Memory required for data: 2334373888
I0316 09:15:02.619798 11765 layer_factory.hpp:77] Creating layer bn4_0
I0316 09:15:02.619822 11765 net.cpp:91] Creating Layer bn4_0
I0316 09:15:02.619832 11765 net.cpp:425] bn4_0 <- conv4_0
I0316 09:15:02.619854 11765 net.cpp:399] bn4_0 -> bn4_0
I0316 09:15:02.620189 11765 net.cpp:141] Setting up bn4_0
I0316 09:15:02.620204 11765 net.cpp:148] Top shape: 128 128 10 10 (1638400)
I0316 09:15:02.620213 11765 net.cpp:156] Memory required for data: 2340927488
I0316 09:15:02.620232 11765 layer_factory.hpp:77] Creating layer scale4_0
I0316 09:15:02.620254 11765 net.cpp:91] Creating Layer scale4_0
I0316 09:15:02.620263 11765 net.cpp:425] scale4_0 <- bn4_0
I0316 09:15:02.620281 11765 net.cpp:399] scale4_0 -> scale4_0
I0316 09:15:02.620354 11765 layer_factory.hpp:77] Creating layer scale4_0
I0316 09:15:02.620538 11765 net.cpp:141] Setting up scale4_0
I0316 09:15:02.620553 11765 net.cpp:148] Top shape: 128 128 10 10 (1638400)
I0316 09:15:02.620561 11765 net.cpp:156] Memory required for data: 2347481088
I0316 09:15:02.620579 11765 layer_factory.hpp:77] Creating layer relu4_0
I0316 09:15:02.620592 11765 net.cpp:91] Creating Layer relu4_0
I0316 09:15:02.620602 11765 net.cpp:425] relu4_0 <- scale4_0
I0316 09:15:02.620620 11765 net.cpp:399] relu4_0 -> relu4_0
I0316 09:15:02.620651 11765 net.cpp:141] Setting up relu4_0
I0316 09:15:02.620663 11765 net.cpp:148] Top shape: 128 128 10 10 (1638400)
I0316 09:15:02.620673 11765 net.cpp:156] Memory required for data: 2354034688
I0316 09:15:02.620682 11765 layer_factory.hpp:77] Creating layer cccp4
I0316 09:15:02.620704 11765 net.cpp:91] Creating Layer cccp4
I0316 09:15:02.620714 11765 net.cpp:425] cccp4 <- relu4_0
I0316 09:15:02.620733 11765 net.cpp:399] cccp4 -> cccp4
I0316 09:15:02.621613 11765 net.cpp:141] Setting up cccp4
I0316 09:15:02.621639 11765 net.cpp:148] Top shape: 128 256 10 10 (3276800)
I0316 09:15:02.621649 11765 net.cpp:156] Memory required for data: 2367141888
I0316 09:15:02.621667 11765 layer_factory.hpp:77] Creating layer relu_cccp4
I0316 09:15:02.621681 11765 net.cpp:91] Creating Layer relu_cccp4
I0316 09:15:02.621692 11765 net.cpp:425] relu_cccp4 <- cccp4
I0316 09:15:02.621703 11765 net.cpp:386] relu_cccp4 -> cccp4 (in-place)
I0316 09:15:02.621726 11765 net.cpp:141] Setting up relu_cccp4
I0316 09:15:02.621737 11765 net.cpp:148] Top shape: 128 256 10 10 (3276800)
I0316 09:15:02.621745 11765 net.cpp:156] Memory required for data: 2380249088
I0316 09:15:02.621752 11765 layer_factory.hpp:77] Creating layer cccp5
I0316 09:15:02.621775 11765 net.cpp:91] Creating Layer cccp5
I0316 09:15:02.621785 11765 net.cpp:425] cccp5 <- cccp4
I0316 09:15:02.621803 11765 net.cpp:399] cccp5 -> cccp5
I0316 09:15:02.622436 11765 net.cpp:141] Setting up cccp5
I0316 09:15:02.622459 11765 net.cpp:148] Top shape: 128 64 10 10 (819200)
I0316 09:15:02.622469 11765 net.cpp:156] Memory required for data: 2383525888
I0316 09:15:02.622488 11765 layer_factory.hpp:77] Creating layer relu_cccp5
I0316 09:15:02.622499 11765 net.cpp:91] Creating Layer relu_cccp5
I0316 09:15:02.622509 11765 net.cpp:425] relu_cccp5 <- cccp5
I0316 09:15:02.622520 11765 net.cpp:386] relu_cccp5 -> cccp5 (in-place)
I0316 09:15:02.622534 11765 net.cpp:141] Setting up relu_cccp5
I0316 09:15:02.622545 11765 net.cpp:148] Top shape: 128 64 10 10 (819200)
I0316 09:15:02.622553 11765 net.cpp:156] Memory required for data: 2386802688
I0316 09:15:02.622560 11765 layer_factory.hpp:77] Creating layer poolcp5
I0316 09:15:02.622591 11765 net.cpp:91] Creating Layer poolcp5
I0316 09:15:02.622609 11765 net.cpp:425] poolcp5 <- cccp5
I0316 09:15:02.622628 11765 net.cpp:399] poolcp5 -> poolcp5
I0316 09:15:02.622704 11765 net.cpp:141] Setting up poolcp5
I0316 09:15:02.622716 11765 net.cpp:148] Top shape: 128 64 5 5 (204800)
I0316 09:15:02.622725 11765 net.cpp:156] Memory required for data: 2387621888
I0316 09:15:02.622733 11765 layer_factory.hpp:77] Creating layer cccp6
I0316 09:15:02.622756 11765 net.cpp:91] Creating Layer cccp6
I0316 09:15:02.622766 11765 net.cpp:425] cccp6 <- poolcp5
I0316 09:15:02.622786 11765 net.cpp:399] cccp6 -> cccp6
I0316 09:15:02.623726 11765 net.cpp:141] Setting up cccp6
I0316 09:15:02.623752 11765 net.cpp:148] Top shape: 128 64 5 5 (204800)
I0316 09:15:02.623759 11765 net.cpp:156] Memory required for data: 2388441088
I0316 09:15:02.623770 11765 layer_factory.hpp:77] Creating layer relu_cccp6
I0316 09:15:02.623783 11765 net.cpp:91] Creating Layer relu_cccp6
I0316 09:15:02.623793 11765 net.cpp:425] relu_cccp6 <- cccp6
I0316 09:15:02.623811 11765 net.cpp:386] relu_cccp6 -> cccp6 (in-place)
I0316 09:15:02.623824 11765 net.cpp:141] Setting up relu_cccp6
I0316 09:15:02.623836 11765 net.cpp:148] Top shape: 128 64 5 5 (204800)
I0316 09:15:02.623845 11765 net.cpp:156] Memory required for data: 2389260288
I0316 09:15:02.623852 11765 layer_factory.hpp:77] Creating layer poolcp6
I0316 09:15:02.623867 11765 net.cpp:91] Creating Layer poolcp6
I0316 09:15:02.623878 11765 net.cpp:425] poolcp6 <- cccp6
I0316 09:15:02.623888 11765 net.cpp:399] poolcp6 -> poolcp6
I0316 09:15:02.623950 11765 net.cpp:141] Setting up poolcp6
I0316 09:15:02.623963 11765 net.cpp:148] Top shape: 128 64 1 1 (8192)
I0316 09:15:02.623970 11765 net.cpp:156] Memory required for data: 2389293056
I0316 09:15:02.623980 11765 layer_factory.hpp:77] Creating layer ip1
I0316 09:15:02.623994 11765 net.cpp:91] Creating Layer ip1
I0316 09:15:02.624004 11765 net.cpp:425] ip1 <- poolcp6
I0316 09:15:02.624014 11765 net.cpp:399] ip1 -> ip1
I0316 09:15:02.625152 11765 net.cpp:141] Setting up ip1
I0316 09:15:02.625175 11765 net.cpp:148] Top shape: 128 1000 (128000)
I0316 09:15:02.625182 11765 net.cpp:156] Memory required for data: 2389805056
I0316 09:15:02.625196 11765 layer_factory.hpp:77] Creating layer loss
I0316 09:15:02.625217 11765 net.cpp:91] Creating Layer loss
I0316 09:15:02.625227 11765 net.cpp:425] loss <- ip1
I0316 09:15:02.625244 11765 net.cpp:425] loss <- label
I0316 09:15:02.625257 11765 net.cpp:399] loss -> loss
I0316 09:15:02.625275 11765 layer_factory.hpp:77] Creating layer loss
I0316 09:15:02.625630 11765 net.cpp:141] Setting up loss
I0316 09:15:02.625654 11765 net.cpp:148] Top shape: (1)
I0316 09:15:02.625663 11765 net.cpp:151]     with loss weight 1
I0316 09:15:02.625694 11765 net.cpp:156] Memory required for data: 2389805060
I0316 09:15:02.625701 11765 net.cpp:217] loss needs backward computation.
I0316 09:15:02.625712 11765 net.cpp:217] ip1 needs backward computation.
I0316 09:15:02.625722 11765 net.cpp:217] poolcp6 needs backward computation.
I0316 09:15:02.625730 11765 net.cpp:217] relu_cccp6 needs backward computation.
I0316 09:15:02.625741 11765 net.cpp:217] cccp6 needs backward computation.
I0316 09:15:02.625747 11765 net.cpp:217] poolcp5 needs backward computation.
I0316 09:15:02.625756 11765 net.cpp:217] relu_cccp5 needs backward computation.
I0316 09:15:02.625763 11765 net.cpp:217] cccp5 needs backward computation.
I0316 09:15:02.625772 11765 net.cpp:217] relu_cccp4 needs backward computation.
I0316 09:15:02.625779 11765 net.cpp:217] cccp4 needs backward computation.
I0316 09:15:02.625788 11765 net.cpp:217] relu4_0 needs backward computation.
I0316 09:15:02.625795 11765 net.cpp:217] scale4_0 needs backward computation.
I0316 09:15:02.625804 11765 net.cpp:217] bn4_0 needs backward computation.
I0316 09:15:02.625813 11765 net.cpp:217] conv4_0 needs backward computation.
I0316 09:15:02.625823 11765 net.cpp:217] pool4_2 needs backward computation.
I0316 09:15:02.625829 11765 net.cpp:217] relu4_2 needs backward computation.
I0316 09:15:02.625859 11765 net.cpp:217] scale4_2 needs backward computation.
I0316 09:15:02.625866 11765 net.cpp:217] bn4_2 needs backward computation.
I0316 09:15:02.625875 11765 net.cpp:217] conv4_2 needs backward computation.
I0316 09:15:02.625883 11765 net.cpp:217] relu4_1 needs backward computation.
I0316 09:15:02.625892 11765 net.cpp:217] scale4_1 needs backward computation.
I0316 09:15:02.625900 11765 net.cpp:217] bn4_1 needs backward computation.
I0316 09:15:02.625908 11765 net.cpp:217] conv4_1 needs backward computation.
I0316 09:15:02.625916 11765 net.cpp:217] relu4 needs backward computation.
I0316 09:15:02.625926 11765 net.cpp:217] scale4 needs backward computation.
I0316 09:15:02.625934 11765 net.cpp:217] bn4 needs backward computation.
I0316 09:15:02.625942 11765 net.cpp:217] pool4 needs backward computation.
I0316 09:15:02.625952 11765 net.cpp:217] conv4 needs backward computation.
I0316 09:15:02.625959 11765 net.cpp:217] relu3 needs backward computation.
I0316 09:15:02.625968 11765 net.cpp:217] scale3 needs backward computation.
I0316 09:15:02.625977 11765 net.cpp:217] bn3 needs backward computation.
I0316 09:15:02.625985 11765 net.cpp:217] conv3 needs backward computation.
I0316 09:15:02.625993 11765 net.cpp:217] relu2_2 needs backward computation.
I0316 09:15:02.626003 11765 net.cpp:217] scale2_2 needs backward computation.
I0316 09:15:02.626010 11765 net.cpp:217] bn2_2 needs backward computation.
I0316 09:15:02.626019 11765 net.cpp:217] conv2_2 needs backward computation.
I0316 09:15:02.626027 11765 net.cpp:217] pool2_1 needs backward computation.
I0316 09:15:02.626037 11765 net.cpp:217] relu2_1 needs backward computation.
I0316 09:15:02.626044 11765 net.cpp:217] scale2_1 needs backward computation.
I0316 09:15:02.626054 11765 net.cpp:217] bn2_1 needs backward computation.
I0316 09:15:02.626061 11765 net.cpp:217] conv2_1 needs backward computation.
I0316 09:15:02.626070 11765 net.cpp:217] relu2 needs backward computation.
I0316 09:15:02.626077 11765 net.cpp:217] scale2 needs backward computation.
I0316 09:15:02.626086 11765 net.cpp:217] bn2 needs backward computation.
I0316 09:15:02.626096 11765 net.cpp:217] conv2 needs backward computation.
I0316 09:15:02.626103 11765 net.cpp:217] relu1_0 needs backward computation.
I0316 09:15:02.626113 11765 net.cpp:217] scale1_0 needs backward computation.
I0316 09:15:02.626123 11765 net.cpp:217] bn1_0 needs backward computation.
I0316 09:15:02.626132 11765 net.cpp:217] conv1_0 needs backward computation.
I0316 09:15:02.626143 11765 net.cpp:217] relu1 needs backward computation.
I0316 09:15:02.626150 11765 net.cpp:217] scale1 needs backward computation.
I0316 09:15:02.626160 11765 net.cpp:217] bn1 needs backward computation.
I0316 09:15:02.626168 11765 net.cpp:217] conv1 needs backward computation.
I0316 09:15:02.626180 11765 net.cpp:219] data does not need backward computation.
I0316 09:15:02.626191 11765 net.cpp:261] This network produces output loss
I0316 09:15:02.626273 11765 net.cpp:274] Network initialization done.
I0316 09:15:02.629129 11765 solver.cpp:181] Creating test net (#0) specified by net file: imagenet.prototxt
I0316 09:15:02.629292 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I0316 09:15:02.629326 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0316 09:15:02.629349 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0316 09:15:02.629364 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0316 09:15:02.629377 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0316 09:15:02.629392 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0316 09:15:02.629405 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0316 09:15:02.629439 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0316 09:15:02.629490 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0316 09:15:02.629504 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0316 09:15:02.629518 11765 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0316 09:15:02.630075 11765 net.cpp:49] Initializing net from parameters: 
name: "ImageNet_SlimNet_300K_NoDrp"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 227
    mean_file: "imagenet_mean.binaryproto"
  }
  data_param {
    source: "/home/ali/dataset/val_IMDB"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 7
    stride: 3
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    global_pooling: true
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 1000
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
layer {
  name: "accuracy_top-1"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_top-1"
  include {
    phase: TEST
  }
}
layer {
  name: "accuracy_top-5"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_top-5"
  include {
    phase: TEST
  }
  accuracy_param {
    top_k: 5
  }
}
I0316 09:15:02.630475 11765 layer_factory.hpp:77] Creating layer data
I0316 09:15:02.630619 11765 net.cpp:91] Creating Layer data
I0316 09:15:02.630666 11765 net.cpp:399] data -> data
I0316 09:15:02.630688 11765 net.cpp:399] data -> label
I0316 09:15:02.630703 11765 data_transformer.cpp:25] Loading mean file from: imagenet_mean.binaryproto
I0316 09:15:02.631984 11775 db_lmdb.cpp:38] Opened lmdb /home/ali/dataset/val_IMDB
I0316 09:15:02.634836 11765 data_layer.cpp:41] output data size: 50,3,227,227
I0316 09:15:02.705723 11765 net.cpp:141] Setting up data
I0316 09:15:02.705767 11765 net.cpp:148] Top shape: 50 3 227 227 (7729350)
I0316 09:15:02.705776 11765 net.cpp:148] Top shape: 50 (50)
I0316 09:15:02.705782 11765 net.cpp:156] Memory required for data: 30917600
I0316 09:15:02.705791 11765 layer_factory.hpp:77] Creating layer label_data_1_split
I0316 09:15:02.705808 11765 net.cpp:91] Creating Layer label_data_1_split
I0316 09:15:02.705816 11765 net.cpp:425] label_data_1_split <- label
I0316 09:15:02.705831 11765 net.cpp:399] label_data_1_split -> label_data_1_split_0
I0316 09:15:02.705847 11765 net.cpp:399] label_data_1_split -> label_data_1_split_1
I0316 09:15:02.705857 11765 net.cpp:399] label_data_1_split -> label_data_1_split_2
I0316 09:15:02.705968 11765 net.cpp:141] Setting up label_data_1_split
I0316 09:15:02.705979 11765 net.cpp:148] Top shape: 50 (50)
I0316 09:15:02.705986 11765 net.cpp:148] Top shape: 50 (50)
I0316 09:15:02.705992 11765 net.cpp:148] Top shape: 50 (50)
I0316 09:15:02.705997 11765 net.cpp:156] Memory required for data: 30918200
I0316 09:15:02.706003 11765 layer_factory.hpp:77] Creating layer conv1
I0316 09:15:02.706023 11765 net.cpp:91] Creating Layer conv1
I0316 09:15:02.706030 11765 net.cpp:425] conv1 <- data
I0316 09:15:02.706039 11765 net.cpp:399] conv1 -> conv1
I0316 09:15:02.706492 11765 net.cpp:141] Setting up conv1
I0316 09:15:02.706516 11765 net.cpp:148] Top shape: 50 64 75 75 (18000000)
I0316 09:15:02.706521 11765 net.cpp:156] Memory required for data: 102918200
I0316 09:15:02.706535 11765 layer_factory.hpp:77] Creating layer bn1
I0316 09:15:02.706547 11765 net.cpp:91] Creating Layer bn1
I0316 09:15:02.706553 11765 net.cpp:425] bn1 <- conv1
I0316 09:15:02.706560 11765 net.cpp:399] bn1 -> bn1
I0316 09:15:02.706804 11765 net.cpp:141] Setting up bn1
I0316 09:15:02.706816 11765 net.cpp:148] Top shape: 50 64 75 75 (18000000)
I0316 09:15:02.706822 11765 net.cpp:156] Memory required for data: 174918200
I0316 09:15:02.706835 11765 layer_factory.hpp:77] Creating layer scale1
I0316 09:15:02.706848 11765 net.cpp:91] Creating Layer scale1
I0316 09:15:02.706856 11765 net.cpp:425] scale1 <- bn1
I0316 09:15:02.706864 11765 net.cpp:399] scale1 -> scale1
I0316 09:15:02.706921 11765 layer_factory.hpp:77] Creating layer scale1
I0316 09:15:02.707092 11765 net.cpp:141] Setting up scale1
I0316 09:15:02.707103 11765 net.cpp:148] Top shape: 50 64 75 75 (18000000)
I0316 09:15:02.707109 11765 net.cpp:156] Memory required for data: 246918200
I0316 09:15:02.707124 11765 layer_factory.hpp:77] Creating layer relu1
I0316 09:15:02.707135 11765 net.cpp:91] Creating Layer relu1
I0316 09:15:02.707141 11765 net.cpp:425] relu1 <- scale1
I0316 09:15:02.707150 11765 net.cpp:399] relu1 -> relu1
I0316 09:15:02.707190 11765 net.cpp:141] Setting up relu1
I0316 09:15:02.707201 11765 net.cpp:148] Top shape: 50 64 75 75 (18000000)
I0316 09:15:02.707206 11765 net.cpp:156] Memory required for data: 318918200
I0316 09:15:02.707211 11765 layer_factory.hpp:77] Creating layer conv1_0
I0316 09:15:02.707223 11765 net.cpp:91] Creating Layer conv1_0
I0316 09:15:02.707231 11765 net.cpp:425] conv1_0 <- relu1
I0316 09:15:02.707239 11765 net.cpp:399] conv1_0 -> conv1_0
I0316 09:15:02.713171 11765 net.cpp:141] Setting up conv1_0
I0316 09:15:02.713207 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.713212 11765 net.cpp:156] Memory required for data: 354918200
I0316 09:15:02.713233 11765 layer_factory.hpp:77] Creating layer bn1_0
I0316 09:15:02.713253 11765 net.cpp:91] Creating Layer bn1_0
I0316 09:15:02.713259 11765 net.cpp:425] bn1_0 <- conv1_0
I0316 09:15:02.713276 11765 net.cpp:399] bn1_0 -> bn1_0
I0316 09:15:02.713568 11765 net.cpp:141] Setting up bn1_0
I0316 09:15:02.713582 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.713587 11765 net.cpp:156] Memory required for data: 390918200
I0316 09:15:02.713598 11765 layer_factory.hpp:77] Creating layer scale1_0
I0316 09:15:02.713615 11765 net.cpp:91] Creating Layer scale1_0
I0316 09:15:02.713621 11765 net.cpp:425] scale1_0 <- bn1_0
I0316 09:15:02.713656 11765 net.cpp:399] scale1_0 -> scale1_0
I0316 09:15:02.713721 11765 layer_factory.hpp:77] Creating layer scale1_0
I0316 09:15:02.713877 11765 net.cpp:141] Setting up scale1_0
I0316 09:15:02.713888 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.713892 11765 net.cpp:156] Memory required for data: 426918200
I0316 09:15:02.713909 11765 layer_factory.hpp:77] Creating layer relu1_0
I0316 09:15:02.713917 11765 net.cpp:91] Creating Layer relu1_0
I0316 09:15:02.713923 11765 net.cpp:425] relu1_0 <- scale1_0
I0316 09:15:02.713930 11765 net.cpp:399] relu1_0 -> relu1_0
I0316 09:15:02.713964 11765 net.cpp:141] Setting up relu1_0
I0316 09:15:02.713973 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.713977 11765 net.cpp:156] Memory required for data: 462918200
I0316 09:15:02.713982 11765 layer_factory.hpp:77] Creating layer conv2
I0316 09:15:02.714002 11765 net.cpp:91] Creating Layer conv2
I0316 09:15:02.714009 11765 net.cpp:425] conv2 <- relu1_0
I0316 09:15:02.714023 11765 net.cpp:399] conv2 -> conv2
I0316 09:15:02.714661 11765 net.cpp:141] Setting up conv2
I0316 09:15:02.714673 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.714678 11765 net.cpp:156] Memory required for data: 498918200
I0316 09:15:02.714694 11765 layer_factory.hpp:77] Creating layer bn2
I0316 09:15:02.714704 11765 net.cpp:91] Creating Layer bn2
I0316 09:15:02.714709 11765 net.cpp:425] bn2 <- conv2
I0316 09:15:02.714717 11765 net.cpp:399] bn2 -> bn2
I0316 09:15:02.714952 11765 net.cpp:141] Setting up bn2
I0316 09:15:02.714963 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.714967 11765 net.cpp:156] Memory required for data: 534918200
I0316 09:15:02.714984 11765 layer_factory.hpp:77] Creating layer scale2
I0316 09:15:02.714994 11765 net.cpp:91] Creating Layer scale2
I0316 09:15:02.714999 11765 net.cpp:425] scale2 <- bn2
I0316 09:15:02.715008 11765 net.cpp:399] scale2 -> scale2
I0316 09:15:02.715057 11765 layer_factory.hpp:77] Creating layer scale2
I0316 09:15:02.715198 11765 net.cpp:141] Setting up scale2
I0316 09:15:02.715207 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.715212 11765 net.cpp:156] Memory required for data: 570918200
I0316 09:15:02.715220 11765 layer_factory.hpp:77] Creating layer relu2
I0316 09:15:02.715229 11765 net.cpp:91] Creating Layer relu2
I0316 09:15:02.715234 11765 net.cpp:425] relu2 <- scale2
I0316 09:15:02.715240 11765 net.cpp:399] relu2 -> relu2
I0316 09:15:02.715276 11765 net.cpp:141] Setting up relu2
I0316 09:15:02.715284 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.715289 11765 net.cpp:156] Memory required for data: 606918200
I0316 09:15:02.715294 11765 layer_factory.hpp:77] Creating layer conv2_1
I0316 09:15:02.715306 11765 net.cpp:91] Creating Layer conv2_1
I0316 09:15:02.715312 11765 net.cpp:425] conv2_1 <- relu2
I0316 09:15:02.715319 11765 net.cpp:399] conv2_1 -> conv2_1
I0316 09:15:02.715945 11765 net.cpp:141] Setting up conv2_1
I0316 09:15:02.715956 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.715961 11765 net.cpp:156] Memory required for data: 642918200
I0316 09:15:02.715970 11765 layer_factory.hpp:77] Creating layer bn2_1
I0316 09:15:02.715981 11765 net.cpp:91] Creating Layer bn2_1
I0316 09:15:02.715986 11765 net.cpp:425] bn2_1 <- conv2_1
I0316 09:15:02.715994 11765 net.cpp:399] bn2_1 -> bn2_1
I0316 09:15:02.716223 11765 net.cpp:141] Setting up bn2_1
I0316 09:15:02.716233 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.716238 11765 net.cpp:156] Memory required for data: 678918200
I0316 09:15:02.716254 11765 layer_factory.hpp:77] Creating layer scale2_1
I0316 09:15:02.716264 11765 net.cpp:91] Creating Layer scale2_1
I0316 09:15:02.716271 11765 net.cpp:425] scale2_1 <- bn2_1
I0316 09:15:02.716279 11765 net.cpp:399] scale2_1 -> scale2_1
I0316 09:15:02.716331 11765 layer_factory.hpp:77] Creating layer scale2_1
I0316 09:15:02.717052 11765 net.cpp:141] Setting up scale2_1
I0316 09:15:02.717079 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.717102 11765 net.cpp:156] Memory required for data: 714918200
I0316 09:15:02.717119 11765 layer_factory.hpp:77] Creating layer relu2_1
I0316 09:15:02.717129 11765 net.cpp:91] Creating Layer relu2_1
I0316 09:15:02.717134 11765 net.cpp:425] relu2_1 <- scale2_1
I0316 09:15:02.717144 11765 net.cpp:399] relu2_1 -> relu2_1
I0316 09:15:02.717185 11765 net.cpp:141] Setting up relu2_1
I0316 09:15:02.717192 11765 net.cpp:148] Top shape: 50 32 75 75 (9000000)
I0316 09:15:02.717197 11765 net.cpp:156] Memory required for data: 750918200
I0316 09:15:02.717202 11765 layer_factory.hpp:77] Creating layer pool2_1
I0316 09:15:02.717212 11765 net.cpp:91] Creating Layer pool2_1
I0316 09:15:02.717219 11765 net.cpp:425] pool2_1 <- relu2_1
I0316 09:15:02.717226 11765 net.cpp:399] pool2_1 -> pool2_1
I0316 09:15:02.717274 11765 net.cpp:141] Setting up pool2_1
I0316 09:15:02.717283 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.717288 11765 net.cpp:156] Memory required for data: 760159800
I0316 09:15:02.717293 11765 layer_factory.hpp:77] Creating layer conv2_2
I0316 09:15:02.717310 11765 net.cpp:91] Creating Layer conv2_2
I0316 09:15:02.717316 11765 net.cpp:425] conv2_2 <- pool2_1
I0316 09:15:02.717331 11765 net.cpp:399] conv2_2 -> conv2_2
I0316 09:15:02.717991 11765 net.cpp:141] Setting up conv2_2
I0316 09:15:02.718003 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.718008 11765 net.cpp:156] Memory required for data: 769401400
I0316 09:15:02.718024 11765 layer_factory.hpp:77] Creating layer bn2_2
I0316 09:15:02.718035 11765 net.cpp:91] Creating Layer bn2_2
I0316 09:15:02.718041 11765 net.cpp:425] bn2_2 <- conv2_2
I0316 09:15:02.718050 11765 net.cpp:399] bn2_2 -> bn2_2
I0316 09:15:02.718279 11765 net.cpp:141] Setting up bn2_2
I0316 09:15:02.718289 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.718294 11765 net.cpp:156] Memory required for data: 778643000
I0316 09:15:02.718308 11765 layer_factory.hpp:77] Creating layer scale2_2
I0316 09:15:02.718318 11765 net.cpp:91] Creating Layer scale2_2
I0316 09:15:02.718323 11765 net.cpp:425] scale2_2 <- bn2_2
I0316 09:15:02.718331 11765 net.cpp:399] scale2_2 -> scale2_2
I0316 09:15:02.718384 11765 layer_factory.hpp:77] Creating layer scale2_2
I0316 09:15:02.718518 11765 net.cpp:141] Setting up scale2_2
I0316 09:15:02.718528 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.718533 11765 net.cpp:156] Memory required for data: 787884600
I0316 09:15:02.718541 11765 layer_factory.hpp:77] Creating layer relu2_2
I0316 09:15:02.718550 11765 net.cpp:91] Creating Layer relu2_2
I0316 09:15:02.718555 11765 net.cpp:425] relu2_2 <- scale2_2
I0316 09:15:02.718562 11765 net.cpp:399] relu2_2 -> relu2_2
I0316 09:15:02.718587 11765 net.cpp:141] Setting up relu2_2
I0316 09:15:02.718596 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.718601 11765 net.cpp:156] Memory required for data: 797126200
I0316 09:15:02.718605 11765 layer_factory.hpp:77] Creating layer conv3
I0316 09:15:02.718623 11765 net.cpp:91] Creating Layer conv3
I0316 09:15:02.718629 11765 net.cpp:425] conv3 <- relu2_2
I0316 09:15:02.718644 11765 net.cpp:399] conv3 -> conv3
I0316 09:15:02.718983 11765 net.cpp:141] Setting up conv3
I0316 09:15:02.718994 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.718999 11765 net.cpp:156] Memory required for data: 806367800
I0316 09:15:02.719015 11765 layer_factory.hpp:77] Creating layer bn3
I0316 09:15:02.719027 11765 net.cpp:91] Creating Layer bn3
I0316 09:15:02.719033 11765 net.cpp:425] bn3 <- conv3
I0316 09:15:02.719048 11765 net.cpp:399] bn3 -> bn3
I0316 09:15:02.719269 11765 net.cpp:141] Setting up bn3
I0316 09:15:02.719279 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.719283 11765 net.cpp:156] Memory required for data: 815609400
I0316 09:15:02.719295 11765 layer_factory.hpp:77] Creating layer scale3
I0316 09:15:02.719305 11765 net.cpp:91] Creating Layer scale3
I0316 09:15:02.719310 11765 net.cpp:425] scale3 <- bn3
I0316 09:15:02.719318 11765 net.cpp:399] scale3 -> scale3
I0316 09:15:02.719372 11765 layer_factory.hpp:77] Creating layer scale3
I0316 09:15:02.719519 11765 net.cpp:141] Setting up scale3
I0316 09:15:02.719529 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.719534 11765 net.cpp:156] Memory required for data: 824851000
I0316 09:15:02.719543 11765 layer_factory.hpp:77] Creating layer relu3
I0316 09:15:02.719553 11765 net.cpp:91] Creating Layer relu3
I0316 09:15:02.719558 11765 net.cpp:425] relu3 <- scale3
I0316 09:15:02.719564 11765 net.cpp:399] relu3 -> relu3
I0316 09:15:02.719604 11765 net.cpp:141] Setting up relu3
I0316 09:15:02.719614 11765 net.cpp:148] Top shape: 50 32 38 38 (2310400)
I0316 09:15:02.719619 11765 net.cpp:156] Memory required for data: 834092600
I0316 09:15:02.719624 11765 layer_factory.hpp:77] Creating layer conv4
I0316 09:15:02.719633 11765 net.cpp:91] Creating Layer conv4
I0316 09:15:02.719640 11765 net.cpp:425] conv4 <- relu3
I0316 09:15:02.719655 11765 net.cpp:399] conv4 -> conv4
I0316 09:15:02.720087 11765 net.cpp:141] Setting up conv4
I0316 09:15:02.720098 11765 net.cpp:148] Top shape: 50 64 38 38 (4620800)
I0316 09:15:02.720101 11765 net.cpp:156] Memory required for data: 852575800
I0316 09:15:02.720118 11765 layer_factory.hpp:77] Creating layer pool4
I0316 09:15:02.720127 11765 net.cpp:91] Creating Layer pool4
I0316 09:15:02.720132 11765 net.cpp:425] pool4 <- conv4
I0316 09:15:02.720141 11765 net.cpp:399] pool4 -> pool4
I0316 09:15:02.720181 11765 net.cpp:141] Setting up pool4
I0316 09:15:02.720191 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.720196 11765 net.cpp:156] Memory required for data: 857196600
I0316 09:15:02.720201 11765 layer_factory.hpp:77] Creating layer bn4
I0316 09:15:02.720216 11765 net.cpp:91] Creating Layer bn4
I0316 09:15:02.720221 11765 net.cpp:425] bn4 <- pool4
I0316 09:15:02.720228 11765 net.cpp:399] bn4 -> bn4
I0316 09:15:02.720463 11765 net.cpp:141] Setting up bn4
I0316 09:15:02.720474 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.720479 11765 net.cpp:156] Memory required for data: 861817400
I0316 09:15:02.720495 11765 layer_factory.hpp:77] Creating layer scale4
I0316 09:15:02.720504 11765 net.cpp:91] Creating Layer scale4
I0316 09:15:02.720510 11765 net.cpp:425] scale4 <- bn4
I0316 09:15:02.720525 11765 net.cpp:399] scale4 -> scale4
I0316 09:15:02.720576 11765 layer_factory.hpp:77] Creating layer scale4
I0316 09:15:02.720705 11765 net.cpp:141] Setting up scale4
I0316 09:15:02.720715 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.720721 11765 net.cpp:156] Memory required for data: 866438200
I0316 09:15:02.720728 11765 layer_factory.hpp:77] Creating layer relu4
I0316 09:15:02.720736 11765 net.cpp:91] Creating Layer relu4
I0316 09:15:02.720749 11765 net.cpp:425] relu4 <- scale4
I0316 09:15:02.720757 11765 net.cpp:399] relu4 -> relu4
I0316 09:15:02.720788 11765 net.cpp:141] Setting up relu4
I0316 09:15:02.720798 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.720803 11765 net.cpp:156] Memory required for data: 871059000
I0316 09:15:02.720808 11765 layer_factory.hpp:77] Creating layer conv4_1
I0316 09:15:02.720821 11765 net.cpp:91] Creating Layer conv4_1
I0316 09:15:02.720829 11765 net.cpp:425] conv4_1 <- relu4
I0316 09:15:02.720836 11765 net.cpp:399] conv4_1 -> conv4_1
I0316 09:15:02.721454 11765 net.cpp:141] Setting up conv4_1
I0316 09:15:02.721467 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.721472 11765 net.cpp:156] Memory required for data: 875679800
I0316 09:15:02.721480 11765 layer_factory.hpp:77] Creating layer bn4_1
I0316 09:15:02.721490 11765 net.cpp:91] Creating Layer bn4_1
I0316 09:15:02.721496 11765 net.cpp:425] bn4_1 <- conv4_1
I0316 09:15:02.721503 11765 net.cpp:399] bn4_1 -> bn4_1
I0316 09:15:02.721737 11765 net.cpp:141] Setting up bn4_1
I0316 09:15:02.721747 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.721752 11765 net.cpp:156] Memory required for data: 880300600
I0316 09:15:02.721768 11765 layer_factory.hpp:77] Creating layer scale4_1
I0316 09:15:02.721778 11765 net.cpp:91] Creating Layer scale4_1
I0316 09:15:02.721801 11765 net.cpp:425] scale4_1 <- bn4_1
I0316 09:15:02.721817 11765 net.cpp:399] scale4_1 -> scale4_1
I0316 09:15:02.721873 11765 layer_factory.hpp:77] Creating layer scale4_1
I0316 09:15:02.722005 11765 net.cpp:141] Setting up scale4_1
I0316 09:15:02.722014 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.722019 11765 net.cpp:156] Memory required for data: 884921400
I0316 09:15:02.722029 11765 layer_factory.hpp:77] Creating layer relu4_1
I0316 09:15:02.722038 11765 net.cpp:91] Creating Layer relu4_1
I0316 09:15:02.722043 11765 net.cpp:425] relu4_1 <- scale4_1
I0316 09:15:02.722051 11765 net.cpp:399] relu4_1 -> relu4_1
I0316 09:15:02.722084 11765 net.cpp:141] Setting up relu4_1
I0316 09:15:02.722093 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.722097 11765 net.cpp:156] Memory required for data: 889542200
I0316 09:15:02.722102 11765 layer_factory.hpp:77] Creating layer conv4_2
I0316 09:15:02.722113 11765 net.cpp:91] Creating Layer conv4_2
I0316 09:15:02.722120 11765 net.cpp:425] conv4_2 <- relu4_1
I0316 09:15:02.722134 11765 net.cpp:399] conv4_2 -> conv4_2
I0316 09:15:02.722753 11765 net.cpp:141] Setting up conv4_2
I0316 09:15:02.722764 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.722769 11765 net.cpp:156] Memory required for data: 894163000
I0316 09:15:02.722776 11765 layer_factory.hpp:77] Creating layer bn4_2
I0316 09:15:02.722786 11765 net.cpp:91] Creating Layer bn4_2
I0316 09:15:02.722793 11765 net.cpp:425] bn4_2 <- conv4_2
I0316 09:15:02.722801 11765 net.cpp:399] bn4_2 -> bn4_2
I0316 09:15:02.723029 11765 net.cpp:141] Setting up bn4_2
I0316 09:15:02.723040 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.723045 11765 net.cpp:156] Memory required for data: 898783800
I0316 09:15:02.723054 11765 layer_factory.hpp:77] Creating layer scale4_2
I0316 09:15:02.723062 11765 net.cpp:91] Creating Layer scale4_2
I0316 09:15:02.723068 11765 net.cpp:425] scale4_2 <- bn4_2
I0316 09:15:02.723074 11765 net.cpp:399] scale4_2 -> scale4_2
I0316 09:15:02.723126 11765 layer_factory.hpp:77] Creating layer scale4_2
I0316 09:15:02.723251 11765 net.cpp:141] Setting up scale4_2
I0316 09:15:02.723260 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.723265 11765 net.cpp:156] Memory required for data: 903404600
I0316 09:15:02.723281 11765 layer_factory.hpp:77] Creating layer relu4_2
I0316 09:15:02.723290 11765 net.cpp:91] Creating Layer relu4_2
I0316 09:15:02.723295 11765 net.cpp:425] relu4_2 <- scale4_2
I0316 09:15:02.723302 11765 net.cpp:399] relu4_2 -> relu4_2
I0316 09:15:02.723335 11765 net.cpp:141] Setting up relu4_2
I0316 09:15:02.723345 11765 net.cpp:148] Top shape: 50 64 19 19 (1155200)
I0316 09:15:02.723350 11765 net.cpp:156] Memory required for data: 908025400
I0316 09:15:02.723353 11765 layer_factory.hpp:77] Creating layer pool4_2
I0316 09:15:02.723362 11765 net.cpp:91] Creating Layer pool4_2
I0316 09:15:02.723367 11765 net.cpp:425] pool4_2 <- relu4_2
I0316 09:15:02.723376 11765 net.cpp:399] pool4_2 -> pool4_2
I0316 09:15:02.723423 11765 net.cpp:141] Setting up pool4_2
I0316 09:15:02.723430 11765 net.cpp:148] Top shape: 50 64 10 10 (320000)
I0316 09:15:02.723435 11765 net.cpp:156] Memory required for data: 909305400
I0316 09:15:02.723439 11765 layer_factory.hpp:77] Creating layer conv4_0
I0316 09:15:02.723450 11765 net.cpp:91] Creating Layer conv4_0
I0316 09:15:02.723458 11765 net.cpp:425] conv4_0 <- pool4_2
I0316 09:15:02.723472 11765 net.cpp:399] conv4_0 -> conv4_0
I0316 09:15:02.725035 11765 net.cpp:141] Setting up conv4_0
I0316 09:15:02.725064 11765 net.cpp:148] Top shape: 50 128 10 10 (640000)
I0316 09:15:02.725069 11765 net.cpp:156] Memory required for data: 911865400
I0316 09:15:02.725090 11765 layer_factory.hpp:77] Creating layer bn4_0
I0316 09:15:02.725102 11765 net.cpp:91] Creating Layer bn4_0
I0316 09:15:02.725111 11765 net.cpp:425] bn4_0 <- conv4_0
I0316 09:15:02.725126 11765 net.cpp:399] bn4_0 -> bn4_0
I0316 09:15:02.725347 11765 net.cpp:141] Setting up bn4_0
I0316 09:15:02.725356 11765 net.cpp:148] Top shape: 50 128 10 10 (640000)
I0316 09:15:02.725378 11765 net.cpp:156] Memory required for data: 914425400
I0316 09:15:02.725396 11765 layer_factory.hpp:77] Creating layer scale4_0
I0316 09:15:02.725407 11765 net.cpp:91] Creating Layer scale4_0
I0316 09:15:02.725437 11765 net.cpp:425] scale4_0 <- bn4_0
I0316 09:15:02.725447 11765 net.cpp:399] scale4_0 -> scale4_0
I0316 09:15:02.725505 11765 layer_factory.hpp:77] Creating layer scale4_0
I0316 09:15:02.725625 11765 net.cpp:141] Setting up scale4_0
I0316 09:15:02.725635 11765 net.cpp:148] Top shape: 50 128 10 10 (640000)
I0316 09:15:02.725639 11765 net.cpp:156] Memory required for data: 916985400
I0316 09:15:02.725648 11765 layer_factory.hpp:77] Creating layer relu4_0
I0316 09:15:02.725657 11765 net.cpp:91] Creating Layer relu4_0
I0316 09:15:02.725662 11765 net.cpp:425] relu4_0 <- scale4_0
I0316 09:15:02.725672 11765 net.cpp:399] relu4_0 -> relu4_0
I0316 09:15:02.725697 11765 net.cpp:141] Setting up relu4_0
I0316 09:15:02.725705 11765 net.cpp:148] Top shape: 50 128 10 10 (640000)
I0316 09:15:02.725710 11765 net.cpp:156] Memory required for data: 919545400
I0316 09:15:02.725714 11765 layer_factory.hpp:77] Creating layer cccp4
I0316 09:15:02.725734 11765 net.cpp:91] Creating Layer cccp4
I0316 09:15:02.725741 11765 net.cpp:425] cccp4 <- relu4_0
I0316 09:15:02.725757 11765 net.cpp:399] cccp4 -> cccp4
I0316 09:15:02.726308 11765 net.cpp:141] Setting up cccp4
I0316 09:15:02.726320 11765 net.cpp:148] Top shape: 50 256 10 10 (1280000)
I0316 09:15:02.726325 11765 net.cpp:156] Memory required for data: 924665400
I0316 09:15:02.726341 11765 layer_factory.hpp:77] Creating layer relu_cccp4
I0316 09:15:02.726349 11765 net.cpp:91] Creating Layer relu_cccp4
I0316 09:15:02.726354 11765 net.cpp:425] relu_cccp4 <- cccp4
I0316 09:15:02.726361 11765 net.cpp:386] relu_cccp4 -> cccp4 (in-place)
I0316 09:15:02.726369 11765 net.cpp:141] Setting up relu_cccp4
I0316 09:15:02.726375 11765 net.cpp:148] Top shape: 50 256 10 10 (1280000)
I0316 09:15:02.726382 11765 net.cpp:156] Memory required for data: 929785400
I0316 09:15:02.726387 11765 layer_factory.hpp:77] Creating layer cccp5
I0316 09:15:02.726404 11765 net.cpp:91] Creating Layer cccp5
I0316 09:15:02.726411 11765 net.cpp:425] cccp5 <- cccp4
I0316 09:15:02.726418 11765 net.cpp:399] cccp5 -> cccp5
I0316 09:15:02.726814 11765 net.cpp:141] Setting up cccp5
I0316 09:15:02.726825 11765 net.cpp:148] Top shape: 50 64 10 10 (320000)
I0316 09:15:02.726830 11765 net.cpp:156] Memory required for data: 931065400
I0316 09:15:02.726840 11765 layer_factory.hpp:77] Creating layer relu_cccp5
I0316 09:15:02.726847 11765 net.cpp:91] Creating Layer relu_cccp5
I0316 09:15:02.726852 11765 net.cpp:425] relu_cccp5 <- cccp5
I0316 09:15:02.726858 11765 net.cpp:386] relu_cccp5 -> cccp5 (in-place)
I0316 09:15:02.726867 11765 net.cpp:141] Setting up relu_cccp5
I0316 09:15:02.726873 11765 net.cpp:148] Top shape: 50 64 10 10 (320000)
I0316 09:15:02.726879 11765 net.cpp:156] Memory required for data: 932345400
I0316 09:15:02.726884 11765 layer_factory.hpp:77] Creating layer poolcp5
I0316 09:15:02.726899 11765 net.cpp:91] Creating Layer poolcp5
I0316 09:15:02.726905 11765 net.cpp:425] poolcp5 <- cccp5
I0316 09:15:02.726912 11765 net.cpp:399] poolcp5 -> poolcp5
I0316 09:15:02.726958 11765 net.cpp:141] Setting up poolcp5
I0316 09:15:02.726968 11765 net.cpp:148] Top shape: 50 64 5 5 (80000)
I0316 09:15:02.726971 11765 net.cpp:156] Memory required for data: 932665400
I0316 09:15:02.726976 11765 layer_factory.hpp:77] Creating layer cccp6
I0316 09:15:02.726987 11765 net.cpp:91] Creating Layer cccp6
I0316 09:15:02.726994 11765 net.cpp:425] cccp6 <- poolcp5
I0316 09:15:02.727010 11765 net.cpp:399] cccp6 -> cccp6
I0316 09:15:02.727584 11765 net.cpp:141] Setting up cccp6
I0316 09:15:02.727596 11765 net.cpp:148] Top shape: 50 64 5 5 (80000)
I0316 09:15:02.727599 11765 net.cpp:156] Memory required for data: 932985400
I0316 09:15:02.727608 11765 layer_factory.hpp:77] Creating layer relu_cccp6
I0316 09:15:02.727617 11765 net.cpp:91] Creating Layer relu_cccp6
I0316 09:15:02.727623 11765 net.cpp:425] relu_cccp6 <- cccp6
I0316 09:15:02.727644 11765 net.cpp:386] relu_cccp6 -> cccp6 (in-place)
I0316 09:15:02.727660 11765 net.cpp:141] Setting up relu_cccp6
I0316 09:15:02.727668 11765 net.cpp:148] Top shape: 50 64 5 5 (80000)
I0316 09:15:02.727672 11765 net.cpp:156] Memory required for data: 933305400
I0316 09:15:02.727677 11765 layer_factory.hpp:77] Creating layer poolcp6
I0316 09:15:02.727692 11765 net.cpp:91] Creating Layer poolcp6
I0316 09:15:02.727699 11765 net.cpp:425] poolcp6 <- cccp6
I0316 09:15:02.727705 11765 net.cpp:399] poolcp6 -> poolcp6
I0316 09:15:02.727756 11765 net.cpp:141] Setting up poolcp6
I0316 09:15:02.727766 11765 net.cpp:148] Top shape: 50 64 1 1 (3200)
I0316 09:15:02.727771 11765 net.cpp:156] Memory required for data: 933318200
I0316 09:15:02.727774 11765 layer_factory.hpp:77] Creating layer ip1
I0316 09:15:02.727792 11765 net.cpp:91] Creating Layer ip1
I0316 09:15:02.727797 11765 net.cpp:425] ip1 <- poolcp6
I0316 09:15:02.727804 11765 net.cpp:399] ip1 -> ip1
I0316 09:15:02.728499 11765 net.cpp:141] Setting up ip1
I0316 09:15:02.728510 11765 net.cpp:148] Top shape: 50 1000 (50000)
I0316 09:15:02.728515 11765 net.cpp:156] Memory required for data: 933518200
I0316 09:15:02.728531 11765 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I0316 09:15:02.728540 11765 net.cpp:91] Creating Layer ip1_ip1_0_split
I0316 09:15:02.728545 11765 net.cpp:425] ip1_ip1_0_split <- ip1
I0316 09:15:02.728554 11765 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0316 09:15:02.728561 11765 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0316 09:15:02.728571 11765 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_2
I0316 09:15:02.728632 11765 net.cpp:141] Setting up ip1_ip1_0_split
I0316 09:15:02.728641 11765 net.cpp:148] Top shape: 50 1000 (50000)
I0316 09:15:02.728646 11765 net.cpp:148] Top shape: 50 1000 (50000)
I0316 09:15:02.728653 11765 net.cpp:148] Top shape: 50 1000 (50000)
I0316 09:15:02.728658 11765 net.cpp:156] Memory required for data: 934118200
I0316 09:15:02.728662 11765 layer_factory.hpp:77] Creating layer loss
I0316 09:15:02.728670 11765 net.cpp:91] Creating Layer loss
I0316 09:15:02.728688 11765 net.cpp:425] loss <- ip1_ip1_0_split_0
I0316 09:15:02.728695 11765 net.cpp:425] loss <- label_data_1_split_0
I0316 09:15:02.728701 11765 net.cpp:399] loss -> loss
I0316 09:15:02.728713 11765 layer_factory.hpp:77] Creating layer loss
I0316 09:15:02.729450 11765 net.cpp:141] Setting up loss
I0316 09:15:02.729475 11765 net.cpp:148] Top shape: (1)
I0316 09:15:02.729482 11765 net.cpp:151]     with loss weight 1
I0316 09:15:02.729502 11765 net.cpp:156] Memory required for data: 934118204
I0316 09:15:02.729507 11765 layer_factory.hpp:77] Creating layer accuracy_top-1
I0316 09:15:02.729523 11765 net.cpp:91] Creating Layer accuracy_top-1
I0316 09:15:02.729532 11765 net.cpp:425] accuracy_top-1 <- ip1_ip1_0_split_1
I0316 09:15:02.729537 11765 net.cpp:425] accuracy_top-1 <- label_data_1_split_1
I0316 09:15:02.729547 11765 net.cpp:399] accuracy_top-1 -> accuracy_top-1
I0316 09:15:02.729562 11765 net.cpp:141] Setting up accuracy_top-1
I0316 09:15:02.729570 11765 net.cpp:148] Top shape: (1)
I0316 09:15:02.729575 11765 net.cpp:156] Memory required for data: 934118208
I0316 09:15:02.729580 11765 layer_factory.hpp:77] Creating layer accuracy_top-5
I0316 09:15:02.729589 11765 net.cpp:91] Creating Layer accuracy_top-5
I0316 09:15:02.729598 11765 net.cpp:425] accuracy_top-5 <- ip1_ip1_0_split_2
I0316 09:15:02.729602 11765 net.cpp:425] accuracy_top-5 <- label_data_1_split_2
I0316 09:15:02.729609 11765 net.cpp:399] accuracy_top-5 -> accuracy_top-5
I0316 09:15:02.729619 11765 net.cpp:141] Setting up accuracy_top-5
I0316 09:15:02.729626 11765 net.cpp:148] Top shape: (1)
I0316 09:15:02.729631 11765 net.cpp:156] Memory required for data: 934118212
I0316 09:15:02.729635 11765 net.cpp:219] accuracy_top-5 does not need backward computation.
I0316 09:15:02.729641 11765 net.cpp:219] accuracy_top-1 does not need backward computation.
I0316 09:15:02.729647 11765 net.cpp:217] loss needs backward computation.
I0316 09:15:02.729653 11765 net.cpp:217] ip1_ip1_0_split needs backward computation.
I0316 09:15:02.729674 11765 net.cpp:217] ip1 needs backward computation.
I0316 09:15:02.729679 11765 net.cpp:217] poolcp6 needs backward computation.
I0316 09:15:02.729684 11765 net.cpp:217] relu_cccp6 needs backward computation.
I0316 09:15:02.729689 11765 net.cpp:217] cccp6 needs backward computation.
I0316 09:15:02.729696 11765 net.cpp:217] poolcp5 needs backward computation.
I0316 09:15:02.729701 11765 net.cpp:217] relu_cccp5 needs backward computation.
I0316 09:15:02.729706 11765 net.cpp:217] cccp5 needs backward computation.
I0316 09:15:02.729710 11765 net.cpp:217] relu_cccp4 needs backward computation.
I0316 09:15:02.729714 11765 net.cpp:217] cccp4 needs backward computation.
I0316 09:15:02.729722 11765 net.cpp:217] relu4_0 needs backward computation.
I0316 09:15:02.729727 11765 net.cpp:217] scale4_0 needs backward computation.
I0316 09:15:02.729730 11765 net.cpp:217] bn4_0 needs backward computation.
I0316 09:15:02.729735 11765 net.cpp:217] conv4_0 needs backward computation.
I0316 09:15:02.729740 11765 net.cpp:217] pool4_2 needs backward computation.
I0316 09:15:02.729748 11765 net.cpp:217] relu4_2 needs backward computation.
I0316 09:15:02.729753 11765 net.cpp:217] scale4_2 needs backward computation.
I0316 09:15:02.729756 11765 net.cpp:217] bn4_2 needs backward computation.
I0316 09:15:02.729761 11765 net.cpp:217] conv4_2 needs backward computation.
I0316 09:15:02.729768 11765 net.cpp:217] relu4_1 needs backward computation.
I0316 09:15:02.729773 11765 net.cpp:217] scale4_1 needs backward computation.
I0316 09:15:02.729779 11765 net.cpp:217] bn4_1 needs backward computation.
I0316 09:15:02.729784 11765 net.cpp:217] conv4_1 needs backward computation.
I0316 09:15:02.729790 11765 net.cpp:217] relu4 needs backward computation.
I0316 09:15:02.729795 11765 net.cpp:217] scale4 needs backward computation.
I0316 09:15:02.729800 11765 net.cpp:217] bn4 needs backward computation.
I0316 09:15:02.729807 11765 net.cpp:217] pool4 needs backward computation.
I0316 09:15:02.729812 11765 net.cpp:217] conv4 needs backward computation.
I0316 09:15:02.729816 11765 net.cpp:217] relu3 needs backward computation.
I0316 09:15:02.729821 11765 net.cpp:217] scale3 needs backward computation.
I0316 09:15:02.729828 11765 net.cpp:217] bn3 needs backward computation.
I0316 09:15:02.729833 11765 net.cpp:217] conv3 needs backward computation.
I0316 09:15:02.729838 11765 net.cpp:217] relu2_2 needs backward computation.
I0316 09:15:02.729845 11765 net.cpp:217] scale2_2 needs backward computation.
I0316 09:15:02.729851 11765 net.cpp:217] bn2_2 needs backward computation.
I0316 09:15:02.729856 11765 net.cpp:217] conv2_2 needs backward computation.
I0316 09:15:02.729861 11765 net.cpp:217] pool2_1 needs backward computation.
I0316 09:15:02.729867 11765 net.cpp:217] relu2_1 needs backward computation.
I0316 09:15:02.729872 11765 net.cpp:217] scale2_1 needs backward computation.
I0316 09:15:02.729877 11765 net.cpp:217] bn2_1 needs backward computation.
I0316 09:15:02.729885 11765 net.cpp:217] conv2_1 needs backward computation.
I0316 09:15:02.729890 11765 net.cpp:217] relu2 needs backward computation.
I0316 09:15:02.729895 11765 net.cpp:217] scale2 needs backward computation.
I0316 09:15:02.729902 11765 net.cpp:217] bn2 needs backward computation.
I0316 09:15:02.729907 11765 net.cpp:217] conv2 needs backward computation.
I0316 09:15:02.729913 11765 net.cpp:217] relu1_0 needs backward computation.
I0316 09:15:02.729919 11765 net.cpp:217] scale1_0 needs backward computation.
I0316 09:15:02.729924 11765 net.cpp:217] bn1_0 needs backward computation.
I0316 09:15:02.729929 11765 net.cpp:217] conv1_0 needs backward computation.
I0316 09:15:02.729936 11765 net.cpp:217] relu1 needs backward computation.
I0316 09:15:02.729941 11765 net.cpp:217] scale1 needs backward computation.
I0316 09:15:02.729946 11765 net.cpp:217] bn1 needs backward computation.
I0316 09:15:02.729953 11765 net.cpp:217] conv1 needs backward computation.
I0316 09:15:02.729959 11765 net.cpp:219] label_data_1_split does not need backward computation.
I0316 09:15:02.729977 11765 net.cpp:219] data does not need backward computation.
I0316 09:15:02.729982 11765 net.cpp:261] This network produces output accuracy_top-1
I0316 09:15:02.729988 11765 net.cpp:261] This network produces output accuracy_top-5
I0316 09:15:02.729995 11765 net.cpp:261] This network produces output loss
I0316 09:15:02.730046 11765 net.cpp:274] Network initialization done.
I0316 09:15:02.730285 11765 solver.cpp:60] Solver scaffolding done.
I0316 09:15:02.736768 11765 parallel.cpp:392] GPUs pairs 0:1
I0316 09:15:03.009376 11765 data_layer.cpp:41] output data size: 128,3,227,227
I0316 09:15:03.331949 11765 parallel.cpp:425] Starting Optimization
I0316 09:15:03.332028 11765 solver.cpp:279] Solving ImageNet_SlimNet_300K_NoDrp
I0316 09:15:03.332034 11765 solver.cpp:280] Learning Rate Policy: multistep
I0316 09:15:03.332625 11765 solver.cpp:337] Iteration 0, Testing net (#0)
I0316 09:16:15.103739 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.00126
I0316 09:16:15.103828 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.00484
I0316 09:16:15.103847 11765 solver.cpp:404]     Test net output #2: loss = 87.226 (* 1 = 87.226 loss)
I0316 09:16:16.130134 11765 solver.cpp:228] Iteration 0, loss = 7.1751
I0316 09:16:16.130172 11765 solver.cpp:244]     Train net output #0: loss = 7.1751 (* 1 = 7.1751 loss)
I0316 09:16:16.130218 11765 sgd_solver.cpp:106] Iteration 0, lr = 0.2
I0316 09:17:27.881597 11765 solver.cpp:228] Iteration 100, loss = 6.90384
I0316 09:17:27.881989 11765 solver.cpp:244]     Train net output #0: loss = 6.90384 (* 1 = 6.90384 loss)
I0316 09:17:27.967980 11765 sgd_solver.cpp:106] Iteration 100, lr = 0.2
I0316 09:18:40.030270 11765 solver.cpp:228] Iteration 200, loss = 6.91089
I0316 09:18:40.030403 11765 solver.cpp:244]     Train net output #0: loss = 6.91089 (* 1 = 6.91089 loss)
I0316 09:18:40.089093 11765 sgd_solver.cpp:106] Iteration 200, lr = 0.2
I0316 09:19:52.184597 11765 solver.cpp:228] Iteration 300, loss = 6.89828
I0316 09:19:52.184756 11765 solver.cpp:244]     Train net output #0: loss = 6.89828 (* 1 = 6.89828 loss)
I0316 09:19:52.245213 11765 sgd_solver.cpp:106] Iteration 300, lr = 0.2
I0316 09:21:03.785336 11765 solver.cpp:228] Iteration 400, loss = 6.88066
I0316 09:21:03.785495 11765 solver.cpp:244]     Train net output #0: loss = 6.88066 (* 1 = 6.88066 loss)
I0316 09:21:03.844408 11765 sgd_solver.cpp:106] Iteration 400, lr = 0.2
I0316 09:22:16.108279 11765 solver.cpp:228] Iteration 500, loss = 6.88918
I0316 09:22:16.108439 11765 solver.cpp:244]     Train net output #0: loss = 6.88918 (* 1 = 6.88918 loss)
I0316 09:22:16.167605 11765 sgd_solver.cpp:106] Iteration 500, lr = 0.2
I0316 09:23:29.010798 11765 solver.cpp:228] Iteration 600, loss = 6.8793
I0316 09:23:29.010957 11765 solver.cpp:244]     Train net output #0: loss = 6.8793 (* 1 = 6.8793 loss)
I0316 09:23:29.076750 11765 sgd_solver.cpp:106] Iteration 600, lr = 0.2
I0316 09:24:40.527653 11765 solver.cpp:228] Iteration 700, loss = 6.86988
I0316 09:24:40.527789 11765 solver.cpp:244]     Train net output #0: loss = 6.86988 (* 1 = 6.86988 loss)
I0316 09:24:40.588122 11765 sgd_solver.cpp:106] Iteration 700, lr = 0.2
I0316 09:25:54.049391 11765 solver.cpp:228] Iteration 800, loss = 6.90065
I0316 09:25:54.049542 11765 solver.cpp:244]     Train net output #0: loss = 6.90065 (* 1 = 6.90065 loss)
I0316 09:25:54.108566 11765 sgd_solver.cpp:106] Iteration 800, lr = 0.2
I0316 09:27:05.729838 11765 solver.cpp:228] Iteration 900, loss = 6.78032
I0316 09:27:05.729959 11765 solver.cpp:244]     Train net output #0: loss = 6.78032 (* 1 = 6.78032 loss)
I0316 09:27:05.788631 11765 sgd_solver.cpp:106] Iteration 900, lr = 0.2
I0316 09:28:18.223562 11765 solver.cpp:337] Iteration 1000, Testing net (#0)
I0316 09:29:30.730706 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.00298
I0316 09:29:30.730868 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.0144601
I0316 09:29:30.730897 11765 solver.cpp:404]     Test net output #2: loss = 6.84212 (* 1 = 6.84212 loss)
I0316 09:29:31.396770 11765 solver.cpp:228] Iteration 1000, loss = 6.78784
I0316 09:29:31.396806 11765 solver.cpp:244]     Train net output #0: loss = 6.78784 (* 1 = 6.78784 loss)
I0316 09:29:31.473258 11765 sgd_solver.cpp:106] Iteration 1000, lr = 0.2
I0316 09:30:45.118165 11765 solver.cpp:228] Iteration 1100, loss = 6.78068
I0316 09:30:45.118355 11765 solver.cpp:244]     Train net output #0: loss = 6.78068 (* 1 = 6.78068 loss)
I0316 09:30:45.184710 11765 sgd_solver.cpp:106] Iteration 1100, lr = 0.2
I0316 09:31:57.917438 11765 solver.cpp:228] Iteration 1200, loss = 6.84458
I0316 09:31:57.917726 11765 solver.cpp:244]     Train net output #0: loss = 6.84458 (* 1 = 6.84458 loss)
I0316 09:31:57.978628 11765 sgd_solver.cpp:106] Iteration 1200, lr = 0.2
I0316 09:33:10.103751 11765 solver.cpp:228] Iteration 1300, loss = 6.73562
I0316 09:33:10.103888 11765 solver.cpp:244]     Train net output #0: loss = 6.73562 (* 1 = 6.73562 loss)
I0316 09:33:10.166664 11765 sgd_solver.cpp:106] Iteration 1300, lr = 0.2
I0316 09:34:24.362458 11765 solver.cpp:228] Iteration 1400, loss = 6.81245
I0316 09:34:24.362627 11765 solver.cpp:244]     Train net output #0: loss = 6.81245 (* 1 = 6.81245 loss)
I0316 09:34:24.421802 11765 sgd_solver.cpp:106] Iteration 1400, lr = 0.2
I0316 09:35:38.790246 11765 solver.cpp:228] Iteration 1500, loss = 6.70915
I0316 09:35:38.791049 11765 solver.cpp:244]     Train net output #0: loss = 6.70915 (* 1 = 6.70915 loss)
I0316 09:35:38.807147 11765 sgd_solver.cpp:106] Iteration 1500, lr = 0.2
I0316 09:36:52.619689 11765 solver.cpp:228] Iteration 1600, loss = 6.72152
I0316 09:36:52.619825 11765 solver.cpp:244]     Train net output #0: loss = 6.72152 (* 1 = 6.72152 loss)
I0316 09:36:52.678499 11765 sgd_solver.cpp:106] Iteration 1600, lr = 0.2
I0316 09:38:04.002538 11765 solver.cpp:228] Iteration 1700, loss = 6.60292
I0316 09:38:04.002686 11765 solver.cpp:244]     Train net output #0: loss = 6.60292 (* 1 = 6.60292 loss)
I0316 09:38:04.061302 11765 sgd_solver.cpp:106] Iteration 1700, lr = 0.2
I0316 09:39:15.637670 11765 solver.cpp:228] Iteration 1800, loss = 6.7381
I0316 09:39:15.637795 11765 solver.cpp:244]     Train net output #0: loss = 6.7381 (* 1 = 6.7381 loss)
I0316 09:39:15.696563 11765 sgd_solver.cpp:106] Iteration 1800, lr = 0.2
I0316 09:40:28.108886 11765 solver.cpp:228] Iteration 1900, loss = 6.83834
I0316 09:40:28.109020 11765 solver.cpp:244]     Train net output #0: loss = 6.83834 (* 1 = 6.83834 loss)
I0316 09:40:28.168445 11765 sgd_solver.cpp:106] Iteration 1900, lr = 0.2
I0316 09:41:40.067934 11765 solver.cpp:337] Iteration 2000, Testing net (#0)
I0316 09:42:52.394441 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.00616
I0316 09:42:52.394577 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.0238002
I0316 09:42:52.394603 11765 solver.cpp:404]     Test net output #2: loss = 6.68032 (* 1 = 6.68032 loss)
I0316 09:42:53.032632 11765 solver.cpp:228] Iteration 2000, loss = 6.60474
I0316 09:42:53.032660 11765 solver.cpp:244]     Train net output #0: loss = 6.60474 (* 1 = 6.60474 loss)
I0316 09:42:53.105933 11765 sgd_solver.cpp:106] Iteration 2000, lr = 0.2
I0316 09:44:04.848378 11765 solver.cpp:228] Iteration 2100, loss = 6.85216
I0316 09:44:04.848523 11765 solver.cpp:244]     Train net output #0: loss = 6.85216 (* 1 = 6.85216 loss)
I0316 09:44:04.920307 11765 sgd_solver.cpp:106] Iteration 2100, lr = 0.2
I0316 09:45:18.467890 11765 solver.cpp:228] Iteration 2200, loss = 6.59971
I0316 09:45:18.468036 11765 solver.cpp:244]     Train net output #0: loss = 6.59971 (* 1 = 6.59971 loss)
I0316 09:45:18.528806 11765 sgd_solver.cpp:106] Iteration 2200, lr = 0.2
I0316 09:46:30.103618 11765 solver.cpp:228] Iteration 2300, loss = 6.55106
I0316 09:46:30.103783 11765 solver.cpp:244]     Train net output #0: loss = 6.55106 (* 1 = 6.55106 loss)
I0316 09:46:30.162319 11765 sgd_solver.cpp:106] Iteration 2300, lr = 0.2
I0316 09:47:41.436931 11765 solver.cpp:228] Iteration 2400, loss = 6.55337
I0316 09:47:41.437108 11765 solver.cpp:244]     Train net output #0: loss = 6.55337 (* 1 = 6.55337 loss)
I0316 09:47:41.496284 11765 sgd_solver.cpp:106] Iteration 2400, lr = 0.2
I0316 09:48:52.973959 11765 solver.cpp:228] Iteration 2500, loss = 6.51726
I0316 09:48:52.974270 11765 solver.cpp:244]     Train net output #0: loss = 6.51726 (* 1 = 6.51726 loss)
I0316 09:48:53.033458 11765 sgd_solver.cpp:106] Iteration 2500, lr = 0.2
I0316 09:50:05.280081 11765 solver.cpp:228] Iteration 2600, loss = 6.51841
I0316 09:50:05.280221 11765 solver.cpp:244]     Train net output #0: loss = 6.51841 (* 1 = 6.51841 loss)
I0316 09:50:05.338876 11765 sgd_solver.cpp:106] Iteration 2600, lr = 0.2
I0316 09:51:17.786440 11765 solver.cpp:228] Iteration 2700, loss = 6.41041
I0316 09:51:17.786571 11765 solver.cpp:244]     Train net output #0: loss = 6.41041 (* 1 = 6.41041 loss)
I0316 09:51:17.845569 11765 sgd_solver.cpp:106] Iteration 2700, lr = 0.2
I0316 09:52:30.420840 11765 solver.cpp:228] Iteration 2800, loss = 6.22748
I0316 09:52:30.420969 11765 solver.cpp:244]     Train net output #0: loss = 6.22748 (* 1 = 6.22748 loss)
I0316 09:52:30.483930 11765 sgd_solver.cpp:106] Iteration 2800, lr = 0.2
I0316 09:53:45.317090 11765 solver.cpp:228] Iteration 2900, loss = 6.27067
I0316 09:53:45.317222 11765 solver.cpp:244]     Train net output #0: loss = 6.27067 (* 1 = 6.27067 loss)
I0316 09:53:45.375213 11765 sgd_solver.cpp:106] Iteration 2900, lr = 0.2
I0316 09:54:59.218407 11765 solver.cpp:337] Iteration 3000, Testing net (#0)
I0316 09:56:11.450325 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.01122
I0316 09:56:11.450424 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.0420403
I0316 09:56:11.450438 11765 solver.cpp:404]     Test net output #2: loss = 6.38371 (* 1 = 6.38371 loss)
I0316 09:56:12.089097 11765 solver.cpp:228] Iteration 3000, loss = 6.38999
I0316 09:56:12.089134 11765 solver.cpp:244]     Train net output #0: loss = 6.38999 (* 1 = 6.38999 loss)
I0316 09:56:12.166203 11765 sgd_solver.cpp:106] Iteration 3000, lr = 0.2
I0316 09:57:25.642560 11765 solver.cpp:228] Iteration 3100, loss = 6.22377
I0316 09:57:25.642715 11765 solver.cpp:244]     Train net output #0: loss = 6.22377 (* 1 = 6.22377 loss)
I0316 09:57:25.735929 11765 sgd_solver.cpp:106] Iteration 3100, lr = 0.2
I0316 09:58:40.766149 11765 solver.cpp:228] Iteration 3200, loss = 6.18109
I0316 09:58:40.766314 11765 solver.cpp:244]     Train net output #0: loss = 6.18109 (* 1 = 6.18109 loss)
I0316 09:58:40.824793 11765 sgd_solver.cpp:106] Iteration 3200, lr = 0.2
I0316 09:59:52.987035 11765 solver.cpp:228] Iteration 3300, loss = 6.17059
I0316 09:59:52.987211 11765 solver.cpp:244]     Train net output #0: loss = 6.17059 (* 1 = 6.17059 loss)
I0316 09:59:53.071554 11765 sgd_solver.cpp:106] Iteration 3300, lr = 0.2
I0316 10:01:09.448153 11765 solver.cpp:228] Iteration 3400, loss = 6.13704
I0316 10:01:09.448299 11765 solver.cpp:244]     Train net output #0: loss = 6.13704 (* 1 = 6.13704 loss)
I0316 10:01:09.504922 11765 sgd_solver.cpp:106] Iteration 3400, lr = 0.2
I0316 10:02:25.803237 11765 solver.cpp:228] Iteration 3500, loss = 5.95616
I0316 10:02:25.803380 11765 solver.cpp:244]     Train net output #0: loss = 5.95616 (* 1 = 5.95616 loss)
I0316 10:02:25.881487 11765 sgd_solver.cpp:106] Iteration 3500, lr = 0.2
I0316 10:03:45.655377 11765 solver.cpp:228] Iteration 3600, loss = 6.00941
I0316 10:03:45.655490 11765 solver.cpp:244]     Train net output #0: loss = 6.00941 (* 1 = 6.00941 loss)
I0316 10:03:45.714432 11765 sgd_solver.cpp:106] Iteration 3600, lr = 0.2
I0316 10:05:03.008404 11765 solver.cpp:228] Iteration 3700, loss = 5.88069
I0316 10:05:03.008580 11765 solver.cpp:244]     Train net output #0: loss = 5.88069 (* 1 = 5.88069 loss)
I0316 10:05:03.098546 11765 sgd_solver.cpp:106] Iteration 3700, lr = 0.2
I0316 10:06:19.971184 11765 solver.cpp:228] Iteration 3800, loss = 5.73222
I0316 10:06:19.971319 11765 solver.cpp:244]     Train net output #0: loss = 5.73222 (* 1 = 5.73222 loss)
I0316 10:06:20.035478 11765 sgd_solver.cpp:106] Iteration 3800, lr = 0.2
I0316 10:07:36.374433 11765 solver.cpp:228] Iteration 3900, loss = 5.98681
I0316 10:07:36.374603 11765 solver.cpp:244]     Train net output #0: loss = 5.98681 (* 1 = 5.98681 loss)
I0316 10:07:36.437062 11765 sgd_solver.cpp:106] Iteration 3900, lr = 0.2
I0316 10:08:51.200209 11765 solver.cpp:337] Iteration 4000, Testing net (#0)
I0316 10:09:54.898247 11765 blocking_queue.cpp:50] Data layer prefetch queue empty
I0316 10:10:04.354640 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0215801
I0316 10:10:04.354688 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.0812202
I0316 10:10:04.354706 11765 solver.cpp:404]     Test net output #2: loss = 5.93386 (* 1 = 5.93386 loss)
I0316 10:10:04.993463 11765 solver.cpp:228] Iteration 4000, loss = 5.91865
I0316 10:10:04.993512 11765 solver.cpp:244]     Train net output #0: loss = 5.91865 (* 1 = 5.91865 loss)
I0316 10:10:05.077509 11765 sgd_solver.cpp:106] Iteration 4000, lr = 0.2
I0316 10:11:21.582939 11765 solver.cpp:228] Iteration 4100, loss = 5.63517
I0316 10:11:21.583142 11765 solver.cpp:244]     Train net output #0: loss = 5.63517 (* 1 = 5.63517 loss)
I0316 10:11:21.715083 11765 sgd_solver.cpp:106] Iteration 4100, lr = 0.2
I0316 10:12:38.058291 11765 solver.cpp:228] Iteration 4200, loss = 5.63759
I0316 10:12:38.058646 11765 solver.cpp:244]     Train net output #0: loss = 5.63759 (* 1 = 5.63759 loss)
I0316 10:12:38.065599 11765 sgd_solver.cpp:106] Iteration 4200, lr = 0.2
I0316 10:13:58.961297 11765 solver.cpp:228] Iteration 4300, loss = 5.67418
I0316 10:13:58.961434 11765 solver.cpp:244]     Train net output #0: loss = 5.67418 (* 1 = 5.67418 loss)
I0316 10:13:59.035038 11765 sgd_solver.cpp:106] Iteration 4300, lr = 0.2
I0316 10:15:14.872860 11765 solver.cpp:228] Iteration 4400, loss = 5.73727
I0316 10:15:14.873020 11765 solver.cpp:244]     Train net output #0: loss = 5.73727 (* 1 = 5.73727 loss)
I0316 10:15:14.955219 11765 sgd_solver.cpp:106] Iteration 4400, lr = 0.2
I0316 10:16:31.956496 11765 solver.cpp:228] Iteration 4500, loss = 5.64625
I0316 10:16:31.956634 11765 solver.cpp:244]     Train net output #0: loss = 5.64625 (* 1 = 5.64625 loss)
I0316 10:16:32.023967 11765 sgd_solver.cpp:106] Iteration 4500, lr = 0.2
I0316 10:17:51.925670 11765 solver.cpp:228] Iteration 4600, loss = 5.42695
I0316 10:17:51.925801 11765 solver.cpp:244]     Train net output #0: loss = 5.42695 (* 1 = 5.42695 loss)
I0316 10:17:51.984405 11765 sgd_solver.cpp:106] Iteration 4600, lr = 0.2
I0316 10:19:11.840293 11765 solver.cpp:228] Iteration 4700, loss = 5.75989
I0316 10:19:11.840425 11765 solver.cpp:244]     Train net output #0: loss = 5.75989 (* 1 = 5.75989 loss)
I0316 10:19:11.905093 11765 sgd_solver.cpp:106] Iteration 4700, lr = 0.2
I0316 10:20:27.963806 11765 solver.cpp:228] Iteration 4800, loss = 5.43648
I0316 10:20:27.963956 11765 solver.cpp:244]     Train net output #0: loss = 5.43648 (* 1 = 5.43648 loss)
I0316 10:20:28.024706 11765 sgd_solver.cpp:106] Iteration 4800, lr = 0.2
I0316 10:21:44.889786 11765 solver.cpp:228] Iteration 4900, loss = 5.51083
I0316 10:21:44.889993 11765 solver.cpp:244]     Train net output #0: loss = 5.51083 (* 1 = 5.51083 loss)
I0316 10:21:44.984141 11765 sgd_solver.cpp:106] Iteration 4900, lr = 0.2
I0316 10:23:04.316790 11765 solver.cpp:337] Iteration 5000, Testing net (#0)
I0316 10:24:17.372207 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0458604
I0316 10:24:17.372355 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.14492
I0316 10:24:17.372370 11765 solver.cpp:404]     Test net output #2: loss = 5.43601 (* 1 = 5.43601 loss)
I0316 10:24:18.009769 11765 solver.cpp:228] Iteration 5000, loss = 5.50469
I0316 10:24:18.009819 11765 solver.cpp:244]     Train net output #0: loss = 5.50469 (* 1 = 5.50469 loss)
I0316 10:24:18.078539 11765 sgd_solver.cpp:106] Iteration 5000, lr = 0.2
I0316 10:25:30.939069 11765 solver.cpp:228] Iteration 5100, loss = 5.56468
I0316 10:25:30.939195 11765 solver.cpp:244]     Train net output #0: loss = 5.56468 (* 1 = 5.56468 loss)
I0316 10:25:31.011929 11765 sgd_solver.cpp:106] Iteration 5100, lr = 0.2
I0316 10:26:44.854713 11765 solver.cpp:228] Iteration 5200, loss = 5.37511
I0316 10:26:44.854918 11765 solver.cpp:244]     Train net output #0: loss = 5.37511 (* 1 = 5.37511 loss)
I0316 10:26:44.921746 11765 sgd_solver.cpp:106] Iteration 5200, lr = 0.2
I0316 10:27:58.043495 11765 solver.cpp:228] Iteration 5300, loss = 5.25807
I0316 10:27:58.043644 11765 solver.cpp:244]     Train net output #0: loss = 5.25807 (* 1 = 5.25807 loss)
I0316 10:27:58.100337 11765 sgd_solver.cpp:106] Iteration 5300, lr = 0.2
I0316 10:29:13.317555 11765 solver.cpp:228] Iteration 5400, loss = 5.2134
I0316 10:29:13.317682 11765 solver.cpp:244]     Train net output #0: loss = 5.2134 (* 1 = 5.2134 loss)
I0316 10:29:13.373247 11765 sgd_solver.cpp:106] Iteration 5400, lr = 0.2
I0316 10:30:32.261991 11765 solver.cpp:228] Iteration 5500, loss = 5.25657
I0316 10:30:32.262115 11765 solver.cpp:244]     Train net output #0: loss = 5.25657 (* 1 = 5.25657 loss)
I0316 10:30:32.342361 11765 sgd_solver.cpp:106] Iteration 5500, lr = 0.2
I0316 10:31:49.796205 11765 solver.cpp:228] Iteration 5600, loss = 5.27109
I0316 10:31:49.796353 11765 solver.cpp:244]     Train net output #0: loss = 5.27109 (* 1 = 5.27109 loss)
I0316 10:31:49.860801 11765 sgd_solver.cpp:106] Iteration 5600, lr = 0.2
I0316 10:33:06.810400 11765 solver.cpp:228] Iteration 5700, loss = 5.23086
I0316 10:33:06.810513 11765 solver.cpp:244]     Train net output #0: loss = 5.23086 (* 1 = 5.23086 loss)
I0316 10:33:06.874727 11765 sgd_solver.cpp:106] Iteration 5700, lr = 0.2
I0316 10:34:30.061753 11765 solver.cpp:228] Iteration 5800, loss = 5.18186
I0316 10:34:30.061962 11765 solver.cpp:244]     Train net output #0: loss = 5.18186 (* 1 = 5.18186 loss)
I0316 10:34:30.196764 11765 sgd_solver.cpp:106] Iteration 5800, lr = 0.2
I0316 10:35:56.689241 11765 solver.cpp:228] Iteration 5900, loss = 5.23375
I0316 10:35:56.689642 11765 solver.cpp:244]     Train net output #0: loss = 5.23375 (* 1 = 5.23375 loss)
I0316 10:35:56.719729 11765 sgd_solver.cpp:106] Iteration 5900, lr = 0.2
I0316 10:37:16.720528 11765 solver.cpp:337] Iteration 6000, Testing net (#0)
I0316 10:38:32.946218 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0563804
I0316 10:38:32.946372 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.17158
I0316 10:38:32.946388 11765 solver.cpp:404]     Test net output #2: loss = 5.26566 (* 1 = 5.26566 loss)
I0316 10:38:33.849658 11765 solver.cpp:228] Iteration 6000, loss = 5.04453
I0316 10:38:33.849745 11765 solver.cpp:244]     Train net output #0: loss = 5.04453 (* 1 = 5.04453 loss)
I0316 10:38:33.998776 11765 sgd_solver.cpp:106] Iteration 6000, lr = 0.2
I0316 10:39:52.430436 11765 solver.cpp:228] Iteration 6100, loss = 5.26479
I0316 10:39:52.430619 11765 solver.cpp:244]     Train net output #0: loss = 5.26479 (* 1 = 5.26479 loss)
I0316 10:39:52.545501 11765 sgd_solver.cpp:106] Iteration 6100, lr = 0.2
I0316 10:41:11.967342 11765 solver.cpp:228] Iteration 6200, loss = 5.0574
I0316 10:41:11.967499 11765 solver.cpp:244]     Train net output #0: loss = 5.0574 (* 1 = 5.0574 loss)
I0316 10:41:12.016983 11765 sgd_solver.cpp:106] Iteration 6200, lr = 0.2
I0316 10:42:39.682730 11765 solver.cpp:228] Iteration 6300, loss = 5.24088
I0316 10:42:39.682867 11765 solver.cpp:244]     Train net output #0: loss = 5.24088 (* 1 = 5.24088 loss)
I0316 10:42:39.819756 11765 sgd_solver.cpp:106] Iteration 6300, lr = 0.2
I0316 10:43:59.855710 11765 solver.cpp:228] Iteration 6400, loss = 5.22096
I0316 10:43:59.855824 11765 solver.cpp:244]     Train net output #0: loss = 5.22096 (* 1 = 5.22096 loss)
I0316 10:43:59.914456 11765 sgd_solver.cpp:106] Iteration 6400, lr = 0.2
I0316 10:45:17.301393 11765 solver.cpp:228] Iteration 6500, loss = 4.90439
I0316 10:45:17.301575 11765 solver.cpp:244]     Train net output #0: loss = 4.90439 (* 1 = 4.90439 loss)
I0316 10:45:17.330943 11765 sgd_solver.cpp:106] Iteration 6500, lr = 0.2
I0316 10:46:31.984252 11765 solver.cpp:228] Iteration 6600, loss = 5.19797
I0316 10:46:31.984380 11765 solver.cpp:244]     Train net output #0: loss = 5.19797 (* 1 = 5.19797 loss)
I0316 10:46:32.043018 11765 sgd_solver.cpp:106] Iteration 6600, lr = 0.2
I0316 10:47:50.447789 11765 solver.cpp:228] Iteration 6700, loss = 5.20437
I0316 10:47:50.447983 11765 solver.cpp:244]     Train net output #0: loss = 5.20437 (* 1 = 5.20437 loss)
I0316 10:47:50.542840 11765 sgd_solver.cpp:106] Iteration 6700, lr = 0.2
I0316 10:49:08.109427 11765 solver.cpp:228] Iteration 6800, loss = 5.00599
I0316 10:49:08.109861 11765 solver.cpp:244]     Train net output #0: loss = 5.00599 (* 1 = 5.00599 loss)
I0316 10:49:08.192209 11765 sgd_solver.cpp:106] Iteration 6800, lr = 0.2
I0316 10:50:30.110824 11765 solver.cpp:228] Iteration 6900, loss = 4.78185
I0316 10:50:30.110945 11765 solver.cpp:244]     Train net output #0: loss = 4.78185 (* 1 = 4.78185 loss)
I0316 10:50:30.182422 11765 sgd_solver.cpp:106] Iteration 6900, lr = 0.2
I0316 10:51:49.624550 11765 solver.cpp:337] Iteration 7000, Testing net (#0)
I0316 10:53:02.438145 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0745803
I0316 10:53:02.438297 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.2112
I0316 10:53:02.438318 11765 solver.cpp:404]     Test net output #2: loss = 5.05553 (* 1 = 5.05553 loss)
I0316 10:53:03.079558 11765 solver.cpp:228] Iteration 7000, loss = 4.76258
I0316 10:53:03.079591 11765 solver.cpp:244]     Train net output #0: loss = 4.76258 (* 1 = 4.76258 loss)
I0316 10:53:03.139730 11765 sgd_solver.cpp:106] Iteration 7000, lr = 0.2
I0316 10:54:19.926971 11765 solver.cpp:228] Iteration 7100, loss = 4.96102
I0316 10:54:19.927150 11765 solver.cpp:244]     Train net output #0: loss = 4.96102 (* 1 = 4.96102 loss)
I0316 10:54:20.011945 11765 sgd_solver.cpp:106] Iteration 7100, lr = 0.2
I0316 10:55:36.717257 11765 solver.cpp:228] Iteration 7200, loss = 5.15204
I0316 10:55:36.717433 11765 solver.cpp:244]     Train net output #0: loss = 5.15204 (* 1 = 5.15204 loss)
I0316 10:55:36.785831 11765 sgd_solver.cpp:106] Iteration 7200, lr = 0.2
I0316 10:56:52.939095 11765 solver.cpp:228] Iteration 7300, loss = 4.97989
I0316 10:56:52.939247 11765 solver.cpp:244]     Train net output #0: loss = 4.97989 (* 1 = 4.97989 loss)
I0316 10:56:53.003751 11765 sgd_solver.cpp:106] Iteration 7300, lr = 0.2
I0316 10:58:09.746575 11765 solver.cpp:228] Iteration 7400, loss = 4.93962
I0316 10:58:09.746707 11765 solver.cpp:244]     Train net output #0: loss = 4.93962 (* 1 = 4.93962 loss)
I0316 10:58:09.805912 11765 sgd_solver.cpp:106] Iteration 7400, lr = 0.2
I0316 10:59:26.974834 11765 solver.cpp:228] Iteration 7500, loss = 4.92827
I0316 10:59:26.974973 11765 solver.cpp:244]     Train net output #0: loss = 4.92827 (* 1 = 4.92827 loss)
I0316 10:59:27.032613 11765 sgd_solver.cpp:106] Iteration 7500, lr = 0.2
I0316 11:00:40.630429 11765 solver.cpp:228] Iteration 7600, loss = 4.96484
I0316 11:00:40.630591 11765 solver.cpp:244]     Train net output #0: loss = 4.96484 (* 1 = 4.96484 loss)
I0316 11:00:40.683029 11765 sgd_solver.cpp:106] Iteration 7600, lr = 0.2
I0316 11:01:56.598922 11765 solver.cpp:228] Iteration 7700, loss = 4.71145
I0316 11:01:56.599131 11765 solver.cpp:244]     Train net output #0: loss = 4.71145 (* 1 = 4.71145 loss)
I0316 11:01:56.702211 11765 sgd_solver.cpp:106] Iteration 7700, lr = 0.2
I0316 11:03:11.579010 11765 solver.cpp:228] Iteration 7800, loss = 4.69161
I0316 11:03:11.579710 11765 solver.cpp:244]     Train net output #0: loss = 4.69161 (* 1 = 4.69161 loss)
I0316 11:03:11.627450 11765 sgd_solver.cpp:106] Iteration 7800, lr = 0.2
I0316 11:04:25.556037 11765 solver.cpp:228] Iteration 7900, loss = 4.40276
I0316 11:04:25.556180 11765 solver.cpp:244]     Train net output #0: loss = 4.40276 (* 1 = 4.40276 loss)
I0316 11:04:25.609738 11765 sgd_solver.cpp:106] Iteration 7900, lr = 0.2
I0316 11:05:39.927533 11765 solver.cpp:337] Iteration 8000, Testing net (#0)
I0316 11:06:52.064466 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0724603
I0316 11:06:52.064644 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.20436
I0316 11:06:52.064680 11765 solver.cpp:404]     Test net output #2: loss = 5.17765 (* 1 = 5.17765 loss)
I0316 11:06:52.701483 11765 solver.cpp:228] Iteration 8000, loss = 5.05485
I0316 11:06:52.701515 11765 solver.cpp:244]     Train net output #0: loss = 5.05485 (* 1 = 5.05485 loss)
I0316 11:06:52.771674 11765 sgd_solver.cpp:106] Iteration 8000, lr = 0.2
I0316 11:08:06.137405 11765 solver.cpp:228] Iteration 8100, loss = 4.35306
I0316 11:08:06.137701 11765 solver.cpp:244]     Train net output #0: loss = 4.35306 (* 1 = 4.35306 loss)
I0316 11:08:06.232940 11765 sgd_solver.cpp:106] Iteration 8100, lr = 0.2
I0316 11:09:20.631903 11765 solver.cpp:228] Iteration 8200, loss = 4.72914
I0316 11:09:20.632047 11765 solver.cpp:244]     Train net output #0: loss = 4.72914 (* 1 = 4.72914 loss)
I0316 11:09:20.698707 11765 sgd_solver.cpp:106] Iteration 8200, lr = 0.2
I0316 11:10:36.751193 11765 solver.cpp:228] Iteration 8300, loss = 4.61841
I0316 11:10:36.751338 11765 solver.cpp:244]     Train net output #0: loss = 4.61841 (* 1 = 4.61841 loss)
I0316 11:10:36.809972 11765 sgd_solver.cpp:106] Iteration 8300, lr = 0.2
I0316 11:11:48.867187 11765 solver.cpp:228] Iteration 8400, loss = 4.6428
I0316 11:11:48.867324 11765 solver.cpp:244]     Train net output #0: loss = 4.6428 (* 1 = 4.6428 loss)
I0316 11:11:48.922592 11765 sgd_solver.cpp:106] Iteration 8400, lr = 0.2
I0316 11:13:03.606222 11765 solver.cpp:228] Iteration 8500, loss = 4.92657
I0316 11:13:03.606365 11765 solver.cpp:244]     Train net output #0: loss = 4.92657 (* 1 = 4.92657 loss)
I0316 11:13:03.665915 11765 sgd_solver.cpp:106] Iteration 8500, lr = 0.2
I0316 11:14:17.087056 11765 solver.cpp:228] Iteration 8600, loss = 4.66333
I0316 11:14:17.087191 11765 solver.cpp:244]     Train net output #0: loss = 4.66333 (* 1 = 4.66333 loss)
I0316 11:14:17.146842 11765 sgd_solver.cpp:106] Iteration 8600, lr = 0.2
I0316 11:15:33.572728 11765 solver.cpp:228] Iteration 8700, loss = 4.51062
I0316 11:15:33.572846 11765 solver.cpp:244]     Train net output #0: loss = 4.51062 (* 1 = 4.51062 loss)
I0316 11:15:33.632072 11765 sgd_solver.cpp:106] Iteration 8700, lr = 0.2
I0316 11:16:51.489050 11765 solver.cpp:228] Iteration 8800, loss = 4.68254
I0316 11:16:51.489748 11765 solver.cpp:244]     Train net output #0: loss = 4.68254 (* 1 = 4.68254 loss)
I0316 11:16:51.493544 11765 sgd_solver.cpp:106] Iteration 8800, lr = 0.2
I0316 11:18:05.659250 11765 solver.cpp:228] Iteration 8900, loss = 4.61731
I0316 11:18:05.659402 11765 solver.cpp:244]     Train net output #0: loss = 4.61731 (* 1 = 4.61731 loss)
I0316 11:18:05.718121 11765 sgd_solver.cpp:106] Iteration 8900, lr = 0.2
I0316 11:19:19.124703 11765 solver.cpp:337] Iteration 9000, Testing net (#0)
I0316 11:20:31.712740 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.0977401
I0316 11:20:31.712894 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.26092
I0316 11:20:31.712916 11765 solver.cpp:404]     Test net output #2: loss = 4.83587 (* 1 = 4.83587 loss)
I0316 11:20:32.351893 11765 solver.cpp:228] Iteration 9000, loss = 4.64643
I0316 11:20:32.351928 11765 solver.cpp:244]     Train net output #0: loss = 4.64643 (* 1 = 4.64643 loss)
I0316 11:20:32.420958 11765 sgd_solver.cpp:106] Iteration 9000, lr = 0.2
I0316 11:21:46.929986 11765 solver.cpp:228] Iteration 9100, loss = 4.56437
I0316 11:21:46.930135 11765 solver.cpp:244]     Train net output #0: loss = 4.56437 (* 1 = 4.56437 loss)
I0316 11:21:47.025950 11765 sgd_solver.cpp:106] Iteration 9100, lr = 0.2
I0316 11:23:02.362221 11765 solver.cpp:228] Iteration 9200, loss = 4.87103
I0316 11:23:02.362362 11765 solver.cpp:244]     Train net output #0: loss = 4.87103 (* 1 = 4.87103 loss)
I0316 11:23:02.422852 11765 sgd_solver.cpp:106] Iteration 9200, lr = 0.2
I0316 11:24:18.328426 11765 solver.cpp:228] Iteration 9300, loss = 4.60422
I0316 11:24:18.329339 11765 solver.cpp:244]     Train net output #0: loss = 4.60422 (* 1 = 4.60422 loss)
I0316 11:24:18.375762 11765 sgd_solver.cpp:106] Iteration 9300, lr = 0.2
I0316 11:25:42.027570 11765 solver.cpp:228] Iteration 9400, loss = 4.55647
I0316 11:25:42.027729 11765 solver.cpp:244]     Train net output #0: loss = 4.55647 (* 1 = 4.55647 loss)
I0316 11:25:42.050289 11765 sgd_solver.cpp:106] Iteration 9400, lr = 0.2
I0316 11:26:56.104904 11765 solver.cpp:228] Iteration 9500, loss = 4.59108
I0316 11:26:56.105481 11765 solver.cpp:244]     Train net output #0: loss = 4.59108 (* 1 = 4.59108 loss)
I0316 11:26:56.158411 11765 sgd_solver.cpp:106] Iteration 9500, lr = 0.2
I0316 11:28:13.065009 11765 solver.cpp:228] Iteration 9600, loss = 4.55277
I0316 11:28:13.065871 11765 solver.cpp:244]     Train net output #0: loss = 4.55277 (* 1 = 4.55277 loss)
I0316 11:28:13.118180 11765 sgd_solver.cpp:106] Iteration 9600, lr = 0.2
I0316 11:29:28.949800 11765 solver.cpp:228] Iteration 9700, loss = 4.32676
I0316 11:29:28.949977 11765 solver.cpp:244]     Train net output #0: loss = 4.32676 (* 1 = 4.32676 loss)
I0316 11:29:29.040707 11765 sgd_solver.cpp:106] Iteration 9700, lr = 0.2
I0316 11:30:47.176086 11765 solver.cpp:228] Iteration 9800, loss = 4.28327
I0316 11:30:47.176226 11765 solver.cpp:244]     Train net output #0: loss = 4.28327 (* 1 = 4.28327 loss)
I0316 11:30:47.235600 11765 sgd_solver.cpp:106] Iteration 9800, lr = 0.2
I0316 11:32:01.574524 11765 solver.cpp:228] Iteration 9900, loss = 4.20509
I0316 11:32:01.574661 11765 solver.cpp:244]     Train net output #0: loss = 4.20509 (* 1 = 4.20509 loss)
I0316 11:32:01.636601 11765 sgd_solver.cpp:106] Iteration 9900, lr = 0.2
I0316 11:33:15.717842 11765 solver.cpp:337] Iteration 10000, Testing net (#0)
I0316 11:34:28.880012 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.10868
I0316 11:34:28.880172 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.2729
I0316 11:34:28.880203 11765 solver.cpp:404]     Test net output #2: loss = 4.78455 (* 1 = 4.78455 loss)
I0316 11:34:29.521806 11765 solver.cpp:228] Iteration 10000, loss = 4.6606
I0316 11:34:29.521842 11765 solver.cpp:244]     Train net output #0: loss = 4.6606 (* 1 = 4.6606 loss)
I0316 11:34:29.585474 11765 sgd_solver.cpp:106] Iteration 10000, lr = 0.2
I0316 11:35:44.384582 11765 solver.cpp:228] Iteration 10100, loss = 4.5824
I0316 11:35:44.384763 11765 solver.cpp:244]     Train net output #0: loss = 4.5824 (* 1 = 4.5824 loss)
I0316 11:35:44.481642 11765 sgd_solver.cpp:106] Iteration 10100, lr = 0.2
I0316 11:36:58.613195 11765 solver.cpp:228] Iteration 10200, loss = 4.70414
I0316 11:36:58.613346 11765 solver.cpp:244]     Train net output #0: loss = 4.70414 (* 1 = 4.70414 loss)
I0316 11:36:58.679868 11765 sgd_solver.cpp:106] Iteration 10200, lr = 0.2
I0316 11:38:12.847059 11765 solver.cpp:228] Iteration 10300, loss = 3.99611
I0316 11:38:12.847187 11765 solver.cpp:244]     Train net output #0: loss = 3.99611 (* 1 = 3.99611 loss)
I0316 11:38:12.898085 11765 sgd_solver.cpp:106] Iteration 10300, lr = 0.2
I0316 11:39:26.078671 11765 solver.cpp:228] Iteration 10400, loss = 4.53047
I0316 11:39:26.078824 11765 solver.cpp:244]     Train net output #0: loss = 4.53047 (* 1 = 4.53047 loss)
I0316 11:39:26.137970 11765 sgd_solver.cpp:106] Iteration 10400, lr = 0.2
I0316 11:40:41.699378 11765 solver.cpp:228] Iteration 10500, loss = 4.54139
I0316 11:40:41.699529 11765 solver.cpp:244]     Train net output #0: loss = 4.54139 (* 1 = 4.54139 loss)
I0316 11:40:41.758618 11765 sgd_solver.cpp:106] Iteration 10500, lr = 0.2
I0316 11:41:56.885699 11765 solver.cpp:228] Iteration 10600, loss = 4.29606
I0316 11:41:56.885864 11765 solver.cpp:244]     Train net output #0: loss = 4.29606 (* 1 = 4.29606 loss)
I0316 11:41:56.937328 11765 sgd_solver.cpp:106] Iteration 10600, lr = 0.2
I0316 11:43:12.049804 11765 solver.cpp:228] Iteration 10700, loss = 4.20025
I0316 11:43:12.049960 11765 solver.cpp:244]     Train net output #0: loss = 4.20025 (* 1 = 4.20025 loss)
I0316 11:43:12.088207 11765 sgd_solver.cpp:106] Iteration 10700, lr = 0.2
I0316 11:44:27.134580 11765 solver.cpp:228] Iteration 10800, loss = 4.42413
I0316 11:44:27.134709 11765 solver.cpp:244]     Train net output #0: loss = 4.42413 (* 1 = 4.42413 loss)
I0316 11:44:27.188320 11765 sgd_solver.cpp:106] Iteration 10800, lr = 0.2
I0316 11:45:40.326587 11765 solver.cpp:228] Iteration 10900, loss = 4.42825
I0316 11:45:40.326759 11765 solver.cpp:244]     Train net output #0: loss = 4.42825 (* 1 = 4.42825 loss)
I0316 11:45:40.378723 11765 sgd_solver.cpp:106] Iteration 10900, lr = 0.2
I0316 11:46:53.486445 11765 solver.cpp:337] Iteration 11000, Testing net (#0)
I0316 11:48:06.645854 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.10022
I0316 11:48:06.646023 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.2546
I0316 11:48:06.646042 11765 solver.cpp:404]     Test net output #2: loss = 4.94097 (* 1 = 4.94097 loss)
I0316 11:48:07.294598 11765 solver.cpp:228] Iteration 11000, loss = 4.19257
I0316 11:48:07.294622 11765 solver.cpp:244]     Train net output #0: loss = 4.19257 (* 1 = 4.19257 loss)
I0316 11:48:07.363741 11765 sgd_solver.cpp:106] Iteration 11000, lr = 0.2
I0316 11:49:20.582834 11765 solver.cpp:228] Iteration 11100, loss = 4.33037
I0316 11:49:20.582968 11765 solver.cpp:244]     Train net output #0: loss = 4.33037 (* 1 = 4.33037 loss)
I0316 11:49:20.659020 11765 sgd_solver.cpp:106] Iteration 11100, lr = 0.2
I0316 11:50:38.274097 11765 solver.cpp:228] Iteration 11200, loss = 4.09105
I0316 11:50:38.274221 11765 solver.cpp:244]     Train net output #0: loss = 4.09105 (* 1 = 4.09105 loss)
I0316 11:50:38.325856 11765 sgd_solver.cpp:106] Iteration 11200, lr = 0.2
I0316 11:51:57.635435 11765 solver.cpp:228] Iteration 11300, loss = 4.37473
I0316 11:51:57.635571 11765 solver.cpp:244]     Train net output #0: loss = 4.37473 (* 1 = 4.37473 loss)
I0316 11:51:57.701917 11765 sgd_solver.cpp:106] Iteration 11300, lr = 0.2
I0316 11:53:14.949107 11765 solver.cpp:228] Iteration 11400, loss = 4.28347
I0316 11:53:14.949251 11765 solver.cpp:244]     Train net output #0: loss = 4.28347 (* 1 = 4.28347 loss)
I0316 11:53:15.013981 11765 sgd_solver.cpp:106] Iteration 11400, lr = 0.2
I0316 11:54:29.064260 11765 solver.cpp:228] Iteration 11500, loss = 4.45778
I0316 11:54:29.064393 11765 solver.cpp:244]     Train net output #0: loss = 4.45778 (* 1 = 4.45778 loss)
I0316 11:54:29.121426 11765 sgd_solver.cpp:106] Iteration 11500, lr = 0.2
I0316 11:55:42.034575 11765 solver.cpp:228] Iteration 11600, loss = 4.4583
I0316 11:55:42.034701 11765 solver.cpp:244]     Train net output #0: loss = 4.4583 (* 1 = 4.4583 loss)
I0316 11:55:42.093942 11765 sgd_solver.cpp:106] Iteration 11600, lr = 0.2
I0316 11:56:55.700175 11765 solver.cpp:228] Iteration 11700, loss = 4.21251
I0316 11:56:55.700281 11765 solver.cpp:244]     Train net output #0: loss = 4.21251 (* 1 = 4.21251 loss)
I0316 11:56:55.757719 11765 sgd_solver.cpp:106] Iteration 11700, lr = 0.2
I0316 11:58:10.662789 11765 solver.cpp:228] Iteration 11800, loss = 4.44787
I0316 11:58:10.662925 11765 solver.cpp:244]     Train net output #0: loss = 4.44787 (* 1 = 4.44787 loss)
I0316 11:58:10.722405 11765 sgd_solver.cpp:106] Iteration 11800, lr = 0.2
I0316 11:59:24.306632 11765 solver.cpp:228] Iteration 11900, loss = 4.33474
I0316 11:59:24.306754 11765 solver.cpp:244]     Train net output #0: loss = 4.33474 (* 1 = 4.33474 loss)
I0316 11:59:24.334465 11765 sgd_solver.cpp:106] Iteration 11900, lr = 0.2
I0316 12:00:38.018604 11765 solver.cpp:337] Iteration 12000, Testing net (#0)
I0316 12:01:50.161504 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.14512
I0316 12:01:50.161643 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.340959
I0316 12:01:50.161662 11765 solver.cpp:404]     Test net output #2: loss = 4.36667 (* 1 = 4.36667 loss)
I0316 12:01:50.800590 11765 solver.cpp:228] Iteration 12000, loss = 3.82572
I0316 12:01:50.800623 11765 solver.cpp:244]     Train net output #0: loss = 3.82572 (* 1 = 3.82572 loss)
I0316 12:01:50.867343 11765 sgd_solver.cpp:106] Iteration 12000, lr = 0.2
I0316 12:03:03.571081 11765 solver.cpp:228] Iteration 12100, loss = 3.93798
I0316 12:03:03.571225 11765 solver.cpp:244]     Train net output #0: loss = 3.93798 (* 1 = 3.93798 loss)
I0316 12:03:03.674319 11765 sgd_solver.cpp:106] Iteration 12100, lr = 0.2
I0316 12:04:16.765458 11765 solver.cpp:228] Iteration 12200, loss = 4.1617
I0316 12:04:16.765660 11765 solver.cpp:244]     Train net output #0: loss = 4.1617 (* 1 = 4.1617 loss)
I0316 12:04:16.831738 11765 sgd_solver.cpp:106] Iteration 12200, lr = 0.2
I0316 12:05:29.336736 11765 solver.cpp:228] Iteration 12300, loss = 4.00258
I0316 12:05:29.336911 11765 solver.cpp:244]     Train net output #0: loss = 4.00258 (* 1 = 4.00258 loss)
I0316 12:05:29.398855 11765 sgd_solver.cpp:106] Iteration 12300, lr = 0.2
I0316 12:06:42.756880 11765 solver.cpp:228] Iteration 12400, loss = 3.99138
I0316 12:06:42.757009 11765 solver.cpp:244]     Train net output #0: loss = 3.99138 (* 1 = 3.99138 loss)
I0316 12:06:42.815634 11765 sgd_solver.cpp:106] Iteration 12400, lr = 0.2
I0316 12:07:57.862305 11765 solver.cpp:228] Iteration 12500, loss = 3.86439
I0316 12:07:57.862449 11765 solver.cpp:244]     Train net output #0: loss = 3.86439 (* 1 = 3.86439 loss)
I0316 12:07:57.921022 11765 sgd_solver.cpp:106] Iteration 12500, lr = 0.2
I0316 12:09:11.298485 11765 solver.cpp:228] Iteration 12600, loss = 4.29593
I0316 12:09:11.298650 11765 solver.cpp:244]     Train net output #0: loss = 4.29593 (* 1 = 4.29593 loss)
I0316 12:09:11.356636 11765 sgd_solver.cpp:106] Iteration 12600, lr = 0.2
I0316 12:10:24.544404 11765 solver.cpp:228] Iteration 12700, loss = 4.03228
I0316 12:10:24.544534 11765 solver.cpp:244]     Train net output #0: loss = 4.03228 (* 1 = 4.03228 loss)
I0316 12:10:24.603340 11765 sgd_solver.cpp:106] Iteration 12700, lr = 0.2
I0316 12:11:38.933543 11765 solver.cpp:228] Iteration 12800, loss = 3.88757
I0316 12:11:38.933663 11765 solver.cpp:244]     Train net output #0: loss = 3.88757 (* 1 = 3.88757 loss)
I0316 12:11:38.992588 11765 sgd_solver.cpp:106] Iteration 12800, lr = 0.2
I0316 12:12:51.474282 11765 solver.cpp:228] Iteration 12900, loss = 4.32094
I0316 12:12:51.474447 11765 solver.cpp:244]     Train net output #0: loss = 4.32094 (* 1 = 4.32094 loss)
I0316 12:12:51.531708 11765 sgd_solver.cpp:106] Iteration 12900, lr = 0.2
I0316 12:14:03.184434 11765 solver.cpp:337] Iteration 13000, Testing net (#0)
I0316 12:15:15.496839 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.14144
I0316 12:15:15.496984 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.3409
I0316 12:15:15.497009 11765 solver.cpp:404]     Test net output #2: loss = 4.43637 (* 1 = 4.43637 loss)
I0316 12:15:16.452178 11765 solver.cpp:228] Iteration 13000, loss = 4.0852
I0316 12:15:16.452214 11765 solver.cpp:244]     Train net output #0: loss = 4.0852 (* 1 = 4.0852 loss)
I0316 12:15:16.472981 11765 sgd_solver.cpp:106] Iteration 13000, lr = 0.2
I0316 12:16:29.839300 11765 solver.cpp:228] Iteration 13100, loss = 4.09249
I0316 12:16:29.839427 11765 solver.cpp:244]     Train net output #0: loss = 4.09249 (* 1 = 4.09249 loss)
I0316 12:16:29.917189 11765 sgd_solver.cpp:106] Iteration 13100, lr = 0.2
I0316 12:17:42.349761 11765 solver.cpp:228] Iteration 13200, loss = 3.7804
I0316 12:17:42.349889 11765 solver.cpp:244]     Train net output #0: loss = 3.7804 (* 1 = 3.7804 loss)
I0316 12:17:42.416731 11765 sgd_solver.cpp:106] Iteration 13200, lr = 0.2
I0316 12:18:54.125881 11765 solver.cpp:228] Iteration 13300, loss = 4.31997
I0316 12:18:54.126060 11765 solver.cpp:244]     Train net output #0: loss = 4.31997 (* 1 = 4.31997 loss)
I0316 12:18:54.194406 11765 sgd_solver.cpp:106] Iteration 13300, lr = 0.2
I0316 12:20:10.750732 11765 solver.cpp:228] Iteration 13400, loss = 4.33643
I0316 12:20:10.750880 11765 solver.cpp:244]     Train net output #0: loss = 4.33643 (* 1 = 4.33643 loss)
I0316 12:20:10.811472 11765 sgd_solver.cpp:106] Iteration 13400, lr = 0.2
I0316 12:21:25.395581 11765 solver.cpp:228] Iteration 13500, loss = 3.75009
I0316 12:21:25.397074 11765 solver.cpp:244]     Train net output #0: loss = 3.75009 (* 1 = 3.75009 loss)
I0316 12:21:25.426559 11765 sgd_solver.cpp:106] Iteration 13500, lr = 0.2
I0316 12:22:38.700104 11765 solver.cpp:228] Iteration 13600, loss = 3.90901
I0316 12:22:38.700309 11765 solver.cpp:244]     Train net output #0: loss = 3.90901 (* 1 = 3.90901 loss)
I0316 12:22:38.775650 11765 sgd_solver.cpp:106] Iteration 13600, lr = 0.2
I0316 12:23:53.833683 11765 solver.cpp:228] Iteration 13700, loss = 4.26401
I0316 12:23:53.833843 11765 solver.cpp:244]     Train net output #0: loss = 4.26401 (* 1 = 4.26401 loss)
I0316 12:23:53.892577 11765 sgd_solver.cpp:106] Iteration 13700, lr = 0.2
I0316 12:25:08.166167 11765 solver.cpp:228] Iteration 13800, loss = 3.73567
I0316 12:25:08.166508 11765 solver.cpp:244]     Train net output #0: loss = 3.73567 (* 1 = 3.73567 loss)
I0316 12:25:08.225514 11765 sgd_solver.cpp:106] Iteration 13800, lr = 0.2
I0316 12:26:27.690115 11765 solver.cpp:228] Iteration 13900, loss = 3.85419
I0316 12:26:27.690268 11765 solver.cpp:244]     Train net output #0: loss = 3.85419 (* 1 = 3.85419 loss)
I0316 12:26:27.747931 11765 sgd_solver.cpp:106] Iteration 13900, lr = 0.2
I0316 12:27:43.022716 11765 solver.cpp:337] Iteration 14000, Testing net (#0)
I0316 12:28:55.601181 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.1399
I0316 12:28:55.601306 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.33568
I0316 12:28:55.601327 11765 solver.cpp:404]     Test net output #2: loss = 4.47984 (* 1 = 4.47984 loss)
I0316 12:28:56.248935 11765 solver.cpp:228] Iteration 14000, loss = 4.08058
I0316 12:28:56.248967 11765 solver.cpp:244]     Train net output #0: loss = 4.08058 (* 1 = 4.08058 loss)
I0316 12:28:56.312001 11765 sgd_solver.cpp:106] Iteration 14000, lr = 0.2
I0316 12:30:14.490142 11765 solver.cpp:228] Iteration 14100, loss = 4.10412
I0316 12:30:14.490285 11765 solver.cpp:244]     Train net output #0: loss = 4.10412 (* 1 = 4.10412 loss)
I0316 12:30:14.563329 11765 sgd_solver.cpp:106] Iteration 14100, lr = 0.2
I0316 12:31:32.457460 11765 solver.cpp:228] Iteration 14200, loss = 3.93942
I0316 12:31:32.457634 11765 solver.cpp:244]     Train net output #0: loss = 3.93942 (* 1 = 3.93942 loss)
I0316 12:31:32.491559 11765 sgd_solver.cpp:106] Iteration 14200, lr = 0.2
I0316 12:32:49.871026 11765 solver.cpp:228] Iteration 14300, loss = 3.96651
I0316 12:32:49.871207 11765 solver.cpp:244]     Train net output #0: loss = 3.96651 (* 1 = 3.96651 loss)
I0316 12:32:49.885059 11765 sgd_solver.cpp:106] Iteration 14300, lr = 0.2
I0316 12:34:08.014313 11765 solver.cpp:228] Iteration 14400, loss = 4.15984
I0316 12:34:08.014461 11765 solver.cpp:244]     Train net output #0: loss = 4.15984 (* 1 = 4.15984 loss)
I0316 12:34:08.063344 11765 sgd_solver.cpp:106] Iteration 14400, lr = 0.2
I0316 12:35:22.853075 11765 solver.cpp:228] Iteration 14500, loss = 4.04597
I0316 12:35:22.853215 11765 solver.cpp:244]     Train net output #0: loss = 4.04597 (* 1 = 4.04597 loss)
I0316 12:35:22.907295 11765 sgd_solver.cpp:106] Iteration 14500, lr = 0.2
I0316 12:36:38.200177 11765 solver.cpp:228] Iteration 14600, loss = 4.08402
I0316 12:36:38.200299 11765 solver.cpp:244]     Train net output #0: loss = 4.08402 (* 1 = 4.08402 loss)
I0316 12:36:38.253935 11765 sgd_solver.cpp:106] Iteration 14600, lr = 0.2
I0316 12:37:55.607823 11765 solver.cpp:228] Iteration 14700, loss = 4.31479
I0316 12:37:55.607962 11765 solver.cpp:244]     Train net output #0: loss = 4.31479 (* 1 = 4.31479 loss)
I0316 12:37:55.634798 11765 sgd_solver.cpp:106] Iteration 14700, lr = 0.2
I0316 12:39:11.959403 11765 solver.cpp:228] Iteration 14800, loss = 4.34354
I0316 12:39:11.959576 11765 solver.cpp:244]     Train net output #0: loss = 4.34354 (* 1 = 4.34354 loss)
I0316 12:39:11.959630 11765 sgd_solver.cpp:106] Iteration 14800, lr = 0.2
I0316 12:40:28.540515 11765 solver.cpp:228] Iteration 14900, loss = 4.22397
I0316 12:40:28.540657 11765 solver.cpp:244]     Train net output #0: loss = 4.22397 (* 1 = 4.22397 loss)
I0316 12:40:28.588819 11765 sgd_solver.cpp:106] Iteration 14900, lr = 0.2
I0316 12:41:40.807219 11765 solver.cpp:337] Iteration 15000, Testing net (#0)
I0316 12:42:53.538295 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.1707
I0316 12:42:53.538440 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.38242
I0316 12:42:53.538460 11765 solver.cpp:404]     Test net output #2: loss = 4.19817 (* 1 = 4.19817 loss)
I0316 12:42:54.181289 11765 solver.cpp:228] Iteration 15000, loss = 3.87956
I0316 12:42:54.181325 11765 solver.cpp:244]     Train net output #0: loss = 3.87956 (* 1 = 3.87956 loss)
I0316 12:42:54.248033 11765 sgd_solver.cpp:106] Iteration 15000, lr = 0.2
I0316 12:44:09.203920 11765 solver.cpp:228] Iteration 15100, loss = 3.7518
I0316 12:44:09.204130 11765 solver.cpp:244]     Train net output #0: loss = 3.7518 (* 1 = 3.7518 loss)
I0316 12:44:09.299029 11765 sgd_solver.cpp:106] Iteration 15100, lr = 0.2
I0316 12:45:28.362596 11765 solver.cpp:228] Iteration 15200, loss = 3.9719
I0316 12:45:28.362743 11765 solver.cpp:244]     Train net output #0: loss = 3.9719 (* 1 = 3.9719 loss)
I0316 12:45:28.423607 11765 sgd_solver.cpp:106] Iteration 15200, lr = 0.2
I0316 12:46:46.063779 11765 solver.cpp:228] Iteration 15300, loss = 3.79205
I0316 12:46:46.064002 11765 solver.cpp:244]     Train net output #0: loss = 3.79205 (* 1 = 3.79205 loss)
I0316 12:46:46.094955 11765 sgd_solver.cpp:106] Iteration 15300, lr = 0.2
I0316 12:48:01.966578 11765 solver.cpp:228] Iteration 15400, loss = 4.25942
I0316 12:48:01.966745 11765 solver.cpp:244]     Train net output #0: loss = 4.25942 (* 1 = 4.25942 loss)
I0316 12:48:02.018299 11765 sgd_solver.cpp:106] Iteration 15400, lr = 0.2
I0316 12:49:18.954628 11765 solver.cpp:228] Iteration 15500, loss = 4.19486
I0316 12:49:18.954800 11765 solver.cpp:244]     Train net output #0: loss = 4.19486 (* 1 = 4.19486 loss)
I0316 12:49:19.006099 11765 sgd_solver.cpp:106] Iteration 15500, lr = 0.2
I0316 12:50:35.097704 11765 solver.cpp:228] Iteration 15600, loss = 3.99148
I0316 12:50:35.097856 11765 solver.cpp:244]     Train net output #0: loss = 3.99148 (* 1 = 3.99148 loss)
I0316 12:50:35.150782 11765 sgd_solver.cpp:106] Iteration 15600, lr = 0.2
I0316 12:51:51.757189 11765 solver.cpp:228] Iteration 15700, loss = 3.99583
I0316 12:51:51.757311 11765 solver.cpp:244]     Train net output #0: loss = 3.99583 (* 1 = 3.99583 loss)
I0316 12:51:51.816016 11765 sgd_solver.cpp:106] Iteration 15700, lr = 0.2
I0316 12:53:07.271713 11765 solver.cpp:228] Iteration 15800, loss = 3.83585
I0316 12:53:07.271857 11765 solver.cpp:244]     Train net output #0: loss = 3.83585 (* 1 = 3.83585 loss)
I0316 12:53:07.323521 11765 sgd_solver.cpp:106] Iteration 15800, lr = 0.2
I0316 12:54:21.097299 11765 solver.cpp:228] Iteration 15900, loss = 4.04608
I0316 12:54:21.097575 11765 solver.cpp:244]     Train net output #0: loss = 4.04608 (* 1 = 4.04608 loss)
I0316 12:54:21.151497 11765 sgd_solver.cpp:106] Iteration 15900, lr = 0.2
I0316 12:55:37.457098 11765 solver.cpp:337] Iteration 16000, Testing net (#0)
I0316 12:56:50.827410 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.1727
I0316 12:56:50.827554 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.39222
I0316 12:56:50.827584 11765 solver.cpp:404]     Test net output #2: loss = 4.13332 (* 1 = 4.13332 loss)
I0316 12:56:51.469761 11765 solver.cpp:228] Iteration 16000, loss = 3.88793
I0316 12:56:51.469800 11765 solver.cpp:244]     Train net output #0: loss = 3.88793 (* 1 = 3.88793 loss)
I0316 12:56:51.535243 11765 sgd_solver.cpp:106] Iteration 16000, lr = 0.2
I0316 12:58:07.971084 11765 solver.cpp:228] Iteration 16100, loss = 3.78547
I0316 12:58:07.971248 11765 solver.cpp:244]     Train net output #0: loss = 3.78547 (* 1 = 3.78547 loss)
I0316 12:58:08.052204 11765 sgd_solver.cpp:106] Iteration 16100, lr = 0.2
I0316 12:59:23.441480 11765 solver.cpp:228] Iteration 16200, loss = 4.34246
I0316 12:59:23.442004 11765 solver.cpp:244]     Train net output #0: loss = 4.34246 (* 1 = 4.34246 loss)
I0316 12:59:23.501094 11765 sgd_solver.cpp:106] Iteration 16200, lr = 0.2
I0316 13:00:39.093966 11765 solver.cpp:228] Iteration 16300, loss = 3.85922
I0316 13:00:39.094089 11765 solver.cpp:244]     Train net output #0: loss = 3.85922 (* 1 = 3.85922 loss)
I0316 13:00:39.144034 11765 sgd_solver.cpp:106] Iteration 16300, lr = 0.2
I0316 13:01:59.450927 11765 solver.cpp:228] Iteration 16400, loss = 3.922
I0316 13:01:59.451071 11765 solver.cpp:244]     Train net output #0: loss = 3.922 (* 1 = 3.922 loss)
I0316 13:01:59.515493 11765 sgd_solver.cpp:106] Iteration 16400, lr = 0.2
I0316 13:03:13.559051 11765 solver.cpp:228] Iteration 16500, loss = 3.86679
I0316 13:03:13.559751 11765 solver.cpp:244]     Train net output #0: loss = 3.86679 (* 1 = 3.86679 loss)
I0316 13:03:13.560191 11765 sgd_solver.cpp:106] Iteration 16500, lr = 0.2
I0316 13:04:32.512737 11765 solver.cpp:228] Iteration 16600, loss = 3.77386
I0316 13:04:32.513141 11765 solver.cpp:244]     Train net output #0: loss = 3.77386 (* 1 = 3.77386 loss)
I0316 13:04:32.513304 11765 sgd_solver.cpp:106] Iteration 16600, lr = 0.2
I0316 13:05:48.516327 11765 solver.cpp:228] Iteration 16700, loss = 3.86564
I0316 13:05:48.516479 11765 solver.cpp:244]     Train net output #0: loss = 3.86564 (* 1 = 3.86564 loss)
I0316 13:05:48.579412 11765 sgd_solver.cpp:106] Iteration 16700, lr = 0.2
I0316 13:07:06.651978 11765 solver.cpp:228] Iteration 16800, loss = 3.83598
I0316 13:07:06.652112 11765 solver.cpp:244]     Train net output #0: loss = 3.83598 (* 1 = 3.83598 loss)
I0316 13:07:06.711242 11765 sgd_solver.cpp:106] Iteration 16800, lr = 0.2
I0316 13:08:27.424212 11765 solver.cpp:228] Iteration 16900, loss = 4.01484
I0316 13:08:27.424350 11765 solver.cpp:244]     Train net output #0: loss = 4.01484 (* 1 = 4.01484 loss)
I0316 13:08:27.475272 11765 sgd_solver.cpp:106] Iteration 16900, lr = 0.2
I0316 13:09:44.339501 11765 solver.cpp:337] Iteration 17000, Testing net (#0)
I0316 13:10:57.688269 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.17996
I0316 13:10:57.688413 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.40172
I0316 13:10:57.688432 11765 solver.cpp:404]     Test net output #2: loss = 4.11359 (* 1 = 4.11359 loss)
I0316 13:10:58.333528 11765 solver.cpp:228] Iteration 17000, loss = 3.98721
I0316 13:10:58.333561 11765 solver.cpp:244]     Train net output #0: loss = 3.98721 (* 1 = 3.98721 loss)
I0316 13:10:58.396019 11765 sgd_solver.cpp:106] Iteration 17000, lr = 0.2
I0316 13:12:13.126168 11765 solver.cpp:228] Iteration 17100, loss = 4.16148
I0316 13:12:13.126307 11765 solver.cpp:244]     Train net output #0: loss = 4.16148 (* 1 = 4.16148 loss)
I0316 13:12:13.208811 11765 sgd_solver.cpp:106] Iteration 17100, lr = 0.2
I0316 13:13:28.488472 11765 solver.cpp:228] Iteration 17200, loss = 4.05823
I0316 13:13:28.488620 11765 solver.cpp:244]     Train net output #0: loss = 4.05823 (* 1 = 4.05823 loss)
I0316 13:13:28.550953 11765 sgd_solver.cpp:106] Iteration 17200, lr = 0.2
I0316 13:14:45.094089 11765 solver.cpp:228] Iteration 17300, loss = 4.04061
I0316 13:14:45.094245 11765 solver.cpp:244]     Train net output #0: loss = 4.04061 (* 1 = 4.04061 loss)
I0316 13:14:45.157637 11765 sgd_solver.cpp:106] Iteration 17300, lr = 0.2
I0316 13:16:01.928340 11765 solver.cpp:228] Iteration 17400, loss = 3.77075
I0316 13:16:01.928494 11765 solver.cpp:244]     Train net output #0: loss = 3.77075 (* 1 = 3.77075 loss)
I0316 13:16:01.982735 11765 sgd_solver.cpp:106] Iteration 17400, lr = 0.2
I0316 13:17:18.896692 11765 solver.cpp:228] Iteration 17500, loss = 4.18031
I0316 13:17:18.896836 11765 solver.cpp:244]     Train net output #0: loss = 4.18031 (* 1 = 4.18031 loss)
I0316 13:17:18.951210 11765 sgd_solver.cpp:106] Iteration 17500, lr = 0.2
I0316 13:18:34.729149 11765 solver.cpp:228] Iteration 17600, loss = 4.00873
I0316 13:18:34.730515 11765 solver.cpp:244]     Train net output #0: loss = 4.00873 (* 1 = 4.00873 loss)
I0316 13:18:34.731032 11765 sgd_solver.cpp:106] Iteration 17600, lr = 0.2
I0316 13:19:50.084947 11765 solver.cpp:228] Iteration 17700, loss = 3.80054
I0316 13:19:50.085114 11765 solver.cpp:244]     Train net output #0: loss = 3.80054 (* 1 = 3.80054 loss)
I0316 13:19:50.146710 11765 sgd_solver.cpp:106] Iteration 17700, lr = 0.2
I0316 13:21:09.068467 11765 solver.cpp:228] Iteration 17800, loss = 3.712
I0316 13:21:09.068599 11765 solver.cpp:244]     Train net output #0: loss = 3.712 (* 1 = 3.712 loss)
I0316 13:21:09.131546 11765 sgd_solver.cpp:106] Iteration 17800, lr = 0.2
I0316 13:22:27.116909 11765 solver.cpp:228] Iteration 17900, loss = 3.77452
I0316 13:22:27.118500 11765 solver.cpp:244]     Train net output #0: loss = 3.77452 (* 1 = 3.77452 loss)
I0316 13:22:27.164459 11765 sgd_solver.cpp:106] Iteration 17900, lr = 0.2
I0316 13:23:41.362359 11765 solver.cpp:337] Iteration 18000, Testing net (#0)
I0316 13:24:55.764282 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.18262
I0316 13:24:55.764648 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.39992
I0316 13:24:55.764698 11765 solver.cpp:404]     Test net output #2: loss = 4.1192 (* 1 = 4.1192 loss)
I0316 13:24:56.410303 11765 solver.cpp:228] Iteration 18000, loss = 3.73325
I0316 13:24:56.410365 11765 solver.cpp:244]     Train net output #0: loss = 3.73325 (* 1 = 3.73325 loss)
I0316 13:24:56.496623 11765 sgd_solver.cpp:106] Iteration 18000, lr = 0.2
I0316 13:26:14.935010 11765 solver.cpp:228] Iteration 18100, loss = 4.26552
I0316 13:26:14.935209 11765 solver.cpp:244]     Train net output #0: loss = 4.26552 (* 1 = 4.26552 loss)
I0316 13:26:15.033174 11765 sgd_solver.cpp:106] Iteration 18100, lr = 0.2
I0316 13:27:34.493198 11765 solver.cpp:228] Iteration 18200, loss = 3.68644
I0316 13:27:34.493296 11765 solver.cpp:244]     Train net output #0: loss = 3.68644 (* 1 = 3.68644 loss)
I0316 13:27:34.554078 11765 sgd_solver.cpp:106] Iteration 18200, lr = 0.2
I0316 13:28:56.238005 11765 solver.cpp:228] Iteration 18300, loss = 3.59865
I0316 13:28:56.238158 11765 solver.cpp:244]     Train net output #0: loss = 3.59865 (* 1 = 3.59865 loss)
I0316 13:28:56.300663 11765 sgd_solver.cpp:106] Iteration 18300, lr = 0.2
I0316 13:30:16.481663 11765 solver.cpp:228] Iteration 18400, loss = 3.65821
I0316 13:30:16.481835 11765 solver.cpp:244]     Train net output #0: loss = 3.65821 (* 1 = 3.65821 loss)
I0316 13:30:16.541611 11765 sgd_solver.cpp:106] Iteration 18400, lr = 0.2
I0316 13:31:34.205618 11765 solver.cpp:228] Iteration 18500, loss = 3.48113
I0316 13:31:34.205747 11765 solver.cpp:244]     Train net output #0: loss = 3.48113 (* 1 = 3.48113 loss)
I0316 13:31:34.269479 11765 sgd_solver.cpp:106] Iteration 18500, lr = 0.2
I0316 13:32:48.276219 11765 solver.cpp:228] Iteration 18600, loss = 3.82746
I0316 13:32:48.276351 11765 solver.cpp:244]     Train net output #0: loss = 3.82746 (* 1 = 3.82746 loss)
I0316 13:32:48.334964 11765 sgd_solver.cpp:106] Iteration 18600, lr = 0.2
I0316 13:34:02.256691 11765 solver.cpp:228] Iteration 18700, loss = 3.69123
I0316 13:34:02.256844 11765 solver.cpp:244]     Train net output #0: loss = 3.69123 (* 1 = 3.69123 loss)
I0316 13:34:02.327407 11765 sgd_solver.cpp:106] Iteration 18700, lr = 0.2
I0316 13:35:18.993497 11765 solver.cpp:228] Iteration 18800, loss = 3.61559
I0316 13:35:18.993644 11765 solver.cpp:244]     Train net output #0: loss = 3.61559 (* 1 = 3.61559 loss)
I0316 13:35:19.050922 11765 sgd_solver.cpp:106] Iteration 18800, lr = 0.2
I0316 13:36:32.239315 11765 solver.cpp:228] Iteration 18900, loss = 3.91981
I0316 13:36:32.239464 11765 solver.cpp:244]     Train net output #0: loss = 3.91981 (* 1 = 3.91981 loss)
I0316 13:36:32.302697 11765 sgd_solver.cpp:106] Iteration 18900, lr = 0.2
I0316 13:37:48.071099 11765 solver.cpp:337] Iteration 19000, Testing net (#0)
I0316 13:39:00.374270 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.15836
I0316 13:39:00.374409 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.35922
I0316 13:39:00.374436 11765 solver.cpp:404]     Test net output #2: loss = 4.48084 (* 1 = 4.48084 loss)
I0316 13:39:01.009526 11765 solver.cpp:228] Iteration 19000, loss = 3.85996
I0316 13:39:01.009560 11765 solver.cpp:244]     Train net output #0: loss = 3.85996 (* 1 = 3.85996 loss)
I0316 13:39:01.074447 11765 sgd_solver.cpp:106] Iteration 19000, lr = 0.2
I0316 13:40:15.895946 11765 solver.cpp:228] Iteration 19100, loss = 3.78572
I0316 13:40:15.896518 11765 solver.cpp:244]     Train net output #0: loss = 3.78572 (* 1 = 3.78572 loss)
I0316 13:40:15.918162 11765 sgd_solver.cpp:106] Iteration 19100, lr = 0.2
I0316 13:41:32.466538 11765 solver.cpp:228] Iteration 19200, loss = 4.01193
I0316 13:41:32.466682 11765 solver.cpp:244]     Train net output #0: loss = 4.01193 (* 1 = 4.01193 loss)
I0316 13:41:32.537542 11765 sgd_solver.cpp:106] Iteration 19200, lr = 0.2
I0316 13:42:47.556354 11765 solver.cpp:228] Iteration 19300, loss = 3.4968
I0316 13:42:47.556567 11765 solver.cpp:244]     Train net output #0: loss = 3.4968 (* 1 = 3.4968 loss)
I0316 13:42:47.623677 11765 sgd_solver.cpp:106] Iteration 19300, lr = 0.2
I0316 13:44:01.955209 11765 solver.cpp:228] Iteration 19400, loss = 3.90488
I0316 13:44:01.955319 11765 solver.cpp:244]     Train net output #0: loss = 3.90488 (* 1 = 3.90488 loss)
I0316 13:44:02.013092 11765 sgd_solver.cpp:106] Iteration 19400, lr = 0.2
I0316 13:45:18.252516 11765 solver.cpp:228] Iteration 19500, loss = 3.8154
I0316 13:45:18.252758 11765 solver.cpp:244]     Train net output #0: loss = 3.8154 (* 1 = 3.8154 loss)
I0316 13:45:18.311259 11765 sgd_solver.cpp:106] Iteration 19500, lr = 0.2
I0316 13:46:31.818656 11765 solver.cpp:228] Iteration 19600, loss = 4.13829
I0316 13:46:31.818806 11765 solver.cpp:244]     Train net output #0: loss = 4.13829 (* 1 = 4.13829 loss)
I0316 13:46:31.867040 11765 sgd_solver.cpp:106] Iteration 19600, lr = 0.2
I0316 13:47:48.197568 11765 solver.cpp:228] Iteration 19700, loss = 3.76771
I0316 13:47:48.197729 11765 solver.cpp:244]     Train net output #0: loss = 3.76771 (* 1 = 3.76771 loss)
I0316 13:47:48.260123 11765 sgd_solver.cpp:106] Iteration 19700, lr = 0.2
I0316 13:49:02.453600 11765 solver.cpp:228] Iteration 19800, loss = 3.68964
I0316 13:49:02.453819 11765 solver.cpp:244]     Train net output #0: loss = 3.68964 (* 1 = 3.68964 loss)
I0316 13:49:02.506821 11765 sgd_solver.cpp:106] Iteration 19800, lr = 0.2
I0316 13:50:16.402545 11765 solver.cpp:228] Iteration 19900, loss = 3.53249
I0316 13:50:16.402712 11765 solver.cpp:244]     Train net output #0: loss = 3.53249 (* 1 = 3.53249 loss)
I0316 13:50:16.458516 11765 sgd_solver.cpp:106] Iteration 19900, lr = 0.2
I0316 13:51:32.218036 11765 solver.cpp:454] Snapshotting to binary proto file snapshots/imageNet_slim_iter_20000.caffemodel
I0316 13:51:32.252498 11765 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/imageNet_slim_iter_20000.solverstate
I0316 13:51:32.261157 11765 solver.cpp:337] Iteration 20000, Testing net (#0)
I0316 13:52:44.483501 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.19118
I0316 13:52:44.483678 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.41512
I0316 13:52:44.483713 11765 solver.cpp:404]     Test net output #2: loss = 4.04639 (* 1 = 4.04639 loss)
I0316 13:52:45.214819 11765 solver.cpp:228] Iteration 20000, loss = 3.7565
I0316 13:52:45.214871 11765 solver.cpp:244]     Train net output #0: loss = 3.7565 (* 1 = 3.7565 loss)
I0316 13:52:45.295696 11765 sgd_solver.cpp:106] Iteration 20000, lr = 0.2
I0316 13:54:00.354560 11765 solver.cpp:228] Iteration 20100, loss = 3.34451
I0316 13:54:00.354784 11765 solver.cpp:244]     Train net output #0: loss = 3.34451 (* 1 = 3.34451 loss)
I0316 13:54:00.494323 11765 sgd_solver.cpp:106] Iteration 20100, lr = 0.2
I0316 13:55:22.267664 11765 solver.cpp:228] Iteration 20200, loss = 3.64862
I0316 13:55:22.267839 11765 solver.cpp:244]     Train net output #0: loss = 3.64862 (* 1 = 3.64862 loss)
I0316 13:55:22.353022 11765 sgd_solver.cpp:106] Iteration 20200, lr = 0.2
I0316 13:56:37.564721 11765 solver.cpp:228] Iteration 20300, loss = 3.46428
I0316 13:56:37.564872 11765 solver.cpp:244]     Train net output #0: loss = 3.46428 (* 1 = 3.46428 loss)
I0316 13:56:37.624915 11765 sgd_solver.cpp:106] Iteration 20300, lr = 0.2
I0316 13:57:51.637593 11765 solver.cpp:228] Iteration 20400, loss = 3.51449
I0316 13:57:51.637748 11765 solver.cpp:244]     Train net output #0: loss = 3.51449 (* 1 = 3.51449 loss)
I0316 13:57:51.697491 11765 sgd_solver.cpp:106] Iteration 20400, lr = 0.2
I0316 13:59:07.975813 11765 solver.cpp:228] Iteration 20500, loss = 3.52156
I0316 13:59:07.975944 11765 solver.cpp:244]     Train net output #0: loss = 3.52156 (* 1 = 3.52156 loss)
I0316 13:59:08.028481 11765 sgd_solver.cpp:106] Iteration 20500, lr = 0.2
I0316 14:00:22.706997 11765 solver.cpp:228] Iteration 20600, loss = 3.6468
I0316 14:00:22.707188 11765 solver.cpp:244]     Train net output #0: loss = 3.6468 (* 1 = 3.6468 loss)
I0316 14:00:22.738037 11765 sgd_solver.cpp:106] Iteration 20600, lr = 0.2
I0316 14:01:38.587276 11765 solver.cpp:228] Iteration 20700, loss = 4.01135
I0316 14:01:38.587422 11765 solver.cpp:244]     Train net output #0: loss = 4.01135 (* 1 = 4.01135 loss)
I0316 14:01:38.617035 11765 sgd_solver.cpp:106] Iteration 20700, lr = 0.2
I0316 14:02:52.652670 11765 solver.cpp:228] Iteration 20800, loss = 3.84238
I0316 14:02:52.652824 11765 solver.cpp:244]     Train net output #0: loss = 3.84238 (* 1 = 3.84238 loss)
I0316 14:02:52.703703 11765 sgd_solver.cpp:106] Iteration 20800, lr = 0.2
I0316 14:04:06.387466 11765 solver.cpp:228] Iteration 20900, loss = 3.87366
I0316 14:04:06.387617 11765 solver.cpp:244]     Train net output #0: loss = 3.87366 (* 1 = 3.87366 loss)
I0316 14:04:06.438498 11765 sgd_solver.cpp:106] Iteration 20900, lr = 0.2
I0316 14:05:20.771289 11765 solver.cpp:337] Iteration 21000, Testing net (#0)
I0316 14:06:34.917997 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.19248
I0316 14:06:34.918151 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.4186
I0316 14:06:34.918180 11765 solver.cpp:404]     Test net output #2: loss = 4.04435 (* 1 = 4.04435 loss)
I0316 14:06:35.557796 11765 solver.cpp:228] Iteration 21000, loss = 3.52952
I0316 14:06:35.557837 11765 solver.cpp:244]     Train net output #0: loss = 3.52952 (* 1 = 3.52952 loss)
I0316 14:06:35.617013 11765 sgd_solver.cpp:106] Iteration 21000, lr = 0.2
I0316 14:07:50.954500 11765 solver.cpp:228] Iteration 21100, loss = 4.00896
I0316 14:07:50.954723 11765 solver.cpp:244]     Train net output #0: loss = 4.00896 (* 1 = 4.00896 loss)
I0316 14:07:51.065887 11765 sgd_solver.cpp:106] Iteration 21100, lr = 0.2
I0316 14:09:12.156924 11765 solver.cpp:228] Iteration 21200, loss = 3.64849
I0316 14:09:12.157059 11765 solver.cpp:244]     Train net output #0: loss = 3.64849 (* 1 = 3.64849 loss)
I0316 14:09:12.216368 11765 sgd_solver.cpp:106] Iteration 21200, lr = 0.2
I0316 14:10:31.902912 11765 solver.cpp:228] Iteration 21300, loss = 3.65994
I0316 14:10:31.903038 11765 solver.cpp:244]     Train net output #0: loss = 3.65994 (* 1 = 3.65994 loss)
I0316 14:10:31.974131 11765 sgd_solver.cpp:106] Iteration 21300, lr = 0.2
I0316 14:11:47.707237 11765 solver.cpp:228] Iteration 21400, loss = 3.75087
I0316 14:11:47.707391 11765 solver.cpp:244]     Train net output #0: loss = 3.75087 (* 1 = 3.75087 loss)
I0316 14:11:47.766059 11765 sgd_solver.cpp:106] Iteration 21400, lr = 0.2
I0316 14:13:03.123957 11765 solver.cpp:228] Iteration 21500, loss = 3.75437
I0316 14:13:03.124079 11765 solver.cpp:244]     Train net output #0: loss = 3.75437 (* 1 = 3.75437 loss)
I0316 14:13:03.178953 11765 sgd_solver.cpp:106] Iteration 21500, lr = 0.2
I0316 14:14:17.039652 11765 solver.cpp:228] Iteration 21600, loss = 3.71312
I0316 14:14:17.039789 11765 solver.cpp:244]     Train net output #0: loss = 3.71312 (* 1 = 3.71312 loss)
I0316 14:14:17.101809 11765 sgd_solver.cpp:106] Iteration 21600, lr = 0.2
I0316 14:15:32.117161 11765 solver.cpp:228] Iteration 21700, loss = 3.5274
I0316 14:15:32.117305 11765 solver.cpp:244]     Train net output #0: loss = 3.5274 (* 1 = 3.5274 loss)
I0316 14:15:32.180382 11765 sgd_solver.cpp:106] Iteration 21700, lr = 0.2
I0316 14:16:50.599362 11765 solver.cpp:228] Iteration 21800, loss = 3.47207
I0316 14:16:50.599495 11765 solver.cpp:244]     Train net output #0: loss = 3.47207 (* 1 = 3.47207 loss)
I0316 14:16:50.658182 11765 sgd_solver.cpp:106] Iteration 21800, lr = 0.2
I0316 14:18:04.752243 11765 solver.cpp:228] Iteration 21900, loss = 3.68694
I0316 14:18:04.752396 11765 solver.cpp:244]     Train net output #0: loss = 3.68694 (* 1 = 3.68694 loss)
I0316 14:18:04.830624 11765 sgd_solver.cpp:106] Iteration 21900, lr = 0.2
I0316 14:19:21.121657 11765 solver.cpp:337] Iteration 22000, Testing net (#0)
I0316 14:20:37.486183 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.22164
I0316 14:20:37.486354 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.46362
I0316 14:20:37.486387 11765 solver.cpp:404]     Test net output #2: loss = 3.76739 (* 1 = 3.76739 loss)
I0316 14:20:38.140343 11765 solver.cpp:228] Iteration 22000, loss = 3.57286
I0316 14:20:38.140374 11765 solver.cpp:244]     Train net output #0: loss = 3.57286 (* 1 = 3.57286 loss)
I0316 14:20:38.210019 11765 sgd_solver.cpp:106] Iteration 22000, lr = 0.2
I0316 14:22:00.288815 11765 solver.cpp:228] Iteration 22100, loss = 3.66757
I0316 14:22:00.289072 11765 solver.cpp:244]     Train net output #0: loss = 3.66757 (* 1 = 3.66757 loss)
I0316 14:22:00.366300 11765 sgd_solver.cpp:106] Iteration 22100, lr = 0.2
I0316 14:23:18.311915 11765 solver.cpp:228] Iteration 22200, loss = 3.48966
I0316 14:23:18.312527 11765 solver.cpp:244]     Train net output #0: loss = 3.48966 (* 1 = 3.48966 loss)
I0316 14:23:18.312731 11765 sgd_solver.cpp:106] Iteration 22200, lr = 0.2
I0316 14:24:35.465819 11765 solver.cpp:228] Iteration 22300, loss = 3.71944
I0316 14:24:35.465986 11765 solver.cpp:244]     Train net output #0: loss = 3.71944 (* 1 = 3.71944 loss)
I0316 14:24:35.524567 11765 sgd_solver.cpp:106] Iteration 22300, lr = 0.2
I0316 14:25:48.942942 11765 solver.cpp:228] Iteration 22400, loss = 3.69562
I0316 14:25:48.943091 11765 solver.cpp:244]     Train net output #0: loss = 3.69562 (* 1 = 3.69562 loss)
I0316 14:25:49.004722 11765 sgd_solver.cpp:106] Iteration 22400, lr = 0.2
I0316 14:27:02.898330 11765 solver.cpp:228] Iteration 22500, loss = 3.83042
I0316 14:27:02.898639 11765 solver.cpp:244]     Train net output #0: loss = 3.83042 (* 1 = 3.83042 loss)
I0316 14:27:02.898835 11765 sgd_solver.cpp:106] Iteration 22500, lr = 0.2
I0316 14:28:17.492111 11765 solver.cpp:228] Iteration 22600, loss = 3.54457
I0316 14:28:17.492250 11765 solver.cpp:244]     Train net output #0: loss = 3.54457 (* 1 = 3.54457 loss)
I0316 14:28:17.550226 11765 sgd_solver.cpp:106] Iteration 22600, lr = 0.2
I0316 14:29:30.312041 11765 solver.cpp:228] Iteration 22700, loss = 3.67574
I0316 14:29:30.312186 11765 solver.cpp:244]     Train net output #0: loss = 3.67574 (* 1 = 3.67574 loss)
I0316 14:29:30.373553 11765 sgd_solver.cpp:106] Iteration 22700, lr = 0.2
I0316 14:30:44.819453 11765 solver.cpp:228] Iteration 22800, loss = 3.48238
I0316 14:30:44.819594 11765 solver.cpp:244]     Train net output #0: loss = 3.48238 (* 1 = 3.48238 loss)
I0316 14:30:44.881407 11765 sgd_solver.cpp:106] Iteration 22800, lr = 0.2
I0316 14:32:00.192278 11765 solver.cpp:228] Iteration 22900, loss = 3.44251
I0316 14:32:00.192503 11765 solver.cpp:244]     Train net output #0: loss = 3.44251 (* 1 = 3.44251 loss)
I0316 14:32:00.287437 11765 sgd_solver.cpp:106] Iteration 22900, lr = 0.2
I0316 14:33:17.391312 11765 solver.cpp:337] Iteration 23000, Testing net (#0)
I0316 14:34:31.129295 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.19536
I0316 14:34:31.129482 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.42546
I0316 14:34:31.129524 11765 solver.cpp:404]     Test net output #2: loss = 3.99509 (* 1 = 3.99509 loss)
I0316 14:34:31.761680 11765 solver.cpp:228] Iteration 23000, loss = 3.90986
I0316 14:34:31.761720 11765 solver.cpp:244]     Train net output #0: loss = 3.90986 (* 1 = 3.90986 loss)
I0316 14:34:31.831976 11765 sgd_solver.cpp:106] Iteration 23000, lr = 0.2
I0316 14:35:47.568959 11765 solver.cpp:228] Iteration 23100, loss = 3.26228
I0316 14:35:47.569124 11765 solver.cpp:244]     Train net output #0: loss = 3.26228 (* 1 = 3.26228 loss)
I0316 14:35:47.661442 11765 sgd_solver.cpp:106] Iteration 23100, lr = 0.2
I0316 14:37:02.077857 11765 solver.cpp:228] Iteration 23200, loss = 3.43987
I0316 14:37:02.078017 11765 solver.cpp:244]     Train net output #0: loss = 3.43987 (* 1 = 3.43987 loss)
I0316 14:37:02.151252 11765 sgd_solver.cpp:106] Iteration 23200, lr = 0.2
I0316 14:38:18.525045 11765 solver.cpp:228] Iteration 23300, loss = 3.5687
I0316 14:38:18.525187 11765 solver.cpp:244]     Train net output #0: loss = 3.5687 (* 1 = 3.5687 loss)
I0316 14:38:18.587096 11765 sgd_solver.cpp:106] Iteration 23300, lr = 0.2
I0316 14:39:32.188716 11765 solver.cpp:228] Iteration 23400, loss = 3.7025
I0316 14:39:32.189036 11765 solver.cpp:244]     Train net output #0: loss = 3.7025 (* 1 = 3.7025 loss)
I0316 14:39:32.250979 11765 sgd_solver.cpp:106] Iteration 23400, lr = 0.2
I0316 14:40:49.418357 11765 solver.cpp:228] Iteration 23500, loss = 3.71362
I0316 14:40:49.418558 11765 solver.cpp:244]     Train net output #0: loss = 3.71362 (* 1 = 3.71362 loss)
I0316 14:40:49.537149 11765 sgd_solver.cpp:106] Iteration 23500, lr = 0.2
I0316 14:42:05.381492 11765 solver.cpp:228] Iteration 23600, loss = 3.54881
I0316 14:42:05.381688 11765 solver.cpp:244]     Train net output #0: loss = 3.54881 (* 1 = 3.54881 loss)
I0316 14:42:05.456167 11765 sgd_solver.cpp:106] Iteration 23600, lr = 0.2
I0316 14:43:22.504982 11765 solver.cpp:228] Iteration 23700, loss = 3.3573
I0316 14:43:22.505137 11765 solver.cpp:244]     Train net output #0: loss = 3.3573 (* 1 = 3.3573 loss)
I0316 14:43:22.564223 11765 sgd_solver.cpp:106] Iteration 23700, lr = 0.2
I0316 14:44:37.428113 11765 solver.cpp:228] Iteration 23800, loss = 3.45108
I0316 14:44:37.428234 11765 solver.cpp:244]     Train net output #0: loss = 3.45108 (* 1 = 3.45108 loss)
I0316 14:44:37.491801 11765 sgd_solver.cpp:106] Iteration 23800, lr = 0.2
I0316 14:45:52.651871 11765 solver.cpp:228] Iteration 23900, loss = 4.15609
I0316 14:45:52.652009 11765 solver.cpp:244]     Train net output #0: loss = 4.15609 (* 1 = 4.15609 loss)
I0316 14:45:52.710712 11765 sgd_solver.cpp:106] Iteration 23900, lr = 0.2
I0316 14:47:09.491921 11765 solver.cpp:337] Iteration 24000, Testing net (#0)
I0316 14:48:24.367537 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.20504
I0316 14:48:24.367663 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.4369
I0316 14:48:24.367689 11765 solver.cpp:404]     Test net output #2: loss = 3.93991 (* 1 = 3.93991 loss)
I0316 14:48:25.010071 11765 solver.cpp:228] Iteration 24000, loss = 3.39013
I0316 14:48:25.010105 11765 solver.cpp:244]     Train net output #0: loss = 3.39013 (* 1 = 3.39013 loss)
I0316 14:48:25.077795 11765 sgd_solver.cpp:106] Iteration 24000, lr = 0.2
I0316 14:49:43.267081 11765 solver.cpp:228] Iteration 24100, loss = 3.57223
I0316 14:49:43.267864 11765 solver.cpp:244]     Train net output #0: loss = 3.57223 (* 1 = 3.57223 loss)
I0316 14:49:43.304544 11765 sgd_solver.cpp:106] Iteration 24100, lr = 0.2
I0316 14:51:05.048375 11765 solver.cpp:228] Iteration 24200, loss = 3.86684
I0316 14:51:05.048528 11765 solver.cpp:244]     Train net output #0: loss = 3.86684 (* 1 = 3.86684 loss)
I0316 14:51:05.116575 11765 sgd_solver.cpp:106] Iteration 24200, lr = 0.2
I0316 14:52:20.962903 11765 solver.cpp:228] Iteration 24300, loss = 3.37911
I0316 14:52:20.963037 11765 solver.cpp:244]     Train net output #0: loss = 3.37911 (* 1 = 3.37911 loss)
I0316 14:52:21.031952 11765 sgd_solver.cpp:106] Iteration 24300, lr = 0.2
I0316 14:53:38.774521 11765 solver.cpp:228] Iteration 24400, loss = 3.31206
I0316 14:53:38.774907 11765 solver.cpp:244]     Train net output #0: loss = 3.31206 (* 1 = 3.31206 loss)
I0316 14:53:38.845902 11765 sgd_solver.cpp:106] Iteration 24400, lr = 0.2
I0316 14:55:01.030236 11765 solver.cpp:228] Iteration 24500, loss = 3.63676
I0316 14:55:01.030593 11765 solver.cpp:244]     Train net output #0: loss = 3.63676 (* 1 = 3.63676 loss)
I0316 14:55:01.037170 11765 sgd_solver.cpp:106] Iteration 24500, lr = 0.2
I0316 14:56:20.282299 11765 solver.cpp:228] Iteration 24600, loss = 3.95207
I0316 14:56:20.282428 11765 solver.cpp:244]     Train net output #0: loss = 3.95207 (* 1 = 3.95207 loss)
I0316 14:56:20.343807 11765 sgd_solver.cpp:106] Iteration 24600, lr = 0.2
I0316 14:57:36.908680 11765 solver.cpp:228] Iteration 24700, loss = 3.34929
I0316 14:57:36.908816 11765 solver.cpp:244]     Train net output #0: loss = 3.34929 (* 1 = 3.34929 loss)
I0316 14:57:36.971213 11765 sgd_solver.cpp:106] Iteration 24700, lr = 0.2
I0316 14:58:51.461338 11765 solver.cpp:228] Iteration 24800, loss = 3.21641
I0316 14:58:51.470041 11765 solver.cpp:244]     Train net output #0: loss = 3.21641 (* 1 = 3.21641 loss)
I0316 14:58:51.470640 11765 sgd_solver.cpp:106] Iteration 24800, lr = 0.2
I0316 15:00:07.549275 11765 solver.cpp:228] Iteration 24900, loss = 3.95807
I0316 15:00:07.549505 11765 solver.cpp:244]     Train net output #0: loss = 3.95807 (* 1 = 3.95807 loss)
I0316 15:00:07.586171 11765 sgd_solver.cpp:106] Iteration 24900, lr = 0.2
I0316 15:01:20.753651 11765 solver.cpp:337] Iteration 25000, Testing net (#0)
I0316 15:02:33.258699 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.21442
I0316 15:02:33.258879 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.45442
I0316 15:02:33.258908 11765 solver.cpp:404]     Test net output #2: loss = 3.84248 (* 1 = 3.84248 loss)
I0316 15:02:33.896328 11765 solver.cpp:228] Iteration 25000, loss = 3.62483
I0316 15:02:33.896365 11765 solver.cpp:244]     Train net output #0: loss = 3.62483 (* 1 = 3.62483 loss)
I0316 15:02:33.967679 11765 sgd_solver.cpp:106] Iteration 25000, lr = 0.2
I0316 15:03:54.512684 11765 solver.cpp:228] Iteration 25100, loss = 3.53212
I0316 15:03:54.512862 11765 solver.cpp:244]     Train net output #0: loss = 3.53212 (* 1 = 3.53212 loss)
I0316 15:03:54.603261 11765 sgd_solver.cpp:106] Iteration 25100, lr = 0.2
I0316 15:05:12.415138 11765 solver.cpp:228] Iteration 25200, loss = 3.35251
I0316 15:05:12.415688 11765 solver.cpp:244]     Train net output #0: loss = 3.35251 (* 1 = 3.35251 loss)
I0316 15:05:12.471092 11765 sgd_solver.cpp:106] Iteration 25200, lr = 0.2
I0316 15:06:29.029786 11765 solver.cpp:228] Iteration 25300, loss = 3.43394
I0316 15:06:29.030539 11765 solver.cpp:244]     Train net output #0: loss = 3.43394 (* 1 = 3.43394 loss)
I0316 15:06:29.031033 11765 sgd_solver.cpp:106] Iteration 25300, lr = 0.2
I0316 15:07:48.813451 11765 solver.cpp:228] Iteration 25400, loss = 3.48326
I0316 15:07:48.813603 11765 solver.cpp:244]     Train net output #0: loss = 3.48326 (* 1 = 3.48326 loss)
I0316 15:07:48.880962 11765 sgd_solver.cpp:106] Iteration 25400, lr = 0.2
I0316 15:09:06.728238 11765 solver.cpp:228] Iteration 25500, loss = 3.76775
I0316 15:09:06.728389 11765 solver.cpp:244]     Train net output #0: loss = 3.76775 (* 1 = 3.76775 loss)
I0316 15:09:06.789563 11765 sgd_solver.cpp:106] Iteration 25500, lr = 0.2
I0316 15:10:24.593014 11765 solver.cpp:228] Iteration 25600, loss = 3.63414
I0316 15:10:24.593200 11765 solver.cpp:244]     Train net output #0: loss = 3.63414 (* 1 = 3.63414 loss)
I0316 15:10:24.653162 11765 sgd_solver.cpp:106] Iteration 25600, lr = 0.2
I0316 15:11:40.739629 11765 solver.cpp:228] Iteration 25700, loss = 3.56131
I0316 15:11:40.739773 11765 solver.cpp:244]     Train net output #0: loss = 3.56131 (* 1 = 3.56131 loss)
I0316 15:11:40.802894 11765 sgd_solver.cpp:106] Iteration 25700, lr = 0.2
I0316 15:12:55.805865 11765 solver.cpp:228] Iteration 25800, loss = 3.88992
I0316 15:12:55.806818 11765 solver.cpp:244]     Train net output #0: loss = 3.88992 (* 1 = 3.88992 loss)
I0316 15:12:55.861939 11765 sgd_solver.cpp:106] Iteration 25800, lr = 0.2
I0316 15:14:12.130296 11765 solver.cpp:228] Iteration 25900, loss = 3.60804
I0316 15:14:12.130437 11765 solver.cpp:244]     Train net output #0: loss = 3.60804 (* 1 = 3.60804 loss)
I0316 15:14:12.187047 11765 sgd_solver.cpp:106] Iteration 25900, lr = 0.2
I0316 15:15:28.828002 11765 solver.cpp:337] Iteration 26000, Testing net (#0)
I0316 15:16:41.154906 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.21946
I0316 15:16:41.155058 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.45888
I0316 15:16:41.155088 11765 solver.cpp:404]     Test net output #2: loss = 3.82346 (* 1 = 3.82346 loss)
I0316 15:16:41.906025 11765 solver.cpp:228] Iteration 26000, loss = 3.22541
I0316 15:16:41.906239 11765 solver.cpp:244]     Train net output #0: loss = 3.22541 (* 1 = 3.22541 loss)
I0316 15:16:41.968806 11765 sgd_solver.cpp:106] Iteration 26000, lr = 0.2
I0316 15:17:57.110607 11765 solver.cpp:228] Iteration 26100, loss = 3.63277
I0316 15:17:57.111868 11765 solver.cpp:244]     Train net output #0: loss = 3.63277 (* 1 = 3.63277 loss)
I0316 15:17:57.131553 11765 sgd_solver.cpp:106] Iteration 26100, lr = 0.2
I0316 15:19:13.776801 11765 solver.cpp:228] Iteration 26200, loss = 3.40469
I0316 15:19:13.777092 11765 solver.cpp:244]     Train net output #0: loss = 3.40469 (* 1 = 3.40469 loss)
I0316 15:19:13.796082 11765 sgd_solver.cpp:106] Iteration 26200, lr = 0.2
I0316 15:20:29.751237 11765 solver.cpp:228] Iteration 26300, loss = 3.39544
I0316 15:20:29.751374 11765 solver.cpp:244]     Train net output #0: loss = 3.39544 (* 1 = 3.39544 loss)
I0316 15:20:29.812747 11765 sgd_solver.cpp:106] Iteration 26300, lr = 0.2
I0316 15:21:44.529944 11765 solver.cpp:228] Iteration 26400, loss = 3.27361
I0316 15:21:44.530089 11765 solver.cpp:244]     Train net output #0: loss = 3.27361 (* 1 = 3.27361 loss)
I0316 15:21:44.587786 11765 sgd_solver.cpp:106] Iteration 26400, lr = 0.2
I0316 15:22:59.002535 11765 solver.cpp:228] Iteration 26500, loss = 3.39261
I0316 15:22:59.002707 11765 solver.cpp:244]     Train net output #0: loss = 3.39261 (* 1 = 3.39261 loss)
I0316 15:22:59.061278 11765 sgd_solver.cpp:106] Iteration 26500, lr = 0.2
I0316 15:24:11.256281 11765 solver.cpp:228] Iteration 26600, loss = 3.49019
I0316 15:24:11.257153 11765 solver.cpp:244]     Train net output #0: loss = 3.49019 (* 1 = 3.49019 loss)
I0316 15:24:11.270056 11765 sgd_solver.cpp:106] Iteration 26600, lr = 0.2
I0316 15:25:26.706651 11765 solver.cpp:228] Iteration 26700, loss = 3.54211
I0316 15:25:26.706820 11765 solver.cpp:244]     Train net output #0: loss = 3.54211 (* 1 = 3.54211 loss)
I0316 15:25:26.777716 11765 sgd_solver.cpp:106] Iteration 26700, lr = 0.2
I0316 15:26:41.373577 11765 solver.cpp:228] Iteration 26800, loss = 3.71985
I0316 15:26:41.374845 11765 solver.cpp:244]     Train net output #0: loss = 3.71985 (* 1 = 3.71985 loss)
I0316 15:26:41.431244 11765 sgd_solver.cpp:106] Iteration 26800, lr = 0.2
I0316 15:27:55.777937 11765 solver.cpp:228] Iteration 26900, loss = 3.29556
I0316 15:27:55.778043 11765 solver.cpp:244]     Train net output #0: loss = 3.29556 (* 1 = 3.29556 loss)
I0316 15:27:55.840030 11765 sgd_solver.cpp:106] Iteration 26900, lr = 0.2
I0316 15:29:11.020630 11765 solver.cpp:337] Iteration 27000, Testing net (#0)
I0316 15:30:23.306151 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.23064
I0316 15:30:23.306316 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.47842
I0316 15:30:23.306350 11765 solver.cpp:404]     Test net output #2: loss = 3.72626 (* 1 = 3.72626 loss)
I0316 15:30:23.941249 11765 solver.cpp:228] Iteration 27000, loss = 3.82371
I0316 15:30:23.941293 11765 solver.cpp:244]     Train net output #0: loss = 3.82371 (* 1 = 3.82371 loss)
I0316 15:30:24.011572 11765 sgd_solver.cpp:106] Iteration 27000, lr = 0.2
I0316 15:31:37.347218 11765 solver.cpp:228] Iteration 27100, loss = 3.62181
I0316 15:31:37.348414 11765 solver.cpp:244]     Train net output #0: loss = 3.62181 (* 1 = 3.62181 loss)
I0316 15:31:37.405809 11765 sgd_solver.cpp:106] Iteration 27100, lr = 0.2
I0316 15:32:55.851246 11765 solver.cpp:228] Iteration 27200, loss = 3.5979
I0316 15:32:55.851410 11765 solver.cpp:244]     Train net output #0: loss = 3.5979 (* 1 = 3.5979 loss)
I0316 15:32:55.920763 11765 sgd_solver.cpp:106] Iteration 27200, lr = 0.2
I0316 15:34:10.550087 11765 solver.cpp:228] Iteration 27300, loss = 3.36079
I0316 15:34:10.550217 11765 solver.cpp:244]     Train net output #0: loss = 3.36079 (* 1 = 3.36079 loss)
I0316 15:34:10.608903 11765 sgd_solver.cpp:106] Iteration 27300, lr = 0.2
I0316 15:35:25.529711 11765 solver.cpp:228] Iteration 27400, loss = 3.13096
I0316 15:35:25.529877 11765 solver.cpp:244]     Train net output #0: loss = 3.13096 (* 1 = 3.13096 loss)
I0316 15:35:25.589551 11765 sgd_solver.cpp:106] Iteration 27400, lr = 0.2
I0316 15:36:40.865797 11765 solver.cpp:228] Iteration 27500, loss = 3.94779
I0316 15:36:40.865932 11765 solver.cpp:244]     Train net output #0: loss = 3.94779 (* 1 = 3.94779 loss)
I0316 15:36:40.933272 11765 sgd_solver.cpp:106] Iteration 27500, lr = 0.2
I0316 15:37:56.021257 11765 solver.cpp:228] Iteration 27600, loss = 3.9448
I0316 15:37:56.021467 11765 solver.cpp:244]     Train net output #0: loss = 3.9448 (* 1 = 3.9448 loss)
I0316 15:37:56.080570 11765 sgd_solver.cpp:106] Iteration 27600, lr = 0.2
I0316 15:39:10.026742 11765 solver.cpp:228] Iteration 27700, loss = 3.44624
I0316 15:39:10.026990 11765 solver.cpp:244]     Train net output #0: loss = 3.44624 (* 1 = 3.44624 loss)
I0316 15:39:10.079291 11765 sgd_solver.cpp:106] Iteration 27700, lr = 0.2
I0316 15:40:23.478596 11765 solver.cpp:228] Iteration 27800, loss = 3.24351
I0316 15:40:23.478723 11765 solver.cpp:244]     Train net output #0: loss = 3.24351 (* 1 = 3.24351 loss)
I0316 15:40:23.546325 11765 sgd_solver.cpp:106] Iteration 27800, lr = 0.2
I0316 15:41:35.681098 11765 solver.cpp:228] Iteration 27900, loss = 3.27604
I0316 15:41:35.681262 11765 solver.cpp:244]     Train net output #0: loss = 3.27604 (* 1 = 3.27604 loss)
I0316 15:41:35.737798 11765 sgd_solver.cpp:106] Iteration 27900, lr = 0.2
I0316 15:42:48.756489 11765 solver.cpp:337] Iteration 28000, Testing net (#0)
I0316 15:44:01.043184 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.19138
I0316 15:44:01.043345 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.41504
I0316 15:44:01.043373 11765 solver.cpp:404]     Test net output #2: loss = 4.11094 (* 1 = 4.11094 loss)
I0316 15:44:01.711709 11765 solver.cpp:228] Iteration 28000, loss = 3.69581
I0316 15:44:01.711984 11765 solver.cpp:244]     Train net output #0: loss = 3.69581 (* 1 = 3.69581 loss)
I0316 15:44:01.797245 11765 sgd_solver.cpp:106] Iteration 28000, lr = 0.2
I0316 15:45:15.267266 11765 solver.cpp:228] Iteration 28100, loss = 3.50833
I0316 15:45:15.267443 11765 solver.cpp:244]     Train net output #0: loss = 3.50833 (* 1 = 3.50833 loss)
I0316 15:45:15.377570 11765 sgd_solver.cpp:106] Iteration 28100, lr = 0.2
I0316 15:46:28.141764 11765 solver.cpp:228] Iteration 28200, loss = 3.84704
I0316 15:46:28.141962 11765 solver.cpp:244]     Train net output #0: loss = 3.84704 (* 1 = 3.84704 loss)
I0316 15:46:28.206843 11765 sgd_solver.cpp:106] Iteration 28200, lr = 0.2
I0316 15:47:45.112393 11765 solver.cpp:228] Iteration 28300, loss = 3.03936
I0316 15:47:45.112596 11765 solver.cpp:244]     Train net output #0: loss = 3.03936 (* 1 = 3.03936 loss)
I0316 15:47:45.169805 11765 sgd_solver.cpp:106] Iteration 28300, lr = 0.2
I0316 15:49:02.106250 11765 solver.cpp:228] Iteration 28400, loss = 3.70453
I0316 15:49:02.106665 11765 solver.cpp:244]     Train net output #0: loss = 3.70453 (* 1 = 3.70453 loss)
I0316 15:49:02.113811 11765 sgd_solver.cpp:106] Iteration 28400, lr = 0.2
I0316 15:50:23.073602 11765 solver.cpp:228] Iteration 28500, loss = 3.36109
I0316 15:50:23.073735 11765 solver.cpp:244]     Train net output #0: loss = 3.36109 (* 1 = 3.36109 loss)
I0316 15:50:23.132748 11765 sgd_solver.cpp:106] Iteration 28500, lr = 0.2
I0316 15:51:42.872588 11765 solver.cpp:228] Iteration 28600, loss = 3.49518
I0316 15:51:42.872798 11765 solver.cpp:244]     Train net output #0: loss = 3.49518 (* 1 = 3.49518 loss)
I0316 15:51:42.929041 11765 sgd_solver.cpp:106] Iteration 28600, lr = 0.2
I0316 15:52:59.072999 11765 solver.cpp:228] Iteration 28700, loss = 3.66238
I0316 15:52:59.073166 11765 solver.cpp:244]     Train net output #0: loss = 3.66238 (* 1 = 3.66238 loss)
I0316 15:52:59.131769 11765 sgd_solver.cpp:106] Iteration 28700, lr = 0.2
I0316 15:54:13.574769 11765 solver.cpp:228] Iteration 28800, loss = 3.67696
I0316 15:54:13.574921 11765 solver.cpp:244]     Train net output #0: loss = 3.67696 (* 1 = 3.67696 loss)
I0316 15:54:13.632256 11765 sgd_solver.cpp:106] Iteration 28800, lr = 0.2
I0316 15:55:28.115839 11765 solver.cpp:228] Iteration 28900, loss = 3.52091
I0316 15:55:28.115944 11765 solver.cpp:244]     Train net output #0: loss = 3.52091 (* 1 = 3.52091 loss)
I0316 15:55:28.184383 11765 sgd_solver.cpp:106] Iteration 28900, lr = 0.2
I0316 15:56:40.381613 11765 solver.cpp:337] Iteration 29000, Testing net (#0)
I0316 15:57:52.594319 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.2308
I0316 15:57:52.594457 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.47736
I0316 15:57:52.594470 11765 solver.cpp:404]     Test net output #2: loss = 3.74265 (* 1 = 3.74265 loss)
I0316 15:57:53.230608 11765 solver.cpp:228] Iteration 29000, loss = 3.22736
I0316 15:57:53.230674 11765 solver.cpp:244]     Train net output #0: loss = 3.22736 (* 1 = 3.22736 loss)
I0316 15:57:53.310824 11765 sgd_solver.cpp:106] Iteration 29000, lr = 0.2
I0316 15:59:09.342905 11765 solver.cpp:228] Iteration 29100, loss = 3.71138
I0316 15:59:09.343147 11765 solver.cpp:244]     Train net output #0: loss = 3.71138 (* 1 = 3.71138 loss)
I0316 15:59:09.430640 11765 sgd_solver.cpp:106] Iteration 29100, lr = 0.2
I0316 16:00:25.286489 11765 solver.cpp:228] Iteration 29200, loss = 3.57751
I0316 16:00:25.286654 11765 solver.cpp:244]     Train net output #0: loss = 3.57751 (* 1 = 3.57751 loss)
I0316 16:00:25.372223 11765 sgd_solver.cpp:106] Iteration 29200, lr = 0.2
I0316 16:01:42.537004 11765 solver.cpp:228] Iteration 29300, loss = 3.46846
I0316 16:01:42.537159 11765 solver.cpp:244]     Train net output #0: loss = 3.46846 (* 1 = 3.46846 loss)
I0316 16:01:42.608198 11765 sgd_solver.cpp:106] Iteration 29300, lr = 0.2
I0316 16:02:56.597117 11765 solver.cpp:228] Iteration 29400, loss = 3.54985
I0316 16:02:56.597252 11765 solver.cpp:244]     Train net output #0: loss = 3.54985 (* 1 = 3.54985 loss)
I0316 16:02:56.655884 11765 sgd_solver.cpp:106] Iteration 29400, lr = 0.2
I0316 16:04:10.833887 11765 solver.cpp:228] Iteration 29500, loss = 3.43451
I0316 16:04:10.834065 11765 solver.cpp:244]     Train net output #0: loss = 3.43451 (* 1 = 3.43451 loss)
I0316 16:04:10.891083 11765 sgd_solver.cpp:106] Iteration 29500, lr = 0.2
I0316 16:05:29.188709 11765 solver.cpp:228] Iteration 29600, loss = 3.27363
I0316 16:05:29.188848 11765 solver.cpp:244]     Train net output #0: loss = 3.27363 (* 1 = 3.27363 loss)
I0316 16:05:29.247370 11765 sgd_solver.cpp:106] Iteration 29600, lr = 0.2
I0316 16:06:43.937629 11765 solver.cpp:228] Iteration 29700, loss = 3.3497
I0316 16:06:43.937772 11765 solver.cpp:244]     Train net output #0: loss = 3.3497 (* 1 = 3.3497 loss)
I0316 16:06:43.996393 11765 sgd_solver.cpp:106] Iteration 29700, lr = 0.2
I0316 16:07:57.017598 11765 solver.cpp:228] Iteration 29800, loss = 3.25488
I0316 16:07:57.017757 11765 solver.cpp:244]     Train net output #0: loss = 3.25488 (* 1 = 3.25488 loss)
I0316 16:07:57.073678 11765 sgd_solver.cpp:106] Iteration 29800, lr = 0.2
I0316 16:09:09.572674 11765 solver.cpp:228] Iteration 29900, loss = 3.49233
I0316 16:09:09.572815 11765 solver.cpp:244]     Train net output #0: loss = 3.49233 (* 1 = 3.49233 loss)
I0316 16:09:09.628088 11765 sgd_solver.cpp:106] Iteration 29900, lr = 0.2
I0316 16:10:22.689134 11765 solver.cpp:337] Iteration 30000, Testing net (#0)
I0316 16:11:35.602726 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.23456
I0316 16:11:35.602881 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.4846
I0316 16:11:35.602910 11765 solver.cpp:404]     Test net output #2: loss = 3.68833 (* 1 = 3.68833 loss)
I0316 16:11:36.236294 11765 solver.cpp:228] Iteration 30000, loss = 3.5117
I0316 16:11:36.236336 11765 solver.cpp:244]     Train net output #0: loss = 3.5117 (* 1 = 3.5117 loss)
I0316 16:11:36.309032 11765 sgd_solver.cpp:106] Iteration 30000, lr = 0.2
I0316 16:12:49.381702 11765 solver.cpp:228] Iteration 30100, loss = 3.08902
I0316 16:12:49.381907 11765 solver.cpp:244]     Train net output #0: loss = 3.08902 (* 1 = 3.08902 loss)
I0316 16:12:49.477545 11765 sgd_solver.cpp:106] Iteration 30100, lr = 0.2
I0316 16:14:05.316332 11765 solver.cpp:228] Iteration 30200, loss = 3.63743
I0316 16:14:05.316452 11765 solver.cpp:244]     Train net output #0: loss = 3.63743 (* 1 = 3.63743 loss)
I0316 16:14:05.377096 11765 sgd_solver.cpp:106] Iteration 30200, lr = 0.2
I0316 16:15:19.764667 11765 solver.cpp:228] Iteration 30300, loss = 3.56567
I0316 16:15:19.764809 11765 solver.cpp:244]     Train net output #0: loss = 3.56567 (* 1 = 3.56567 loss)
I0316 16:15:19.834743 11765 sgd_solver.cpp:106] Iteration 30300, lr = 0.2
I0316 16:16:35.464879 11765 solver.cpp:228] Iteration 30400, loss = 3.47632
I0316 16:16:35.465034 11765 solver.cpp:244]     Train net output #0: loss = 3.47632 (* 1 = 3.47632 loss)
I0316 16:16:35.524533 11765 sgd_solver.cpp:106] Iteration 30400, lr = 0.2
I0316 16:17:47.954777 11765 solver.cpp:228] Iteration 30500, loss = 3.20334
I0316 16:17:47.954910 11765 solver.cpp:244]     Train net output #0: loss = 3.20334 (* 1 = 3.20334 loss)
I0316 16:17:48.013563 11765 sgd_solver.cpp:106] Iteration 30500, lr = 0.2
I0316 16:19:03.711189 11765 solver.cpp:228] Iteration 30600, loss = 3.37813
I0316 16:19:03.711355 11765 solver.cpp:244]     Train net output #0: loss = 3.37813 (* 1 = 3.37813 loss)
I0316 16:19:03.774320 11765 sgd_solver.cpp:106] Iteration 30600, lr = 0.2
I0316 16:20:20.470404 11765 solver.cpp:228] Iteration 30700, loss = 3.59946
I0316 16:20:20.470561 11765 solver.cpp:244]     Train net output #0: loss = 3.59946 (* 1 = 3.59946 loss)
I0316 16:20:20.538105 11765 sgd_solver.cpp:106] Iteration 30700, lr = 0.2
I0316 16:21:35.141453 11765 solver.cpp:228] Iteration 30800, loss = 3.23192
I0316 16:21:35.141631 11765 solver.cpp:244]     Train net output #0: loss = 3.23192 (* 1 = 3.23192 loss)
I0316 16:21:35.200243 11765 sgd_solver.cpp:106] Iteration 30800, lr = 0.2
I0316 16:22:50.341053 11765 solver.cpp:228] Iteration 30900, loss = 3.50874
I0316 16:22:50.341159 11765 solver.cpp:244]     Train net output #0: loss = 3.50874 (* 1 = 3.50874 loss)
I0316 16:22:50.400210 11765 sgd_solver.cpp:106] Iteration 30900, lr = 0.2
I0316 16:24:03.274883 11765 solver.cpp:337] Iteration 31000, Testing net (#0)
I0316 16:25:15.684252 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.22576
I0316 16:25:15.684423 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.47168
I0316 16:25:15.684453 11765 solver.cpp:404]     Test net output #2: loss = 3.75495 (* 1 = 3.75495 loss)
I0316 16:25:16.319033 11765 solver.cpp:228] Iteration 31000, loss = 3.49794
I0316 16:25:16.319073 11765 solver.cpp:244]     Train net output #0: loss = 3.49794 (* 1 = 3.49794 loss)
I0316 16:25:16.387445 11765 sgd_solver.cpp:106] Iteration 31000, lr = 0.2
I0316 16:26:28.401041 11765 solver.cpp:228] Iteration 31100, loss = 3.0741
I0316 16:26:28.401206 11765 solver.cpp:244]     Train net output #0: loss = 3.0741 (* 1 = 3.0741 loss)
I0316 16:26:28.502938 11765 sgd_solver.cpp:106] Iteration 31100, lr = 0.2
I0316 16:27:40.809550 11765 solver.cpp:228] Iteration 31200, loss = 3.54053
I0316 16:27:40.809676 11765 solver.cpp:244]     Train net output #0: loss = 3.54053 (* 1 = 3.54053 loss)
I0316 16:27:40.874325 11765 sgd_solver.cpp:106] Iteration 31200, lr = 0.2
I0316 16:28:57.163542 11765 solver.cpp:228] Iteration 31300, loss = 3.59123
I0316 16:28:57.163715 11765 solver.cpp:244]     Train net output #0: loss = 3.59123 (* 1 = 3.59123 loss)
I0316 16:28:57.247200 11765 sgd_solver.cpp:106] Iteration 31300, lr = 0.2
I0316 16:30:11.902933 11765 solver.cpp:228] Iteration 31400, loss = 3.12984
I0316 16:30:11.903057 11765 solver.cpp:244]     Train net output #0: loss = 3.12984 (* 1 = 3.12984 loss)
I0316 16:30:11.964488 11765 sgd_solver.cpp:106] Iteration 31400, lr = 0.2
I0316 16:31:28.342428 11765 solver.cpp:228] Iteration 31500, loss = 2.84335
I0316 16:31:28.342538 11765 solver.cpp:244]     Train net output #0: loss = 2.84335 (* 1 = 2.84335 loss)
I0316 16:31:28.401872 11765 sgd_solver.cpp:106] Iteration 31500, lr = 0.2
I0316 16:32:44.540561 11765 solver.cpp:228] Iteration 31600, loss = 3.87896
I0316 16:32:44.540719 11765 solver.cpp:244]     Train net output #0: loss = 3.87896 (* 1 = 3.87896 loss)
I0316 16:32:44.609346 11765 sgd_solver.cpp:106] Iteration 31600, lr = 0.2
I0316 16:34:01.233330 11765 solver.cpp:228] Iteration 31700, loss = 3.52779
I0316 16:34:01.234123 11765 solver.cpp:244]     Train net output #0: loss = 3.52779 (* 1 = 3.52779 loss)
I0316 16:34:01.246978 11765 sgd_solver.cpp:106] Iteration 31700, lr = 0.2
I0316 16:35:19.317759 11765 solver.cpp:228] Iteration 31800, loss = 3.76118
I0316 16:35:19.318323 11765 solver.cpp:244]     Train net output #0: loss = 3.76118 (* 1 = 3.76118 loss)
I0316 16:35:19.383357 11765 sgd_solver.cpp:106] Iteration 31800, lr = 0.2
I0316 16:36:32.958814 11765 solver.cpp:228] Iteration 31900, loss = 3.13542
I0316 16:36:32.958961 11765 solver.cpp:244]     Train net output #0: loss = 3.13542 (* 1 = 3.13542 loss)
I0316 16:36:33.012828 11765 sgd_solver.cpp:106] Iteration 31900, lr = 0.2
I0316 16:37:46.146302 11765 solver.cpp:337] Iteration 32000, Testing net (#0)
I0316 16:38:58.413853 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.22326
I0316 16:38:58.414011 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.46736
I0316 16:38:58.414041 11765 solver.cpp:404]     Test net output #2: loss = 3.80542 (* 1 = 3.80542 loss)
I0316 16:38:59.047382 11765 solver.cpp:228] Iteration 32000, loss = 3.41514
I0316 16:38:59.047464 11765 solver.cpp:244]     Train net output #0: loss = 3.41514 (* 1 = 3.41514 loss)
I0316 16:38:59.152966 11765 sgd_solver.cpp:106] Iteration 32000, lr = 0.2
I0316 16:40:11.283126 11765 solver.cpp:228] Iteration 32100, loss = 3.48279
I0316 16:40:11.283356 11765 solver.cpp:244]     Train net output #0: loss = 3.48279 (* 1 = 3.48279 loss)
I0316 16:40:11.376755 11765 sgd_solver.cpp:106] Iteration 32100, lr = 0.2
I0316 16:41:25.248337 11765 solver.cpp:228] Iteration 32200, loss = 3.41756
I0316 16:41:25.248494 11765 solver.cpp:244]     Train net output #0: loss = 3.41756 (* 1 = 3.41756 loss)
I0316 16:41:25.309478 11765 sgd_solver.cpp:106] Iteration 32200, lr = 0.2
I0316 16:42:37.489258 11765 solver.cpp:228] Iteration 32300, loss = 3.60823
I0316 16:42:37.489405 11765 solver.cpp:244]     Train net output #0: loss = 3.60823 (* 1 = 3.60823 loss)
I0316 16:42:37.552986 11765 sgd_solver.cpp:106] Iteration 32300, lr = 0.2
I0316 16:43:50.568902 11765 solver.cpp:228] Iteration 32400, loss = 3.47367
I0316 16:43:50.569037 11765 solver.cpp:244]     Train net output #0: loss = 3.47367 (* 1 = 3.47367 loss)
I0316 16:43:50.627689 11765 sgd_solver.cpp:106] Iteration 32400, lr = 0.2
I0316 16:45:01.930263 11765 solver.cpp:228] Iteration 32500, loss = 3.53276
I0316 16:45:01.930418 11765 solver.cpp:244]     Train net output #0: loss = 3.53276 (* 1 = 3.53276 loss)
I0316 16:45:01.987737 11765 sgd_solver.cpp:106] Iteration 32500, lr = 0.2
I0316 16:46:13.183398 11765 solver.cpp:228] Iteration 32600, loss = 2.98158
I0316 16:46:13.183507 11765 solver.cpp:244]     Train net output #0: loss = 2.98158 (* 1 = 2.98158 loss)
I0316 16:46:13.242218 11765 sgd_solver.cpp:106] Iteration 32600, lr = 0.2
I0316 16:47:25.400014 11765 solver.cpp:228] Iteration 32700, loss = 3.52925
I0316 16:47:25.400192 11765 solver.cpp:244]     Train net output #0: loss = 3.52925 (* 1 = 3.52925 loss)
I0316 16:47:25.458787 11765 sgd_solver.cpp:106] Iteration 32700, lr = 0.2
I0316 16:48:37.495627 11765 solver.cpp:228] Iteration 32800, loss = 3.295
I0316 16:48:37.495749 11765 solver.cpp:244]     Train net output #0: loss = 3.295 (* 1 = 3.295 loss)
I0316 16:48:37.555418 11765 sgd_solver.cpp:106] Iteration 32800, lr = 0.2
I0316 16:49:50.166779 11765 solver.cpp:228] Iteration 32900, loss = 3.39642
I0316 16:49:50.166921 11765 solver.cpp:244]     Train net output #0: loss = 3.39642 (* 1 = 3.39642 loss)
I0316 16:49:50.227123 11765 sgd_solver.cpp:106] Iteration 32900, lr = 0.2
I0316 16:51:02.290900 11765 solver.cpp:337] Iteration 33000, Testing net (#0)
I0316 16:52:14.443109 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.23008
I0316 16:52:14.443265 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.4716
I0316 16:52:14.443292 11765 solver.cpp:404]     Test net output #2: loss = 3.75947 (* 1 = 3.75947 loss)
I0316 16:52:15.079463 11765 solver.cpp:228] Iteration 33000, loss = 3.52803
I0316 16:52:15.079501 11765 solver.cpp:244]     Train net output #0: loss = 3.52803 (* 1 = 3.52803 loss)
I0316 16:52:15.146978 11765 sgd_solver.cpp:106] Iteration 33000, lr = 0.2
I0316 16:53:27.098304 11765 solver.cpp:228] Iteration 33100, loss = 3.89573
I0316 16:53:27.098461 11765 solver.cpp:244]     Train net output #0: loss = 3.89573 (* 1 = 3.89573 loss)
I0316 16:53:27.187764 11765 sgd_solver.cpp:106] Iteration 33100, lr = 0.2
I0316 16:54:39.124086 11765 solver.cpp:228] Iteration 33200, loss = 3.18416
I0316 16:54:39.124296 11765 solver.cpp:244]     Train net output #0: loss = 3.18416 (* 1 = 3.18416 loss)
I0316 16:54:39.183845 11765 sgd_solver.cpp:106] Iteration 33200, lr = 0.2
I0316 16:55:51.606016 11765 solver.cpp:228] Iteration 33300, loss = 3.53464
I0316 16:55:51.606173 11765 solver.cpp:244]     Train net output #0: loss = 3.53464 (* 1 = 3.53464 loss)
I0316 16:55:51.662740 11765 sgd_solver.cpp:106] Iteration 33300, lr = 0.2
I0316 16:57:04.971019 11765 solver.cpp:228] Iteration 33400, loss = 3.52648
I0316 16:57:04.971343 11765 solver.cpp:244]     Train net output #0: loss = 3.52648 (* 1 = 3.52648 loss)
I0316 16:57:04.971483 11765 sgd_solver.cpp:106] Iteration 33400, lr = 0.2
I0316 16:58:16.480917 11765 solver.cpp:228] Iteration 33500, loss = 3.21612
I0316 16:58:16.481050 11765 solver.cpp:244]     Train net output #0: loss = 3.21612 (* 1 = 3.21612 loss)
I0316 16:58:16.540144 11765 sgd_solver.cpp:106] Iteration 33500, lr = 0.2
I0316 16:59:28.130957 11765 solver.cpp:228] Iteration 33600, loss = 3.51243
I0316 16:59:28.131147 11765 solver.cpp:244]     Train net output #0: loss = 3.51243 (* 1 = 3.51243 loss)
I0316 16:59:28.189726 11765 sgd_solver.cpp:106] Iteration 33600, lr = 0.2
I0316 17:00:40.693985 11765 solver.cpp:228] Iteration 33700, loss = 3.57774
I0316 17:00:40.694124 11765 solver.cpp:244]     Train net output #0: loss = 3.57774 (* 1 = 3.57774 loss)
I0316 17:00:40.753368 11765 sgd_solver.cpp:106] Iteration 33700, lr = 0.2
I0316 17:01:52.633177 11765 solver.cpp:228] Iteration 33800, loss = 3.52975
I0316 17:01:52.633344 11765 solver.cpp:244]     Train net output #0: loss = 3.52975 (* 1 = 3.52975 loss)
I0316 17:01:52.690186 11765 sgd_solver.cpp:106] Iteration 33800, lr = 0.2
I0316 17:03:04.533385 11765 solver.cpp:228] Iteration 33900, loss = 3.3454
I0316 17:03:04.533545 11765 solver.cpp:244]     Train net output #0: loss = 3.3454 (* 1 = 3.3454 loss)
I0316 17:03:04.571712 11765 sgd_solver.cpp:106] Iteration 33900, lr = 0.2
I0316 17:04:15.511907 11765 solver.cpp:337] Iteration 34000, Testing net (#0)
I0316 17:05:27.820819 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.2414
I0316 17:05:27.820997 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.48822
I0316 17:05:27.821023 11765 solver.cpp:404]     Test net output #2: loss = 3.67191 (* 1 = 3.67191 loss)
I0316 17:05:28.456929 11765 solver.cpp:228] Iteration 34000, loss = 3.55747
I0316 17:05:28.456964 11765 solver.cpp:244]     Train net output #0: loss = 3.55747 (* 1 = 3.55747 loss)
I0316 17:05:28.522972 11765 sgd_solver.cpp:106] Iteration 34000, lr = 0.2
I0316 17:06:40.490175 11765 solver.cpp:228] Iteration 34100, loss = 3.52591
I0316 17:06:40.490315 11765 solver.cpp:244]     Train net output #0: loss = 3.52591 (* 1 = 3.52591 loss)
I0316 17:06:40.600049 11765 sgd_solver.cpp:106] Iteration 34100, lr = 0.2
I0316 17:07:54.292747 11765 solver.cpp:228] Iteration 34200, loss = 3.40299
I0316 17:07:54.292876 11765 solver.cpp:244]     Train net output #0: loss = 3.40299 (* 1 = 3.40299 loss)
I0316 17:07:54.353149 11765 sgd_solver.cpp:106] Iteration 34200, lr = 0.2
I0316 17:09:09.270886 11765 solver.cpp:228] Iteration 34300, loss = 3.50486
I0316 17:09:09.271023 11765 solver.cpp:244]     Train net output #0: loss = 3.50486 (* 1 = 3.50486 loss)
I0316 17:09:09.323843 11765 sgd_solver.cpp:106] Iteration 34300, lr = 0.2
I0316 17:10:25.407486 11765 solver.cpp:228] Iteration 34400, loss = 3.23382
I0316 17:10:25.407625 11765 solver.cpp:244]     Train net output #0: loss = 3.23382 (* 1 = 3.23382 loss)
I0316 17:10:25.466243 11765 sgd_solver.cpp:106] Iteration 34400, lr = 0.2
I0316 17:11:37.990902 11765 solver.cpp:228] Iteration 34500, loss = 3.41861
I0316 17:11:37.991014 11765 solver.cpp:244]     Train net output #0: loss = 3.41861 (* 1 = 3.41861 loss)
I0316 17:11:38.052309 11765 sgd_solver.cpp:106] Iteration 34500, lr = 0.2
I0316 17:12:51.722779 11765 solver.cpp:228] Iteration 34600, loss = 3.20746
I0316 17:12:51.722930 11765 solver.cpp:244]     Train net output #0: loss = 3.20746 (* 1 = 3.20746 loss)
I0316 17:12:51.782954 11765 sgd_solver.cpp:106] Iteration 34600, lr = 0.2
I0316 17:14:04.766533 11765 solver.cpp:228] Iteration 34700, loss = 3.3146
I0316 17:14:04.766717 11765 solver.cpp:244]     Train net output #0: loss = 3.3146 (* 1 = 3.3146 loss)
I0316 17:14:04.823765 11765 sgd_solver.cpp:106] Iteration 34700, lr = 0.2
I0316 17:15:22.986243 11765 solver.cpp:228] Iteration 34800, loss = 3.41644
I0316 17:15:22.986469 11765 solver.cpp:244]     Train net output #0: loss = 3.41644 (* 1 = 3.41644 loss)
I0316 17:15:22.986570 11765 sgd_solver.cpp:106] Iteration 34800, lr = 0.2
I0316 17:16:40.578439 11765 solver.cpp:228] Iteration 34900, loss = 2.94184
I0316 17:16:40.578572 11765 solver.cpp:244]     Train net output #0: loss = 2.94184 (* 1 = 2.94184 loss)
I0316 17:16:40.647547 11765 sgd_solver.cpp:106] Iteration 34900, lr = 0.2
I0316 17:17:55.182834 11765 solver.cpp:337] Iteration 35000, Testing net (#0)
I0316 17:19:08.984514 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.23724
I0316 17:19:08.984655 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.48262
I0316 17:19:08.984668 11765 solver.cpp:404]     Test net output #2: loss = 3.69419 (* 1 = 3.69419 loss)
I0316 17:19:09.622180 11765 solver.cpp:228] Iteration 35000, loss = 3.32885
I0316 17:19:09.622210 11765 solver.cpp:244]     Train net output #0: loss = 3.32885 (* 1 = 3.32885 loss)
I0316 17:19:09.692720 11765 sgd_solver.cpp:106] Iteration 35000, lr = 0.2
I0316 17:20:22.424931 11765 solver.cpp:228] Iteration 35100, loss = 3.35595
I0316 17:20:22.425092 11765 solver.cpp:244]     Train net output #0: loss = 3.35595 (* 1 = 3.35595 loss)
I0316 17:20:22.513797 11765 sgd_solver.cpp:106] Iteration 35100, lr = 0.2
I0316 17:21:35.905624 11765 solver.cpp:228] Iteration 35200, loss = 3.24504
I0316 17:21:35.905753 11765 solver.cpp:244]     Train net output #0: loss = 3.24504 (* 1 = 3.24504 loss)
I0316 17:21:35.964990 11765 sgd_solver.cpp:106] Iteration 35200, lr = 0.2
I0316 17:22:49.090442 11765 solver.cpp:228] Iteration 35300, loss = 3.22419
I0316 17:22:49.090565 11765 solver.cpp:244]     Train net output #0: loss = 3.22419 (* 1 = 3.22419 loss)
I0316 17:22:49.131654 11765 sgd_solver.cpp:106] Iteration 35300, lr = 0.2
I0316 17:24:03.374042 11765 solver.cpp:228] Iteration 35400, loss = 3.42285
I0316 17:24:03.374176 11765 solver.cpp:244]     Train net output #0: loss = 3.42285 (* 1 = 3.42285 loss)
I0316 17:24:03.428364 11765 sgd_solver.cpp:106] Iteration 35400, lr = 0.2
I0316 17:25:16.472820 11765 solver.cpp:228] Iteration 35500, loss = 3.34039
I0316 17:25:16.472965 11765 solver.cpp:244]     Train net output #0: loss = 3.34039 (* 1 = 3.34039 loss)
I0316 17:25:16.526597 11765 sgd_solver.cpp:106] Iteration 35500, lr = 0.2
I0316 17:26:32.027477 11765 solver.cpp:228] Iteration 35600, loss = 3.40446
I0316 17:26:32.027609 11765 solver.cpp:244]     Train net output #0: loss = 3.40446 (* 1 = 3.40446 loss)
I0316 17:26:32.095832 11765 sgd_solver.cpp:106] Iteration 35600, lr = 0.2
I0316 17:27:46.840901 11765 solver.cpp:228] Iteration 35700, loss = 3.21661
I0316 17:27:46.841030 11765 solver.cpp:244]     Train net output #0: loss = 3.21661 (* 1 = 3.21661 loss)
I0316 17:27:46.900143 11765 sgd_solver.cpp:106] Iteration 35700, lr = 0.2
I0316 17:29:01.858227 11765 solver.cpp:228] Iteration 35800, loss = 3.29919
I0316 17:29:01.859405 11765 solver.cpp:244]     Train net output #0: loss = 3.29919 (* 1 = 3.29919 loss)
I0316 17:29:01.908325 11765 sgd_solver.cpp:106] Iteration 35800, lr = 0.2
I0316 17:30:17.222257 11765 solver.cpp:228] Iteration 35900, loss = 3.29181
I0316 17:30:17.222440 11765 solver.cpp:244]     Train net output #0: loss = 3.29181 (* 1 = 3.29181 loss)
I0316 17:30:17.260725 11765 sgd_solver.cpp:106] Iteration 35900, lr = 0.2
I0316 17:31:30.820499 11765 solver.cpp:337] Iteration 36000, Testing net (#0)
I0316 17:32:43.530525 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.24022
I0316 17:32:43.530689 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.48414
I0316 17:32:43.530709 11765 solver.cpp:404]     Test net output #2: loss = 3.71478 (* 1 = 3.71478 loss)
I0316 17:32:44.175510 11765 solver.cpp:228] Iteration 36000, loss = 3.19465
I0316 17:32:44.175545 11765 solver.cpp:244]     Train net output #0: loss = 3.19465 (* 1 = 3.19465 loss)
I0316 17:32:44.248611 11765 sgd_solver.cpp:106] Iteration 36000, lr = 0.2
I0316 17:33:58.745162 11765 solver.cpp:228] Iteration 36100, loss = 3.44034
I0316 17:33:58.745396 11765 solver.cpp:244]     Train net output #0: loss = 3.44034 (* 1 = 3.44034 loss)
I0316 17:33:58.816725 11765 sgd_solver.cpp:106] Iteration 36100, lr = 0.2
I0316 17:35:12.641005 11765 solver.cpp:228] Iteration 36200, loss = 3.08571
I0316 17:35:12.641129 11765 solver.cpp:244]     Train net output #0: loss = 3.08571 (* 1 = 3.08571 loss)
I0316 17:35:12.689337 11765 sgd_solver.cpp:106] Iteration 36200, lr = 0.2
I0316 17:36:26.792299 11765 solver.cpp:228] Iteration 36300, loss = 3.25731
I0316 17:36:26.792454 11765 solver.cpp:244]     Train net output #0: loss = 3.25731 (* 1 = 3.25731 loss)
I0316 17:36:26.881597 11765 sgd_solver.cpp:106] Iteration 36300, lr = 0.2
I0316 17:37:45.206818 11765 solver.cpp:228] Iteration 36400, loss = 3.3989
I0316 17:37:45.206959 11765 solver.cpp:244]     Train net output #0: loss = 3.3989 (* 1 = 3.3989 loss)
I0316 17:37:45.262694 11765 sgd_solver.cpp:106] Iteration 36400, lr = 0.2
I0316 17:39:00.627698 11765 solver.cpp:228] Iteration 36500, loss = 3.10618
I0316 17:39:00.627825 11765 solver.cpp:244]     Train net output #0: loss = 3.10618 (* 1 = 3.10618 loss)
I0316 17:39:00.677790 11765 sgd_solver.cpp:106] Iteration 36500, lr = 0.2
I0316 17:40:13.704758 11765 solver.cpp:228] Iteration 36600, loss = 3.06448
I0316 17:40:13.704922 11765 solver.cpp:244]     Train net output #0: loss = 3.06448 (* 1 = 3.06448 loss)
I0316 17:40:13.769670 11765 sgd_solver.cpp:106] Iteration 36600, lr = 0.2
I0316 17:41:27.189376 11765 solver.cpp:228] Iteration 36700, loss = 3.1349
I0316 17:41:27.189522 11765 solver.cpp:244]     Train net output #0: loss = 3.1349 (* 1 = 3.1349 loss)
I0316 17:41:27.239743 11765 sgd_solver.cpp:106] Iteration 36700, lr = 0.2
I0316 17:42:40.640507 11765 solver.cpp:228] Iteration 36800, loss = 3.30399
I0316 17:42:40.640817 11765 solver.cpp:244]     Train net output #0: loss = 3.30399 (* 1 = 3.30399 loss)
I0316 17:42:40.671242 11765 sgd_solver.cpp:106] Iteration 36800, lr = 0.2
I0316 17:43:57.445657 11765 solver.cpp:228] Iteration 36900, loss = 3.37924
I0316 17:43:57.445945 11765 solver.cpp:244]     Train net output #0: loss = 3.37924 (* 1 = 3.37924 loss)
I0316 17:43:57.469450 11765 sgd_solver.cpp:106] Iteration 36900, lr = 0.2
I0316 17:45:14.658027 11765 solver.cpp:337] Iteration 37000, Testing net (#0)
I0316 17:46:31.776890 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.25374
I0316 17:46:31.777004 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.50864
I0316 17:46:31.777014 11765 solver.cpp:404]     Test net output #2: loss = 3.57189 (* 1 = 3.57189 loss)
I0316 17:46:32.418447 11765 solver.cpp:228] Iteration 37000, loss = 3.44452
I0316 17:46:32.418485 11765 solver.cpp:244]     Train net output #0: loss = 3.44452 (* 1 = 3.44452 loss)
I0316 17:46:32.478922 11765 sgd_solver.cpp:106] Iteration 37000, lr = 0.2
I0316 17:47:48.718472 11765 solver.cpp:228] Iteration 37100, loss = 3.64545
I0316 17:47:48.718628 11765 solver.cpp:244]     Train net output #0: loss = 3.64545 (* 1 = 3.64545 loss)
I0316 17:47:48.796255 11765 sgd_solver.cpp:106] Iteration 37100, lr = 0.2
I0316 17:49:07.784243 11765 solver.cpp:228] Iteration 37200, loss = 3.50564
I0316 17:49:07.784395 11765 solver.cpp:244]     Train net output #0: loss = 3.50564 (* 1 = 3.50564 loss)
I0316 17:49:07.845100 11765 sgd_solver.cpp:106] Iteration 37200, lr = 0.2
I0316 17:50:21.913996 11765 solver.cpp:228] Iteration 37300, loss = 3.15442
I0316 17:50:21.914113 11765 solver.cpp:244]     Train net output #0: loss = 3.15442 (* 1 = 3.15442 loss)
I0316 17:50:21.973584 11765 sgd_solver.cpp:106] Iteration 37300, lr = 0.2
I0316 17:51:34.427738 11765 solver.cpp:228] Iteration 37400, loss = 3.3916
I0316 17:51:34.427894 11765 solver.cpp:244]     Train net output #0: loss = 3.3916 (* 1 = 3.3916 loss)
I0316 17:51:34.486806 11765 sgd_solver.cpp:106] Iteration 37400, lr = 0.2
I0316 17:52:52.943971 11765 solver.cpp:228] Iteration 37500, loss = 3.43053
I0316 17:52:52.944175 11765 solver.cpp:244]     Train net output #0: loss = 3.43053 (* 1 = 3.43053 loss)
I0316 17:52:52.992480 11765 sgd_solver.cpp:106] Iteration 37500, lr = 0.2
I0316 17:54:07.890796 11765 solver.cpp:228] Iteration 37600, loss = 3.25382
I0316 17:54:07.891084 11765 solver.cpp:244]     Train net output #0: loss = 3.25382 (* 1 = 3.25382 loss)
I0316 17:54:07.960824 11765 sgd_solver.cpp:106] Iteration 37600, lr = 0.2
I0316 17:55:24.722241 11765 solver.cpp:228] Iteration 37700, loss = 3.72268
I0316 17:55:24.722388 11765 solver.cpp:244]     Train net output #0: loss = 3.72268 (* 1 = 3.72268 loss)
I0316 17:55:24.780944 11765 sgd_solver.cpp:106] Iteration 37700, lr = 0.2
I0316 17:56:38.508379 11765 solver.cpp:228] Iteration 37800, loss = 3.23584
I0316 17:56:38.508566 11765 solver.cpp:244]     Train net output #0: loss = 3.23584 (* 1 = 3.23584 loss)
I0316 17:56:38.562429 11765 sgd_solver.cpp:106] Iteration 37800, lr = 0.2
I0316 17:57:53.908509 11765 solver.cpp:228] Iteration 37900, loss = 3.34246
I0316 17:57:53.908659 11765 solver.cpp:244]     Train net output #0: loss = 3.34246 (* 1 = 3.34246 loss)
I0316 17:57:53.967188 11765 sgd_solver.cpp:106] Iteration 37900, lr = 0.2
I0316 17:59:08.098155 11765 solver.cpp:337] Iteration 38000, Testing net (#0)
I0316 18:00:21.243979 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.2507
I0316 18:00:21.244120 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.49332
I0316 18:00:21.244153 11765 solver.cpp:404]     Test net output #2: loss = 3.65274 (* 1 = 3.65274 loss)
I0316 18:00:21.881253 11765 solver.cpp:228] Iteration 38000, loss = 3.5691
I0316 18:00:21.881284 11765 solver.cpp:244]     Train net output #0: loss = 3.5691 (* 1 = 3.5691 loss)
I0316 18:00:21.947942 11765 sgd_solver.cpp:106] Iteration 38000, lr = 0.2
I0316 18:01:34.946391 11765 solver.cpp:228] Iteration 38100, loss = 3.07732
I0316 18:01:34.946574 11765 solver.cpp:244]     Train net output #0: loss = 3.07732 (* 1 = 3.07732 loss)
I0316 18:01:35.057911 11765 sgd_solver.cpp:106] Iteration 38100, lr = 0.2
I0316 18:02:50.024593 11765 solver.cpp:228] Iteration 38200, loss = 3.78894
I0316 18:02:50.024729 11765 solver.cpp:244]     Train net output #0: loss = 3.78894 (* 1 = 3.78894 loss)
I0316 18:02:50.091925 11765 sgd_solver.cpp:106] Iteration 38200, lr = 0.2
I0316 18:04:06.142266 11765 solver.cpp:228] Iteration 38300, loss = 3.32319
I0316 18:04:06.142418 11765 solver.cpp:244]     Train net output #0: loss = 3.32319 (* 1 = 3.32319 loss)
I0316 18:04:06.199214 11765 sgd_solver.cpp:106] Iteration 38300, lr = 0.2
I0316 18:05:21.757352 11765 solver.cpp:228] Iteration 38400, loss = 3.17932
I0316 18:05:21.757612 11765 solver.cpp:244]     Train net output #0: loss = 3.17932 (* 1 = 3.17932 loss)
I0316 18:05:21.776062 11765 sgd_solver.cpp:106] Iteration 38400, lr = 0.2
I0316 18:06:37.095254 11765 solver.cpp:228] Iteration 38500, loss = 3.11721
I0316 18:06:37.095438 11765 solver.cpp:244]     Train net output #0: loss = 3.11721 (* 1 = 3.11721 loss)
I0316 18:06:37.139065 11765 sgd_solver.cpp:106] Iteration 38500, lr = 0.2
I0316 18:07:52.625279 11765 solver.cpp:228] Iteration 38600, loss = 3.29233
I0316 18:07:52.625497 11765 solver.cpp:244]     Train net output #0: loss = 3.29233 (* 1 = 3.29233 loss)
I0316 18:07:52.685364 11765 sgd_solver.cpp:106] Iteration 38600, lr = 0.2
I0316 18:09:07.500782 11765 solver.cpp:228] Iteration 38700, loss = 3.27114
I0316 18:09:07.500988 11765 solver.cpp:244]     Train net output #0: loss = 3.27114 (* 1 = 3.27114 loss)
I0316 18:09:07.562844 11765 sgd_solver.cpp:106] Iteration 38700, lr = 0.2
I0316 18:10:27.613143 11765 solver.cpp:228] Iteration 38800, loss = 3.12337
I0316 18:10:27.613317 11765 solver.cpp:244]     Train net output #0: loss = 3.12337 (* 1 = 3.12337 loss)
I0316 18:10:27.673506 11765 sgd_solver.cpp:106] Iteration 38800, lr = 0.2
I0316 18:11:43.084727 11765 solver.cpp:228] Iteration 38900, loss = 3.36096
I0316 18:11:43.084898 11765 solver.cpp:244]     Train net output #0: loss = 3.36096 (* 1 = 3.36096 loss)
I0316 18:11:43.142448 11765 sgd_solver.cpp:106] Iteration 38900, lr = 0.2
I0316 18:13:03.169967 11765 solver.cpp:337] Iteration 39000, Testing net (#0)
I0316 18:14:17.534626 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.2681
I0316 18:14:17.534888 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.52242
I0316 18:14:17.534910 11765 solver.cpp:404]     Test net output #2: loss = 3.50307 (* 1 = 3.50307 loss)
I0316 18:14:18.172646 11765 solver.cpp:228] Iteration 39000, loss = 3.60722
I0316 18:14:18.172705 11765 solver.cpp:244]     Train net output #0: loss = 3.60722 (* 1 = 3.60722 loss)
I0316 18:14:18.240751 11765 sgd_solver.cpp:106] Iteration 39000, lr = 0.2
I0316 18:15:36.668678 11765 solver.cpp:228] Iteration 39100, loss = 3.21584
I0316 18:15:36.669404 11765 solver.cpp:244]     Train net output #0: loss = 3.21584 (* 1 = 3.21584 loss)
I0316 18:15:36.735690 11765 sgd_solver.cpp:106] Iteration 39100, lr = 0.2
I0316 18:16:57.147222 11765 solver.cpp:228] Iteration 39200, loss = 3.23168
I0316 18:16:57.148008 11765 solver.cpp:244]     Train net output #0: loss = 3.23168 (* 1 = 3.23168 loss)
I0316 18:16:57.163592 11765 sgd_solver.cpp:106] Iteration 39200, lr = 0.2
I0316 18:18:14.683614 11765 solver.cpp:228] Iteration 39300, loss = 3.39649
I0316 18:18:14.683768 11765 solver.cpp:244]     Train net output #0: loss = 3.39649 (* 1 = 3.39649 loss)
I0316 18:18:14.745437 11765 sgd_solver.cpp:106] Iteration 39300, lr = 0.2
I0316 18:19:33.915215 11765 solver.cpp:228] Iteration 39400, loss = 3.79723
I0316 18:19:33.915370 11765 solver.cpp:244]     Train net output #0: loss = 3.79723 (* 1 = 3.79723 loss)
I0316 18:19:33.973943 11765 sgd_solver.cpp:106] Iteration 39400, lr = 0.2
I0316 18:20:52.938066 11765 solver.cpp:228] Iteration 39500, loss = 3.26178
I0316 18:20:52.938207 11765 solver.cpp:244]     Train net output #0: loss = 3.26178 (* 1 = 3.26178 loss)
I0316 18:20:52.995939 11765 sgd_solver.cpp:106] Iteration 39500, lr = 0.2
I0316 18:22:09.123924 11765 solver.cpp:228] Iteration 39600, loss = 2.63369
I0316 18:22:09.124070 11765 solver.cpp:244]     Train net output #0: loss = 2.63369 (* 1 = 2.63369 loss)
I0316 18:22:09.182744 11765 sgd_solver.cpp:106] Iteration 39600, lr = 0.2
I0316 18:23:24.835366 11765 solver.cpp:228] Iteration 39700, loss = 3.22475
I0316 18:23:24.836246 11765 solver.cpp:244]     Train net output #0: loss = 3.22475 (* 1 = 3.22475 loss)
I0316 18:23:24.884665 11765 sgd_solver.cpp:106] Iteration 39700, lr = 0.2
I0316 18:24:40.749773 11765 solver.cpp:228] Iteration 39800, loss = 3.24152
I0316 18:24:40.749902 11765 solver.cpp:244]     Train net output #0: loss = 3.24152 (* 1 = 3.24152 loss)
I0316 18:24:40.808562 11765 sgd_solver.cpp:106] Iteration 39800, lr = 0.2
I0316 18:25:55.099925 11765 solver.cpp:228] Iteration 39900, loss = 3.43929
I0316 18:25:55.100101 11765 solver.cpp:244]     Train net output #0: loss = 3.43929 (* 1 = 3.43929 loss)
I0316 18:25:55.155251 11765 sgd_solver.cpp:106] Iteration 39900, lr = 0.2
I0316 18:27:11.227244 11765 solver.cpp:454] Snapshotting to binary proto file snapshots/imageNet_slim_iter_40000.caffemodel
I0316 18:27:11.263605 11765 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/imageNet_slim_iter_40000.solverstate
I0316 18:27:11.271991 11765 solver.cpp:337] Iteration 40000, Testing net (#0)
I0316 18:28:25.986188 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.231
I0316 18:28:25.986364 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.4738
I0316 18:28:25.986395 11765 solver.cpp:404]     Test net output #2: loss = 3.78349 (* 1 = 3.78349 loss)
I0316 18:28:26.625761 11765 solver.cpp:228] Iteration 40000, loss = 3.78389
I0316 18:28:26.625809 11765 solver.cpp:244]     Train net output #0: loss = 3.78389 (* 1 = 3.78389 loss)
I0316 18:28:26.692804 11765 sgd_solver.cpp:106] Iteration 40000, lr = 0.2
I0316 18:29:41.969316 11765 solver.cpp:228] Iteration 40100, loss = 2.92398
I0316 18:29:41.969544 11765 solver.cpp:244]     Train net output #0: loss = 2.92398 (* 1 = 2.92398 loss)
I0316 18:29:42.076545 11765 sgd_solver.cpp:106] Iteration 40100, lr = 0.2
I0316 18:30:59.249903 11765 solver.cpp:228] Iteration 40200, loss = 3.48909
I0316 18:30:59.250082 11765 solver.cpp:244]     Train net output #0: loss = 3.48909 (* 1 = 3.48909 loss)
I0316 18:30:59.315199 11765 sgd_solver.cpp:106] Iteration 40200, lr = 0.2
I0316 18:32:16.927623 11765 solver.cpp:228] Iteration 40300, loss = 3.40751
I0316 18:32:16.927817 11765 solver.cpp:244]     Train net output #0: loss = 3.40751 (* 1 = 3.40751 loss)
I0316 18:32:16.984583 11765 sgd_solver.cpp:106] Iteration 40300, lr = 0.2
I0316 18:33:33.967499 11765 solver.cpp:228] Iteration 40400, loss = 3.04154
I0316 18:33:33.967700 11765 solver.cpp:244]     Train net output #0: loss = 3.04154 (* 1 = 3.04154 loss)
I0316 18:33:33.981241 11765 sgd_solver.cpp:106] Iteration 40400, lr = 0.2
I0316 18:34:54.758376 11765 solver.cpp:228] Iteration 40500, loss = 3.1556
I0316 18:34:54.758580 11765 solver.cpp:244]     Train net output #0: loss = 3.1556 (* 1 = 3.1556 loss)
I0316 18:34:54.886612 11765 sgd_solver.cpp:106] Iteration 40500, lr = 0.2
I0316 18:36:17.940069 11765 solver.cpp:228] Iteration 40600, loss = 3.23676
I0316 18:36:17.940249 11765 solver.cpp:244]     Train net output #0: loss = 3.23676 (* 1 = 3.23676 loss)
I0316 18:36:18.021914 11765 sgd_solver.cpp:106] Iteration 40600, lr = 0.2
I0316 18:37:35.069317 11765 solver.cpp:228] Iteration 40700, loss = 3.22077
I0316 18:37:35.069494 11765 solver.cpp:244]     Train net output #0: loss = 3.22077 (* 1 = 3.22077 loss)
I0316 18:37:35.127418 11765 sgd_solver.cpp:106] Iteration 40700, lr = 0.2
I0316 18:38:56.508698 11765 solver.cpp:228] Iteration 40800, loss = 3.2465
I0316 18:38:56.508880 11765 solver.cpp:244]     Train net output #0: loss = 3.2465 (* 1 = 3.2465 loss)
I0316 18:38:56.590826 11765 sgd_solver.cpp:106] Iteration 40800, lr = 0.2
I0316 18:40:16.171121 11765 solver.cpp:228] Iteration 40900, loss = 3.13582
I0316 18:40:16.171269 11765 solver.cpp:244]     Train net output #0: loss = 3.13582 (* 1 = 3.13582 loss)
I0316 18:40:16.231752 11765 sgd_solver.cpp:106] Iteration 40900, lr = 0.2
I0316 18:41:29.744429 11765 solver.cpp:337] Iteration 41000, Testing net (#0)
I0316 18:42:42.809541 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.25604
I0316 18:42:42.809694 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.50854
I0316 18:42:42.809713 11765 solver.cpp:404]     Test net output #2: loss = 3.571 (* 1 = 3.571 loss)
I0316 18:42:43.524339 11765 solver.cpp:228] Iteration 41000, loss = 3.16315
I0316 18:42:43.524600 11765 solver.cpp:244]     Train net output #0: loss = 3.16315 (* 1 = 3.16315 loss)
I0316 18:42:43.597733 11765 sgd_solver.cpp:106] Iteration 41000, lr = 0.2
I0316 18:44:02.622267 11765 solver.cpp:228] Iteration 41100, loss = 3.24614
I0316 18:44:02.622437 11765 solver.cpp:244]     Train net output #0: loss = 3.24614 (* 1 = 3.24614 loss)
I0316 18:44:02.733350 11765 sgd_solver.cpp:106] Iteration 41100, lr = 0.2
I0316 18:45:18.733711 11765 solver.cpp:228] Iteration 41200, loss = 3.41273
I0316 18:45:18.733856 11765 solver.cpp:244]     Train net output #0: loss = 3.41273 (* 1 = 3.41273 loss)
I0316 18:45:18.790489 11765 sgd_solver.cpp:106] Iteration 41200, lr = 0.2
I0316 18:46:32.645990 11765 solver.cpp:228] Iteration 41300, loss = 3.65657
I0316 18:46:32.646144 11765 solver.cpp:244]     Train net output #0: loss = 3.65657 (* 1 = 3.65657 loss)
I0316 18:46:32.707173 11765 sgd_solver.cpp:106] Iteration 41300, lr = 0.2
I0316 18:47:46.753829 11765 solver.cpp:228] Iteration 41400, loss = 3.03436
I0316 18:47:46.753986 11765 solver.cpp:244]     Train net output #0: loss = 3.03436 (* 1 = 3.03436 loss)
I0316 18:47:46.808946 11765 sgd_solver.cpp:106] Iteration 41400, lr = 0.2
I0316 18:49:01.133743 11765 solver.cpp:228] Iteration 41500, loss = 3.12593
I0316 18:49:01.133878 11765 solver.cpp:244]     Train net output #0: loss = 3.12593 (* 1 = 3.12593 loss)
I0316 18:49:01.192488 11765 sgd_solver.cpp:106] Iteration 41500, lr = 0.2
I0316 18:50:15.289504 11765 solver.cpp:228] Iteration 41600, loss = 2.83525
I0316 18:50:15.289664 11765 solver.cpp:244]     Train net output #0: loss = 2.83525 (* 1 = 2.83525 loss)
I0316 18:50:15.350330 11765 sgd_solver.cpp:106] Iteration 41600, lr = 0.2
I0316 18:51:29.352732 11765 solver.cpp:228] Iteration 41700, loss = 3.21349
I0316 18:51:29.352890 11765 solver.cpp:244]     Train net output #0: loss = 3.21349 (* 1 = 3.21349 loss)
I0316 18:51:29.411206 11765 sgd_solver.cpp:106] Iteration 41700, lr = 0.2
I0316 18:52:43.715229 11765 solver.cpp:228] Iteration 41800, loss = 3.43615
I0316 18:52:43.715369 11765 solver.cpp:244]     Train net output #0: loss = 3.43615 (* 1 = 3.43615 loss)
I0316 18:52:43.773974 11765 sgd_solver.cpp:106] Iteration 41800, lr = 0.2
I0316 18:53:57.016786 11765 solver.cpp:228] Iteration 41900, loss = 3.20493
I0316 18:53:57.016911 11765 solver.cpp:244]     Train net output #0: loss = 3.20493 (* 1 = 3.20493 loss)
I0316 18:53:57.075764 11765 sgd_solver.cpp:106] Iteration 41900, lr = 0.2
I0316 18:55:11.562281 11765 solver.cpp:337] Iteration 42000, Testing net (#0)
I0316 18:56:23.978550 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.24704
I0316 18:56:23.978684 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.49518
I0316 18:56:23.978700 11765 solver.cpp:404]     Test net output #2: loss = 3.63859 (* 1 = 3.63859 loss)
I0316 18:56:24.613219 11765 solver.cpp:228] Iteration 42000, loss = 3.37702
I0316 18:56:24.613257 11765 solver.cpp:244]     Train net output #0: loss = 3.37702 (* 1 = 3.37702 loss)
I0316 18:56:24.674197 11765 sgd_solver.cpp:106] Iteration 42000, lr = 0.2
I0316 18:57:40.646296 11765 solver.cpp:228] Iteration 42100, loss = 2.98741
I0316 18:57:40.646473 11765 solver.cpp:244]     Train net output #0: loss = 2.98741 (* 1 = 2.98741 loss)
I0316 18:57:40.740067 11765 sgd_solver.cpp:106] Iteration 42100, lr = 0.2
I0316 18:58:56.142503 11765 solver.cpp:228] Iteration 42200, loss = 3.34463
I0316 18:58:56.142647 11765 solver.cpp:244]     Train net output #0: loss = 3.34463 (* 1 = 3.34463 loss)
I0316 18:58:56.210656 11765 sgd_solver.cpp:106] Iteration 42200, lr = 0.2
I0316 19:00:11.124182 11765 solver.cpp:228] Iteration 42300, loss = 3.17636
I0316 19:00:11.124349 11765 solver.cpp:244]     Train net output #0: loss = 3.17636 (* 1 = 3.17636 loss)
I0316 19:00:11.185677 11765 sgd_solver.cpp:106] Iteration 42300, lr = 0.2
I0316 19:01:28.034133 11765 solver.cpp:228] Iteration 42400, loss = 3.12731
I0316 19:01:28.034268 11765 solver.cpp:244]     Train net output #0: loss = 3.12731 (* 1 = 3.12731 loss)
I0316 19:01:28.092896 11765 sgd_solver.cpp:106] Iteration 42400, lr = 0.2
I0316 19:02:44.703238 11765 solver.cpp:228] Iteration 42500, loss = 2.70627
I0316 19:02:44.703363 11765 solver.cpp:244]     Train net output #0: loss = 2.70627 (* 1 = 2.70627 loss)
I0316 19:02:44.763034 11765 sgd_solver.cpp:106] Iteration 42500, lr = 0.2
I0316 19:03:59.885274 11765 solver.cpp:228] Iteration 42600, loss = 2.89258
I0316 19:03:59.885423 11765 solver.cpp:244]     Train net output #0: loss = 2.89258 (* 1 = 2.89258 loss)
I0316 19:03:59.942384 11765 sgd_solver.cpp:106] Iteration 42600, lr = 0.2
I0316 19:05:17.381849 11765 solver.cpp:228] Iteration 42700, loss = 3.19162
I0316 19:05:17.381983 11765 solver.cpp:244]     Train net output #0: loss = 3.19162 (* 1 = 3.19162 loss)
I0316 19:05:17.443228 11765 sgd_solver.cpp:106] Iteration 42700, lr = 0.2
I0316 19:06:28.972847 11765 solver.cpp:228] Iteration 42800, loss = 3.19036
I0316 19:06:28.972993 11765 solver.cpp:244]     Train net output #0: loss = 3.19036 (* 1 = 3.19036 loss)
I0316 19:06:29.032718 11765 sgd_solver.cpp:106] Iteration 42800, lr = 0.2
I0316 19:07:44.921914 11765 solver.cpp:228] Iteration 42900, loss = 3.15815
I0316 19:07:44.922056 11765 solver.cpp:244]     Train net output #0: loss = 3.15815 (* 1 = 3.15815 loss)
I0316 19:07:44.981143 11765 sgd_solver.cpp:106] Iteration 42900, lr = 0.2
I0316 19:08:57.017175 11765 solver.cpp:337] Iteration 43000, Testing net (#0)
I0316 19:10:09.151669 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.26252
I0316 19:10:09.151818 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.51332
I0316 19:10:09.151837 11765 solver.cpp:404]     Test net output #2: loss = 3.57982 (* 1 = 3.57982 loss)
I0316 19:10:09.786370 11765 solver.cpp:228] Iteration 43000, loss = 2.99448
I0316 19:10:09.786413 11765 solver.cpp:244]     Train net output #0: loss = 2.99448 (* 1 = 2.99448 loss)
I0316 19:10:09.853843 11765 sgd_solver.cpp:106] Iteration 43000, lr = 0.2
I0316 19:11:24.729840 11765 solver.cpp:228] Iteration 43100, loss = 3.03903
I0316 19:11:24.730047 11765 solver.cpp:244]     Train net output #0: loss = 3.03903 (* 1 = 3.03903 loss)
I0316 19:11:24.813531 11765 sgd_solver.cpp:106] Iteration 43100, lr = 0.2
I0316 19:12:39.499907 11765 solver.cpp:228] Iteration 43200, loss = 3.41691
I0316 19:12:39.500039 11765 solver.cpp:244]     Train net output #0: loss = 3.41691 (* 1 = 3.41691 loss)
I0316 19:12:39.561134 11765 sgd_solver.cpp:106] Iteration 43200, lr = 0.2
I0316 19:13:57.826427 11765 solver.cpp:228] Iteration 43300, loss = 3.04045
I0316 19:13:57.826558 11765 solver.cpp:244]     Train net output #0: loss = 3.04045 (* 1 = 3.04045 loss)
I0316 19:13:57.888550 11765 sgd_solver.cpp:106] Iteration 43300, lr = 0.2
I0316 19:15:14.262233 11765 solver.cpp:228] Iteration 43400, loss = 3.16341
I0316 19:15:14.262362 11765 solver.cpp:244]     Train net output #0: loss = 3.16341 (* 1 = 3.16341 loss)
I0316 19:15:14.320957 11765 sgd_solver.cpp:106] Iteration 43400, lr = 0.2
I0316 19:16:30.962893 11765 solver.cpp:228] Iteration 43500, loss = 3.21915
I0316 19:16:30.962994 11765 solver.cpp:244]     Train net output #0: loss = 3.21915 (* 1 = 3.21915 loss)
I0316 19:16:31.023550 11765 sgd_solver.cpp:106] Iteration 43500, lr = 0.2
I0316 19:17:46.035910 11765 solver.cpp:228] Iteration 43600, loss = 3.26475
I0316 19:17:46.036070 11765 solver.cpp:244]     Train net output #0: loss = 3.26475 (* 1 = 3.26475 loss)
I0316 19:17:46.092041 11765 sgd_solver.cpp:106] Iteration 43600, lr = 0.2
I0316 19:19:02.519093 11765 solver.cpp:228] Iteration 43700, loss = 2.95387
I0316 19:19:02.519222 11765 solver.cpp:244]     Train net output #0: loss = 2.95387 (* 1 = 2.95387 loss)
I0316 19:19:02.577798 11765 sgd_solver.cpp:106] Iteration 43700, lr = 0.2
I0316 19:20:19.824261 11765 solver.cpp:228] Iteration 43800, loss = 3.4115
I0316 19:20:19.824430 11765 solver.cpp:244]     Train net output #0: loss = 3.4115 (* 1 = 3.4115 loss)
I0316 19:20:19.882930 11765 sgd_solver.cpp:106] Iteration 43800, lr = 0.2
I0316 19:21:32.425990 11765 solver.cpp:228] Iteration 43900, loss = 2.79844
I0316 19:21:32.426121 11765 solver.cpp:244]     Train net output #0: loss = 2.79844 (* 1 = 2.79844 loss)
I0316 19:21:32.483204 11765 sgd_solver.cpp:106] Iteration 43900, lr = 0.2
I0316 19:22:47.588345 11765 solver.cpp:337] Iteration 44000, Testing net (#0)
I0316 19:23:59.907840 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.25204
I0316 19:23:59.908007 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.50192
I0316 19:23:59.908035 11765 solver.cpp:404]     Test net output #2: loss = 3.61711 (* 1 = 3.61711 loss)
I0316 19:24:00.543658 11765 solver.cpp:228] Iteration 44000, loss = 2.99111
I0316 19:24:00.543686 11765 solver.cpp:244]     Train net output #0: loss = 2.99111 (* 1 = 2.99111 loss)
I0316 19:24:00.613333 11765 sgd_solver.cpp:106] Iteration 44000, lr = 0.2
I0316 19:25:17.188297 11765 solver.cpp:228] Iteration 44100, loss = 3.29898
I0316 19:25:17.188402 11765 solver.cpp:244]     Train net output #0: loss = 3.29898 (* 1 = 3.29898 loss)
I0316 19:25:17.280402 11765 sgd_solver.cpp:106] Iteration 44100, lr = 0.2
I0316 19:26:32.993588 11765 solver.cpp:228] Iteration 44200, loss = 2.89178
I0316 19:26:32.993736 11765 solver.cpp:244]     Train net output #0: loss = 2.89178 (* 1 = 2.89178 loss)
I0316 19:26:33.057757 11765 sgd_solver.cpp:106] Iteration 44200, lr = 0.2
I0316 19:27:48.767611 11765 solver.cpp:228] Iteration 44300, loss = 3.30146
I0316 19:27:48.767750 11765 solver.cpp:244]     Train net output #0: loss = 3.30146 (* 1 = 3.30146 loss)
I0316 19:27:48.827874 11765 sgd_solver.cpp:106] Iteration 44300, lr = 0.2
I0316 19:29:04.397349 11765 solver.cpp:228] Iteration 44400, loss = 3.15919
I0316 19:29:04.397549 11765 solver.cpp:244]     Train net output #0: loss = 3.15919 (* 1 = 3.15919 loss)
I0316 19:29:04.454073 11765 sgd_solver.cpp:106] Iteration 44400, lr = 0.2
I0316 19:30:23.929633 11765 solver.cpp:228] Iteration 44500, loss = 3.19445
I0316 19:30:23.929790 11765 solver.cpp:244]     Train net output #0: loss = 3.19445 (* 1 = 3.19445 loss)
I0316 19:30:23.988545 11765 sgd_solver.cpp:106] Iteration 44500, lr = 0.2
I0316 19:31:38.127189 11765 solver.cpp:228] Iteration 44600, loss = 3.25991
I0316 19:31:38.127332 11765 solver.cpp:244]     Train net output #0: loss = 3.25991 (* 1 = 3.25991 loss)
I0316 19:31:38.192131 11765 sgd_solver.cpp:106] Iteration 44600, lr = 0.2
I0316 19:32:55.047489 11765 solver.cpp:228] Iteration 44700, loss = 3.11516
I0316 19:32:55.047627 11765 solver.cpp:244]     Train net output #0: loss = 3.11516 (* 1 = 3.11516 loss)
I0316 19:32:55.106230 11765 sgd_solver.cpp:106] Iteration 44700, lr = 0.2
I0316 19:34:09.991190 11765 solver.cpp:228] Iteration 44800, loss = 3.08149
I0316 19:34:09.991364 11765 solver.cpp:244]     Train net output #0: loss = 3.08149 (* 1 = 3.08149 loss)
I0316 19:34:10.002758 11765 sgd_solver.cpp:106] Iteration 44800, lr = 0.2
I0316 19:35:26.737421 11765 solver.cpp:228] Iteration 44900, loss = 3.15929
I0316 19:35:26.737565 11765 solver.cpp:244]     Train net output #0: loss = 3.15929 (* 1 = 3.15929 loss)
I0316 19:35:26.796119 11765 sgd_solver.cpp:106] Iteration 44900, lr = 0.2
I0316 19:36:40.739395 11765 solver.cpp:337] Iteration 45000, Testing net (#0)
I0316 19:37:53.515902 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.25294
I0316 19:37:53.516043 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.50352
I0316 19:37:53.516072 11765 solver.cpp:404]     Test net output #2: loss = 3.60295 (* 1 = 3.60295 loss)
I0316 19:37:54.150352 11765 solver.cpp:228] Iteration 45000, loss = 3.08351
I0316 19:37:54.150383 11765 solver.cpp:244]     Train net output #0: loss = 3.08351 (* 1 = 3.08351 loss)
I0316 19:37:54.217597 11765 sgd_solver.cpp:106] Iteration 45000, lr = 0.2
I0316 19:39:08.558611 11765 solver.cpp:228] Iteration 45100, loss = 2.91176
I0316 19:39:08.558776 11765 solver.cpp:244]     Train net output #0: loss = 2.91176 (* 1 = 2.91176 loss)
I0316 19:39:08.643379 11765 sgd_solver.cpp:106] Iteration 45100, lr = 0.2
I0316 19:40:25.472295 11765 solver.cpp:228] Iteration 45200, loss = 2.96669
I0316 19:40:25.472447 11765 solver.cpp:244]     Train net output #0: loss = 2.96669 (* 1 = 2.96669 loss)
I0316 19:40:25.531919 11765 sgd_solver.cpp:106] Iteration 45200, lr = 0.2
I0316 19:41:41.050564 11765 solver.cpp:228] Iteration 45300, loss = 3.43944
I0316 19:41:41.050719 11765 solver.cpp:244]     Train net output #0: loss = 3.43944 (* 1 = 3.43944 loss)
I0316 19:41:41.103255 11765 sgd_solver.cpp:106] Iteration 45300, lr = 0.2
I0316 19:42:55.933823 11765 solver.cpp:228] Iteration 45400, loss = 3.13841
I0316 19:42:55.934031 11765 solver.cpp:244]     Train net output #0: loss = 3.13841 (* 1 = 3.13841 loss)
I0316 19:42:55.997056 11765 sgd_solver.cpp:106] Iteration 45400, lr = 0.2
I0316 19:44:12.734511 11765 solver.cpp:228] Iteration 45500, loss = 2.89684
I0316 19:44:12.734673 11765 solver.cpp:244]     Train net output #0: loss = 2.89684 (* 1 = 2.89684 loss)
I0316 19:44:12.793520 11765 sgd_solver.cpp:106] Iteration 45500, lr = 0.2
I0316 19:45:25.809442 11765 solver.cpp:228] Iteration 45600, loss = 3.1332
I0316 19:45:25.809543 11765 solver.cpp:244]     Train net output #0: loss = 3.1332 (* 1 = 3.1332 loss)
I0316 19:45:25.864154 11765 sgd_solver.cpp:106] Iteration 45600, lr = 0.2
I0316 19:46:39.852454 11765 solver.cpp:228] Iteration 45700, loss = 3.40282
I0316 19:46:39.852612 11765 solver.cpp:244]     Train net output #0: loss = 3.40282 (* 1 = 3.40282 loss)
I0316 19:46:39.906728 11765 sgd_solver.cpp:106] Iteration 45700, lr = 0.2
I0316 19:47:55.982749 11765 solver.cpp:228] Iteration 45800, loss = 3.16118
I0316 19:47:55.982947 11765 solver.cpp:244]     Train net output #0: loss = 3.16118 (* 1 = 3.16118 loss)
I0316 19:47:56.010306 11765 sgd_solver.cpp:106] Iteration 45800, lr = 0.2
I0316 19:49:09.524065 11765 solver.cpp:228] Iteration 45900, loss = 3.24252
I0316 19:49:09.524884 11765 solver.cpp:244]     Train net output #0: loss = 3.24252 (* 1 = 3.24252 loss)
I0316 19:49:09.572907 11765 sgd_solver.cpp:106] Iteration 45900, lr = 0.2
I0316 19:50:24.744684 11765 solver.cpp:337] Iteration 46000, Testing net (#0)
I0316 19:51:37.291486 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.27952
I0316 19:51:37.291656 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.53664
I0316 19:51:37.291676 11765 solver.cpp:404]     Test net output #2: loss = 3.42271 (* 1 = 3.42271 loss)
I0316 19:51:37.930765 11765 solver.cpp:228] Iteration 46000, loss = 3.05748
I0316 19:51:37.930806 11765 solver.cpp:244]     Train net output #0: loss = 3.05748 (* 1 = 3.05748 loss)
I0316 19:51:37.997365 11765 sgd_solver.cpp:106] Iteration 46000, lr = 0.2
I0316 19:52:51.464037 11765 solver.cpp:228] Iteration 46100, loss = 3.6679
I0316 19:52:51.464210 11765 solver.cpp:244]     Train net output #0: loss = 3.6679 (* 1 = 3.6679 loss)
I0316 19:52:51.552376 11765 sgd_solver.cpp:106] Iteration 46100, lr = 0.2
I0316 19:54:05.934295 11765 solver.cpp:228] Iteration 46200, loss = 3.3555
I0316 19:54:05.934430 11765 solver.cpp:244]     Train net output #0: loss = 3.3555 (* 1 = 3.3555 loss)
I0316 19:54:05.993008 11765 sgd_solver.cpp:106] Iteration 46200, lr = 0.2
I0316 19:55:21.195771 11765 solver.cpp:228] Iteration 46300, loss = 2.85518
I0316 19:55:21.195911 11765 solver.cpp:244]     Train net output #0: loss = 2.85518 (* 1 = 2.85518 loss)
I0316 19:55:21.254057 11765 sgd_solver.cpp:106] Iteration 46300, lr = 0.2
I0316 19:56:35.659019 11765 solver.cpp:228] Iteration 46400, loss = 3.02077
I0316 19:56:35.659173 11765 solver.cpp:244]     Train net output #0: loss = 3.02077 (* 1 = 3.02077 loss)
I0316 19:56:35.714437 11765 sgd_solver.cpp:106] Iteration 46400, lr = 0.2
I0316 19:57:50.991967 11765 solver.cpp:228] Iteration 46500, loss = 3.20705
I0316 19:57:50.992142 11765 solver.cpp:244]     Train net output #0: loss = 3.20705 (* 1 = 3.20705 loss)
I0316 19:57:51.047417 11765 sgd_solver.cpp:106] Iteration 46500, lr = 0.2
I0316 19:59:04.934206 11765 solver.cpp:228] Iteration 46600, loss = 3.14915
I0316 19:59:04.934342 11765 solver.cpp:244]     Train net output #0: loss = 3.14915 (* 1 = 3.14915 loss)
I0316 19:59:04.989452 11765 sgd_solver.cpp:106] Iteration 46600, lr = 0.2
I0316 20:00:17.756559 11765 solver.cpp:228] Iteration 46700, loss = 2.90305
I0316 20:00:17.756670 11765 solver.cpp:244]     Train net output #0: loss = 2.90305 (* 1 = 2.90305 loss)
I0316 20:00:17.811909 11765 sgd_solver.cpp:106] Iteration 46700, lr = 0.2
I0316 20:01:31.455927 11765 solver.cpp:228] Iteration 46800, loss = 3.19177
I0316 20:01:31.456079 11765 solver.cpp:244]     Train net output #0: loss = 3.19177 (* 1 = 3.19177 loss)
I0316 20:01:31.515195 11765 sgd_solver.cpp:106] Iteration 46800, lr = 0.2
I0316 20:02:45.765097 11765 solver.cpp:228] Iteration 46900, loss = 3.33964
I0316 20:02:45.765241 11765 solver.cpp:244]     Train net output #0: loss = 3.33964 (* 1 = 3.33964 loss)
I0316 20:02:45.824080 11765 sgd_solver.cpp:106] Iteration 46900, lr = 0.2
I0316 20:03:57.608171 11765 solver.cpp:337] Iteration 47000, Testing net (#0)
I0316 20:05:09.977408 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.26098
I0316 20:05:09.977526 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.51044
I0316 20:05:09.977541 11765 solver.cpp:404]     Test net output #2: loss = 3.57125 (* 1 = 3.57125 loss)
I0316 20:05:10.612711 11765 solver.cpp:228] Iteration 47000, loss = 3.07284
I0316 20:05:10.612751 11765 solver.cpp:244]     Train net output #0: loss = 3.07284 (* 1 = 3.07284 loss)
I0316 20:05:10.681020 11765 sgd_solver.cpp:106] Iteration 47000, lr = 0.2
I0316 20:06:26.844290 11765 solver.cpp:228] Iteration 47100, loss = 2.92476
I0316 20:06:26.844481 11765 solver.cpp:244]     Train net output #0: loss = 2.92476 (* 1 = 2.92476 loss)
I0316 20:06:26.947463 11765 sgd_solver.cpp:106] Iteration 47100, lr = 0.2
I0316 20:07:40.201174 11765 solver.cpp:228] Iteration 47200, loss = 3.08836
I0316 20:07:40.201367 11765 solver.cpp:244]     Train net output #0: loss = 3.08836 (* 1 = 3.08836 loss)
I0316 20:07:40.260781 11765 sgd_solver.cpp:106] Iteration 47200, lr = 0.2
I0316 20:08:54.882535 11765 solver.cpp:228] Iteration 47300, loss = 2.96626
I0316 20:08:54.882690 11765 solver.cpp:244]     Train net output #0: loss = 2.96626 (* 1 = 2.96626 loss)
I0316 20:08:54.943171 11765 sgd_solver.cpp:106] Iteration 47300, lr = 0.2
I0316 20:10:08.461660 11765 solver.cpp:228] Iteration 47400, loss = 3.28672
I0316 20:10:08.461848 11765 solver.cpp:244]     Train net output #0: loss = 3.28672 (* 1 = 3.28672 loss)
I0316 20:10:08.523214 11765 sgd_solver.cpp:106] Iteration 47400, lr = 0.2
I0316 20:11:23.390998 11765 solver.cpp:228] Iteration 47500, loss = 3.23628
I0316 20:11:23.391108 11765 solver.cpp:244]     Train net output #0: loss = 3.23628 (* 1 = 3.23628 loss)
I0316 20:11:23.446167 11765 sgd_solver.cpp:106] Iteration 47500, lr = 0.2
I0316 20:12:39.456660 11765 solver.cpp:228] Iteration 47600, loss = 3.36395
I0316 20:12:39.456903 11765 solver.cpp:244]     Train net output #0: loss = 3.36395 (* 1 = 3.36395 loss)
I0316 20:12:39.457022 11765 sgd_solver.cpp:106] Iteration 47600, lr = 0.2
I0316 20:13:53.272119 11765 solver.cpp:228] Iteration 47700, loss = 3.04039
I0316 20:13:53.272289 11765 solver.cpp:244]     Train net output #0: loss = 3.04039 (* 1 = 3.04039 loss)
I0316 20:13:53.326947 11765 sgd_solver.cpp:106] Iteration 47700, lr = 0.2
I0316 20:15:06.265806 11765 solver.cpp:228] Iteration 47800, loss = 3.05258
I0316 20:15:06.265950 11765 solver.cpp:244]     Train net output #0: loss = 3.05258 (* 1 = 3.05258 loss)
I0316 20:15:06.320525 11765 sgd_solver.cpp:106] Iteration 47800, lr = 0.2
I0316 20:16:20.199800 11765 solver.cpp:228] Iteration 47900, loss = 3.37132
I0316 20:16:20.199959 11765 solver.cpp:244]     Train net output #0: loss = 3.37132 (* 1 = 3.37132 loss)
I0316 20:16:20.256526 11765 sgd_solver.cpp:106] Iteration 47900, lr = 0.2
I0316 20:17:32.348665 11765 solver.cpp:337] Iteration 48000, Testing net (#0)
I0316 20:18:44.570588 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.26336
I0316 20:18:44.570781 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.51728
I0316 20:18:44.570802 11765 solver.cpp:404]     Test net output #2: loss = 3.52829 (* 1 = 3.52829 loss)
I0316 20:18:45.206825 11765 solver.cpp:228] Iteration 48000, loss = 3.05029
I0316 20:18:45.206862 11765 solver.cpp:244]     Train net output #0: loss = 3.05029 (* 1 = 3.05029 loss)
I0316 20:18:45.272629 11765 sgd_solver.cpp:106] Iteration 48000, lr = 0.2
I0316 20:19:58.850855 11765 solver.cpp:228] Iteration 48100, loss = 3.03976
I0316 20:19:58.851030 11765 solver.cpp:244]     Train net output #0: loss = 3.03976 (* 1 = 3.03976 loss)
I0316 20:19:58.934772 11765 sgd_solver.cpp:106] Iteration 48100, lr = 0.2
I0316 20:21:14.179080 11765 solver.cpp:228] Iteration 48200, loss = 3.26324
I0316 20:21:14.179250 11765 solver.cpp:244]     Train net output #0: loss = 3.26324 (* 1 = 3.26324 loss)
I0316 20:21:14.245271 11765 sgd_solver.cpp:106] Iteration 48200, lr = 0.2
I0316 20:22:28.305210 11765 solver.cpp:228] Iteration 48300, loss = 3.07712
I0316 20:22:28.305340 11765 solver.cpp:244]     Train net output #0: loss = 3.07712 (* 1 = 3.07712 loss)
I0316 20:22:28.365149 11765 sgd_solver.cpp:106] Iteration 48300, lr = 0.2
I0316 20:23:44.450918 11765 solver.cpp:228] Iteration 48400, loss = 2.9935
I0316 20:23:44.451046 11765 solver.cpp:244]     Train net output #0: loss = 2.9935 (* 1 = 2.9935 loss)
I0316 20:23:44.509670 11765 sgd_solver.cpp:106] Iteration 48400, lr = 0.2
I0316 20:24:58.911916 11765 solver.cpp:228] Iteration 48500, loss = 3.68677
I0316 20:24:58.912080 11765 solver.cpp:244]     Train net output #0: loss = 3.68677 (* 1 = 3.68677 loss)
I0316 20:24:58.970724 11765 sgd_solver.cpp:106] Iteration 48500, lr = 0.2
I0316 20:26:12.523628 11765 solver.cpp:228] Iteration 48600, loss = 3.25095
I0316 20:26:12.523778 11765 solver.cpp:244]     Train net output #0: loss = 3.25095 (* 1 = 3.25095 loss)
I0316 20:26:12.582816 11765 sgd_solver.cpp:106] Iteration 48600, lr = 0.2
I0316 20:27:23.981278 11765 solver.cpp:228] Iteration 48700, loss = 3.07981
I0316 20:27:23.981521 11765 solver.cpp:244]     Train net output #0: loss = 3.07981 (* 1 = 3.07981 loss)
I0316 20:27:24.038662 11765 sgd_solver.cpp:106] Iteration 48700, lr = 0.2
I0316 20:28:38.822667 11765 solver.cpp:228] Iteration 48800, loss = 3.08884
I0316 20:28:38.822823 11765 solver.cpp:244]     Train net output #0: loss = 3.08884 (* 1 = 3.08884 loss)
I0316 20:28:38.881356 11765 sgd_solver.cpp:106] Iteration 48800, lr = 0.2
I0316 20:29:54.445675 11765 solver.cpp:228] Iteration 48900, loss = 2.80597
I0316 20:29:54.445869 11765 solver.cpp:244]     Train net output #0: loss = 2.80597 (* 1 = 2.80597 loss)
I0316 20:29:54.492172 11765 sgd_solver.cpp:106] Iteration 48900, lr = 0.2
I0316 20:31:07.733093 11765 solver.cpp:337] Iteration 49000, Testing net (#0)
I0316 20:32:19.969141 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.26422
I0316 20:32:19.969298 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.51528
I0316 20:32:19.969318 11765 solver.cpp:404]     Test net output #2: loss = 3.52689 (* 1 = 3.52689 loss)
I0316 20:32:20.607265 11765 solver.cpp:228] Iteration 49000, loss = 3.15067
I0316 20:32:20.607298 11765 solver.cpp:244]     Train net output #0: loss = 3.15067 (* 1 = 3.15067 loss)
I0316 20:32:20.672626 11765 sgd_solver.cpp:106] Iteration 49000, lr = 0.2
I0316 20:33:34.944334 11765 solver.cpp:228] Iteration 49100, loss = 3.03525
I0316 20:33:34.944497 11765 solver.cpp:244]     Train net output #0: loss = 3.03525 (* 1 = 3.03525 loss)
I0316 20:33:35.021926 11765 sgd_solver.cpp:106] Iteration 49100, lr = 0.2
I0316 20:34:51.764937 11765 solver.cpp:228] Iteration 49200, loss = 3.46247
I0316 20:34:51.765079 11765 solver.cpp:244]     Train net output #0: loss = 3.46247 (* 1 = 3.46247 loss)
I0316 20:34:51.823434 11765 sgd_solver.cpp:106] Iteration 49200, lr = 0.2
I0316 20:36:07.277117 11765 solver.cpp:228] Iteration 49300, loss = 2.993
I0316 20:36:07.277335 11765 solver.cpp:244]     Train net output #0: loss = 2.993 (* 1 = 2.993 loss)
I0316 20:36:07.339198 11765 sgd_solver.cpp:106] Iteration 49300, lr = 0.2
I0316 20:37:21.714720 11765 solver.cpp:228] Iteration 49400, loss = 3.06809
I0316 20:37:21.714855 11765 solver.cpp:244]     Train net output #0: loss = 3.06809 (* 1 = 3.06809 loss)
I0316 20:37:21.773208 11765 sgd_solver.cpp:106] Iteration 49400, lr = 0.2
I0316 20:38:37.416765 11765 solver.cpp:228] Iteration 49500, loss = 3.03807
I0316 20:38:37.416896 11765 solver.cpp:244]     Train net output #0: loss = 3.03807 (* 1 = 3.03807 loss)
I0316 20:38:37.477365 11765 sgd_solver.cpp:106] Iteration 49500, lr = 0.2
I0316 20:39:53.742863 11765 solver.cpp:228] Iteration 49600, loss = 2.76823
I0316 20:39:53.742993 11765 solver.cpp:244]     Train net output #0: loss = 2.76823 (* 1 = 2.76823 loss)
I0316 20:39:53.810994 11765 sgd_solver.cpp:106] Iteration 49600, lr = 0.2
I0316 20:41:11.647682 11765 solver.cpp:228] Iteration 49700, loss = 3.24137
I0316 20:41:11.647866 11765 solver.cpp:244]     Train net output #0: loss = 3.24137 (* 1 = 3.24137 loss)
I0316 20:41:11.708793 11765 sgd_solver.cpp:106] Iteration 49700, lr = 0.2
I0316 20:42:29.622613 11765 solver.cpp:228] Iteration 49800, loss = 3.29852
I0316 20:42:29.622741 11765 solver.cpp:244]     Train net output #0: loss = 3.29852 (* 1 = 3.29852 loss)
I0316 20:42:29.681361 11765 sgd_solver.cpp:106] Iteration 49800, lr = 0.2
I0316 20:43:46.549057 11765 solver.cpp:228] Iteration 49900, loss = 2.99159
I0316 20:43:46.549207 11765 solver.cpp:244]     Train net output #0: loss = 2.99159 (* 1 = 2.99159 loss)
I0316 20:43:46.600374 11765 sgd_solver.cpp:106] Iteration 49900, lr = 0.2
I0316 20:45:02.135808 11765 solver.cpp:337] Iteration 50000, Testing net (#0)
I0316 20:46:14.925101 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.26266
I0316 20:46:14.925263 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.51194
I0316 20:46:14.925292 11765 solver.cpp:404]     Test net output #2: loss = 3.54601 (* 1 = 3.54601 loss)
I0316 20:46:15.566030 11765 solver.cpp:228] Iteration 50000, loss = 3.11311
I0316 20:46:15.566057 11765 solver.cpp:244]     Train net output #0: loss = 3.11311 (* 1 = 3.11311 loss)
I0316 20:46:15.628235 11765 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I0316 20:46:15.628262 11765 sgd_solver.cpp:106] Iteration 50000, lr = 0.02
I0316 20:47:31.054062 11765 solver.cpp:228] Iteration 50100, loss = 3.05066
I0316 20:47:31.054260 11765 solver.cpp:244]     Train net output #0: loss = 3.05066 (* 1 = 3.05066 loss)
I0316 20:47:31.136556 11765 sgd_solver.cpp:106] Iteration 50100, lr = 0.02
I0316 20:48:45.296726 11765 solver.cpp:228] Iteration 50200, loss = 2.72635
I0316 20:48:45.296881 11765 solver.cpp:244]     Train net output #0: loss = 2.72635 (* 1 = 2.72635 loss)
I0316 20:48:45.355393 11765 sgd_solver.cpp:106] Iteration 50200, lr = 0.02
I0316 20:49:59.959059 11765 solver.cpp:228] Iteration 50300, loss = 3.03232
I0316 20:49:59.959192 11765 solver.cpp:244]     Train net output #0: loss = 3.03232 (* 1 = 3.03232 loss)
I0316 20:50:00.016641 11765 sgd_solver.cpp:106] Iteration 50300, lr = 0.02
I0316 20:51:13.062003 11765 solver.cpp:228] Iteration 50400, loss = 3.04896
I0316 20:51:13.063237 11765 solver.cpp:244]     Train net output #0: loss = 3.04896 (* 1 = 3.04896 loss)
I0316 20:51:13.103062 11765 sgd_solver.cpp:106] Iteration 50400, lr = 0.02
I0316 20:52:29.008005 11765 solver.cpp:228] Iteration 50500, loss = 2.81397
I0316 20:52:29.008126 11765 solver.cpp:244]     Train net output #0: loss = 2.81397 (* 1 = 2.81397 loss)
I0316 20:52:29.057338 11765 sgd_solver.cpp:106] Iteration 50500, lr = 0.02
I0316 20:53:44.840701 11765 solver.cpp:228] Iteration 50600, loss = 3.03401
I0316 20:53:44.840844 11765 solver.cpp:244]     Train net output #0: loss = 3.03401 (* 1 = 3.03401 loss)
I0316 20:53:44.899469 11765 sgd_solver.cpp:106] Iteration 50600, lr = 0.02
I0316 20:54:59.155670 11765 solver.cpp:228] Iteration 50700, loss = 3.09534
I0316 20:54:59.155781 11765 solver.cpp:244]     Train net output #0: loss = 3.09534 (* 1 = 3.09534 loss)
I0316 20:54:59.216787 11765 sgd_solver.cpp:106] Iteration 50700, lr = 0.02
I0316 20:56:15.937830 11765 solver.cpp:228] Iteration 50800, loss = 3.22422
I0316 20:56:15.937976 11765 solver.cpp:244]     Train net output #0: loss = 3.22422 (* 1 = 3.22422 loss)
I0316 20:56:15.989666 11765 sgd_solver.cpp:106] Iteration 50800, lr = 0.02
I0316 20:57:31.346873 11765 solver.cpp:228] Iteration 50900, loss = 3.01579
I0316 20:57:31.347021 11765 solver.cpp:244]     Train net output #0: loss = 3.01579 (* 1 = 3.01579 loss)
I0316 20:57:31.407847 11765 sgd_solver.cpp:106] Iteration 50900, lr = 0.02
I0316 20:58:43.181776 11765 solver.cpp:337] Iteration 51000, Testing net (#0)
I0316 20:59:55.347164 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.35438
I0316 20:59:55.347338 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.615519
I0316 20:59:55.347367 11765 solver.cpp:404]     Test net output #2: loss = 2.99315 (* 1 = 2.99315 loss)
I0316 20:59:56.032727 11765 solver.cpp:228] Iteration 51000, loss = 2.67733
I0316 20:59:56.032790 11765 solver.cpp:244]     Train net output #0: loss = 2.67733 (* 1 = 2.67733 loss)
I0316 20:59:56.170303 11765 sgd_solver.cpp:106] Iteration 51000, lr = 0.02
I0316 21:01:11.429353 11765 solver.cpp:228] Iteration 51100, loss = 2.88801
I0316 21:01:11.429545 11765 solver.cpp:244]     Train net output #0: loss = 2.88801 (* 1 = 2.88801 loss)
I0316 21:01:11.526971 11765 sgd_solver.cpp:106] Iteration 51100, lr = 0.02
I0316 21:02:25.503576 11765 solver.cpp:228] Iteration 51200, loss = 3.19443
I0316 21:02:25.503705 11765 solver.cpp:244]     Train net output #0: loss = 3.19443 (* 1 = 3.19443 loss)
I0316 21:02:25.554616 11765 sgd_solver.cpp:106] Iteration 51200, lr = 0.02
I0316 21:03:39.679906 11765 solver.cpp:228] Iteration 51300, loss = 3.04337
I0316 21:03:39.680053 11765 solver.cpp:244]     Train net output #0: loss = 3.04337 (* 1 = 3.04337 loss)
I0316 21:03:39.735311 11765 sgd_solver.cpp:106] Iteration 51300, lr = 0.02
I0316 21:04:55.101553 11765 solver.cpp:228] Iteration 51400, loss = 2.63696
I0316 21:04:55.101763 11765 solver.cpp:244]     Train net output #0: loss = 2.63696 (* 1 = 2.63696 loss)
I0316 21:04:55.160303 11765 sgd_solver.cpp:106] Iteration 51400, lr = 0.02
I0316 21:06:08.288372 11765 solver.cpp:228] Iteration 51500, loss = 2.75469
I0316 21:06:08.288519 11765 solver.cpp:244]     Train net output #0: loss = 2.75469 (* 1 = 2.75469 loss)
I0316 21:06:08.344096 11765 sgd_solver.cpp:106] Iteration 51500, lr = 0.02
I0316 21:07:22.526075 11765 solver.cpp:228] Iteration 51600, loss = 2.76852
I0316 21:07:22.526188 11765 solver.cpp:244]     Train net output #0: loss = 2.76852 (* 1 = 2.76852 loss)
I0316 21:07:22.584970 11765 sgd_solver.cpp:106] Iteration 51600, lr = 0.02
I0316 21:08:37.514873 11765 solver.cpp:228] Iteration 51700, loss = 2.88178
I0316 21:08:37.515039 11765 solver.cpp:244]     Train net output #0: loss = 2.88178 (* 1 = 2.88178 loss)
I0316 21:08:37.574903 11765 sgd_solver.cpp:106] Iteration 51700, lr = 0.02
I0316 21:09:49.911115 11765 solver.cpp:228] Iteration 51800, loss = 3.354
I0316 21:09:49.911232 11765 solver.cpp:244]     Train net output #0: loss = 3.354 (* 1 = 3.354 loss)
I0316 21:09:49.963863 11765 sgd_solver.cpp:106] Iteration 51800, lr = 0.02
I0316 21:11:05.752091 11765 solver.cpp:228] Iteration 51900, loss = 3.0135
I0316 21:11:05.752214 11765 solver.cpp:244]     Train net output #0: loss = 3.0135 (* 1 = 3.0135 loss)
I0316 21:11:05.811048 11765 sgd_solver.cpp:106] Iteration 51900, lr = 0.02
I0316 21:12:18.009460 11765 solver.cpp:337] Iteration 52000, Testing net (#0)
I0316 21:13:30.479207 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.35752
I0316 21:13:30.479367 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.618019
I0316 21:13:30.479399 11765 solver.cpp:404]     Test net output #2: loss = 2.96896 (* 1 = 2.96896 loss)
I0316 21:13:31.118782 11765 solver.cpp:228] Iteration 52000, loss = 2.81048
I0316 21:13:31.118815 11765 solver.cpp:244]     Train net output #0: loss = 2.81048 (* 1 = 2.81048 loss)
I0316 21:13:31.188287 11765 sgd_solver.cpp:106] Iteration 52000, lr = 0.02
I0316 21:14:46.969560 11765 solver.cpp:228] Iteration 52100, loss = 2.63397
I0316 21:14:46.969718 11765 solver.cpp:244]     Train net output #0: loss = 2.63397 (* 1 = 2.63397 loss)
I0316 21:14:47.062275 11765 sgd_solver.cpp:106] Iteration 52100, lr = 0.02
I0316 21:16:00.069823 11765 solver.cpp:228] Iteration 52200, loss = 2.94552
I0316 21:16:00.070454 11765 solver.cpp:244]     Train net output #0: loss = 2.94552 (* 1 = 2.94552 loss)
I0316 21:16:00.098611 11765 sgd_solver.cpp:106] Iteration 52200, lr = 0.02
I0316 21:17:15.137926 11765 solver.cpp:228] Iteration 52300, loss = 3.26102
I0316 21:17:15.138095 11765 solver.cpp:244]     Train net output #0: loss = 3.26102 (* 1 = 3.26102 loss)
I0316 21:17:15.194912 11765 sgd_solver.cpp:106] Iteration 52300, lr = 0.02
I0316 21:18:28.922824 11765 solver.cpp:228] Iteration 52400, loss = 2.71764
I0316 21:18:28.922912 11765 solver.cpp:244]     Train net output #0: loss = 2.71764 (* 1 = 2.71764 loss)
I0316 21:18:28.982242 11765 sgd_solver.cpp:106] Iteration 52400, lr = 0.02
I0316 21:19:45.949626 11765 solver.cpp:228] Iteration 52500, loss = 2.60924
I0316 21:19:45.949766 11765 solver.cpp:244]     Train net output #0: loss = 2.60924 (* 1 = 2.60924 loss)
I0316 21:19:46.000578 11765 sgd_solver.cpp:106] Iteration 52500, lr = 0.02
I0316 21:21:03.416769 11765 solver.cpp:228] Iteration 52600, loss = 2.99093
I0316 21:21:03.416878 11765 solver.cpp:244]     Train net output #0: loss = 2.99093 (* 1 = 2.99093 loss)
I0316 21:21:03.475579 11765 sgd_solver.cpp:106] Iteration 52600, lr = 0.02
I0316 21:22:18.471508 11765 solver.cpp:228] Iteration 52700, loss = 2.70067
I0316 21:22:18.471640 11765 solver.cpp:244]     Train net output #0: loss = 2.70067 (* 1 = 2.70067 loss)
I0316 21:22:18.530236 11765 sgd_solver.cpp:106] Iteration 52700, lr = 0.02
I0316 21:23:33.139082 11765 solver.cpp:228] Iteration 52800, loss = 2.7469
I0316 21:23:33.139228 11765 solver.cpp:244]     Train net output #0: loss = 2.7469 (* 1 = 2.7469 loss)
I0316 21:23:33.195439 11765 sgd_solver.cpp:106] Iteration 52800, lr = 0.02
I0316 21:24:46.978731 11765 solver.cpp:228] Iteration 52900, loss = 2.59918
I0316 21:24:46.978899 11765 solver.cpp:244]     Train net output #0: loss = 2.59918 (* 1 = 2.59918 loss)
I0316 21:24:47.037477 11765 sgd_solver.cpp:106] Iteration 52900, lr = 0.02
I0316 21:26:01.311815 11765 solver.cpp:337] Iteration 53000, Testing net (#0)
I0316 21:27:13.573150 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.35702
I0316 21:27:13.573276 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.620799
I0316 21:27:13.573303 11765 solver.cpp:404]     Test net output #2: loss = 2.96311 (* 1 = 2.96311 loss)
I0316 21:27:14.211926 11765 solver.cpp:228] Iteration 53000, loss = 2.60044
I0316 21:27:14.211962 11765 solver.cpp:244]     Train net output #0: loss = 2.60044 (* 1 = 2.60044 loss)
I0316 21:27:14.279948 11765 sgd_solver.cpp:106] Iteration 53000, lr = 0.02
I0316 21:28:27.333595 11765 solver.cpp:228] Iteration 53100, loss = 2.86693
I0316 21:28:27.333758 11765 solver.cpp:244]     Train net output #0: loss = 2.86693 (* 1 = 2.86693 loss)
I0316 21:28:27.430534 11765 sgd_solver.cpp:106] Iteration 53100, lr = 0.02
I0316 21:29:41.712925 11765 solver.cpp:228] Iteration 53200, loss = 2.71691
I0316 21:29:41.713131 11765 solver.cpp:244]     Train net output #0: loss = 2.71691 (* 1 = 2.71691 loss)
I0316 21:29:41.779165 11765 sgd_solver.cpp:106] Iteration 53200, lr = 0.02
I0316 21:30:57.813385 11765 solver.cpp:228] Iteration 53300, loss = 2.74873
I0316 21:30:57.813549 11765 solver.cpp:244]     Train net output #0: loss = 2.74873 (* 1 = 2.74873 loss)
I0316 21:30:57.872699 11765 sgd_solver.cpp:106] Iteration 53300, lr = 0.02
I0316 21:32:14.334910 11765 solver.cpp:228] Iteration 53400, loss = 2.72188
I0316 21:32:14.335052 11765 solver.cpp:244]     Train net output #0: loss = 2.72188 (* 1 = 2.72188 loss)
I0316 21:32:14.392299 11765 sgd_solver.cpp:106] Iteration 53400, lr = 0.02
I0316 21:33:29.810524 11765 solver.cpp:228] Iteration 53500, loss = 3.01899
I0316 21:33:29.810680 11765 solver.cpp:244]     Train net output #0: loss = 3.01899 (* 1 = 3.01899 loss)
I0316 21:33:29.868557 11765 sgd_solver.cpp:106] Iteration 53500, lr = 0.02
I0316 21:34:45.700448 11765 solver.cpp:228] Iteration 53600, loss = 3.2408
I0316 21:34:45.700938 11765 solver.cpp:244]     Train net output #0: loss = 3.2408 (* 1 = 3.2408 loss)
I0316 21:34:45.730096 11765 sgd_solver.cpp:106] Iteration 53600, lr = 0.02
I0316 21:36:00.520817 11765 solver.cpp:228] Iteration 53700, loss = 3.11087
I0316 21:36:00.521050 11765 solver.cpp:244]     Train net output #0: loss = 3.11087 (* 1 = 3.11087 loss)
I0316 21:36:00.580948 11765 sgd_solver.cpp:106] Iteration 53700, lr = 0.02
I0316 21:37:17.062659 11765 solver.cpp:228] Iteration 53800, loss = 2.9573
I0316 21:37:17.062791 11765 solver.cpp:244]     Train net output #0: loss = 2.9573 (* 1 = 2.9573 loss)
I0316 21:37:17.121393 11765 sgd_solver.cpp:106] Iteration 53800, lr = 0.02
I0316 21:38:30.883672 11765 solver.cpp:228] Iteration 53900, loss = 2.89784
I0316 21:38:30.883801 11765 solver.cpp:244]     Train net output #0: loss = 2.89784 (* 1 = 2.89784 loss)
I0316 21:38:30.941067 11765 sgd_solver.cpp:106] Iteration 53900, lr = 0.02
I0316 21:39:47.741067 11765 solver.cpp:337] Iteration 54000, Testing net (#0)
I0316 21:40:59.947702 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36102
I0316 21:40:59.947861 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.622159
I0316 21:40:59.947890 11765 solver.cpp:404]     Test net output #2: loss = 2.94458 (* 1 = 2.94458 loss)
I0316 21:41:00.582516 11765 solver.cpp:228] Iteration 54000, loss = 2.77172
I0316 21:41:00.582551 11765 solver.cpp:244]     Train net output #0: loss = 2.77172 (* 1 = 2.77172 loss)
I0316 21:41:00.641396 11765 sgd_solver.cpp:106] Iteration 54000, lr = 0.02
I0316 21:42:18.650920 11765 solver.cpp:228] Iteration 54100, loss = 2.78554
I0316 21:42:18.651058 11765 solver.cpp:244]     Train net output #0: loss = 2.78554 (* 1 = 2.78554 loss)
I0316 21:42:18.727216 11765 sgd_solver.cpp:106] Iteration 54100, lr = 0.02
I0316 21:43:33.473610 11765 solver.cpp:228] Iteration 54200, loss = 2.94111
I0316 21:43:33.473786 11765 solver.cpp:244]     Train net output #0: loss = 2.94111 (* 1 = 2.94111 loss)
I0316 21:43:33.532897 11765 sgd_solver.cpp:106] Iteration 54200, lr = 0.02
I0316 21:44:48.316260 11765 solver.cpp:228] Iteration 54300, loss = 2.63319
I0316 21:44:48.316370 11765 solver.cpp:244]     Train net output #0: loss = 2.63319 (* 1 = 2.63319 loss)
I0316 21:44:48.365875 11765 sgd_solver.cpp:106] Iteration 54300, lr = 0.02
I0316 21:46:04.918331 11765 solver.cpp:228] Iteration 54400, loss = 2.65271
I0316 21:46:04.918881 11765 solver.cpp:244]     Train net output #0: loss = 2.65271 (* 1 = 2.65271 loss)
I0316 21:46:04.966234 11765 sgd_solver.cpp:106] Iteration 54400, lr = 0.02
I0316 21:47:20.564942 11765 solver.cpp:228] Iteration 54500, loss = 2.56286
I0316 21:47:20.565085 11765 solver.cpp:244]     Train net output #0: loss = 2.56286 (* 1 = 2.56286 loss)
I0316 21:47:20.618412 11765 sgd_solver.cpp:106] Iteration 54500, lr = 0.02
I0316 21:48:38.096391 11765 solver.cpp:228] Iteration 54600, loss = 2.74038
I0316 21:48:38.096529 11765 solver.cpp:244]     Train net output #0: loss = 2.74038 (* 1 = 2.74038 loss)
I0316 21:48:38.153599 11765 sgd_solver.cpp:106] Iteration 54600, lr = 0.02
I0316 21:49:50.478384 11765 solver.cpp:228] Iteration 54700, loss = 2.87462
I0316 21:49:50.478513 11765 solver.cpp:244]     Train net output #0: loss = 2.87462 (* 1 = 2.87462 loss)
I0316 21:49:50.537825 11765 sgd_solver.cpp:106] Iteration 54700, lr = 0.02
I0316 21:51:06.235543 11765 solver.cpp:228] Iteration 54800, loss = 3.12301
I0316 21:51:06.235669 11765 solver.cpp:244]     Train net output #0: loss = 3.12301 (* 1 = 3.12301 loss)
I0316 21:51:06.283843 11765 sgd_solver.cpp:106] Iteration 54800, lr = 0.02
I0316 21:52:21.019431 11765 solver.cpp:228] Iteration 54900, loss = 3.02066
I0316 21:52:21.019593 11765 solver.cpp:244]     Train net output #0: loss = 3.02066 (* 1 = 3.02066 loss)
I0316 21:52:21.096192 11765 sgd_solver.cpp:106] Iteration 54900, lr = 0.02
I0316 21:53:35.854419 11765 solver.cpp:337] Iteration 55000, Testing net (#0)
I0316 21:54:48.842357 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36216
I0316 21:54:48.842531 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.621299
I0316 21:54:48.842543 11765 solver.cpp:404]     Test net output #2: loss = 2.9494 (* 1 = 2.9494 loss)
I0316 21:54:49.484443 11765 solver.cpp:228] Iteration 55000, loss = 2.71932
I0316 21:54:49.484486 11765 solver.cpp:244]     Train net output #0: loss = 2.71932 (* 1 = 2.71932 loss)
I0316 21:54:49.545572 11765 sgd_solver.cpp:106] Iteration 55000, lr = 0.02
I0316 21:56:05.198727 11765 solver.cpp:228] Iteration 55100, loss = 2.88856
I0316 21:56:05.198859 11765 solver.cpp:244]     Train net output #0: loss = 2.88856 (* 1 = 2.88856 loss)
I0316 21:56:05.283795 11765 sgd_solver.cpp:106] Iteration 55100, lr = 0.02
I0316 21:57:18.794744 11765 solver.cpp:228] Iteration 55200, loss = 2.43098
I0316 21:57:18.794911 11765 solver.cpp:244]     Train net output #0: loss = 2.43098 (* 1 = 2.43098 loss)
I0316 21:57:18.857789 11765 sgd_solver.cpp:106] Iteration 55200, lr = 0.02
I0316 21:58:33.240144 11765 solver.cpp:228] Iteration 55300, loss = 2.95072
I0316 21:58:33.240288 11765 solver.cpp:244]     Train net output #0: loss = 2.95072 (* 1 = 2.95072 loss)
I0316 21:58:33.299243 11765 sgd_solver.cpp:106] Iteration 55300, lr = 0.02
I0316 21:59:48.542058 11765 solver.cpp:228] Iteration 55400, loss = 2.97787
I0316 21:59:48.542171 11765 solver.cpp:244]     Train net output #0: loss = 2.97787 (* 1 = 2.97787 loss)
I0316 21:59:48.597801 11765 sgd_solver.cpp:106] Iteration 55400, lr = 0.02
I0316 22:01:02.922734 11765 solver.cpp:228] Iteration 55500, loss = 2.99966
I0316 22:01:02.922889 11765 solver.cpp:244]     Train net output #0: loss = 2.99966 (* 1 = 2.99966 loss)
I0316 22:01:02.976392 11765 sgd_solver.cpp:106] Iteration 55500, lr = 0.02
I0316 22:02:19.403605 11765 solver.cpp:228] Iteration 55600, loss = 2.92183
I0316 22:02:19.404949 11765 solver.cpp:244]     Train net output #0: loss = 2.92183 (* 1 = 2.92183 loss)
I0316 22:02:19.405342 11765 sgd_solver.cpp:106] Iteration 55600, lr = 0.02
I0316 22:03:35.730742 11765 solver.cpp:228] Iteration 55700, loss = 2.67005
I0316 22:03:35.730964 11765 solver.cpp:244]     Train net output #0: loss = 2.67005 (* 1 = 2.67005 loss)
I0316 22:03:35.731070 11765 sgd_solver.cpp:106] Iteration 55700, lr = 0.02
I0316 22:04:51.788586 11765 solver.cpp:228] Iteration 55800, loss = 2.86629
I0316 22:04:51.789351 11765 solver.cpp:244]     Train net output #0: loss = 2.86629 (* 1 = 2.86629 loss)
I0316 22:04:51.863469 11765 sgd_solver.cpp:106] Iteration 55800, lr = 0.02
I0316 22:06:08.751667 11765 solver.cpp:228] Iteration 55900, loss = 2.88351
I0316 22:06:08.751822 11765 solver.cpp:244]     Train net output #0: loss = 2.88351 (* 1 = 2.88351 loss)
I0316 22:06:08.800642 11765 sgd_solver.cpp:106] Iteration 55900, lr = 0.02
I0316 22:07:22.319772 11765 solver.cpp:337] Iteration 56000, Testing net (#0)
I0316 22:08:35.294133 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36344
I0316 22:08:35.294327 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.62758
I0316 22:08:35.294347 11765 solver.cpp:404]     Test net output #2: loss = 2.92402 (* 1 = 2.92402 loss)
I0316 22:08:35.938838 11765 solver.cpp:228] Iteration 56000, loss = 2.73967
I0316 22:08:35.938872 11765 solver.cpp:244]     Train net output #0: loss = 2.73967 (* 1 = 2.73967 loss)
I0316 22:08:35.998177 11765 sgd_solver.cpp:106] Iteration 56000, lr = 0.02
I0316 22:09:51.854137 11765 solver.cpp:228] Iteration 56100, loss = 2.81785
I0316 22:09:51.854307 11765 solver.cpp:244]     Train net output #0: loss = 2.81785 (* 1 = 2.81785 loss)
I0316 22:09:51.937176 11765 sgd_solver.cpp:106] Iteration 56100, lr = 0.02
I0316 22:11:07.877656 11765 solver.cpp:228] Iteration 56200, loss = 3.09174
I0316 22:11:07.877831 11765 solver.cpp:244]     Train net output #0: loss = 3.09174 (* 1 = 3.09174 loss)
I0316 22:11:07.939617 11765 sgd_solver.cpp:106] Iteration 56200, lr = 0.02
I0316 22:12:23.605444 11765 solver.cpp:228] Iteration 56300, loss = 2.594
I0316 22:12:23.605556 11765 solver.cpp:244]     Train net output #0: loss = 2.594 (* 1 = 2.594 loss)
I0316 22:12:23.665698 11765 sgd_solver.cpp:106] Iteration 56300, lr = 0.02
I0316 22:13:39.361773 11765 solver.cpp:228] Iteration 56400, loss = 2.96121
I0316 22:13:39.361888 11765 solver.cpp:244]     Train net output #0: loss = 2.96121 (* 1 = 2.96121 loss)
I0316 22:13:39.414806 11765 sgd_solver.cpp:106] Iteration 56400, lr = 0.02
I0316 22:14:54.174355 11765 solver.cpp:228] Iteration 56500, loss = 2.71122
I0316 22:14:54.174490 11765 solver.cpp:244]     Train net output #0: loss = 2.71122 (* 1 = 2.71122 loss)
I0316 22:14:54.223290 11765 sgd_solver.cpp:106] Iteration 56500, lr = 0.02
I0316 22:16:10.836617 11765 solver.cpp:228] Iteration 56600, loss = 2.66662
I0316 22:16:10.836802 11765 solver.cpp:244]     Train net output #0: loss = 2.66662 (* 1 = 2.66662 loss)
I0316 22:16:10.836886 11765 sgd_solver.cpp:106] Iteration 56600, lr = 0.02
I0316 22:17:26.752960 11765 solver.cpp:228] Iteration 56700, loss = 2.64109
I0316 22:17:26.753104 11765 solver.cpp:244]     Train net output #0: loss = 2.64109 (* 1 = 2.64109 loss)
I0316 22:17:26.813125 11765 sgd_solver.cpp:106] Iteration 56700, lr = 0.02
I0316 22:18:40.979594 11765 solver.cpp:228] Iteration 56800, loss = 3.15339
I0316 22:18:40.980341 11765 solver.cpp:244]     Train net output #0: loss = 3.15339 (* 1 = 3.15339 loss)
I0316 22:18:40.980911 11765 sgd_solver.cpp:106] Iteration 56800, lr = 0.02
I0316 22:19:55.711830 11765 solver.cpp:228] Iteration 56900, loss = 2.76278
I0316 22:19:55.711971 11765 solver.cpp:244]     Train net output #0: loss = 2.76278 (* 1 = 2.76278 loss)
I0316 22:19:55.765220 11765 sgd_solver.cpp:106] Iteration 56900, lr = 0.02
I0316 22:21:09.862529 11765 solver.cpp:337] Iteration 57000, Testing net (#0)
I0316 22:22:22.914824 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36414
I0316 22:22:22.914989 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.625659
I0316 22:22:22.915019 11765 solver.cpp:404]     Test net output #2: loss = 2.92429 (* 1 = 2.92429 loss)
I0316 22:22:23.556180 11765 solver.cpp:228] Iteration 57000, loss = 2.76457
I0316 22:22:23.556211 11765 solver.cpp:244]     Train net output #0: loss = 2.76457 (* 1 = 2.76457 loss)
I0316 22:22:23.624126 11765 sgd_solver.cpp:106] Iteration 57000, lr = 0.02
I0316 22:23:39.408700 11765 solver.cpp:228] Iteration 57100, loss = 2.64744
I0316 22:23:39.408942 11765 solver.cpp:244]     Train net output #0: loss = 2.64744 (* 1 = 2.64744 loss)
I0316 22:23:39.493858 11765 sgd_solver.cpp:106] Iteration 57100, lr = 0.02
I0316 22:24:54.473673 11765 solver.cpp:228] Iteration 57200, loss = 2.648
I0316 22:24:54.473889 11765 solver.cpp:244]     Train net output #0: loss = 2.648 (* 1 = 2.648 loss)
I0316 22:24:54.495223 11765 sgd_solver.cpp:106] Iteration 57200, lr = 0.02
I0316 22:26:09.594738 11765 solver.cpp:228] Iteration 57300, loss = 2.63511
I0316 22:26:09.594920 11765 solver.cpp:244]     Train net output #0: loss = 2.63511 (* 1 = 2.63511 loss)
I0316 22:26:09.654170 11765 sgd_solver.cpp:106] Iteration 57300, lr = 0.02
I0316 22:27:23.053468 11765 solver.cpp:228] Iteration 57400, loss = 2.67634
I0316 22:27:23.053596 11765 solver.cpp:244]     Train net output #0: loss = 2.67634 (* 1 = 2.67634 loss)
I0316 22:27:23.081866 11765 sgd_solver.cpp:106] Iteration 57400, lr = 0.02
I0316 22:28:39.090055 11765 solver.cpp:228] Iteration 57500, loss = 2.774
I0316 22:28:39.090204 11765 solver.cpp:244]     Train net output #0: loss = 2.774 (* 1 = 2.774 loss)
I0316 22:28:39.143831 11765 sgd_solver.cpp:106] Iteration 57500, lr = 0.02
I0316 22:29:53.968582 11765 solver.cpp:228] Iteration 57600, loss = 3.01946
I0316 22:29:53.968734 11765 solver.cpp:244]     Train net output #0: loss = 3.01946 (* 1 = 3.01946 loss)
I0316 22:29:54.027675 11765 sgd_solver.cpp:106] Iteration 57600, lr = 0.02
I0316 22:31:10.943219 11765 solver.cpp:228] Iteration 57700, loss = 2.78142
I0316 22:31:10.943370 11765 solver.cpp:244]     Train net output #0: loss = 2.78142 (* 1 = 2.78142 loss)
I0316 22:31:10.994455 11765 sgd_solver.cpp:106] Iteration 57700, lr = 0.02
I0316 22:32:26.505789 11765 solver.cpp:228] Iteration 57800, loss = 2.79246
I0316 22:32:26.505928 11765 solver.cpp:244]     Train net output #0: loss = 2.79246 (* 1 = 2.79246 loss)
I0316 22:32:26.574880 11765 sgd_solver.cpp:106] Iteration 57800, lr = 0.02
I0316 22:33:41.873668 11765 solver.cpp:228] Iteration 57900, loss = 2.71338
I0316 22:33:41.874280 11765 solver.cpp:244]     Train net output #0: loss = 2.71338 (* 1 = 2.71338 loss)
I0316 22:33:41.874634 11765 sgd_solver.cpp:106] Iteration 57900, lr = 0.02
I0316 22:34:58.580039 11765 solver.cpp:337] Iteration 58000, Testing net (#0)
I0316 22:36:11.655560 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36348
I0316 22:36:11.655722 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.626839
I0316 22:36:11.655750 11765 solver.cpp:404]     Test net output #2: loss = 2.92797 (* 1 = 2.92797 loss)
I0316 22:36:12.298091 11765 solver.cpp:228] Iteration 58000, loss = 2.77983
I0316 22:36:12.298125 11765 solver.cpp:244]     Train net output #0: loss = 2.77983 (* 1 = 2.77983 loss)
I0316 22:36:12.366192 11765 sgd_solver.cpp:106] Iteration 58000, lr = 0.02
I0316 22:37:29.553236 11765 solver.cpp:228] Iteration 58100, loss = 2.92994
I0316 22:37:29.553402 11765 solver.cpp:244]     Train net output #0: loss = 2.92994 (* 1 = 2.92994 loss)
I0316 22:37:29.677309 11765 sgd_solver.cpp:106] Iteration 58100, lr = 0.02
I0316 22:38:45.744251 11765 solver.cpp:228] Iteration 58200, loss = 2.60455
I0316 22:38:45.744354 11765 solver.cpp:244]     Train net output #0: loss = 2.60455 (* 1 = 2.60455 loss)
I0316 22:38:45.808698 11765 sgd_solver.cpp:106] Iteration 58200, lr = 0.02
I0316 22:40:01.938741 11765 solver.cpp:228] Iteration 58300, loss = 2.69459
I0316 22:40:01.938854 11765 solver.cpp:244]     Train net output #0: loss = 2.69459 (* 1 = 2.69459 loss)
I0316 22:40:01.997905 11765 sgd_solver.cpp:106] Iteration 58300, lr = 0.02
I0316 22:41:19.704447 11765 solver.cpp:228] Iteration 58400, loss = 2.81387
I0316 22:41:19.704668 11765 solver.cpp:244]     Train net output #0: loss = 2.81387 (* 1 = 2.81387 loss)
I0316 22:41:19.756485 11765 sgd_solver.cpp:106] Iteration 58400, lr = 0.02
I0316 22:42:34.352458 11765 solver.cpp:228] Iteration 58500, loss = 2.95762
I0316 22:42:34.352620 11765 solver.cpp:244]     Train net output #0: loss = 2.95762 (* 1 = 2.95762 loss)
I0316 22:42:34.411599 11765 sgd_solver.cpp:106] Iteration 58500, lr = 0.02
I0316 22:43:51.201764 11765 solver.cpp:228] Iteration 58600, loss = 2.79453
I0316 22:43:51.202317 11765 solver.cpp:244]     Train net output #0: loss = 2.79453 (* 1 = 2.79453 loss)
I0316 22:43:51.211774 11765 sgd_solver.cpp:106] Iteration 58600, lr = 0.02
I0316 22:45:09.588009 11765 solver.cpp:228] Iteration 58700, loss = 2.71121
I0316 22:45:09.588146 11765 solver.cpp:244]     Train net output #0: loss = 2.71121 (* 1 = 2.71121 loss)
I0316 22:45:09.612923 11765 sgd_solver.cpp:106] Iteration 58700, lr = 0.02
I0316 22:46:26.656855 11765 solver.cpp:228] Iteration 58800, loss = 2.94073
I0316 22:46:26.657008 11765 solver.cpp:244]     Train net output #0: loss = 2.94073 (* 1 = 2.94073 loss)
I0316 22:46:26.716758 11765 sgd_solver.cpp:106] Iteration 58800, lr = 0.02
I0316 22:47:41.558349 11765 solver.cpp:228] Iteration 58900, loss = 2.77549
I0316 22:47:41.558511 11765 solver.cpp:244]     Train net output #0: loss = 2.77549 (* 1 = 2.77549 loss)
I0316 22:47:41.611773 11765 sgd_solver.cpp:106] Iteration 58900, lr = 0.02
I0316 22:48:55.520045 11765 solver.cpp:337] Iteration 59000, Testing net (#0)
I0316 22:50:08.245519 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36732
I0316 22:50:08.245692 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.62816
I0316 22:50:08.245720 11765 solver.cpp:404]     Test net output #2: loss = 2.91687 (* 1 = 2.91687 loss)
I0316 22:50:08.884282 11765 solver.cpp:228] Iteration 59000, loss = 2.75901
I0316 22:50:08.884322 11765 solver.cpp:244]     Train net output #0: loss = 2.75901 (* 1 = 2.75901 loss)
I0316 22:50:08.943435 11765 sgd_solver.cpp:106] Iteration 59000, lr = 0.02
I0316 22:51:24.572757 11765 solver.cpp:228] Iteration 59100, loss = 2.73319
I0316 22:51:24.572886 11765 solver.cpp:244]     Train net output #0: loss = 2.73319 (* 1 = 2.73319 loss)
I0316 22:51:24.649737 11765 sgd_solver.cpp:106] Iteration 59100, lr = 0.02
I0316 22:52:39.082402 11765 solver.cpp:228] Iteration 59200, loss = 2.69304
I0316 22:52:39.082542 11765 solver.cpp:244]     Train net output #0: loss = 2.69304 (* 1 = 2.69304 loss)
I0316 22:52:39.147217 11765 sgd_solver.cpp:106] Iteration 59200, lr = 0.02
I0316 22:53:52.511405 11765 solver.cpp:228] Iteration 59300, loss = 2.5231
I0316 22:53:52.511548 11765 solver.cpp:244]     Train net output #0: loss = 2.5231 (* 1 = 2.5231 loss)
I0316 22:53:52.564033 11765 sgd_solver.cpp:106] Iteration 59300, lr = 0.02
I0316 22:55:10.300132 11765 solver.cpp:228] Iteration 59400, loss = 3.16241
I0316 22:55:10.300249 11765 solver.cpp:244]     Train net output #0: loss = 3.16241 (* 1 = 3.16241 loss)
I0316 22:55:10.359473 11765 sgd_solver.cpp:106] Iteration 59400, lr = 0.02
I0316 22:56:27.003013 11765 solver.cpp:228] Iteration 59500, loss = 2.66617
I0316 22:56:27.003147 11765 solver.cpp:244]     Train net output #0: loss = 2.66617 (* 1 = 2.66617 loss)
I0316 22:56:27.062611 11765 sgd_solver.cpp:106] Iteration 59500, lr = 0.02
I0316 22:57:43.628566 11765 solver.cpp:228] Iteration 59600, loss = 3.06272
I0316 22:57:43.628713 11765 solver.cpp:244]     Train net output #0: loss = 3.06272 (* 1 = 3.06272 loss)
I0316 22:57:43.684974 11765 sgd_solver.cpp:106] Iteration 59600, lr = 0.02
I0316 22:58:59.376121 11765 solver.cpp:228] Iteration 59700, loss = 2.70712
I0316 22:58:59.376237 11765 solver.cpp:244]     Train net output #0: loss = 2.70712 (* 1 = 2.70712 loss)
I0316 22:58:59.424449 11765 sgd_solver.cpp:106] Iteration 59700, lr = 0.02
I0316 23:00:17.017338 11765 solver.cpp:228] Iteration 59800, loss = 3.1039
I0316 23:00:17.017479 11765 solver.cpp:244]     Train net output #0: loss = 3.1039 (* 1 = 3.1039 loss)
I0316 23:00:17.073115 11765 sgd_solver.cpp:106] Iteration 59800, lr = 0.02
I0316 23:01:32.345214 11765 solver.cpp:228] Iteration 59900, loss = 3.1438
I0316 23:01:32.345397 11765 solver.cpp:244]     Train net output #0: loss = 3.1438 (* 1 = 3.1438 loss)
I0316 23:01:32.397260 11765 sgd_solver.cpp:106] Iteration 59900, lr = 0.02
I0316 23:02:46.030567 11765 solver.cpp:454] Snapshotting to binary proto file snapshots/imageNet_slim_iter_60000.caffemodel
I0316 23:02:46.044306 11765 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/imageNet_slim_iter_60000.solverstate
I0316 23:02:46.052335 11765 solver.cpp:337] Iteration 60000, Testing net (#0)
I0316 23:03:58.620033 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36918
I0316 23:03:58.620146 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.629919
I0316 23:03:58.620165 11765 solver.cpp:404]     Test net output #2: loss = 2.90759 (* 1 = 2.90759 loss)
I0316 23:03:59.267824 11765 solver.cpp:228] Iteration 60000, loss = 2.92676
I0316 23:03:59.267860 11765 solver.cpp:244]     Train net output #0: loss = 2.92676 (* 1 = 2.92676 loss)
I0316 23:03:59.327641 11765 sgd_solver.cpp:106] Iteration 60000, lr = 0.02
I0316 23:05:14.792958 11765 solver.cpp:228] Iteration 60100, loss = 2.72519
I0316 23:05:14.793094 11765 solver.cpp:244]     Train net output #0: loss = 2.72519 (* 1 = 2.72519 loss)
I0316 23:05:14.873030 11765 sgd_solver.cpp:106] Iteration 60100, lr = 0.02
I0316 23:06:30.570467 11765 solver.cpp:228] Iteration 60200, loss = 2.86181
I0316 23:06:30.570616 11765 solver.cpp:244]     Train net output #0: loss = 2.86181 (* 1 = 2.86181 loss)
I0316 23:06:30.629612 11765 sgd_solver.cpp:106] Iteration 60200, lr = 0.02
I0316 23:07:46.654994 11765 solver.cpp:228] Iteration 60300, loss = 2.88891
I0316 23:07:46.655135 11765 solver.cpp:244]     Train net output #0: loss = 2.88891 (* 1 = 2.88891 loss)
I0316 23:07:46.705878 11765 sgd_solver.cpp:106] Iteration 60300, lr = 0.02
I0316 23:09:02.308763 11765 solver.cpp:228] Iteration 60400, loss = 2.81074
I0316 23:09:02.310175 11765 solver.cpp:244]     Train net output #0: loss = 2.81074 (* 1 = 2.81074 loss)
I0316 23:09:02.310535 11765 sgd_solver.cpp:106] Iteration 60400, lr = 0.02
I0316 23:10:18.378190 11765 solver.cpp:228] Iteration 60500, loss = 2.74423
I0316 23:10:18.378325 11765 solver.cpp:244]     Train net output #0: loss = 2.74423 (* 1 = 2.74423 loss)
I0316 23:10:18.407284 11765 sgd_solver.cpp:106] Iteration 60500, lr = 0.02
I0316 23:11:34.401661 11765 solver.cpp:228] Iteration 60600, loss = 2.55668
I0316 23:11:34.402221 11765 solver.cpp:244]     Train net output #0: loss = 2.55668 (* 1 = 2.55668 loss)
I0316 23:11:34.402482 11765 sgd_solver.cpp:106] Iteration 60600, lr = 0.02
I0316 23:12:50.816303 11765 solver.cpp:228] Iteration 60700, loss = 2.89118
I0316 23:12:50.816471 11765 solver.cpp:244]     Train net output #0: loss = 2.89118 (* 1 = 2.89118 loss)
I0316 23:12:50.870656 11765 sgd_solver.cpp:106] Iteration 60700, lr = 0.02
I0316 23:14:06.994808 11765 solver.cpp:228] Iteration 60800, loss = 2.5884
I0316 23:14:06.994964 11765 solver.cpp:244]     Train net output #0: loss = 2.5884 (* 1 = 2.5884 loss)
I0316 23:14:07.049232 11765 sgd_solver.cpp:106] Iteration 60800, lr = 0.02
I0316 23:15:23.066426 11765 solver.cpp:228] Iteration 60900, loss = 2.70593
I0316 23:15:23.066598 11765 solver.cpp:244]     Train net output #0: loss = 2.70593 (* 1 = 2.70593 loss)
I0316 23:15:23.095438 11765 sgd_solver.cpp:106] Iteration 60900, lr = 0.02
I0316 23:16:40.009620 11765 solver.cpp:337] Iteration 61000, Testing net (#0)
I0316 23:17:52.950610 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.364
I0316 23:17:52.950815 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.626839
I0316 23:17:52.950845 11765 solver.cpp:404]     Test net output #2: loss = 2.92688 (* 1 = 2.92688 loss)
I0316 23:17:53.592301 11765 solver.cpp:228] Iteration 61000, loss = 2.88971
I0316 23:17:53.592355 11765 solver.cpp:244]     Train net output #0: loss = 2.88971 (* 1 = 2.88971 loss)
I0316 23:17:53.657346 11765 sgd_solver.cpp:106] Iteration 61000, lr = 0.02
I0316 23:19:07.305063 11765 solver.cpp:228] Iteration 61100, loss = 2.50241
I0316 23:19:07.305272 11765 solver.cpp:244]     Train net output #0: loss = 2.50241 (* 1 = 2.50241 loss)
I0316 23:19:07.401466 11765 sgd_solver.cpp:106] Iteration 61100, lr = 0.02
I0316 23:20:21.821096 11765 solver.cpp:228] Iteration 61200, loss = 3.20472
I0316 23:20:21.821247 11765 solver.cpp:244]     Train net output #0: loss = 3.20472 (* 1 = 3.20472 loss)
I0316 23:20:21.877228 11765 sgd_solver.cpp:106] Iteration 61200, lr = 0.02
I0316 23:21:37.531538 11765 solver.cpp:228] Iteration 61300, loss = 2.31245
I0316 23:21:37.531695 11765 solver.cpp:244]     Train net output #0: loss = 2.31245 (* 1 = 2.31245 loss)
I0316 23:21:37.594027 11765 sgd_solver.cpp:106] Iteration 61300, lr = 0.02
I0316 23:22:52.330524 11765 solver.cpp:228] Iteration 61400, loss = 2.52825
I0316 23:22:52.330636 11765 solver.cpp:244]     Train net output #0: loss = 2.52825 (* 1 = 2.52825 loss)
I0316 23:22:52.360535 11765 sgd_solver.cpp:106] Iteration 61400, lr = 0.02
I0316 23:24:06.168161 11765 solver.cpp:228] Iteration 61500, loss = 2.6004
I0316 23:24:06.168315 11765 solver.cpp:244]     Train net output #0: loss = 2.6004 (* 1 = 2.6004 loss)
I0316 23:24:06.217140 11765 sgd_solver.cpp:106] Iteration 61500, lr = 0.02
I0316 23:25:22.018632 11765 solver.cpp:228] Iteration 61600, loss = 2.25832
I0316 23:25:22.018776 11765 solver.cpp:244]     Train net output #0: loss = 2.25832 (* 1 = 2.25832 loss)
I0316 23:25:22.083333 11765 sgd_solver.cpp:106] Iteration 61600, lr = 0.02
I0316 23:26:35.792728 11765 solver.cpp:228] Iteration 61700, loss = 2.74936
I0316 23:26:35.793215 11765 solver.cpp:244]     Train net output #0: loss = 2.74936 (* 1 = 2.74936 loss)
I0316 23:26:35.793468 11765 sgd_solver.cpp:106] Iteration 61700, lr = 0.02
I0316 23:27:53.990113 11765 solver.cpp:228] Iteration 61800, loss = 2.58239
I0316 23:27:53.990280 11765 solver.cpp:244]     Train net output #0: loss = 2.58239 (* 1 = 2.58239 loss)
I0316 23:27:54.041895 11765 sgd_solver.cpp:106] Iteration 61800, lr = 0.02
I0316 23:29:09.999130 11765 solver.cpp:228] Iteration 61900, loss = 2.55496
I0316 23:29:09.999281 11765 solver.cpp:244]     Train net output #0: loss = 2.55496 (* 1 = 2.55496 loss)
I0316 23:29:10.058393 11765 sgd_solver.cpp:106] Iteration 61900, lr = 0.02
I0316 23:30:23.778669 11765 solver.cpp:337] Iteration 62000, Testing net (#0)
I0316 23:31:36.615952 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3686
I0316 23:31:36.616130 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.630399
I0316 23:31:36.616159 11765 solver.cpp:404]     Test net output #2: loss = 2.90585 (* 1 = 2.90585 loss)
I0316 23:31:37.260185 11765 solver.cpp:228] Iteration 62000, loss = 2.88966
I0316 23:31:37.260222 11765 solver.cpp:244]     Train net output #0: loss = 2.88966 (* 1 = 2.88966 loss)
I0316 23:31:37.326479 11765 sgd_solver.cpp:106] Iteration 62000, lr = 0.02
I0316 23:32:51.248399 11765 solver.cpp:228] Iteration 62100, loss = 2.39567
I0316 23:32:51.248572 11765 solver.cpp:244]     Train net output #0: loss = 2.39567 (* 1 = 2.39567 loss)
I0316 23:32:51.330235 11765 sgd_solver.cpp:106] Iteration 62100, lr = 0.02
I0316 23:34:09.117198 11765 solver.cpp:228] Iteration 62200, loss = 2.79278
I0316 23:34:09.117348 11765 solver.cpp:244]     Train net output #0: loss = 2.79278 (* 1 = 2.79278 loss)
I0316 23:34:09.168164 11765 sgd_solver.cpp:106] Iteration 62200, lr = 0.02
I0316 23:35:22.768501 11765 solver.cpp:228] Iteration 62300, loss = 2.72982
I0316 23:35:22.769239 11765 solver.cpp:244]     Train net output #0: loss = 2.72982 (* 1 = 2.72982 loss)
I0316 23:35:22.769635 11765 sgd_solver.cpp:106] Iteration 62300, lr = 0.02
I0316 23:36:38.839306 11765 solver.cpp:228] Iteration 62400, loss = 2.65099
I0316 23:36:38.839432 11765 solver.cpp:244]     Train net output #0: loss = 2.65099 (* 1 = 2.65099 loss)
I0316 23:36:38.888121 11765 sgd_solver.cpp:106] Iteration 62400, lr = 0.02
I0316 23:37:55.513329 11765 solver.cpp:228] Iteration 62500, loss = 2.59802
I0316 23:37:55.513530 11765 solver.cpp:244]     Train net output #0: loss = 2.59802 (* 1 = 2.59802 loss)
I0316 23:37:55.563125 11765 sgd_solver.cpp:106] Iteration 62500, lr = 0.02
I0316 23:39:11.254503 11765 solver.cpp:228] Iteration 62600, loss = 2.73658
I0316 23:39:11.254662 11765 solver.cpp:244]     Train net output #0: loss = 2.73658 (* 1 = 2.73658 loss)
I0316 23:39:11.304195 11765 sgd_solver.cpp:106] Iteration 62600, lr = 0.02
I0316 23:40:25.660053 11765 solver.cpp:228] Iteration 62700, loss = 2.39306
I0316 23:40:25.660218 11765 solver.cpp:244]     Train net output #0: loss = 2.39306 (* 1 = 2.39306 loss)
I0316 23:40:25.672821 11765 sgd_solver.cpp:106] Iteration 62700, lr = 0.02
I0316 23:41:38.559710 11765 solver.cpp:228] Iteration 62800, loss = 2.65155
I0316 23:41:38.559819 11765 solver.cpp:244]     Train net output #0: loss = 2.65155 (* 1 = 2.65155 loss)
I0316 23:41:38.609742 11765 sgd_solver.cpp:106] Iteration 62800, lr = 0.02
I0316 23:42:51.260486 11765 solver.cpp:228] Iteration 62900, loss = 2.99018
I0316 23:42:51.260619 11765 solver.cpp:244]     Train net output #0: loss = 2.99018 (* 1 = 2.99018 loss)
I0316 23:42:51.308673 11765 sgd_solver.cpp:106] Iteration 62900, lr = 0.02
I0316 23:44:04.348453 11765 solver.cpp:337] Iteration 63000, Testing net (#0)
I0316 23:45:17.359784 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.366899
I0316 23:45:17.359894 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.62878
I0316 23:45:17.359906 11765 solver.cpp:404]     Test net output #2: loss = 2.9086 (* 1 = 2.9086 loss)
I0316 23:45:18.002622 11765 solver.cpp:228] Iteration 63000, loss = 2.71054
I0316 23:45:18.002671 11765 solver.cpp:244]     Train net output #0: loss = 2.71054 (* 1 = 2.71054 loss)
I0316 23:45:18.067394 11765 sgd_solver.cpp:106] Iteration 63000, lr = 0.02
I0316 23:46:34.654839 11765 solver.cpp:228] Iteration 63100, loss = 2.68559
I0316 23:46:34.654999 11765 solver.cpp:244]     Train net output #0: loss = 2.68559 (* 1 = 2.68559 loss)
I0316 23:46:34.745398 11765 sgd_solver.cpp:106] Iteration 63100, lr = 0.02
I0316 23:47:51.473801 11765 solver.cpp:228] Iteration 63200, loss = 2.79848
I0316 23:47:51.473932 11765 solver.cpp:244]     Train net output #0: loss = 2.79848 (* 1 = 2.79848 loss)
I0316 23:47:51.532877 11765 sgd_solver.cpp:106] Iteration 63200, lr = 0.02
I0316 23:49:05.430168 11765 solver.cpp:228] Iteration 63300, loss = 2.75104
I0316 23:49:05.430301 11765 solver.cpp:244]     Train net output #0: loss = 2.75104 (* 1 = 2.75104 loss)
I0316 23:49:05.484623 11765 sgd_solver.cpp:106] Iteration 63300, lr = 0.02
I0316 23:50:19.412084 11765 solver.cpp:228] Iteration 63400, loss = 2.69423
I0316 23:50:19.412226 11765 solver.cpp:244]     Train net output #0: loss = 2.69423 (* 1 = 2.69423 loss)
I0316 23:50:19.439008 11765 sgd_solver.cpp:106] Iteration 63400, lr = 0.02
I0316 23:51:34.258075 11765 solver.cpp:228] Iteration 63500, loss = 2.83123
I0316 23:51:34.258224 11765 solver.cpp:244]     Train net output #0: loss = 2.83123 (* 1 = 2.83123 loss)
I0316 23:51:34.306342 11765 sgd_solver.cpp:106] Iteration 63500, lr = 0.02
I0316 23:52:48.821265 11765 solver.cpp:228] Iteration 63600, loss = 2.65548
I0316 23:52:48.821375 11765 solver.cpp:244]     Train net output #0: loss = 2.65548 (* 1 = 2.65548 loss)
I0316 23:52:48.873725 11765 sgd_solver.cpp:106] Iteration 63600, lr = 0.02
I0316 23:54:04.170619 11765 solver.cpp:228] Iteration 63700, loss = 2.80631
I0316 23:54:04.170806 11765 solver.cpp:244]     Train net output #0: loss = 2.80631 (* 1 = 2.80631 loss)
I0316 23:54:04.231017 11765 sgd_solver.cpp:106] Iteration 63700, lr = 0.02
I0316 23:55:19.883496 11765 solver.cpp:228] Iteration 63800, loss = 2.83736
I0316 23:55:19.883633 11765 solver.cpp:244]     Train net output #0: loss = 2.83736 (* 1 = 2.83736 loss)
I0316 23:55:19.934494 11765 sgd_solver.cpp:106] Iteration 63800, lr = 0.02
I0316 23:56:32.466279 11765 solver.cpp:228] Iteration 63900, loss = 2.92517
I0316 23:56:32.466437 11765 solver.cpp:244]     Train net output #0: loss = 2.92517 (* 1 = 2.92517 loss)
I0316 23:56:32.514549 11765 sgd_solver.cpp:106] Iteration 63900, lr = 0.02
I0316 23:57:46.953040 11765 solver.cpp:337] Iteration 64000, Testing net (#0)
I0316 23:58:59.518893 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36974
I0316 23:58:59.519024 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.629699
I0316 23:58:59.519037 11765 solver.cpp:404]     Test net output #2: loss = 2.90332 (* 1 = 2.90332 loss)
I0316 23:59:00.164505 11765 solver.cpp:228] Iteration 64000, loss = 2.71007
I0316 23:59:00.164543 11765 solver.cpp:244]     Train net output #0: loss = 2.71007 (* 1 = 2.71007 loss)
I0316 23:59:00.232161 11765 sgd_solver.cpp:106] Iteration 64000, lr = 0.02
I0317 00:00:14.221127 11765 solver.cpp:228] Iteration 64100, loss = 2.65353
I0317 00:00:14.221269 11765 solver.cpp:244]     Train net output #0: loss = 2.65353 (* 1 = 2.65353 loss)
I0317 00:00:14.321223 11765 sgd_solver.cpp:106] Iteration 64100, lr = 0.02
I0317 00:01:30.013532 11765 solver.cpp:228] Iteration 64200, loss = 2.84824
I0317 00:01:30.013685 11765 solver.cpp:244]     Train net output #0: loss = 2.84824 (* 1 = 2.84824 loss)
I0317 00:01:30.077944 11765 sgd_solver.cpp:106] Iteration 64200, lr = 0.02
I0317 00:02:45.752574 11765 solver.cpp:228] Iteration 64300, loss = 2.4183
I0317 00:02:45.752723 11765 solver.cpp:244]     Train net output #0: loss = 2.4183 (* 1 = 2.4183 loss)
I0317 00:02:45.812595 11765 sgd_solver.cpp:106] Iteration 64300, lr = 0.02
I0317 00:04:01.786434 11765 solver.cpp:228] Iteration 64400, loss = 3.01524
I0317 00:04:01.786593 11765 solver.cpp:244]     Train net output #0: loss = 3.01524 (* 1 = 3.01524 loss)
I0317 00:04:01.839164 11765 sgd_solver.cpp:106] Iteration 64400, lr = 0.02
I0317 00:05:16.173738 11765 solver.cpp:228] Iteration 64500, loss = 3.04816
I0317 00:05:16.173871 11765 solver.cpp:244]     Train net output #0: loss = 3.04816 (* 1 = 3.04816 loss)
I0317 00:05:16.234042 11765 sgd_solver.cpp:106] Iteration 64500, lr = 0.02
I0317 00:06:32.608852 11765 solver.cpp:228] Iteration 64600, loss = 2.70831
I0317 00:06:32.609006 11765 solver.cpp:244]     Train net output #0: loss = 2.70831 (* 1 = 2.70831 loss)
I0317 00:06:32.659201 11765 sgd_solver.cpp:106] Iteration 64600, lr = 0.02
I0317 00:07:45.437171 11765 solver.cpp:228] Iteration 64700, loss = 2.70762
I0317 00:07:45.437324 11765 solver.cpp:244]     Train net output #0: loss = 2.70762 (* 1 = 2.70762 loss)
I0317 00:07:45.494020 11765 sgd_solver.cpp:106] Iteration 64700, lr = 0.02
I0317 00:09:05.168952 11765 solver.cpp:228] Iteration 64800, loss = 3.08554
I0317 00:09:05.169193 11765 solver.cpp:244]     Train net output #0: loss = 3.08554 (* 1 = 3.08554 loss)
I0317 00:09:05.197219 11765 sgd_solver.cpp:106] Iteration 64800, lr = 0.02
I0317 00:10:19.727972 11765 solver.cpp:228] Iteration 64900, loss = 3.02993
I0317 00:10:19.728135 11765 solver.cpp:244]     Train net output #0: loss = 3.02993 (* 1 = 3.02993 loss)
I0317 00:10:19.766268 11765 sgd_solver.cpp:106] Iteration 64900, lr = 0.02
I0317 00:11:34.690142 11765 solver.cpp:337] Iteration 65000, Testing net (#0)
I0317 00:12:47.684991 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36896
I0317 00:12:47.685148 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.630239
I0317 00:12:47.685178 11765 solver.cpp:404]     Test net output #2: loss = 2.91448 (* 1 = 2.91448 loss)
I0317 00:12:48.332999 11765 solver.cpp:228] Iteration 65000, loss = 2.60859
I0317 00:12:48.333043 11765 solver.cpp:244]     Train net output #0: loss = 2.60859 (* 1 = 2.60859 loss)
I0317 00:12:48.402757 11765 sgd_solver.cpp:106] Iteration 65000, lr = 0.02
I0317 00:14:04.982278 11765 solver.cpp:228] Iteration 65100, loss = 2.9203
I0317 00:14:04.982416 11765 solver.cpp:244]     Train net output #0: loss = 2.9203 (* 1 = 2.9203 loss)
I0317 00:14:05.065173 11765 sgd_solver.cpp:106] Iteration 65100, lr = 0.02
I0317 00:15:21.764801 11765 solver.cpp:228] Iteration 65200, loss = 3.16865
I0317 00:15:21.764947 11765 solver.cpp:244]     Train net output #0: loss = 3.16865 (* 1 = 3.16865 loss)
I0317 00:15:21.821516 11765 sgd_solver.cpp:106] Iteration 65200, lr = 0.02
I0317 00:16:35.130434 11765 solver.cpp:228] Iteration 65300, loss = 3.07343
I0317 00:16:35.130614 11765 solver.cpp:244]     Train net output #0: loss = 3.07343 (* 1 = 3.07343 loss)
I0317 00:16:35.179831 11765 sgd_solver.cpp:106] Iteration 65300, lr = 0.02
I0317 00:17:50.089681 11765 solver.cpp:228] Iteration 65400, loss = 2.93213
I0317 00:17:50.089818 11765 solver.cpp:244]     Train net output #0: loss = 2.93213 (* 1 = 2.93213 loss)
I0317 00:17:50.110304 11765 sgd_solver.cpp:106] Iteration 65400, lr = 0.02
I0317 00:19:05.299204 11765 solver.cpp:228] Iteration 65500, loss = 2.84288
I0317 00:19:05.299340 11765 solver.cpp:244]     Train net output #0: loss = 2.84288 (* 1 = 2.84288 loss)
I0317 00:19:05.328212 11765 sgd_solver.cpp:106] Iteration 65500, lr = 0.02
I0317 00:20:20.268030 11765 solver.cpp:228] Iteration 65600, loss = 3.32812
I0317 00:20:20.268210 11765 solver.cpp:244]     Train net output #0: loss = 3.32812 (* 1 = 3.32812 loss)
I0317 00:20:20.317662 11765 sgd_solver.cpp:106] Iteration 65600, lr = 0.02
I0317 00:21:35.547577 11765 solver.cpp:228] Iteration 65700, loss = 2.75932
I0317 00:21:35.547729 11765 solver.cpp:244]     Train net output #0: loss = 2.75932 (* 1 = 2.75932 loss)
I0317 00:21:35.596247 11765 sgd_solver.cpp:106] Iteration 65700, lr = 0.02
I0317 00:22:53.533359 11765 solver.cpp:228] Iteration 65800, loss = 2.81087
I0317 00:22:53.533522 11765 solver.cpp:244]     Train net output #0: loss = 2.81087 (* 1 = 2.81087 loss)
I0317 00:22:53.592865 11765 sgd_solver.cpp:106] Iteration 65800, lr = 0.02
I0317 00:24:07.834794 11765 solver.cpp:228] Iteration 65900, loss = 2.6268
I0317 00:24:07.834924 11765 solver.cpp:244]     Train net output #0: loss = 2.6268 (* 1 = 2.6268 loss)
I0317 00:24:07.883090 11765 sgd_solver.cpp:106] Iteration 65900, lr = 0.02
I0317 00:25:22.183912 11765 solver.cpp:337] Iteration 66000, Testing net (#0)
I0317 00:26:34.837545 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36918
I0317 00:26:34.837689 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.62968
I0317 00:26:34.837718 11765 solver.cpp:404]     Test net output #2: loss = 2.90316 (* 1 = 2.90316 loss)
I0317 00:26:35.481802 11765 solver.cpp:228] Iteration 66000, loss = 2.85386
I0317 00:26:35.481837 11765 solver.cpp:244]     Train net output #0: loss = 2.85386 (* 1 = 2.85386 loss)
I0317 00:26:35.540978 11765 sgd_solver.cpp:106] Iteration 66000, lr = 0.02
I0317 00:27:51.245810 11765 solver.cpp:228] Iteration 66100, loss = 2.84058
I0317 00:27:51.245967 11765 solver.cpp:244]     Train net output #0: loss = 2.84058 (* 1 = 2.84058 loss)
I0317 00:27:51.318102 11765 sgd_solver.cpp:106] Iteration 66100, lr = 0.02
I0317 00:29:06.886440 11765 solver.cpp:228] Iteration 66200, loss = 2.44932
I0317 00:29:06.886559 11765 solver.cpp:244]     Train net output #0: loss = 2.44932 (* 1 = 2.44932 loss)
I0317 00:29:06.951201 11765 sgd_solver.cpp:106] Iteration 66200, lr = 0.02
I0317 00:30:20.645571 11765 solver.cpp:228] Iteration 66300, loss = 2.7067
I0317 00:30:20.645705 11765 solver.cpp:244]     Train net output #0: loss = 2.7067 (* 1 = 2.7067 loss)
I0317 00:30:20.696979 11765 sgd_solver.cpp:106] Iteration 66300, lr = 0.02
I0317 00:31:36.341465 11765 solver.cpp:228] Iteration 66400, loss = 2.66342
I0317 00:31:36.341585 11765 solver.cpp:244]     Train net output #0: loss = 2.66342 (* 1 = 2.66342 loss)
I0317 00:31:36.390763 11765 sgd_solver.cpp:106] Iteration 66400, lr = 0.02
I0317 00:32:49.200016 11765 solver.cpp:228] Iteration 66500, loss = 2.74649
I0317 00:32:49.200165 11765 solver.cpp:244]     Train net output #0: loss = 2.74649 (* 1 = 2.74649 loss)
I0317 00:32:49.259269 11765 sgd_solver.cpp:106] Iteration 66500, lr = 0.02
I0317 00:34:02.187872 11765 solver.cpp:228] Iteration 66600, loss = 2.77173
I0317 00:34:02.188014 11765 solver.cpp:244]     Train net output #0: loss = 2.77173 (* 1 = 2.77173 loss)
I0317 00:34:02.247521 11765 sgd_solver.cpp:106] Iteration 66600, lr = 0.02
I0317 00:35:16.711019 11765 solver.cpp:228] Iteration 66700, loss = 2.66724
I0317 00:35:16.711171 11765 solver.cpp:244]     Train net output #0: loss = 2.66724 (* 1 = 2.66724 loss)
I0317 00:35:16.740653 11765 sgd_solver.cpp:106] Iteration 66700, lr = 0.02
I0317 00:36:30.546767 11765 solver.cpp:228] Iteration 66800, loss = 2.72799
I0317 00:36:30.546921 11765 solver.cpp:244]     Train net output #0: loss = 2.72799 (* 1 = 2.72799 loss)
I0317 00:36:30.574383 11765 sgd_solver.cpp:106] Iteration 66800, lr = 0.02
I0317 00:37:44.408094 11765 solver.cpp:228] Iteration 66900, loss = 2.68408
I0317 00:37:44.408252 11765 solver.cpp:244]     Train net output #0: loss = 2.68408 (* 1 = 2.68408 loss)
I0317 00:37:44.461843 11765 sgd_solver.cpp:106] Iteration 66900, lr = 0.02
I0317 00:38:56.094115 11765 solver.cpp:337] Iteration 67000, Testing net (#0)
I0317 00:40:08.767307 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36784
I0317 00:40:08.767453 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632279
I0317 00:40:08.767467 11765 solver.cpp:404]     Test net output #2: loss = 2.90331 (* 1 = 2.90331 loss)
I0317 00:40:09.410693 11765 solver.cpp:228] Iteration 67000, loss = 2.26464
I0317 00:40:09.410739 11765 solver.cpp:244]     Train net output #0: loss = 2.26464 (* 1 = 2.26464 loss)
I0317 00:40:09.479778 11765 sgd_solver.cpp:106] Iteration 67000, lr = 0.02
I0317 00:41:25.134683 11765 solver.cpp:228] Iteration 67100, loss = 2.68643
I0317 00:41:25.134881 11765 solver.cpp:244]     Train net output #0: loss = 2.68643 (* 1 = 2.68643 loss)
I0317 00:41:25.227694 11765 sgd_solver.cpp:106] Iteration 67100, lr = 0.02
I0317 00:42:38.335623 11765 solver.cpp:228] Iteration 67200, loss = 3.05734
I0317 00:42:38.335757 11765 solver.cpp:244]     Train net output #0: loss = 3.05734 (* 1 = 3.05734 loss)
I0317 00:42:38.386940 11765 sgd_solver.cpp:106] Iteration 67200, lr = 0.02
I0317 00:43:53.151907 11765 solver.cpp:228] Iteration 67300, loss = 2.69198
I0317 00:43:53.152762 11765 solver.cpp:244]     Train net output #0: loss = 2.69198 (* 1 = 2.69198 loss)
I0317 00:43:53.153061 11765 sgd_solver.cpp:106] Iteration 67300, lr = 0.02
I0317 00:45:08.222685 11765 solver.cpp:228] Iteration 67400, loss = 2.67756
I0317 00:45:08.222843 11765 solver.cpp:244]     Train net output #0: loss = 2.67756 (* 1 = 2.67756 loss)
I0317 00:45:08.273113 11765 sgd_solver.cpp:106] Iteration 67400, lr = 0.02
I0317 00:46:24.849170 11765 solver.cpp:228] Iteration 67500, loss = 2.16274
I0317 00:46:24.849319 11765 solver.cpp:244]     Train net output #0: loss = 2.16274 (* 1 = 2.16274 loss)
I0317 00:46:24.902889 11765 sgd_solver.cpp:106] Iteration 67500, lr = 0.02
I0317 00:47:40.243257 11765 solver.cpp:228] Iteration 67600, loss = 2.61272
I0317 00:47:40.243389 11765 solver.cpp:244]     Train net output #0: loss = 2.61272 (* 1 = 2.61272 loss)
I0317 00:47:40.302462 11765 sgd_solver.cpp:106] Iteration 67600, lr = 0.02
I0317 00:48:54.469594 11765 solver.cpp:228] Iteration 67700, loss = 2.80548
I0317 00:48:54.469713 11765 solver.cpp:244]     Train net output #0: loss = 2.80548 (* 1 = 2.80548 loss)
I0317 00:48:54.507377 11765 sgd_solver.cpp:106] Iteration 67700, lr = 0.02
I0317 00:50:07.729580 11765 solver.cpp:228] Iteration 67800, loss = 2.84285
I0317 00:50:07.729725 11765 solver.cpp:244]     Train net output #0: loss = 2.84285 (* 1 = 2.84285 loss)
I0317 00:50:07.782294 11765 sgd_solver.cpp:106] Iteration 67800, lr = 0.02
I0317 00:51:19.875696 11765 solver.cpp:228] Iteration 67900, loss = 2.63989
I0317 00:51:19.875844 11765 solver.cpp:244]     Train net output #0: loss = 2.63989 (* 1 = 2.63989 loss)
I0317 00:51:19.924680 11765 sgd_solver.cpp:106] Iteration 67900, lr = 0.02
I0317 00:52:32.623863 11765 solver.cpp:337] Iteration 68000, Testing net (#0)
I0317 00:53:45.434469 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36816
I0317 00:53:45.434629 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.631159
I0317 00:53:45.434659 11765 solver.cpp:404]     Test net output #2: loss = 2.90138 (* 1 = 2.90138 loss)
I0317 00:53:46.076766 11765 solver.cpp:228] Iteration 68000, loss = 2.74952
I0317 00:53:46.076805 11765 solver.cpp:244]     Train net output #0: loss = 2.74952 (* 1 = 2.74952 loss)
I0317 00:53:46.139791 11765 sgd_solver.cpp:106] Iteration 68000, lr = 0.02
I0317 00:54:59.147306 11765 solver.cpp:228] Iteration 68100, loss = 2.71174
I0317 00:54:59.147518 11765 solver.cpp:244]     Train net output #0: loss = 2.71174 (* 1 = 2.71174 loss)
I0317 00:54:59.233722 11765 sgd_solver.cpp:106] Iteration 68100, lr = 0.02
I0317 00:56:14.106143 11765 solver.cpp:228] Iteration 68200, loss = 2.53361
I0317 00:56:14.106272 11765 solver.cpp:244]     Train net output #0: loss = 2.53361 (* 1 = 2.53361 loss)
I0317 00:56:14.160320 11765 sgd_solver.cpp:106] Iteration 68200, lr = 0.02
I0317 00:57:31.074996 11765 solver.cpp:228] Iteration 68300, loss = 2.95688
I0317 00:57:31.075728 11765 solver.cpp:244]     Train net output #0: loss = 2.95688 (* 1 = 2.95688 loss)
I0317 00:57:31.133725 11765 sgd_solver.cpp:106] Iteration 68300, lr = 0.02
I0317 00:58:43.791847 11765 solver.cpp:228] Iteration 68400, loss = 2.62509
I0317 00:58:43.791988 11765 solver.cpp:244]     Train net output #0: loss = 2.62509 (* 1 = 2.62509 loss)
I0317 00:58:43.843451 11765 sgd_solver.cpp:106] Iteration 68400, lr = 0.02
I0317 00:59:56.718446 11765 solver.cpp:228] Iteration 68500, loss = 3.00345
I0317 00:59:56.718605 11765 solver.cpp:244]     Train net output #0: loss = 3.00345 (* 1 = 3.00345 loss)
I0317 00:59:56.770114 11765 sgd_solver.cpp:106] Iteration 68500, lr = 0.02
I0317 01:01:11.208684 11765 solver.cpp:228] Iteration 68600, loss = 2.68192
I0317 01:01:11.208825 11765 solver.cpp:244]     Train net output #0: loss = 2.68192 (* 1 = 2.68192 loss)
I0317 01:01:11.268718 11765 sgd_solver.cpp:106] Iteration 68600, lr = 0.02
I0317 01:02:29.153851 11765 solver.cpp:228] Iteration 68700, loss = 2.61296
I0317 01:02:29.154065 11765 solver.cpp:244]     Train net output #0: loss = 2.61296 (* 1 = 2.61296 loss)
I0317 01:02:29.178122 11765 sgd_solver.cpp:106] Iteration 68700, lr = 0.02
I0317 01:03:43.439319 11765 solver.cpp:228] Iteration 68800, loss = 2.78087
I0317 01:03:43.439430 11765 solver.cpp:244]     Train net output #0: loss = 2.78087 (* 1 = 2.78087 loss)
I0317 01:03:43.467609 11765 sgd_solver.cpp:106] Iteration 68800, lr = 0.02
I0317 01:05:00.049558 11765 solver.cpp:228] Iteration 68900, loss = 2.6211
I0317 01:05:00.049691 11765 solver.cpp:244]     Train net output #0: loss = 2.6211 (* 1 = 2.6211 loss)
I0317 01:05:00.078215 11765 sgd_solver.cpp:106] Iteration 68900, lr = 0.02
I0317 01:06:16.145226 11765 solver.cpp:337] Iteration 69000, Testing net (#0)
I0317 01:07:28.985853 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37166
I0317 01:07:28.986011 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63178
I0317 01:07:28.986032 11765 solver.cpp:404]     Test net output #2: loss = 2.89525 (* 1 = 2.89525 loss)
I0317 01:07:29.628983 11765 solver.cpp:228] Iteration 69000, loss = 2.85544
I0317 01:07:29.629020 11765 solver.cpp:244]     Train net output #0: loss = 2.85544 (* 1 = 2.85544 loss)
I0317 01:07:29.693032 11765 sgd_solver.cpp:106] Iteration 69000, lr = 0.02
I0317 01:08:45.009160 11765 solver.cpp:228] Iteration 69100, loss = 2.82441
I0317 01:08:45.009335 11765 solver.cpp:244]     Train net output #0: loss = 2.82441 (* 1 = 2.82441 loss)
I0317 01:08:45.097378 11765 sgd_solver.cpp:106] Iteration 69100, lr = 0.02
I0317 01:10:01.494858 11765 solver.cpp:228] Iteration 69200, loss = 2.86468
I0317 01:10:01.495002 11765 solver.cpp:244]     Train net output #0: loss = 2.86468 (* 1 = 2.86468 loss)
I0317 01:10:01.543141 11765 sgd_solver.cpp:106] Iteration 69200, lr = 0.02
I0317 01:11:18.870231 11765 solver.cpp:228] Iteration 69300, loss = 2.39712
I0317 01:11:18.870394 11765 solver.cpp:244]     Train net output #0: loss = 2.39712 (* 1 = 2.39712 loss)
I0317 01:11:18.929384 11765 sgd_solver.cpp:106] Iteration 69300, lr = 0.02
I0317 01:12:31.931130 11765 solver.cpp:228] Iteration 69400, loss = 2.71844
I0317 01:12:31.931252 11765 solver.cpp:244]     Train net output #0: loss = 2.71844 (* 1 = 2.71844 loss)
I0317 01:12:31.985028 11765 sgd_solver.cpp:106] Iteration 69400, lr = 0.02
I0317 01:13:44.365384 11765 solver.cpp:228] Iteration 69500, loss = 2.86084
I0317 01:13:44.365599 11765 solver.cpp:244]     Train net output #0: loss = 2.86084 (* 1 = 2.86084 loss)
I0317 01:13:44.417083 11765 sgd_solver.cpp:106] Iteration 69500, lr = 0.02
I0317 01:15:00.211191 11765 solver.cpp:228] Iteration 69600, loss = 2.57951
I0317 01:15:00.213105 11765 solver.cpp:244]     Train net output #0: loss = 2.57951 (* 1 = 2.57951 loss)
I0317 01:15:00.213933 11765 sgd_solver.cpp:106] Iteration 69600, lr = 0.02
I0317 01:16:16.050202 11765 solver.cpp:228] Iteration 69700, loss = 2.75765
I0317 01:16:16.050371 11765 solver.cpp:244]     Train net output #0: loss = 2.75765 (* 1 = 2.75765 loss)
I0317 01:16:16.109944 11765 sgd_solver.cpp:106] Iteration 69700, lr = 0.02
I0317 01:17:29.972193 11765 solver.cpp:228] Iteration 69800, loss = 2.87965
I0317 01:17:29.972337 11765 solver.cpp:244]     Train net output #0: loss = 2.87965 (* 1 = 2.87965 loss)
I0317 01:17:30.024207 11765 sgd_solver.cpp:106] Iteration 69800, lr = 0.02
I0317 01:18:44.060024 11765 solver.cpp:228] Iteration 69900, loss = 2.41862
I0317 01:18:44.060174 11765 solver.cpp:244]     Train net output #0: loss = 2.41862 (* 1 = 2.41862 loss)
I0317 01:18:44.109282 11765 sgd_solver.cpp:106] Iteration 69900, lr = 0.02
I0317 01:19:59.395246 11765 solver.cpp:337] Iteration 70000, Testing net (#0)
I0317 01:21:12.184041 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37048
I0317 01:21:12.184192 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.631499
I0317 01:21:12.184221 11765 solver.cpp:404]     Test net output #2: loss = 2.90558 (* 1 = 2.90558 loss)
I0317 01:21:12.831143 11765 solver.cpp:228] Iteration 70000, loss = 2.73882
I0317 01:21:12.831178 11765 solver.cpp:244]     Train net output #0: loss = 2.73882 (* 1 = 2.73882 loss)
I0317 01:21:12.895423 11765 sgd_solver.cpp:106] Iteration 70000, lr = 0.02
I0317 01:22:25.739748 11765 solver.cpp:228] Iteration 70100, loss = 2.45254
I0317 01:22:25.739892 11765 solver.cpp:244]     Train net output #0: loss = 2.45254 (* 1 = 2.45254 loss)
I0317 01:22:25.818498 11765 sgd_solver.cpp:106] Iteration 70100, lr = 0.02
I0317 01:23:43.709933 11765 solver.cpp:228] Iteration 70200, loss = 2.99401
I0317 01:23:43.710072 11765 solver.cpp:244]     Train net output #0: loss = 2.99401 (* 1 = 2.99401 loss)
I0317 01:23:43.779456 11765 sgd_solver.cpp:106] Iteration 70200, lr = 0.02
I0317 01:25:00.884898 11765 solver.cpp:228] Iteration 70300, loss = 2.93051
I0317 01:25:00.885041 11765 solver.cpp:244]     Train net output #0: loss = 2.93051 (* 1 = 2.93051 loss)
I0317 01:25:00.912344 11765 sgd_solver.cpp:106] Iteration 70300, lr = 0.02
I0317 01:26:16.946364 11765 solver.cpp:228] Iteration 70400, loss = 2.85574
I0317 01:26:16.946518 11765 solver.cpp:244]     Train net output #0: loss = 2.85574 (* 1 = 2.85574 loss)
I0317 01:26:17.003924 11765 sgd_solver.cpp:106] Iteration 70400, lr = 0.02
I0317 01:27:32.296720 11765 solver.cpp:228] Iteration 70500, loss = 2.85611
I0317 01:27:32.297682 11765 solver.cpp:244]     Train net output #0: loss = 2.85611 (* 1 = 2.85611 loss)
I0317 01:27:32.324508 11765 sgd_solver.cpp:106] Iteration 70500, lr = 0.02
I0317 01:28:47.170953 11765 solver.cpp:228] Iteration 70600, loss = 2.66788
I0317 01:28:47.171097 11765 solver.cpp:244]     Train net output #0: loss = 2.66788 (* 1 = 2.66788 loss)
I0317 01:28:47.230383 11765 sgd_solver.cpp:106] Iteration 70600, lr = 0.02
I0317 01:30:00.445894 11765 solver.cpp:228] Iteration 70700, loss = 2.80384
I0317 01:30:00.446027 11765 solver.cpp:244]     Train net output #0: loss = 2.80384 (* 1 = 2.80384 loss)
I0317 01:30:00.505405 11765 sgd_solver.cpp:106] Iteration 70700, lr = 0.02
I0317 01:31:16.922582 11765 solver.cpp:228] Iteration 70800, loss = 2.88583
I0317 01:31:16.922731 11765 solver.cpp:244]     Train net output #0: loss = 2.88583 (* 1 = 2.88583 loss)
I0317 01:31:16.978893 11765 sgd_solver.cpp:106] Iteration 70800, lr = 0.02
I0317 01:32:31.802290 11765 solver.cpp:228] Iteration 70900, loss = 2.76039
I0317 01:32:31.802722 11765 solver.cpp:244]     Train net output #0: loss = 2.76039 (* 1 = 2.76039 loss)
I0317 01:32:31.855403 11765 sgd_solver.cpp:106] Iteration 70900, lr = 0.02
I0317 01:33:48.000141 11765 solver.cpp:337] Iteration 71000, Testing net (#0)
I0317 01:35:00.874593 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37052
I0317 01:35:00.874974 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633239
I0317 01:35:00.875022 11765 solver.cpp:404]     Test net output #2: loss = 2.88825 (* 1 = 2.88825 loss)
I0317 01:35:01.517544 11765 solver.cpp:228] Iteration 71000, loss = 2.78341
I0317 01:35:01.517588 11765 solver.cpp:244]     Train net output #0: loss = 2.78341 (* 1 = 2.78341 loss)
I0317 01:35:01.577563 11765 sgd_solver.cpp:106] Iteration 71000, lr = 0.02
I0317 01:36:16.631057 11765 solver.cpp:228] Iteration 71100, loss = 2.81561
I0317 01:36:16.631243 11765 solver.cpp:244]     Train net output #0: loss = 2.81561 (* 1 = 2.81561 loss)
I0317 01:36:16.713735 11765 sgd_solver.cpp:106] Iteration 71100, lr = 0.02
I0317 01:37:32.885567 11765 solver.cpp:228] Iteration 71200, loss = 2.78748
I0317 01:37:32.885756 11765 solver.cpp:244]     Train net output #0: loss = 2.78748 (* 1 = 2.78748 loss)
I0317 01:37:32.948873 11765 sgd_solver.cpp:106] Iteration 71200, lr = 0.02
I0317 01:38:47.155028 11765 solver.cpp:228] Iteration 71300, loss = 2.78829
I0317 01:38:47.155148 11765 solver.cpp:244]     Train net output #0: loss = 2.78829 (* 1 = 2.78829 loss)
I0317 01:38:47.203594 11765 sgd_solver.cpp:106] Iteration 71300, lr = 0.02
I0317 01:40:01.818470 11765 solver.cpp:228] Iteration 71400, loss = 2.54641
I0317 01:40:01.818658 11765 solver.cpp:244]     Train net output #0: loss = 2.54641 (* 1 = 2.54641 loss)
I0317 01:40:01.872503 11765 sgd_solver.cpp:106] Iteration 71400, lr = 0.02
I0317 01:41:17.575428 11765 solver.cpp:228] Iteration 71500, loss = 2.51746
I0317 01:41:17.575553 11765 solver.cpp:244]     Train net output #0: loss = 2.51746 (* 1 = 2.51746 loss)
I0317 01:41:17.627830 11765 sgd_solver.cpp:106] Iteration 71500, lr = 0.02
I0317 01:42:35.318390 11765 solver.cpp:228] Iteration 71600, loss = 2.82715
I0317 01:42:35.318536 11765 solver.cpp:244]     Train net output #0: loss = 2.82715 (* 1 = 2.82715 loss)
I0317 01:42:35.377708 11765 sgd_solver.cpp:106] Iteration 71600, lr = 0.02
I0317 01:43:51.174176 11765 solver.cpp:228] Iteration 71700, loss = 2.41137
I0317 01:43:51.174326 11765 solver.cpp:244]     Train net output #0: loss = 2.41137 (* 1 = 2.41137 loss)
I0317 01:43:51.206483 11765 sgd_solver.cpp:106] Iteration 71700, lr = 0.02
I0317 01:45:08.067250 11765 solver.cpp:228] Iteration 71800, loss = 2.98583
I0317 01:45:08.067397 11765 solver.cpp:244]     Train net output #0: loss = 2.98583 (* 1 = 2.98583 loss)
I0317 01:45:08.121393 11765 sgd_solver.cpp:106] Iteration 71800, lr = 0.02
I0317 01:46:22.424444 11765 solver.cpp:228] Iteration 71900, loss = 2.96765
I0317 01:46:22.424588 11765 solver.cpp:244]     Train net output #0: loss = 2.96765 (* 1 = 2.96765 loss)
I0317 01:46:22.484310 11765 sgd_solver.cpp:106] Iteration 71900, lr = 0.02
I0317 01:47:37.183584 11765 solver.cpp:337] Iteration 72000, Testing net (#0)
I0317 01:48:49.919972 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37002
I0317 01:48:49.920080 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63194
I0317 01:48:49.920099 11765 solver.cpp:404]     Test net output #2: loss = 2.89473 (* 1 = 2.89473 loss)
I0317 01:48:50.562155 11765 solver.cpp:228] Iteration 72000, loss = 3.14771
I0317 01:48:50.562191 11765 solver.cpp:244]     Train net output #0: loss = 3.14771 (* 1 = 3.14771 loss)
I0317 01:48:50.626025 11765 sgd_solver.cpp:106] Iteration 72000, lr = 0.02
I0317 01:50:05.009816 11765 solver.cpp:228] Iteration 72100, loss = 3.05342
I0317 01:50:05.009999 11765 solver.cpp:244]     Train net output #0: loss = 3.05342 (* 1 = 3.05342 loss)
I0317 01:50:05.102125 11765 sgd_solver.cpp:106] Iteration 72100, lr = 0.02
I0317 01:51:19.151844 11765 solver.cpp:228] Iteration 72200, loss = 2.59533
I0317 01:51:19.151989 11765 solver.cpp:244]     Train net output #0: loss = 2.59533 (* 1 = 2.59533 loss)
I0317 01:51:19.201478 11765 sgd_solver.cpp:106] Iteration 72200, lr = 0.02
I0317 01:52:34.975658 11765 solver.cpp:228] Iteration 72300, loss = 3.09813
I0317 01:52:34.975873 11765 solver.cpp:244]     Train net output #0: loss = 3.09813 (* 1 = 3.09813 loss)
I0317 01:52:35.035217 11765 sgd_solver.cpp:106] Iteration 72300, lr = 0.02
I0317 01:53:48.041101 11765 solver.cpp:228] Iteration 72400, loss = 2.77301
I0317 01:53:48.041237 11765 solver.cpp:244]     Train net output #0: loss = 2.77301 (* 1 = 2.77301 loss)
I0317 01:53:48.041312 11765 sgd_solver.cpp:106] Iteration 72400, lr = 0.02
I0317 01:55:05.206449 11765 solver.cpp:228] Iteration 72500, loss = 2.57432
I0317 01:55:05.206624 11765 solver.cpp:244]     Train net output #0: loss = 2.57432 (* 1 = 2.57432 loss)
I0317 01:55:05.258935 11765 sgd_solver.cpp:106] Iteration 72500, lr = 0.02
I0317 01:56:23.934046 11765 solver.cpp:228] Iteration 72600, loss = 2.73169
I0317 01:56:23.934222 11765 solver.cpp:244]     Train net output #0: loss = 2.73169 (* 1 = 2.73169 loss)
I0317 01:56:23.988832 11765 sgd_solver.cpp:106] Iteration 72600, lr = 0.02
I0317 01:57:37.725039 11765 solver.cpp:228] Iteration 72700, loss = 2.86312
I0317 01:57:37.725225 11765 solver.cpp:244]     Train net output #0: loss = 2.86312 (* 1 = 2.86312 loss)
I0317 01:57:37.725304 11765 sgd_solver.cpp:106] Iteration 72700, lr = 0.02
I0317 01:58:51.745198 11765 solver.cpp:228] Iteration 72800, loss = 2.8853
I0317 01:58:51.745347 11765 solver.cpp:244]     Train net output #0: loss = 2.8853 (* 1 = 2.8853 loss)
I0317 01:58:51.794512 11765 sgd_solver.cpp:106] Iteration 72800, lr = 0.02
I0317 02:00:06.373814 11765 solver.cpp:228] Iteration 72900, loss = 2.5624
I0317 02:00:06.373999 11765 solver.cpp:244]     Train net output #0: loss = 2.5624 (* 1 = 2.5624 loss)
I0317 02:00:06.432905 11765 sgd_solver.cpp:106] Iteration 72900, lr = 0.02
I0317 02:01:19.340111 11765 solver.cpp:337] Iteration 73000, Testing net (#0)
I0317 02:02:32.986091 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36974
I0317 02:02:32.986245 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633639
I0317 02:02:32.986258 11765 solver.cpp:404]     Test net output #2: loss = 2.88424 (* 1 = 2.88424 loss)
I0317 02:02:33.625246 11765 solver.cpp:228] Iteration 73000, loss = 2.77889
I0317 02:02:33.625280 11765 solver.cpp:244]     Train net output #0: loss = 2.77889 (* 1 = 2.77889 loss)
I0317 02:02:33.691766 11765 sgd_solver.cpp:106] Iteration 73000, lr = 0.02
I0317 02:03:46.969772 11765 solver.cpp:228] Iteration 73100, loss = 2.67632
I0317 02:03:46.969933 11765 solver.cpp:244]     Train net output #0: loss = 2.67632 (* 1 = 2.67632 loss)
I0317 02:03:47.066040 11765 sgd_solver.cpp:106] Iteration 73100, lr = 0.02
I0317 02:05:02.754686 11765 solver.cpp:228] Iteration 73200, loss = 2.77755
I0317 02:05:02.754837 11765 solver.cpp:244]     Train net output #0: loss = 2.77755 (* 1 = 2.77755 loss)
I0317 02:05:02.811534 11765 sgd_solver.cpp:106] Iteration 73200, lr = 0.02
I0317 02:06:17.099782 11765 solver.cpp:228] Iteration 73300, loss = 2.40561
I0317 02:06:17.099897 11765 solver.cpp:244]     Train net output #0: loss = 2.40561 (* 1 = 2.40561 loss)
I0317 02:06:17.161437 11765 sgd_solver.cpp:106] Iteration 73300, lr = 0.02
I0317 02:07:31.904628 11765 solver.cpp:228] Iteration 73400, loss = 2.85683
I0317 02:07:31.904789 11765 solver.cpp:244]     Train net output #0: loss = 2.85683 (* 1 = 2.85683 loss)
I0317 02:07:31.945003 11765 sgd_solver.cpp:106] Iteration 73400, lr = 0.02
I0317 02:08:48.380955 11765 solver.cpp:228] Iteration 73500, loss = 2.82227
I0317 02:08:48.381088 11765 solver.cpp:244]     Train net output #0: loss = 2.82227 (* 1 = 2.82227 loss)
I0317 02:08:48.436069 11765 sgd_solver.cpp:106] Iteration 73500, lr = 0.02
I0317 02:10:04.950804 11765 solver.cpp:228] Iteration 73600, loss = 2.50135
I0317 02:10:04.950959 11765 solver.cpp:244]     Train net output #0: loss = 2.50135 (* 1 = 2.50135 loss)
I0317 02:10:04.999056 11765 sgd_solver.cpp:106] Iteration 73600, lr = 0.02
I0317 02:11:18.667526 11765 solver.cpp:228] Iteration 73700, loss = 2.86
I0317 02:11:18.667659 11765 solver.cpp:244]     Train net output #0: loss = 2.86 (* 1 = 2.86 loss)
I0317 02:11:18.725667 11765 sgd_solver.cpp:106] Iteration 73700, lr = 0.02
I0317 02:12:32.491639 11765 solver.cpp:228] Iteration 73800, loss = 2.60414
I0317 02:12:32.491828 11765 solver.cpp:244]     Train net output #0: loss = 2.60414 (* 1 = 2.60414 loss)
I0317 02:12:32.554036 11765 sgd_solver.cpp:106] Iteration 73800, lr = 0.02
I0317 02:13:46.849550 11765 solver.cpp:228] Iteration 73900, loss = 2.75975
I0317 02:13:46.857470 11765 solver.cpp:244]     Train net output #0: loss = 2.75975 (* 1 = 2.75975 loss)
I0317 02:13:46.879261 11765 sgd_solver.cpp:106] Iteration 73900, lr = 0.02
I0317 02:14:58.435115 11765 solver.cpp:337] Iteration 74000, Testing net (#0)
I0317 02:16:11.166565 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3689
I0317 02:16:11.166709 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.62814
I0317 02:16:11.166738 11765 solver.cpp:404]     Test net output #2: loss = 2.90936 (* 1 = 2.90936 loss)
I0317 02:16:11.805842 11765 solver.cpp:228] Iteration 74000, loss = 2.70348
I0317 02:16:11.805871 11765 solver.cpp:244]     Train net output #0: loss = 2.70348 (* 1 = 2.70348 loss)
I0317 02:16:11.877020 11765 sgd_solver.cpp:106] Iteration 74000, lr = 0.02
I0317 02:17:24.450291 11765 solver.cpp:228] Iteration 74100, loss = 2.82426
I0317 02:17:24.450459 11765 solver.cpp:244]     Train net output #0: loss = 2.82426 (* 1 = 2.82426 loss)
I0317 02:17:24.548748 11765 sgd_solver.cpp:106] Iteration 74100, lr = 0.02
I0317 02:18:38.887611 11765 solver.cpp:228] Iteration 74200, loss = 2.67292
I0317 02:18:38.887753 11765 solver.cpp:244]     Train net output #0: loss = 2.67292 (* 1 = 2.67292 loss)
I0317 02:18:38.948627 11765 sgd_solver.cpp:106] Iteration 74200, lr = 0.02
I0317 02:19:52.814584 11765 solver.cpp:228] Iteration 74300, loss = 2.7103
I0317 02:19:52.814733 11765 solver.cpp:244]     Train net output #0: loss = 2.7103 (* 1 = 2.7103 loss)
I0317 02:19:52.876138 11765 sgd_solver.cpp:106] Iteration 74300, lr = 0.02
I0317 02:21:06.910948 11765 solver.cpp:228] Iteration 74400, loss = 2.53386
I0317 02:21:06.911087 11765 solver.cpp:244]     Train net output #0: loss = 2.53386 (* 1 = 2.53386 loss)
I0317 02:21:06.929090 11765 sgd_solver.cpp:106] Iteration 74400, lr = 0.02
I0317 02:22:19.829001 11765 solver.cpp:228] Iteration 74500, loss = 2.73998
I0317 02:22:19.829183 11765 solver.cpp:244]     Train net output #0: loss = 2.73998 (* 1 = 2.73998 loss)
I0317 02:22:19.888167 11765 sgd_solver.cpp:106] Iteration 74500, lr = 0.02
I0317 02:23:32.268504 11765 solver.cpp:228] Iteration 74600, loss = 2.74788
I0317 02:23:32.269876 11765 solver.cpp:244]     Train net output #0: loss = 2.74788 (* 1 = 2.74788 loss)
I0317 02:23:32.310703 11765 sgd_solver.cpp:106] Iteration 74600, lr = 0.02
I0317 02:24:45.220302 11765 solver.cpp:228] Iteration 74700, loss = 2.70548
I0317 02:24:45.220468 11765 solver.cpp:244]     Train net output #0: loss = 2.70548 (* 1 = 2.70548 loss)
I0317 02:24:45.271272 11765 sgd_solver.cpp:106] Iteration 74700, lr = 0.02
I0317 02:25:58.827152 11765 solver.cpp:228] Iteration 74800, loss = 2.7562
I0317 02:25:58.827288 11765 solver.cpp:244]     Train net output #0: loss = 2.7562 (* 1 = 2.7562 loss)
I0317 02:25:58.878571 11765 sgd_solver.cpp:106] Iteration 74800, lr = 0.02
I0317 02:27:12.458904 11765 solver.cpp:228] Iteration 74900, loss = 2.71157
I0317 02:27:12.459045 11765 solver.cpp:244]     Train net output #0: loss = 2.71157 (* 1 = 2.71157 loss)
I0317 02:27:12.495723 11765 sgd_solver.cpp:106] Iteration 74900, lr = 0.02
I0317 02:28:26.638309 11765 solver.cpp:337] Iteration 75000, Testing net (#0)
I0317 02:29:39.458714 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37192
I0317 02:29:39.458902 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632859
I0317 02:29:39.458930 11765 solver.cpp:404]     Test net output #2: loss = 2.89417 (* 1 = 2.89417 loss)
I0317 02:29:40.098407 11765 solver.cpp:228] Iteration 75000, loss = 2.71789
I0317 02:29:40.098441 11765 solver.cpp:244]     Train net output #0: loss = 2.71789 (* 1 = 2.71789 loss)
I0317 02:29:40.164037 11765 sgd_solver.cpp:106] Iteration 75000, lr = 0.02
I0317 02:30:54.269737 11765 solver.cpp:228] Iteration 75100, loss = 2.46933
I0317 02:30:54.269968 11765 solver.cpp:244]     Train net output #0: loss = 2.46933 (* 1 = 2.46933 loss)
I0317 02:30:54.364549 11765 sgd_solver.cpp:106] Iteration 75100, lr = 0.02
I0317 02:32:08.021154 11765 solver.cpp:228] Iteration 75200, loss = 2.73418
I0317 02:32:08.021299 11765 solver.cpp:244]     Train net output #0: loss = 2.73418 (* 1 = 2.73418 loss)
I0317 02:32:08.084724 11765 sgd_solver.cpp:106] Iteration 75200, lr = 0.02
I0317 02:33:22.390817 11765 solver.cpp:228] Iteration 75300, loss = 3.00182
I0317 02:33:22.390950 11765 solver.cpp:244]     Train net output #0: loss = 3.00182 (* 1 = 3.00182 loss)
I0317 02:33:22.439424 11765 sgd_solver.cpp:106] Iteration 75300, lr = 0.02
I0317 02:34:37.269819 11765 solver.cpp:228] Iteration 75400, loss = 2.95077
I0317 02:34:37.269958 11765 solver.cpp:244]     Train net output #0: loss = 2.95077 (* 1 = 2.95077 loss)
I0317 02:34:37.328567 11765 sgd_solver.cpp:106] Iteration 75400, lr = 0.02
I0317 02:35:49.780917 11765 solver.cpp:228] Iteration 75500, loss = 2.68194
I0317 02:35:49.781050 11765 solver.cpp:244]     Train net output #0: loss = 2.68194 (* 1 = 2.68194 loss)
I0317 02:35:49.831665 11765 sgd_solver.cpp:106] Iteration 75500, lr = 0.02
I0317 02:37:05.913184 11765 solver.cpp:228] Iteration 75600, loss = 2.77177
I0317 02:37:05.913410 11765 solver.cpp:244]     Train net output #0: loss = 2.77177 (* 1 = 2.77177 loss)
I0317 02:37:05.922741 11765 sgd_solver.cpp:106] Iteration 75600, lr = 0.02
I0317 02:38:19.208067 11765 solver.cpp:228] Iteration 75700, loss = 2.86588
I0317 02:38:19.208258 11765 solver.cpp:244]     Train net output #0: loss = 2.86588 (* 1 = 2.86588 loss)
I0317 02:38:19.257061 11765 sgd_solver.cpp:106] Iteration 75700, lr = 0.02
I0317 02:39:34.330981 11765 solver.cpp:228] Iteration 75800, loss = 2.88726
I0317 02:39:34.331131 11765 solver.cpp:244]     Train net output #0: loss = 2.88726 (* 1 = 2.88726 loss)
I0317 02:39:34.397670 11765 sgd_solver.cpp:106] Iteration 75800, lr = 0.02
I0317 02:40:47.240427 11765 solver.cpp:228] Iteration 75900, loss = 2.81258
I0317 02:40:47.240546 11765 solver.cpp:244]     Train net output #0: loss = 2.81258 (* 1 = 2.81258 loss)
I0317 02:40:47.281679 11765 sgd_solver.cpp:106] Iteration 75900, lr = 0.02
I0317 02:42:01.444535 11765 solver.cpp:337] Iteration 76000, Testing net (#0)
I0317 02:43:14.186347 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3715
I0317 02:43:14.186522 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632399
I0317 02:43:14.186543 11765 solver.cpp:404]     Test net output #2: loss = 2.88775 (* 1 = 2.88775 loss)
I0317 02:43:14.830037 11765 solver.cpp:228] Iteration 76000, loss = 2.55892
I0317 02:43:14.830078 11765 solver.cpp:244]     Train net output #0: loss = 2.55892 (* 1 = 2.55892 loss)
I0317 02:43:14.898133 11765 sgd_solver.cpp:106] Iteration 76000, lr = 0.02
I0317 02:44:27.280691 11765 solver.cpp:228] Iteration 76100, loss = 2.58495
I0317 02:44:27.280836 11765 solver.cpp:244]     Train net output #0: loss = 2.58495 (* 1 = 2.58495 loss)
I0317 02:44:27.373731 11765 sgd_solver.cpp:106] Iteration 76100, lr = 0.02
I0317 02:45:39.874230 11765 solver.cpp:228] Iteration 76200, loss = 2.56598
I0317 02:45:39.874371 11765 solver.cpp:244]     Train net output #0: loss = 2.56598 (* 1 = 2.56598 loss)
I0317 02:45:39.940563 11765 sgd_solver.cpp:106] Iteration 76200, lr = 0.02
I0317 02:46:53.234975 11765 solver.cpp:228] Iteration 76300, loss = 3.08921
I0317 02:46:53.235123 11765 solver.cpp:244]     Train net output #0: loss = 3.08921 (* 1 = 3.08921 loss)
I0317 02:46:53.294065 11765 sgd_solver.cpp:106] Iteration 76300, lr = 0.02
I0317 02:48:07.569984 11765 solver.cpp:228] Iteration 76400, loss = 2.58991
I0317 02:48:07.570452 11765 solver.cpp:244]     Train net output #0: loss = 2.58991 (* 1 = 2.58991 loss)
I0317 02:48:07.609094 11765 sgd_solver.cpp:106] Iteration 76400, lr = 0.02
I0317 02:49:21.178696 11765 solver.cpp:228] Iteration 76500, loss = 2.58371
I0317 02:49:21.178926 11765 solver.cpp:244]     Train net output #0: loss = 2.58371 (* 1 = 2.58371 loss)
I0317 02:49:21.232208 11765 sgd_solver.cpp:106] Iteration 76500, lr = 0.02
I0317 02:50:34.618144 11765 solver.cpp:228] Iteration 76600, loss = 2.7168
I0317 02:50:34.618547 11765 solver.cpp:244]     Train net output #0: loss = 2.7168 (* 1 = 2.7168 loss)
I0317 02:50:34.618726 11765 sgd_solver.cpp:106] Iteration 76600, lr = 0.02
I0317 02:51:48.827855 11765 solver.cpp:228] Iteration 76700, loss = 2.70331
I0317 02:51:48.827988 11765 solver.cpp:244]     Train net output #0: loss = 2.70331 (* 1 = 2.70331 loss)
I0317 02:51:48.870623 11765 sgd_solver.cpp:106] Iteration 76700, lr = 0.02
I0317 02:53:02.403339 11765 solver.cpp:228] Iteration 76800, loss = 2.62296
I0317 02:53:02.403501 11765 solver.cpp:244]     Train net output #0: loss = 2.62296 (* 1 = 2.62296 loss)
I0317 02:53:02.451910 11765 sgd_solver.cpp:106] Iteration 76800, lr = 0.02
I0317 02:54:14.976398 11765 solver.cpp:228] Iteration 76900, loss = 2.65525
I0317 02:54:14.976518 11765 solver.cpp:244]     Train net output #0: loss = 2.65525 (* 1 = 2.65525 loss)
I0317 02:54:15.008812 11765 sgd_solver.cpp:106] Iteration 76900, lr = 0.02
I0317 02:55:30.176862 11765 solver.cpp:337] Iteration 77000, Testing net (#0)
I0317 02:56:43.083891 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37076
I0317 02:56:43.084089 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632559
I0317 02:56:43.084115 11765 solver.cpp:404]     Test net output #2: loss = 2.89207 (* 1 = 2.89207 loss)
I0317 02:56:43.724155 11765 solver.cpp:228] Iteration 77000, loss = 2.69712
I0317 02:56:43.724195 11765 solver.cpp:244]     Train net output #0: loss = 2.69712 (* 1 = 2.69712 loss)
I0317 02:56:43.792274 11765 sgd_solver.cpp:106] Iteration 77000, lr = 0.02
I0317 02:57:57.456816 11765 solver.cpp:228] Iteration 77100, loss = 2.52236
I0317 02:57:57.456975 11765 solver.cpp:244]     Train net output #0: loss = 2.52236 (* 1 = 2.52236 loss)
I0317 02:57:57.542027 11765 sgd_solver.cpp:106] Iteration 77100, lr = 0.02
I0317 02:59:11.766613 11765 solver.cpp:228] Iteration 77200, loss = 2.94199
I0317 02:59:11.766782 11765 solver.cpp:244]     Train net output #0: loss = 2.94199 (* 1 = 2.94199 loss)
I0317 02:59:11.828100 11765 sgd_solver.cpp:106] Iteration 77200, lr = 0.02
I0317 03:00:27.421838 11765 solver.cpp:228] Iteration 77300, loss = 2.47976
I0317 03:00:27.421964 11765 solver.cpp:244]     Train net output #0: loss = 2.47976 (* 1 = 2.47976 loss)
I0317 03:00:27.471830 11765 sgd_solver.cpp:106] Iteration 77300, lr = 0.02
I0317 03:01:40.517874 11765 solver.cpp:228] Iteration 77400, loss = 2.92504
I0317 03:01:40.518040 11765 solver.cpp:244]     Train net output #0: loss = 2.92504 (* 1 = 2.92504 loss)
I0317 03:01:40.547936 11765 sgd_solver.cpp:106] Iteration 77400, lr = 0.02
I0317 03:02:54.212044 11765 solver.cpp:228] Iteration 77500, loss = 2.6688
I0317 03:02:54.212158 11765 solver.cpp:244]     Train net output #0: loss = 2.6688 (* 1 = 2.6688 loss)
I0317 03:02:54.248956 11765 sgd_solver.cpp:106] Iteration 77500, lr = 0.02
I0317 03:04:07.979681 11765 solver.cpp:228] Iteration 77600, loss = 2.9313
I0317 03:04:07.979812 11765 solver.cpp:244]     Train net output #0: loss = 2.9313 (* 1 = 2.9313 loss)
I0317 03:04:08.017467 11765 sgd_solver.cpp:106] Iteration 77600, lr = 0.02
I0317 03:05:22.992738 11765 solver.cpp:228] Iteration 77700, loss = 2.73676
I0317 03:05:22.992872 11765 solver.cpp:244]     Train net output #0: loss = 2.73676 (* 1 = 2.73676 loss)
I0317 03:05:23.025037 11765 sgd_solver.cpp:106] Iteration 77700, lr = 0.02
I0317 03:06:37.135804 11765 solver.cpp:228] Iteration 77800, loss = 2.976
I0317 03:06:37.135921 11765 solver.cpp:244]     Train net output #0: loss = 2.976 (* 1 = 2.976 loss)
I0317 03:06:37.196660 11765 sgd_solver.cpp:106] Iteration 77800, lr = 0.02
I0317 03:07:49.682554 11765 solver.cpp:228] Iteration 77900, loss = 2.94316
I0317 03:07:49.682708 11765 solver.cpp:244]     Train net output #0: loss = 2.94316 (* 1 = 2.94316 loss)
I0317 03:07:49.735975 11765 sgd_solver.cpp:106] Iteration 77900, lr = 0.02
I0317 03:09:03.574409 11765 solver.cpp:337] Iteration 78000, Testing net (#0)
I0317 03:10:16.658150 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37002
I0317 03:10:16.658490 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.631579
I0317 03:10:16.658529 11765 solver.cpp:404]     Test net output #2: loss = 2.89069 (* 1 = 2.89069 loss)
I0317 03:10:17.300534 11765 solver.cpp:228] Iteration 78000, loss = 2.77216
I0317 03:10:17.300575 11765 solver.cpp:244]     Train net output #0: loss = 2.77216 (* 1 = 2.77216 loss)
I0317 03:10:17.363637 11765 sgd_solver.cpp:106] Iteration 78000, lr = 0.02
I0317 03:11:31.985551 11765 solver.cpp:228] Iteration 78100, loss = 2.78859
I0317 03:11:31.985739 11765 solver.cpp:244]     Train net output #0: loss = 2.78859 (* 1 = 2.78859 loss)
I0317 03:11:32.077564 11765 sgd_solver.cpp:106] Iteration 78100, lr = 0.02
I0317 03:12:46.468721 11765 solver.cpp:228] Iteration 78200, loss = 2.81733
I0317 03:12:46.468874 11765 solver.cpp:244]     Train net output #0: loss = 2.81733 (* 1 = 2.81733 loss)
I0317 03:12:46.527887 11765 sgd_solver.cpp:106] Iteration 78200, lr = 0.02
I0317 03:14:00.878350 11765 solver.cpp:228] Iteration 78300, loss = 2.77652
I0317 03:14:00.878489 11765 solver.cpp:244]     Train net output #0: loss = 2.77652 (* 1 = 2.77652 loss)
I0317 03:14:00.937469 11765 sgd_solver.cpp:106] Iteration 78300, lr = 0.02
I0317 03:15:15.178800 11765 solver.cpp:228] Iteration 78400, loss = 2.73402
I0317 03:15:15.178966 11765 solver.cpp:244]     Train net output #0: loss = 2.73402 (* 1 = 2.73402 loss)
I0317 03:15:15.268882 11765 sgd_solver.cpp:106] Iteration 78400, lr = 0.02
I0317 03:16:31.288364 11765 solver.cpp:228] Iteration 78500, loss = 2.55788
I0317 03:16:31.288516 11765 solver.cpp:244]     Train net output #0: loss = 2.55788 (* 1 = 2.55788 loss)
I0317 03:16:31.312399 11765 sgd_solver.cpp:106] Iteration 78500, lr = 0.02
I0317 03:17:45.485690 11765 solver.cpp:228] Iteration 78600, loss = 2.51483
I0317 03:17:45.485872 11765 solver.cpp:244]     Train net output #0: loss = 2.51483 (* 1 = 2.51483 loss)
I0317 03:17:45.533861 11765 sgd_solver.cpp:106] Iteration 78600, lr = 0.02
I0317 03:19:01.651986 11765 solver.cpp:228] Iteration 78700, loss = 2.5787
I0317 03:19:01.652129 11765 solver.cpp:244]     Train net output #0: loss = 2.5787 (* 1 = 2.5787 loss)
I0317 03:19:01.706079 11765 sgd_solver.cpp:106] Iteration 78700, lr = 0.02
I0317 03:20:17.738144 11765 solver.cpp:228] Iteration 78800, loss = 2.78162
I0317 03:20:17.738318 11765 solver.cpp:244]     Train net output #0: loss = 2.78162 (* 1 = 2.78162 loss)
I0317 03:20:17.792544 11765 sgd_solver.cpp:106] Iteration 78800, lr = 0.02
I0317 03:21:31.394307 11765 solver.cpp:228] Iteration 78900, loss = 2.53517
I0317 03:21:31.394469 11765 solver.cpp:244]     Train net output #0: loss = 2.53517 (* 1 = 2.53517 loss)
I0317 03:21:31.447993 11765 sgd_solver.cpp:106] Iteration 78900, lr = 0.02
I0317 03:22:45.882594 11765 solver.cpp:337] Iteration 79000, Testing net (#0)
I0317 03:23:58.604343 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3738
I0317 03:23:58.604521 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633339
I0317 03:23:58.604542 11765 solver.cpp:404]     Test net output #2: loss = 2.88051 (* 1 = 2.88051 loss)
I0317 03:23:59.248955 11765 solver.cpp:228] Iteration 79000, loss = 2.78396
I0317 03:23:59.248997 11765 solver.cpp:244]     Train net output #0: loss = 2.78396 (* 1 = 2.78396 loss)
I0317 03:23:59.308068 11765 sgd_solver.cpp:106] Iteration 79000, lr = 0.02
I0317 03:25:12.808722 11765 solver.cpp:228] Iteration 79100, loss = 2.50475
I0317 03:25:12.808863 11765 solver.cpp:244]     Train net output #0: loss = 2.50475 (* 1 = 2.50475 loss)
I0317 03:25:12.881597 11765 sgd_solver.cpp:106] Iteration 79100, lr = 0.02
I0317 03:26:28.445077 11765 solver.cpp:228] Iteration 79200, loss = 2.84358
I0317 03:26:28.445211 11765 solver.cpp:244]     Train net output #0: loss = 2.84358 (* 1 = 2.84358 loss)
I0317 03:26:28.510021 11765 sgd_solver.cpp:106] Iteration 79200, lr = 0.02
I0317 03:27:42.918956 11765 solver.cpp:228] Iteration 79300, loss = 2.73384
I0317 03:27:42.919128 11765 solver.cpp:244]     Train net output #0: loss = 2.73384 (* 1 = 2.73384 loss)
I0317 03:27:42.978597 11765 sgd_solver.cpp:106] Iteration 79300, lr = 0.02
I0317 03:28:59.706295 11765 solver.cpp:228] Iteration 79400, loss = 2.73593
I0317 03:28:59.706416 11765 solver.cpp:244]     Train net output #0: loss = 2.73593 (* 1 = 2.73593 loss)
I0317 03:28:59.765445 11765 sgd_solver.cpp:106] Iteration 79400, lr = 0.02
I0317 03:30:14.083580 11765 solver.cpp:228] Iteration 79500, loss = 2.19611
I0317 03:30:14.083812 11765 solver.cpp:244]     Train net output #0: loss = 2.19611 (* 1 = 2.19611 loss)
I0317 03:30:14.134016 11765 sgd_solver.cpp:106] Iteration 79500, lr = 0.02
I0317 03:31:31.460149 11765 solver.cpp:228] Iteration 79600, loss = 2.84673
I0317 03:31:31.460294 11765 solver.cpp:244]     Train net output #0: loss = 2.84673 (* 1 = 2.84673 loss)
I0317 03:31:31.508419 11765 sgd_solver.cpp:106] Iteration 79600, lr = 0.02
I0317 03:32:44.593163 11765 solver.cpp:228] Iteration 79700, loss = 2.61408
I0317 03:32:44.593323 11765 solver.cpp:244]     Train net output #0: loss = 2.61408 (* 1 = 2.61408 loss)
I0317 03:32:44.642557 11765 sgd_solver.cpp:106] Iteration 79700, lr = 0.02
I0317 03:33:59.200996 11765 solver.cpp:228] Iteration 79800, loss = 2.77774
I0317 03:33:59.201210 11765 solver.cpp:244]     Train net output #0: loss = 2.77774 (* 1 = 2.77774 loss)
I0317 03:33:59.201287 11765 sgd_solver.cpp:106] Iteration 79800, lr = 0.02
I0317 03:35:13.843703 11765 solver.cpp:228] Iteration 79900, loss = 3.18674
I0317 03:35:13.843830 11765 solver.cpp:244]     Train net output #0: loss = 3.18674 (* 1 = 3.18674 loss)
I0317 03:35:13.893229 11765 sgd_solver.cpp:106] Iteration 79900, lr = 0.02
I0317 03:36:28.174017 11765 solver.cpp:454] Snapshotting to binary proto file snapshots/imageNet_slim_iter_80000.caffemodel
I0317 03:36:28.187726 11765 sgd_solver.cpp:273] Snapshotting solver state to binary proto file snapshots/imageNet_slim_iter_80000.solverstate
I0317 03:36:28.195955 11765 solver.cpp:337] Iteration 80000, Testing net (#0)
I0317 03:37:40.841635 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37034
I0317 03:37:40.841830 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632919
I0317 03:37:40.841866 11765 solver.cpp:404]     Test net output #2: loss = 2.89998 (* 1 = 2.89998 loss)
I0317 03:37:41.482363 11765 solver.cpp:228] Iteration 80000, loss = 2.89353
I0317 03:37:41.482409 11765 solver.cpp:244]     Train net output #0: loss = 2.89353 (* 1 = 2.89353 loss)
I0317 03:37:41.542865 11765 sgd_solver.cpp:106] Iteration 80000, lr = 0.02
I0317 03:38:54.116753 11765 solver.cpp:228] Iteration 80100, loss = 2.61289
I0317 03:38:54.116896 11765 solver.cpp:244]     Train net output #0: loss = 2.61289 (* 1 = 2.61289 loss)
I0317 03:38:54.210584 11765 sgd_solver.cpp:106] Iteration 80100, lr = 0.02
I0317 03:40:08.777746 11765 solver.cpp:228] Iteration 80200, loss = 2.74155
I0317 03:40:08.777937 11765 solver.cpp:244]     Train net output #0: loss = 2.74155 (* 1 = 2.74155 loss)
I0317 03:40:08.778009 11765 sgd_solver.cpp:106] Iteration 80200, lr = 0.02
I0317 03:41:23.168067 11765 solver.cpp:228] Iteration 80300, loss = 2.5696
I0317 03:41:23.168231 11765 solver.cpp:244]     Train net output #0: loss = 2.5696 (* 1 = 2.5696 loss)
I0317 03:41:23.217766 11765 sgd_solver.cpp:106] Iteration 80300, lr = 0.02
I0317 03:42:36.468705 11765 solver.cpp:228] Iteration 80400, loss = 2.69842
I0317 03:42:36.468852 11765 solver.cpp:244]     Train net output #0: loss = 2.69842 (* 1 = 2.69842 loss)
I0317 03:42:36.519243 11765 sgd_solver.cpp:106] Iteration 80400, lr = 0.02
I0317 03:43:49.398998 11765 solver.cpp:228] Iteration 80500, loss = 2.5239
I0317 03:43:49.399145 11765 solver.cpp:244]     Train net output #0: loss = 2.5239 (* 1 = 2.5239 loss)
I0317 03:43:49.448010 11765 sgd_solver.cpp:106] Iteration 80500, lr = 0.02
I0317 03:45:01.949868 11765 solver.cpp:228] Iteration 80600, loss = 2.70544
I0317 03:45:01.950024 11765 solver.cpp:244]     Train net output #0: loss = 2.70544 (* 1 = 2.70544 loss)
I0317 03:45:01.970108 11765 sgd_solver.cpp:106] Iteration 80600, lr = 0.02
I0317 03:46:16.186636 11765 solver.cpp:228] Iteration 80700, loss = 2.71765
I0317 03:46:16.186877 11765 solver.cpp:244]     Train net output #0: loss = 2.71765 (* 1 = 2.71765 loss)
I0317 03:46:16.245847 11765 sgd_solver.cpp:106] Iteration 80700, lr = 0.02
I0317 03:47:32.098186 11765 solver.cpp:228] Iteration 80800, loss = 2.58153
I0317 03:47:32.098330 11765 solver.cpp:244]     Train net output #0: loss = 2.58153 (* 1 = 2.58153 loss)
I0317 03:47:32.151588 11765 sgd_solver.cpp:106] Iteration 80800, lr = 0.02
I0317 03:48:46.631234 11765 solver.cpp:228] Iteration 80900, loss = 2.63884
I0317 03:48:46.631377 11765 solver.cpp:244]     Train net output #0: loss = 2.63884 (* 1 = 2.63884 loss)
I0317 03:48:46.668944 11765 sgd_solver.cpp:106] Iteration 80900, lr = 0.02
I0317 03:50:01.053064 11765 solver.cpp:337] Iteration 81000, Testing net (#0)
I0317 03:51:13.695783 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37096
I0317 03:51:13.695920 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633879
I0317 03:51:13.695960 11765 solver.cpp:404]     Test net output #2: loss = 2.88835 (* 1 = 2.88835 loss)
I0317 03:51:14.377526 11765 solver.cpp:228] Iteration 81000, loss = 2.53726
I0317 03:51:14.377565 11765 solver.cpp:244]     Train net output #0: loss = 2.53726 (* 1 = 2.53726 loss)
I0317 03:51:14.452858 11765 sgd_solver.cpp:106] Iteration 81000, lr = 0.02
I0317 03:52:28.143718 11765 solver.cpp:228] Iteration 81100, loss = 2.61301
I0317 03:52:28.143859 11765 solver.cpp:244]     Train net output #0: loss = 2.61301 (* 1 = 2.61301 loss)
I0317 03:52:28.232653 11765 sgd_solver.cpp:106] Iteration 81100, lr = 0.02
I0317 03:53:41.598554 11765 solver.cpp:228] Iteration 81200, loss = 2.95069
I0317 03:53:41.598709 11765 solver.cpp:244]     Train net output #0: loss = 2.95069 (* 1 = 2.95069 loss)
I0317 03:53:41.661051 11765 sgd_solver.cpp:106] Iteration 81200, lr = 0.02
I0317 03:54:56.900843 11765 solver.cpp:228] Iteration 81300, loss = 2.51285
I0317 03:54:56.900996 11765 solver.cpp:244]     Train net output #0: loss = 2.51285 (* 1 = 2.51285 loss)
I0317 03:54:56.952297 11765 sgd_solver.cpp:106] Iteration 81300, lr = 0.02
I0317 03:56:12.553695 11765 solver.cpp:228] Iteration 81400, loss = 2.76482
I0317 03:56:12.553845 11765 solver.cpp:244]     Train net output #0: loss = 2.76482 (* 1 = 2.76482 loss)
I0317 03:56:12.604431 11765 sgd_solver.cpp:106] Iteration 81400, lr = 0.02
I0317 03:57:25.783673 11765 solver.cpp:228] Iteration 81500, loss = 2.84078
I0317 03:57:25.783823 11765 solver.cpp:244]     Train net output #0: loss = 2.84078 (* 1 = 2.84078 loss)
I0317 03:57:25.834669 11765 sgd_solver.cpp:106] Iteration 81500, lr = 0.02
I0317 03:58:39.557891 11765 solver.cpp:228] Iteration 81600, loss = 2.59408
I0317 03:58:39.558058 11765 solver.cpp:244]     Train net output #0: loss = 2.59408 (* 1 = 2.59408 loss)
I0317 03:58:39.606922 11765 sgd_solver.cpp:106] Iteration 81600, lr = 0.02
I0317 03:59:52.786238 11765 solver.cpp:228] Iteration 81700, loss = 2.58066
I0317 03:59:52.786365 11765 solver.cpp:244]     Train net output #0: loss = 2.58066 (* 1 = 2.58066 loss)
I0317 03:59:52.819342 11765 sgd_solver.cpp:106] Iteration 81700, lr = 0.02
I0317 04:01:07.113914 11765 solver.cpp:228] Iteration 81800, loss = 3.12437
I0317 04:01:07.114053 11765 solver.cpp:244]     Train net output #0: loss = 3.12437 (* 1 = 3.12437 loss)
I0317 04:01:07.173224 11765 sgd_solver.cpp:106] Iteration 81800, lr = 0.02
I0317 04:02:23.756543 11765 solver.cpp:228] Iteration 81900, loss = 3.08897
I0317 04:02:23.756692 11765 solver.cpp:244]     Train net output #0: loss = 3.08897 (* 1 = 3.08897 loss)
I0317 04:02:23.817667 11765 sgd_solver.cpp:106] Iteration 81900, lr = 0.02
I0317 04:03:40.359810 11765 solver.cpp:337] Iteration 82000, Testing net (#0)
I0317 04:04:53.023548 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3699
I0317 04:04:53.023692 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.634199
I0317 04:04:53.023713 11765 solver.cpp:404]     Test net output #2: loss = 2.89172 (* 1 = 2.89172 loss)
I0317 04:04:53.666756 11765 solver.cpp:228] Iteration 82000, loss = 2.60252
I0317 04:04:53.666793 11765 solver.cpp:244]     Train net output #0: loss = 2.60252 (* 1 = 2.60252 loss)
I0317 04:04:53.734040 11765 sgd_solver.cpp:106] Iteration 82000, lr = 0.02
I0317 04:06:07.763186 11765 solver.cpp:228] Iteration 82100, loss = 2.62777
I0317 04:06:07.763402 11765 solver.cpp:244]     Train net output #0: loss = 2.62777 (* 1 = 2.62777 loss)
I0317 04:06:07.835599 11765 sgd_solver.cpp:106] Iteration 82100, lr = 0.02
I0317 04:07:20.838546 11765 solver.cpp:228] Iteration 82200, loss = 2.66019
I0317 04:07:20.838701 11765 solver.cpp:244]     Train net output #0: loss = 2.66019 (* 1 = 2.66019 loss)
I0317 04:07:20.892356 11765 sgd_solver.cpp:106] Iteration 82200, lr = 0.02
I0317 04:08:35.936468 11765 solver.cpp:228] Iteration 82300, loss = 2.52125
I0317 04:08:35.936605 11765 solver.cpp:244]     Train net output #0: loss = 2.52125 (* 1 = 2.52125 loss)
I0317 04:08:35.995669 11765 sgd_solver.cpp:106] Iteration 82300, lr = 0.02
I0317 04:09:49.057750 11765 solver.cpp:228] Iteration 82400, loss = 2.48682
I0317 04:09:49.057904 11765 solver.cpp:244]     Train net output #0: loss = 2.48682 (* 1 = 2.48682 loss)
I0317 04:09:49.094666 11765 sgd_solver.cpp:106] Iteration 82400, lr = 0.02
I0317 04:11:02.569248 11765 solver.cpp:228] Iteration 82500, loss = 2.75475
I0317 04:11:02.569422 11765 solver.cpp:244]     Train net output #0: loss = 2.75475 (* 1 = 2.75475 loss)
I0317 04:11:02.599012 11765 sgd_solver.cpp:106] Iteration 82500, lr = 0.02
I0317 04:12:16.952848 11765 solver.cpp:228] Iteration 82600, loss = 2.58934
I0317 04:12:16.952996 11765 solver.cpp:244]     Train net output #0: loss = 2.58934 (* 1 = 2.58934 loss)
I0317 04:12:16.980192 11765 sgd_solver.cpp:106] Iteration 82600, lr = 0.02
I0317 04:13:31.306602 11765 solver.cpp:228] Iteration 82700, loss = 2.99407
I0317 04:13:31.306751 11765 solver.cpp:244]     Train net output #0: loss = 2.99407 (* 1 = 2.99407 loss)
I0317 04:13:31.366052 11765 sgd_solver.cpp:106] Iteration 82700, lr = 0.02
I0317 04:14:50.128495 11765 solver.cpp:228] Iteration 82800, loss = 2.83763
I0317 04:14:50.128760 11765 solver.cpp:244]     Train net output #0: loss = 2.83763 (* 1 = 2.83763 loss)
I0317 04:14:50.128862 11765 sgd_solver.cpp:106] Iteration 82800, lr = 0.02
I0317 04:16:06.354260 11765 solver.cpp:228] Iteration 82900, loss = 2.50061
I0317 04:16:06.354384 11765 solver.cpp:244]     Train net output #0: loss = 2.50061 (* 1 = 2.50061 loss)
I0317 04:16:06.402879 11765 sgd_solver.cpp:106] Iteration 82900, lr = 0.02
I0317 04:17:19.198688 11765 solver.cpp:337] Iteration 83000, Testing net (#0)
I0317 04:18:31.879812 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37104
I0317 04:18:31.879981 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63314
I0317 04:18:31.880009 11765 solver.cpp:404]     Test net output #2: loss = 2.89121 (* 1 = 2.89121 loss)
I0317 04:18:32.524988 11765 solver.cpp:228] Iteration 83000, loss = 2.80541
I0317 04:18:32.525035 11765 solver.cpp:244]     Train net output #0: loss = 2.80541 (* 1 = 2.80541 loss)
I0317 04:18:32.584151 11765 sgd_solver.cpp:106] Iteration 83000, lr = 0.02
I0317 04:19:46.162122 11765 solver.cpp:228] Iteration 83100, loss = 2.92425
I0317 04:19:46.162312 11765 solver.cpp:244]     Train net output #0: loss = 2.92425 (* 1 = 2.92425 loss)
I0317 04:19:46.252077 11765 sgd_solver.cpp:106] Iteration 83100, lr = 0.02
I0317 04:21:01.581378 11765 solver.cpp:228] Iteration 83200, loss = 2.60251
I0317 04:21:01.581516 11765 solver.cpp:244]     Train net output #0: loss = 2.60251 (* 1 = 2.60251 loss)
I0317 04:21:01.634732 11765 sgd_solver.cpp:106] Iteration 83200, lr = 0.02
I0317 04:22:15.390897 11765 solver.cpp:228] Iteration 83300, loss = 2.84249
I0317 04:22:15.391033 11765 solver.cpp:244]     Train net output #0: loss = 2.84249 (* 1 = 2.84249 loss)
I0317 04:22:15.449301 11765 sgd_solver.cpp:106] Iteration 83300, lr = 0.02
I0317 04:23:28.616363 11765 solver.cpp:228] Iteration 83400, loss = 2.50531
I0317 04:23:28.616555 11765 solver.cpp:244]     Train net output #0: loss = 2.50531 (* 1 = 2.50531 loss)
I0317 04:23:28.648735 11765 sgd_solver.cpp:106] Iteration 83400, lr = 0.02
I0317 04:24:41.273489 11765 solver.cpp:228] Iteration 83500, loss = 2.39337
I0317 04:24:41.273653 11765 solver.cpp:244]     Train net output #0: loss = 2.39337 (* 1 = 2.39337 loss)
I0317 04:24:41.295914 11765 sgd_solver.cpp:106] Iteration 83500, lr = 0.02
I0317 04:25:55.579407 11765 solver.cpp:228] Iteration 83600, loss = 2.75649
I0317 04:25:55.579547 11765 solver.cpp:244]     Train net output #0: loss = 2.75649 (* 1 = 2.75649 loss)
I0317 04:25:55.629686 11765 sgd_solver.cpp:106] Iteration 83600, lr = 0.02
I0317 04:27:10.558131 11765 solver.cpp:228] Iteration 83700, loss = 2.40409
I0317 04:27:10.558269 11765 solver.cpp:244]     Train net output #0: loss = 2.40409 (* 1 = 2.40409 loss)
I0317 04:27:10.612857 11765 sgd_solver.cpp:106] Iteration 83700, lr = 0.02
I0317 04:28:24.994690 11765 solver.cpp:228] Iteration 83800, loss = 2.77129
I0317 04:28:24.994841 11765 solver.cpp:244]     Train net output #0: loss = 2.77129 (* 1 = 2.77129 loss)
I0317 04:28:25.033107 11765 sgd_solver.cpp:106] Iteration 83800, lr = 0.02
I0317 04:29:38.286200 11765 solver.cpp:228] Iteration 83900, loss = 2.83059
I0317 04:29:38.286355 11765 solver.cpp:244]     Train net output #0: loss = 2.83059 (* 1 = 2.83059 loss)
I0317 04:29:38.338330 11765 sgd_solver.cpp:106] Iteration 83900, lr = 0.02
I0317 04:30:54.528425 11765 solver.cpp:337] Iteration 84000, Testing net (#0)
I0317 04:32:07.193156 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3732
I0317 04:32:07.193315 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63184
I0317 04:32:07.193343 11765 solver.cpp:404]     Test net output #2: loss = 2.88913 (* 1 = 2.88913 loss)
I0317 04:32:07.830070 11765 solver.cpp:228] Iteration 84000, loss = 2.56401
I0317 04:32:07.830112 11765 solver.cpp:244]     Train net output #0: loss = 2.56401 (* 1 = 2.56401 loss)
I0317 04:32:07.898706 11765 sgd_solver.cpp:106] Iteration 84000, lr = 0.02
I0317 04:33:23.375131 11765 solver.cpp:228] Iteration 84100, loss = 2.61747
I0317 04:33:23.375630 11765 solver.cpp:244]     Train net output #0: loss = 2.61747 (* 1 = 2.61747 loss)
I0317 04:33:23.468135 11765 sgd_solver.cpp:106] Iteration 84100, lr = 0.02
I0317 04:34:37.591723 11765 solver.cpp:228] Iteration 84200, loss = 2.55254
I0317 04:34:37.591899 11765 solver.cpp:244]     Train net output #0: loss = 2.55254 (* 1 = 2.55254 loss)
I0317 04:34:37.653540 11765 sgd_solver.cpp:106] Iteration 84200, lr = 0.02
I0317 04:35:52.896406 11765 solver.cpp:228] Iteration 84300, loss = 2.67506
I0317 04:35:52.896576 11765 solver.cpp:244]     Train net output #0: loss = 2.67506 (* 1 = 2.67506 loss)
I0317 04:35:52.939206 11765 sgd_solver.cpp:106] Iteration 84300, lr = 0.02
I0317 04:37:07.722751 11765 solver.cpp:228] Iteration 84400, loss = 2.48896
I0317 04:37:07.722910 11765 solver.cpp:244]     Train net output #0: loss = 2.48896 (* 1 = 2.48896 loss)
I0317 04:37:07.774417 11765 sgd_solver.cpp:106] Iteration 84400, lr = 0.02
I0317 04:38:22.324337 11765 solver.cpp:228] Iteration 84500, loss = 2.66881
I0317 04:38:22.324456 11765 solver.cpp:244]     Train net output #0: loss = 2.66881 (* 1 = 2.66881 loss)
I0317 04:38:22.376812 11765 sgd_solver.cpp:106] Iteration 84500, lr = 0.02
I0317 04:39:36.321590 11765 solver.cpp:228] Iteration 84600, loss = 2.88372
I0317 04:39:36.321699 11765 solver.cpp:244]     Train net output #0: loss = 2.88372 (* 1 = 2.88372 loss)
I0317 04:39:36.374331 11765 sgd_solver.cpp:106] Iteration 84600, lr = 0.02
I0317 04:40:49.669064 11765 solver.cpp:228] Iteration 84700, loss = 2.38753
I0317 04:40:49.669195 11765 solver.cpp:244]     Train net output #0: loss = 2.38753 (* 1 = 2.38753 loss)
I0317 04:40:49.721797 11765 sgd_solver.cpp:106] Iteration 84700, lr = 0.02
I0317 04:42:06.041491 11765 solver.cpp:228] Iteration 84800, loss = 2.93789
I0317 04:42:06.041646 11765 solver.cpp:244]     Train net output #0: loss = 2.93789 (* 1 = 2.93789 loss)
I0317 04:42:06.090184 11765 sgd_solver.cpp:106] Iteration 84800, lr = 0.02
I0317 04:43:21.629099 11765 solver.cpp:228] Iteration 84900, loss = 2.6475
I0317 04:43:21.629325 11765 solver.cpp:244]     Train net output #0: loss = 2.6475 (* 1 = 2.6475 loss)
I0317 04:43:21.656802 11765 sgd_solver.cpp:106] Iteration 84900, lr = 0.02
I0317 04:44:34.836534 11765 solver.cpp:337] Iteration 85000, Testing net (#0)
I0317 04:45:48.456260 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37178
I0317 04:45:48.456419 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633819
I0317 04:45:48.456447 11765 solver.cpp:404]     Test net output #2: loss = 2.89239 (* 1 = 2.89239 loss)
I0317 04:45:49.095965 11765 solver.cpp:228] Iteration 85000, loss = 2.83394
I0317 04:45:49.096005 11765 solver.cpp:244]     Train net output #0: loss = 2.83394 (* 1 = 2.83394 loss)
I0317 04:45:49.162760 11765 sgd_solver.cpp:106] Iteration 85000, lr = 0.02
I0317 04:47:04.017666 11765 solver.cpp:228] Iteration 85100, loss = 2.58795
I0317 04:47:04.018512 11765 solver.cpp:244]     Train net output #0: loss = 2.58795 (* 1 = 2.58795 loss)
I0317 04:47:04.046294 11765 sgd_solver.cpp:106] Iteration 85100, lr = 0.02
I0317 04:48:19.560196 11765 solver.cpp:228] Iteration 85200, loss = 2.52773
I0317 04:48:19.560346 11765 solver.cpp:244]     Train net output #0: loss = 2.52773 (* 1 = 2.52773 loss)
I0317 04:48:19.619292 11765 sgd_solver.cpp:106] Iteration 85200, lr = 0.02
I0317 04:49:35.254209 11765 solver.cpp:228] Iteration 85300, loss = 3.11524
I0317 04:49:35.254351 11765 solver.cpp:244]     Train net output #0: loss = 3.11524 (* 1 = 3.11524 loss)
I0317 04:49:35.302803 11765 sgd_solver.cpp:106] Iteration 85300, lr = 0.02
I0317 04:50:53.955121 11765 solver.cpp:228] Iteration 85400, loss = 2.72091
I0317 04:50:53.955330 11765 solver.cpp:244]     Train net output #0: loss = 2.72091 (* 1 = 2.72091 loss)
I0317 04:50:53.955432 11765 sgd_solver.cpp:106] Iteration 85400, lr = 0.02
I0317 04:52:08.727952 11765 solver.cpp:228] Iteration 85500, loss = 3.13335
I0317 04:52:08.728085 11765 solver.cpp:244]     Train net output #0: loss = 3.13335 (* 1 = 3.13335 loss)
I0317 04:52:08.757614 11765 sgd_solver.cpp:106] Iteration 85500, lr = 0.02
I0317 04:53:26.631649 11765 solver.cpp:228] Iteration 85600, loss = 2.71593
I0317 04:53:26.631832 11765 solver.cpp:244]     Train net output #0: loss = 2.71593 (* 1 = 2.71593 loss)
I0317 04:53:26.646121 11765 sgd_solver.cpp:106] Iteration 85600, lr = 0.02
I0317 04:54:44.558887 11765 solver.cpp:228] Iteration 85700, loss = 2.83615
I0317 04:54:44.559027 11765 solver.cpp:244]     Train net output #0: loss = 2.83615 (* 1 = 2.83615 loss)
I0317 04:54:44.612505 11765 sgd_solver.cpp:106] Iteration 85700, lr = 0.02
I0317 04:56:01.922628 11765 solver.cpp:228] Iteration 85800, loss = 2.84156
I0317 04:56:01.922787 11765 solver.cpp:244]     Train net output #0: loss = 2.84156 (* 1 = 2.84156 loss)
I0317 04:56:01.971947 11765 sgd_solver.cpp:106] Iteration 85800, lr = 0.02
I0317 04:57:16.553462 11765 solver.cpp:228] Iteration 85900, loss = 2.93097
I0317 04:57:16.553591 11765 solver.cpp:244]     Train net output #0: loss = 2.93097 (* 1 = 2.93097 loss)
I0317 04:57:16.612599 11765 sgd_solver.cpp:106] Iteration 85900, lr = 0.02
I0317 04:58:30.869247 11765 solver.cpp:337] Iteration 86000, Testing net (#0)
I0317 04:59:43.824285 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37158
I0317 04:59:43.824924 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.631979
I0317 04:59:43.824939 11765 solver.cpp:404]     Test net output #2: loss = 2.89092 (* 1 = 2.89092 loss)
I0317 04:59:44.470484 11765 solver.cpp:228] Iteration 86000, loss = 2.7197
I0317 04:59:44.470527 11765 solver.cpp:244]     Train net output #0: loss = 2.7197 (* 1 = 2.7197 loss)
I0317 04:59:44.537268 11765 sgd_solver.cpp:106] Iteration 86000, lr = 0.02
I0317 05:00:58.769639 11765 solver.cpp:228] Iteration 86100, loss = 2.77859
I0317 05:00:58.769821 11765 solver.cpp:244]     Train net output #0: loss = 2.77859 (* 1 = 2.77859 loss)
I0317 05:00:58.871743 11765 sgd_solver.cpp:106] Iteration 86100, lr = 0.02
I0317 05:02:14.476059 11765 solver.cpp:228] Iteration 86200, loss = 3.17649
I0317 05:02:14.476238 11765 solver.cpp:244]     Train net output #0: loss = 3.17649 (* 1 = 3.17649 loss)
I0317 05:02:14.538537 11765 sgd_solver.cpp:106] Iteration 86200, lr = 0.02
I0317 05:03:32.306023 11765 solver.cpp:228] Iteration 86300, loss = 2.74496
I0317 05:03:32.306162 11765 solver.cpp:244]     Train net output #0: loss = 2.74496 (* 1 = 2.74496 loss)
I0317 05:03:32.360854 11765 sgd_solver.cpp:106] Iteration 86300, lr = 0.02
I0317 05:04:47.212690 11765 solver.cpp:228] Iteration 86400, loss = 2.79957
I0317 05:04:47.212875 11765 solver.cpp:244]     Train net output #0: loss = 2.79957 (* 1 = 2.79957 loss)
I0317 05:04:47.262589 11765 sgd_solver.cpp:106] Iteration 86400, lr = 0.02
I0317 05:06:04.879587 11765 solver.cpp:228] Iteration 86500, loss = 3.07416
I0317 05:06:04.879766 11765 solver.cpp:244]     Train net output #0: loss = 3.07416 (* 1 = 3.07416 loss)
I0317 05:06:04.908416 11765 sgd_solver.cpp:106] Iteration 86500, lr = 0.02
I0317 05:07:21.227602 11765 solver.cpp:228] Iteration 86600, loss = 2.96413
I0317 05:07:21.227737 11765 solver.cpp:244]     Train net output #0: loss = 2.96413 (* 1 = 2.96413 loss)
I0317 05:07:21.284513 11765 sgd_solver.cpp:106] Iteration 86600, lr = 0.02
I0317 05:08:36.937010 11765 solver.cpp:228] Iteration 86700, loss = 3.14936
I0317 05:08:36.938325 11765 solver.cpp:244]     Train net output #0: loss = 3.14936 (* 1 = 3.14936 loss)
I0317 05:08:36.967851 11765 sgd_solver.cpp:106] Iteration 86700, lr = 0.02
I0317 05:09:50.051722 11765 solver.cpp:228] Iteration 86800, loss = 2.61304
I0317 05:09:50.051872 11765 solver.cpp:244]     Train net output #0: loss = 2.61304 (* 1 = 2.61304 loss)
I0317 05:09:50.114656 11765 sgd_solver.cpp:106] Iteration 86800, lr = 0.02
I0317 05:11:04.860604 11765 solver.cpp:228] Iteration 86900, loss = 2.9065
I0317 05:11:04.860764 11765 solver.cpp:244]     Train net output #0: loss = 2.9065 (* 1 = 2.9065 loss)
I0317 05:11:04.910022 11765 sgd_solver.cpp:106] Iteration 86900, lr = 0.02
I0317 05:12:21.275902 11765 solver.cpp:337] Iteration 87000, Testing net (#0)
I0317 05:13:34.150030 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37004
I0317 05:13:34.150185 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633499
I0317 05:13:34.150215 11765 solver.cpp:404]     Test net output #2: loss = 2.89065 (* 1 = 2.89065 loss)
I0317 05:13:34.858885 11765 solver.cpp:228] Iteration 87000, loss = 2.81719
I0317 05:13:34.858963 11765 solver.cpp:244]     Train net output #0: loss = 2.81719 (* 1 = 2.81719 loss)
I0317 05:13:34.935204 11765 sgd_solver.cpp:106] Iteration 87000, lr = 0.02
I0317 05:14:48.279683 11765 solver.cpp:228] Iteration 87100, loss = 2.67032
I0317 05:14:48.279832 11765 solver.cpp:244]     Train net output #0: loss = 2.67032 (* 1 = 2.67032 loss)
I0317 05:14:48.363720 11765 sgd_solver.cpp:106] Iteration 87100, lr = 0.02
I0317 05:16:00.981957 11765 solver.cpp:228] Iteration 87200, loss = 2.68035
I0317 05:16:00.982101 11765 solver.cpp:244]     Train net output #0: loss = 2.68035 (* 1 = 2.68035 loss)
I0317 05:16:01.045065 11765 sgd_solver.cpp:106] Iteration 87200, lr = 0.02
I0317 05:17:13.524176 11765 solver.cpp:228] Iteration 87300, loss = 2.76132
I0317 05:17:13.524323 11765 solver.cpp:244]     Train net output #0: loss = 2.76132 (* 1 = 2.76132 loss)
I0317 05:17:13.583392 11765 sgd_solver.cpp:106] Iteration 87300, lr = 0.02
I0317 05:18:29.352370 11765 solver.cpp:228] Iteration 87400, loss = 2.80916
I0317 05:18:29.352520 11765 solver.cpp:244]     Train net output #0: loss = 2.80916 (* 1 = 2.80916 loss)
I0317 05:18:29.402372 11765 sgd_solver.cpp:106] Iteration 87400, lr = 0.02
I0317 05:19:44.328006 11765 solver.cpp:228] Iteration 87500, loss = 2.49675
I0317 05:19:44.328172 11765 solver.cpp:244]     Train net output #0: loss = 2.49675 (* 1 = 2.49675 loss)
I0317 05:19:44.364915 11765 sgd_solver.cpp:106] Iteration 87500, lr = 0.02
I0317 05:21:03.613795 11765 solver.cpp:228] Iteration 87600, loss = 2.64104
I0317 05:21:03.613919 11765 solver.cpp:244]     Train net output #0: loss = 2.64104 (* 1 = 2.64104 loss)
I0317 05:21:03.662603 11765 sgd_solver.cpp:106] Iteration 87600, lr = 0.02
I0317 05:22:20.825712 11765 solver.cpp:228] Iteration 87700, loss = 2.74552
I0317 05:22:20.825896 11765 solver.cpp:244]     Train net output #0: loss = 2.74552 (* 1 = 2.74552 loss)
I0317 05:22:20.876298 11765 sgd_solver.cpp:106] Iteration 87700, lr = 0.02
I0317 05:23:34.552160 11765 solver.cpp:228] Iteration 87800, loss = 2.75772
I0317 05:23:34.552989 11765 solver.cpp:244]     Train net output #0: loss = 2.75772 (* 1 = 2.75772 loss)
I0317 05:23:34.584915 11765 sgd_solver.cpp:106] Iteration 87800, lr = 0.02
I0317 05:24:49.907238 11765 solver.cpp:228] Iteration 87900, loss = 2.51041
I0317 05:24:49.907387 11765 solver.cpp:244]     Train net output #0: loss = 2.51041 (* 1 = 2.51041 loss)
I0317 05:24:49.959125 11765 sgd_solver.cpp:106] Iteration 87900, lr = 0.02
I0317 05:26:05.126694 11765 solver.cpp:337] Iteration 88000, Testing net (#0)
I0317 05:27:17.984823 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.36924
I0317 05:27:17.985002 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63376
I0317 05:27:17.985029 11765 solver.cpp:404]     Test net output #2: loss = 2.89049 (* 1 = 2.89049 loss)
I0317 05:27:18.628792 11765 solver.cpp:228] Iteration 88000, loss = 2.7049
I0317 05:27:18.628829 11765 solver.cpp:244]     Train net output #0: loss = 2.7049 (* 1 = 2.7049 loss)
I0317 05:27:18.687973 11765 sgd_solver.cpp:106] Iteration 88000, lr = 0.02
I0317 05:28:34.699467 11765 solver.cpp:228] Iteration 88100, loss = 2.49533
I0317 05:28:34.699659 11765 solver.cpp:244]     Train net output #0: loss = 2.49533 (* 1 = 2.49533 loss)
I0317 05:28:34.797473 11765 sgd_solver.cpp:106] Iteration 88100, lr = 0.02
I0317 05:29:49.918385 11765 solver.cpp:228] Iteration 88200, loss = 2.85101
I0317 05:29:49.918536 11765 solver.cpp:244]     Train net output #0: loss = 2.85101 (* 1 = 2.85101 loss)
I0317 05:29:49.983476 11765 sgd_solver.cpp:106] Iteration 88200, lr = 0.02
I0317 05:31:06.234119 11765 solver.cpp:228] Iteration 88300, loss = 2.79379
I0317 05:31:06.234328 11765 solver.cpp:244]     Train net output #0: loss = 2.79379 (* 1 = 2.79379 loss)
I0317 05:31:06.282398 11765 sgd_solver.cpp:106] Iteration 88300, lr = 0.02
I0317 05:32:23.312072 11765 solver.cpp:228] Iteration 88400, loss = 2.65874
I0317 05:32:23.312228 11765 solver.cpp:244]     Train net output #0: loss = 2.65874 (* 1 = 2.65874 loss)
I0317 05:32:23.362996 11765 sgd_solver.cpp:106] Iteration 88400, lr = 0.02
I0317 05:33:36.098948 11765 solver.cpp:228] Iteration 88500, loss = 2.64773
I0317 05:33:36.099103 11765 solver.cpp:244]     Train net output #0: loss = 2.64773 (* 1 = 2.64773 loss)
I0317 05:33:36.154176 11765 sgd_solver.cpp:106] Iteration 88500, lr = 0.02
I0317 05:34:51.875586 11765 solver.cpp:228] Iteration 88600, loss = 2.56597
I0317 05:34:51.875704 11765 solver.cpp:244]     Train net output #0: loss = 2.56597 (* 1 = 2.56597 loss)
I0317 05:34:51.925935 11765 sgd_solver.cpp:106] Iteration 88600, lr = 0.02
I0317 05:36:07.053223 11765 solver.cpp:228] Iteration 88700, loss = 2.86711
I0317 05:36:07.053355 11765 solver.cpp:244]     Train net output #0: loss = 2.86711 (* 1 = 2.86711 loss)
I0317 05:36:07.080895 11765 sgd_solver.cpp:106] Iteration 88700, lr = 0.02
I0317 05:37:20.009917 11765 solver.cpp:228] Iteration 88800, loss = 3.10568
I0317 05:37:20.010363 11765 solver.cpp:244]     Train net output #0: loss = 3.10568 (* 1 = 3.10568 loss)
I0317 05:37:20.023106 11765 sgd_solver.cpp:106] Iteration 88800, lr = 0.02
I0317 05:38:35.026342 11765 solver.cpp:228] Iteration 88900, loss = 2.85891
I0317 05:38:35.026499 11765 solver.cpp:244]     Train net output #0: loss = 2.85891 (* 1 = 2.85891 loss)
I0317 05:38:35.055157 11765 sgd_solver.cpp:106] Iteration 88900, lr = 0.02
I0317 05:39:48.252102 11765 solver.cpp:337] Iteration 89000, Testing net (#0)
I0317 05:41:01.905514 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37266
I0317 05:41:01.905709 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632479
I0317 05:41:01.905737 11765 solver.cpp:404]     Test net output #2: loss = 2.89337 (* 1 = 2.89337 loss)
I0317 05:41:02.547685 11765 solver.cpp:228] Iteration 89000, loss = 2.66637
I0317 05:41:02.547722 11765 solver.cpp:244]     Train net output #0: loss = 2.66637 (* 1 = 2.66637 loss)
I0317 05:41:02.619927 11765 sgd_solver.cpp:106] Iteration 89000, lr = 0.02
I0317 05:42:16.625027 11765 solver.cpp:228] Iteration 89100, loss = 2.83251
I0317 05:42:16.625285 11765 solver.cpp:244]     Train net output #0: loss = 2.83251 (* 1 = 2.83251 loss)
I0317 05:42:16.720791 11765 sgd_solver.cpp:106] Iteration 89100, lr = 0.02
I0317 05:43:29.907649 11765 solver.cpp:228] Iteration 89200, loss = 2.69421
I0317 05:43:29.908252 11765 solver.cpp:244]     Train net output #0: loss = 2.69421 (* 1 = 2.69421 loss)
I0317 05:43:29.959529 11765 sgd_solver.cpp:106] Iteration 89200, lr = 0.02
I0317 05:44:43.208288 11765 solver.cpp:228] Iteration 89300, loss = 2.62214
I0317 05:44:43.208421 11765 solver.cpp:244]     Train net output #0: loss = 2.62214 (* 1 = 2.62214 loss)
I0317 05:44:43.267668 11765 sgd_solver.cpp:106] Iteration 89300, lr = 0.02
I0317 05:45:59.193461 11765 solver.cpp:228] Iteration 89400, loss = 2.86929
I0317 05:45:59.193605 11765 solver.cpp:244]     Train net output #0: loss = 2.86929 (* 1 = 2.86929 loss)
I0317 05:45:59.252862 11765 sgd_solver.cpp:106] Iteration 89400, lr = 0.02
I0317 05:47:13.719399 11765 solver.cpp:228] Iteration 89500, loss = 2.65594
I0317 05:47:13.719831 11765 solver.cpp:244]     Train net output #0: loss = 2.65594 (* 1 = 2.65594 loss)
I0317 05:47:13.767294 11765 sgd_solver.cpp:106] Iteration 89500, lr = 0.02
I0317 05:48:28.753661 11765 solver.cpp:228] Iteration 89600, loss = 2.57274
I0317 05:48:28.754053 11765 solver.cpp:244]     Train net output #0: loss = 2.57274 (* 1 = 2.57274 loss)
I0317 05:48:28.804157 11765 sgd_solver.cpp:106] Iteration 89600, lr = 0.02
I0317 05:49:44.903108 11765 solver.cpp:228] Iteration 89700, loss = 2.58527
I0317 05:49:44.903249 11765 solver.cpp:244]     Train net output #0: loss = 2.58527 (* 1 = 2.58527 loss)
I0317 05:49:44.955399 11765 sgd_solver.cpp:106] Iteration 89700, lr = 0.02
I0317 05:51:00.587376 11765 solver.cpp:228] Iteration 89800, loss = 2.73963
I0317 05:51:00.588170 11765 solver.cpp:244]     Train net output #0: loss = 2.73963 (* 1 = 2.73963 loss)
I0317 05:51:00.588526 11765 sgd_solver.cpp:106] Iteration 89800, lr = 0.02
I0317 05:52:15.739156 11765 solver.cpp:228] Iteration 89900, loss = 2.88684
I0317 05:52:15.739321 11765 solver.cpp:244]     Train net output #0: loss = 2.88684 (* 1 = 2.88684 loss)
I0317 05:52:15.787382 11765 sgd_solver.cpp:106] Iteration 89900, lr = 0.02
I0317 05:53:30.092303 11765 solver.cpp:337] Iteration 90000, Testing net (#0)
I0317 05:54:42.828867 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.3726
I0317 05:54:42.829061 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633159
I0317 05:54:42.829072 11765 solver.cpp:404]     Test net output #2: loss = 2.89467 (* 1 = 2.89467 loss)
I0317 05:54:43.472496 11765 solver.cpp:228] Iteration 90000, loss = 2.99768
I0317 05:54:43.472530 11765 solver.cpp:244]     Train net output #0: loss = 2.99768 (* 1 = 2.99768 loss)
I0317 05:54:43.539582 11765 sgd_solver.cpp:106] Iteration 90000, lr = 0.02
I0317 05:55:56.961340 11765 solver.cpp:228] Iteration 90100, loss = 2.60612
I0317 05:55:56.961531 11765 solver.cpp:244]     Train net output #0: loss = 2.60612 (* 1 = 2.60612 loss)
I0317 05:55:57.063874 11765 sgd_solver.cpp:106] Iteration 90100, lr = 0.02
I0317 05:57:11.834715 11765 solver.cpp:228] Iteration 90200, loss = 2.71557
I0317 05:57:11.834868 11765 solver.cpp:244]     Train net output #0: loss = 2.71557 (* 1 = 2.71557 loss)
I0317 05:57:11.889004 11765 sgd_solver.cpp:106] Iteration 90200, lr = 0.02
I0317 05:58:27.985649 11765 solver.cpp:228] Iteration 90300, loss = 2.77209
I0317 05:58:27.986052 11765 solver.cpp:244]     Train net output #0: loss = 2.77209 (* 1 = 2.77209 loss)
I0317 05:58:28.028375 11765 sgd_solver.cpp:106] Iteration 90300, lr = 0.02
I0317 05:59:43.053612 11765 solver.cpp:228] Iteration 90400, loss = 3.05813
I0317 05:59:43.053830 11765 solver.cpp:244]     Train net output #0: loss = 3.05813 (* 1 = 3.05813 loss)
I0317 05:59:43.083714 11765 sgd_solver.cpp:106] Iteration 90400, lr = 0.02
I0317 06:00:56.023481 11765 solver.cpp:228] Iteration 90500, loss = 2.70646
I0317 06:00:56.023633 11765 solver.cpp:244]     Train net output #0: loss = 2.70646 (* 1 = 2.70646 loss)
I0317 06:00:56.079134 11765 sgd_solver.cpp:106] Iteration 90500, lr = 0.02
I0317 06:02:09.921005 11765 solver.cpp:228] Iteration 90600, loss = 2.53753
I0317 06:02:09.921138 11765 solver.cpp:244]     Train net output #0: loss = 2.53753 (* 1 = 2.53753 loss)
I0317 06:02:09.976487 11765 sgd_solver.cpp:106] Iteration 90600, lr = 0.02
I0317 06:03:23.181902 11765 solver.cpp:228] Iteration 90700, loss = 2.74678
I0317 06:03:23.182101 11765 solver.cpp:244]     Train net output #0: loss = 2.74678 (* 1 = 2.74678 loss)
I0317 06:03:23.242123 11765 sgd_solver.cpp:106] Iteration 90700, lr = 0.02
I0317 06:04:37.347776 11765 solver.cpp:228] Iteration 90800, loss = 2.71821
I0317 06:04:37.347906 11765 solver.cpp:244]     Train net output #0: loss = 2.71821 (* 1 = 2.71821 loss)
I0317 06:04:37.407493 11765 sgd_solver.cpp:106] Iteration 90800, lr = 0.02
I0317 06:05:52.174404 11765 solver.cpp:228] Iteration 90900, loss = 2.75251
I0317 06:05:52.174556 11765 solver.cpp:244]     Train net output #0: loss = 2.75251 (* 1 = 2.75251 loss)
I0317 06:05:52.223341 11765 sgd_solver.cpp:106] Iteration 90900, lr = 0.02
I0317 06:07:07.133313 11765 solver.cpp:337] Iteration 91000, Testing net (#0)
I0317 06:08:19.925634 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37176
I0317 06:08:19.925791 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.634159
I0317 06:08:19.925803 11765 solver.cpp:404]     Test net output #2: loss = 2.88417 (* 1 = 2.88417 loss)
I0317 06:08:20.569193 11765 solver.cpp:228] Iteration 91000, loss = 2.80838
I0317 06:08:20.569247 11765 solver.cpp:244]     Train net output #0: loss = 2.80838 (* 1 = 2.80838 loss)
I0317 06:08:20.635242 11765 sgd_solver.cpp:106] Iteration 91000, lr = 0.02
I0317 06:09:33.562351 11765 solver.cpp:228] Iteration 91100, loss = 2.96721
I0317 06:09:33.562511 11765 solver.cpp:244]     Train net output #0: loss = 2.96721 (* 1 = 2.96721 loss)
I0317 06:09:33.648880 11765 sgd_solver.cpp:106] Iteration 91100, lr = 0.02
I0317 06:10:45.921178 11765 solver.cpp:228] Iteration 91200, loss = 2.91829
I0317 06:10:45.921303 11765 solver.cpp:244]     Train net output #0: loss = 2.91829 (* 1 = 2.91829 loss)
I0317 06:10:45.981257 11765 sgd_solver.cpp:106] Iteration 91200, lr = 0.02
I0317 06:12:00.365914 11765 solver.cpp:228] Iteration 91300, loss = 2.68059
I0317 06:12:00.366046 11765 solver.cpp:244]     Train net output #0: loss = 2.68059 (* 1 = 2.68059 loss)
I0317 06:12:00.417964 11765 sgd_solver.cpp:106] Iteration 91300, lr = 0.02
I0317 06:13:16.075969 11765 solver.cpp:228] Iteration 91400, loss = 2.76293
I0317 06:13:16.076097 11765 solver.cpp:244]     Train net output #0: loss = 2.76293 (* 1 = 2.76293 loss)
I0317 06:13:16.127394 11765 sgd_solver.cpp:106] Iteration 91400, lr = 0.02
I0317 06:14:29.913877 11765 solver.cpp:228] Iteration 91500, loss = 2.79694
I0317 06:14:29.913991 11765 solver.cpp:244]     Train net output #0: loss = 2.79694 (* 1 = 2.79694 loss)
I0317 06:14:29.972975 11765 sgd_solver.cpp:106] Iteration 91500, lr = 0.02
I0317 06:15:45.464526 11765 solver.cpp:228] Iteration 91600, loss = 2.45785
I0317 06:15:45.464676 11765 solver.cpp:244]     Train net output #0: loss = 2.45785 (* 1 = 2.45785 loss)
I0317 06:15:45.513535 11765 sgd_solver.cpp:106] Iteration 91600, lr = 0.02
I0317 06:17:01.039916 11765 solver.cpp:228] Iteration 91700, loss = 2.75716
I0317 06:17:01.040060 11765 solver.cpp:244]     Train net output #0: loss = 2.75716 (* 1 = 2.75716 loss)
I0317 06:17:01.097807 11765 sgd_solver.cpp:106] Iteration 91700, lr = 0.02
I0317 06:18:19.107897 11765 solver.cpp:228] Iteration 91800, loss = 2.6272
I0317 06:18:19.108042 11765 solver.cpp:244]     Train net output #0: loss = 2.6272 (* 1 = 2.6272 loss)
I0317 06:18:19.158264 11765 sgd_solver.cpp:106] Iteration 91800, lr = 0.02
I0317 06:19:34.738090 11765 solver.cpp:228] Iteration 91900, loss = 2.88389
I0317 06:19:34.738278 11765 solver.cpp:244]     Train net output #0: loss = 2.88389 (* 1 = 2.88389 loss)
I0317 06:19:34.800405 11765 sgd_solver.cpp:106] Iteration 91900, lr = 0.02
I0317 06:20:48.590077 11765 solver.cpp:337] Iteration 92000, Testing net (#0)
I0317 06:22:01.320209 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37132
I0317 06:22:01.320375 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63048
I0317 06:22:01.320389 11765 solver.cpp:404]     Test net output #2: loss = 2.89611 (* 1 = 2.89611 loss)
I0317 06:22:01.962450 11765 solver.cpp:228] Iteration 92000, loss = 2.72701
I0317 06:22:01.962486 11765 solver.cpp:244]     Train net output #0: loss = 2.72701 (* 1 = 2.72701 loss)
I0317 06:22:02.029394 11765 sgd_solver.cpp:106] Iteration 92000, lr = 0.02
I0317 06:23:14.817675 11765 solver.cpp:228] Iteration 92100, loss = 2.92618
I0317 06:23:14.817814 11765 solver.cpp:244]     Train net output #0: loss = 2.92618 (* 1 = 2.92618 loss)
I0317 06:23:14.905761 11765 sgd_solver.cpp:106] Iteration 92100, lr = 0.02
I0317 06:24:28.791839 11765 solver.cpp:228] Iteration 92200, loss = 2.6409
I0317 06:24:28.791990 11765 solver.cpp:244]     Train net output #0: loss = 2.6409 (* 1 = 2.6409 loss)
I0317 06:24:28.854322 11765 sgd_solver.cpp:106] Iteration 92200, lr = 0.02
I0317 06:25:41.552479 11765 solver.cpp:228] Iteration 92300, loss = 2.61888
I0317 06:25:41.552593 11765 solver.cpp:244]     Train net output #0: loss = 2.61888 (* 1 = 2.61888 loss)
I0317 06:25:41.608989 11765 sgd_solver.cpp:106] Iteration 92300, lr = 0.02
I0317 06:26:56.331928 11765 solver.cpp:228] Iteration 92400, loss = 2.48881
I0317 06:26:56.332106 11765 solver.cpp:244]     Train net output #0: loss = 2.48881 (* 1 = 2.48881 loss)
I0317 06:26:56.359679 11765 sgd_solver.cpp:106] Iteration 92400, lr = 0.02
I0317 06:28:09.375239 11765 solver.cpp:228] Iteration 92500, loss = 2.79812
I0317 06:28:09.375376 11765 solver.cpp:244]     Train net output #0: loss = 2.79812 (* 1 = 2.79812 loss)
I0317 06:28:09.424919 11765 sgd_solver.cpp:106] Iteration 92500, lr = 0.02
I0317 06:29:26.578132 11765 solver.cpp:228] Iteration 92600, loss = 2.66993
I0317 06:29:26.578265 11765 solver.cpp:244]     Train net output #0: loss = 2.66993 (* 1 = 2.66993 loss)
I0317 06:29:26.626399 11765 sgd_solver.cpp:106] Iteration 92600, lr = 0.02
I0317 06:30:41.616199 11765 solver.cpp:228] Iteration 92700, loss = 2.96391
I0317 06:30:41.616312 11765 solver.cpp:244]     Train net output #0: loss = 2.96391 (* 1 = 2.96391 loss)
I0317 06:30:41.675348 11765 sgd_solver.cpp:106] Iteration 92700, lr = 0.02
I0317 06:31:58.625749 11765 solver.cpp:228] Iteration 92800, loss = 2.85845
I0317 06:31:58.625891 11765 solver.cpp:244]     Train net output #0: loss = 2.85845 (* 1 = 2.85845 loss)
I0317 06:31:58.681828 11765 sgd_solver.cpp:106] Iteration 92800, lr = 0.02
I0317 06:33:13.486083 11765 solver.cpp:228] Iteration 92900, loss = 2.88503
I0317 06:33:13.487136 11765 solver.cpp:244]     Train net output #0: loss = 2.88503 (* 1 = 2.88503 loss)
I0317 06:33:13.524088 11765 sgd_solver.cpp:106] Iteration 92900, lr = 0.02
I0317 06:34:27.933095 11765 solver.cpp:337] Iteration 93000, Testing net (#0)
I0317 06:35:41.055150 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37156
I0317 06:35:41.055325 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.63322
I0317 06:35:41.055363 11765 solver.cpp:404]     Test net output #2: loss = 2.8858 (* 1 = 2.8858 loss)
I0317 06:35:41.700436 11765 solver.cpp:228] Iteration 93000, loss = 2.5083
I0317 06:35:41.700471 11765 solver.cpp:244]     Train net output #0: loss = 2.5083 (* 1 = 2.5083 loss)
I0317 06:35:41.767535 11765 sgd_solver.cpp:106] Iteration 93000, lr = 0.02
I0317 06:36:59.701025 11765 solver.cpp:228] Iteration 93100, loss = 2.76072
I0317 06:36:59.701171 11765 solver.cpp:244]     Train net output #0: loss = 2.76072 (* 1 = 2.76072 loss)
I0317 06:36:59.775238 11765 sgd_solver.cpp:106] Iteration 93100, lr = 0.02
I0317 06:38:14.101665 11765 solver.cpp:228] Iteration 93200, loss = 3.09268
I0317 06:38:14.102496 11765 solver.cpp:244]     Train net output #0: loss = 3.09268 (* 1 = 3.09268 loss)
I0317 06:38:14.148696 11765 sgd_solver.cpp:106] Iteration 93200, lr = 0.02
I0317 06:39:29.981225 11765 solver.cpp:228] Iteration 93300, loss = 2.59449
I0317 06:39:29.981381 11765 solver.cpp:244]     Train net output #0: loss = 2.59449 (* 1 = 2.59449 loss)
I0317 06:39:30.032869 11765 sgd_solver.cpp:106] Iteration 93300, lr = 0.02
I0317 06:40:46.181370 11765 solver.cpp:228] Iteration 93400, loss = 2.63554
I0317 06:40:46.181505 11765 solver.cpp:244]     Train net output #0: loss = 2.63554 (* 1 = 2.63554 loss)
I0317 06:40:46.229624 11765 sgd_solver.cpp:106] Iteration 93400, lr = 0.02
I0317 06:42:02.080220 11765 solver.cpp:228] Iteration 93500, loss = 2.67366
I0317 06:42:02.080400 11765 solver.cpp:244]     Train net output #0: loss = 2.67366 (* 1 = 2.67366 loss)
I0317 06:42:02.139364 11765 sgd_solver.cpp:106] Iteration 93500, lr = 0.02
I0317 06:43:16.417464 11765 solver.cpp:228] Iteration 93600, loss = 2.73162
I0317 06:43:16.417999 11765 solver.cpp:244]     Train net output #0: loss = 2.73162 (* 1 = 2.73162 loss)
I0317 06:43:16.418259 11765 sgd_solver.cpp:106] Iteration 93600, lr = 0.02
I0317 06:44:34.386174 11765 solver.cpp:228] Iteration 93700, loss = 2.80146
I0317 06:44:34.386351 11765 solver.cpp:244]     Train net output #0: loss = 2.80146 (* 1 = 2.80146 loss)
I0317 06:44:34.448658 11765 sgd_solver.cpp:106] Iteration 93700, lr = 0.02
I0317 06:45:51.659715 11765 solver.cpp:228] Iteration 93800, loss = 2.65219
I0317 06:45:51.660622 11765 solver.cpp:244]     Train net output #0: loss = 2.65219 (* 1 = 2.65219 loss)
I0317 06:45:51.681758 11765 sgd_solver.cpp:106] Iteration 93800, lr = 0.02
I0317 06:47:11.265754 11765 solver.cpp:228] Iteration 93900, loss = 2.79776
I0317 06:47:11.265900 11765 solver.cpp:244]     Train net output #0: loss = 2.79776 (* 1 = 2.79776 loss)
I0317 06:47:11.316779 11765 sgd_solver.cpp:106] Iteration 93900, lr = 0.02
I0317 06:48:28.468487 11765 solver.cpp:337] Iteration 94000, Testing net (#0)
I0317 06:49:41.381005 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.371
I0317 06:49:41.381139 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.631779
I0317 06:49:41.381150 11765 solver.cpp:404]     Test net output #2: loss = 2.90138 (* 1 = 2.90138 loss)
I0317 06:49:42.027657 11765 solver.cpp:228] Iteration 94000, loss = 3.06775
I0317 06:49:42.027688 11765 solver.cpp:244]     Train net output #0: loss = 3.06775 (* 1 = 3.06775 loss)
I0317 06:49:42.090195 11765 sgd_solver.cpp:106] Iteration 94000, lr = 0.02
I0317 06:50:55.244081 11765 solver.cpp:228] Iteration 94100, loss = 3.02302
I0317 06:50:55.244248 11765 solver.cpp:244]     Train net output #0: loss = 3.02302 (* 1 = 3.02302 loss)
I0317 06:50:55.336343 11765 sgd_solver.cpp:106] Iteration 94100, lr = 0.02
I0317 06:52:09.297423 11765 solver.cpp:228] Iteration 94200, loss = 2.62598
I0317 06:52:09.297608 11765 solver.cpp:244]     Train net output #0: loss = 2.62598 (* 1 = 2.62598 loss)
I0317 06:52:09.369232 11765 sgd_solver.cpp:106] Iteration 94200, lr = 0.02
I0317 06:53:23.602444 11765 solver.cpp:228] Iteration 94300, loss = 2.77007
I0317 06:53:23.602566 11765 solver.cpp:244]     Train net output #0: loss = 2.77007 (* 1 = 2.77007 loss)
I0317 06:53:23.661552 11765 sgd_solver.cpp:106] Iteration 94300, lr = 0.02
I0317 06:54:38.820785 11765 solver.cpp:228] Iteration 94400, loss = 2.8332
I0317 06:54:38.820919 11765 solver.cpp:244]     Train net output #0: loss = 2.8332 (* 1 = 2.8332 loss)
I0317 06:54:38.886086 11765 sgd_solver.cpp:106] Iteration 94400, lr = 0.02
I0317 06:55:54.770447 11765 solver.cpp:228] Iteration 94500, loss = 2.81423
I0317 06:55:54.770591 11765 solver.cpp:244]     Train net output #0: loss = 2.81423 (* 1 = 2.81423 loss)
I0317 06:55:54.829601 11765 sgd_solver.cpp:106] Iteration 94500, lr = 0.02
I0317 06:57:10.500039 11765 solver.cpp:228] Iteration 94600, loss = 2.45961
I0317 06:57:10.500188 11765 solver.cpp:244]     Train net output #0: loss = 2.45961 (* 1 = 2.45961 loss)
I0317 06:57:10.550472 11765 sgd_solver.cpp:106] Iteration 94600, lr = 0.02
I0317 06:58:25.816365 11765 solver.cpp:228] Iteration 94700, loss = 3.15791
I0317 06:58:25.816633 11765 solver.cpp:244]     Train net output #0: loss = 3.15791 (* 1 = 3.15791 loss)
I0317 06:58:25.849489 11765 sgd_solver.cpp:106] Iteration 94700, lr = 0.02
I0317 06:59:41.561442 11765 solver.cpp:228] Iteration 94800, loss = 2.5397
I0317 06:59:41.561592 11765 solver.cpp:244]     Train net output #0: loss = 2.5397 (* 1 = 2.5397 loss)
I0317 06:59:41.620642 11765 sgd_solver.cpp:106] Iteration 94800, lr = 0.02
I0317 07:00:58.531275 11765 solver.cpp:228] Iteration 94900, loss = 2.89804
I0317 07:00:58.531446 11765 solver.cpp:244]     Train net output #0: loss = 2.89804 (* 1 = 2.89804 loss)
I0317 07:00:58.580947 11765 sgd_solver.cpp:106] Iteration 94900, lr = 0.02
I0317 07:02:10.258092 11765 solver.cpp:337] Iteration 95000, Testing net (#0)
I0317 07:03:23.506186 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.371519
I0317 07:03:23.506330 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.632719
I0317 07:03:23.506359 11765 solver.cpp:404]     Test net output #2: loss = 2.88642 (* 1 = 2.88642 loss)
I0317 07:03:24.328325 11765 solver.cpp:228] Iteration 95000, loss = 2.88611
I0317 07:03:24.328369 11765 solver.cpp:244]     Train net output #0: loss = 2.88611 (* 1 = 2.88611 loss)
I0317 07:03:24.421238 11765 sgd_solver.cpp:106] Iteration 95000, lr = 0.02
I0317 07:04:38.772538 11765 solver.cpp:228] Iteration 95100, loss = 3.02506
I0317 07:04:38.772744 11765 solver.cpp:244]     Train net output #0: loss = 3.02506 (* 1 = 3.02506 loss)
I0317 07:04:38.870725 11765 sgd_solver.cpp:106] Iteration 95100, lr = 0.02
I0317 07:05:56.349859 11765 solver.cpp:228] Iteration 95200, loss = 2.74034
I0317 07:05:56.350013 11765 solver.cpp:244]     Train net output #0: loss = 2.74034 (* 1 = 2.74034 loss)
I0317 07:05:56.406994 11765 sgd_solver.cpp:106] Iteration 95200, lr = 0.02
I0317 07:07:11.972929 11765 solver.cpp:228] Iteration 95300, loss = 3.1401
I0317 07:07:11.973063 11765 solver.cpp:244]     Train net output #0: loss = 3.1401 (* 1 = 3.1401 loss)
I0317 07:07:12.024255 11765 sgd_solver.cpp:106] Iteration 95300, lr = 0.02
I0317 07:08:27.592284 11765 solver.cpp:228] Iteration 95400, loss = 2.95097
I0317 07:08:27.592461 11765 solver.cpp:244]     Train net output #0: loss = 2.95097 (* 1 = 2.95097 loss)
I0317 07:08:27.644074 11765 sgd_solver.cpp:106] Iteration 95400, lr = 0.02
I0317 07:09:44.147316 11765 solver.cpp:228] Iteration 95500, loss = 2.95744
I0317 07:09:44.147529 11765 solver.cpp:244]     Train net output #0: loss = 2.95744 (* 1 = 2.95744 loss)
I0317 07:09:44.196491 11765 sgd_solver.cpp:106] Iteration 95500, lr = 0.02
I0317 07:10:59.652163 11765 solver.cpp:228] Iteration 95600, loss = 2.90314
I0317 07:10:59.652304 11765 solver.cpp:244]     Train net output #0: loss = 2.90314 (* 1 = 2.90314 loss)
I0317 07:10:59.694979 11765 sgd_solver.cpp:106] Iteration 95600, lr = 0.02
I0317 07:12:18.441793 11765 solver.cpp:228] Iteration 95700, loss = 2.73657
I0317 07:12:18.442019 11765 solver.cpp:244]     Train net output #0: loss = 2.73657 (* 1 = 2.73657 loss)
I0317 07:12:18.471765 11765 sgd_solver.cpp:106] Iteration 95700, lr = 0.02
I0317 07:13:32.705900 11765 solver.cpp:228] Iteration 95800, loss = 2.91165
I0317 07:13:32.706339 11765 solver.cpp:244]     Train net output #0: loss = 2.91165 (* 1 = 2.91165 loss)
I0317 07:13:32.706547 11765 sgd_solver.cpp:106] Iteration 95800, lr = 0.02
I0317 07:14:52.172657 11765 solver.cpp:228] Iteration 95900, loss = 2.76414
I0317 07:14:52.172802 11765 solver.cpp:244]     Train net output #0: loss = 2.76414 (* 1 = 2.76414 loss)
I0317 07:14:52.222698 11765 sgd_solver.cpp:106] Iteration 95900, lr = 0.02
I0317 07:16:09.716706 11765 solver.cpp:337] Iteration 96000, Testing net (#0)
I0317 07:17:22.835599 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37042
I0317 07:17:22.835742 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.6326
I0317 07:17:22.835755 11765 solver.cpp:404]     Test net output #2: loss = 2.89641 (* 1 = 2.89641 loss)
I0317 07:17:23.477860 11765 solver.cpp:228] Iteration 96000, loss = 2.51173
I0317 07:17:23.477890 11765 solver.cpp:244]     Train net output #0: loss = 2.51173 (* 1 = 2.51173 loss)
I0317 07:17:23.546809 11765 sgd_solver.cpp:106] Iteration 96000, lr = 0.02
I0317 07:18:39.028931 11765 solver.cpp:228] Iteration 96100, loss = 2.48998
I0317 07:18:39.029191 11765 solver.cpp:244]     Train net output #0: loss = 2.48998 (* 1 = 2.48998 loss)
I0317 07:18:39.115969 11765 sgd_solver.cpp:106] Iteration 96100, lr = 0.02
I0317 07:19:55.398696 11765 solver.cpp:228] Iteration 96200, loss = 2.66717
I0317 07:19:55.398851 11765 solver.cpp:244]     Train net output #0: loss = 2.66717 (* 1 = 2.66717 loss)
I0317 07:19:55.452275 11765 sgd_solver.cpp:106] Iteration 96200, lr = 0.02
I0317 07:21:10.248015 11765 solver.cpp:228] Iteration 96300, loss = 2.79869
I0317 07:21:10.248184 11765 solver.cpp:244]     Train net output #0: loss = 2.79869 (* 1 = 2.79869 loss)
I0317 07:21:10.277406 11765 sgd_solver.cpp:106] Iteration 96300, lr = 0.02
I0317 07:22:27.325794 11765 solver.cpp:228] Iteration 96400, loss = 2.7514
I0317 07:22:27.325929 11765 solver.cpp:244]     Train net output #0: loss = 2.7514 (* 1 = 2.7514 loss)
I0317 07:22:27.385201 11765 sgd_solver.cpp:106] Iteration 96400, lr = 0.02
I0317 07:23:40.490993 11765 solver.cpp:228] Iteration 96500, loss = 2.777
I0317 07:23:40.491196 11765 solver.cpp:244]     Train net output #0: loss = 2.777 (* 1 = 2.777 loss)
I0317 07:23:40.539283 11765 sgd_solver.cpp:106] Iteration 96500, lr = 0.02
I0317 07:24:54.998111 11765 solver.cpp:228] Iteration 96600, loss = 2.78628
I0317 07:24:54.998242 11765 solver.cpp:244]     Train net output #0: loss = 2.78628 (* 1 = 2.78628 loss)
I0317 07:24:55.048123 11765 sgd_solver.cpp:106] Iteration 96600, lr = 0.02
I0317 07:26:10.733858 11765 solver.cpp:228] Iteration 96700, loss = 2.7492
I0317 07:26:10.733994 11765 solver.cpp:244]     Train net output #0: loss = 2.7492 (* 1 = 2.7492 loss)
I0317 07:26:10.783148 11765 sgd_solver.cpp:106] Iteration 96700, lr = 0.02
I0317 07:27:25.504585 11765 solver.cpp:228] Iteration 96800, loss = 2.74467
I0317 07:27:25.504712 11765 solver.cpp:244]     Train net output #0: loss = 2.74467 (* 1 = 2.74467 loss)
I0317 07:27:25.555852 11765 sgd_solver.cpp:106] Iteration 96800, lr = 0.02
I0317 07:28:38.438668 11765 solver.cpp:228] Iteration 96900, loss = 2.82908
I0317 07:28:38.438819 11765 solver.cpp:244]     Train net output #0: loss = 2.82908 (* 1 = 2.82908 loss)
I0317 07:28:38.468806 11765 sgd_solver.cpp:106] Iteration 96900, lr = 0.02
I0317 07:29:54.291828 11765 solver.cpp:337] Iteration 97000, Testing net (#0)
I0317 07:31:07.026804 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37238
I0317 07:31:07.026958 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633139
I0317 07:31:07.026978 11765 solver.cpp:404]     Test net output #2: loss = 2.89111 (* 1 = 2.89111 loss)
I0317 07:31:07.672649 11765 solver.cpp:228] Iteration 97000, loss = 2.90201
I0317 07:31:07.672693 11765 solver.cpp:244]     Train net output #0: loss = 2.90201 (* 1 = 2.90201 loss)
I0317 07:31:07.732796 11765 sgd_solver.cpp:106] Iteration 97000, lr = 0.02
I0317 07:32:20.064223 11765 solver.cpp:228] Iteration 97100, loss = 2.9505
I0317 07:32:20.064570 11765 solver.cpp:244]     Train net output #0: loss = 2.9505 (* 1 = 2.9505 loss)
I0317 07:32:20.143581 11765 sgd_solver.cpp:106] Iteration 97100, lr = 0.02
I0317 07:33:33.069803 11765 solver.cpp:228] Iteration 97200, loss = 2.70411
I0317 07:33:33.069947 11765 solver.cpp:244]     Train net output #0: loss = 2.70411 (* 1 = 2.70411 loss)
I0317 07:33:33.123492 11765 sgd_solver.cpp:106] Iteration 97200, lr = 0.02
I0317 07:34:48.938278 11765 solver.cpp:228] Iteration 97300, loss = 2.4342
I0317 07:34:48.938432 11765 solver.cpp:244]     Train net output #0: loss = 2.4342 (* 1 = 2.4342 loss)
I0317 07:34:48.963287 11765 sgd_solver.cpp:106] Iteration 97300, lr = 0.02
I0317 07:36:02.084394 11765 solver.cpp:228] Iteration 97400, loss = 2.39588
I0317 07:36:02.084647 11765 solver.cpp:244]     Train net output #0: loss = 2.39588 (* 1 = 2.39588 loss)
I0317 07:36:02.142609 11765 sgd_solver.cpp:106] Iteration 97400, lr = 0.02
I0317 07:37:15.807085 11765 solver.cpp:228] Iteration 97500, loss = 2.71919
I0317 07:37:15.807235 11765 solver.cpp:244]     Train net output #0: loss = 2.71919 (* 1 = 2.71919 loss)
I0317 07:37:15.844003 11765 sgd_solver.cpp:106] Iteration 97500, lr = 0.02
I0317 07:38:30.861953 11765 solver.cpp:228] Iteration 97600, loss = 2.66519
I0317 07:38:30.862107 11765 solver.cpp:244]     Train net output #0: loss = 2.66519 (* 1 = 2.66519 loss)
I0317 07:38:30.912921 11765 sgd_solver.cpp:106] Iteration 97600, lr = 0.02
I0317 07:39:44.793251 11765 solver.cpp:228] Iteration 97700, loss = 2.97226
I0317 07:39:44.793396 11765 solver.cpp:244]     Train net output #0: loss = 2.97226 (* 1 = 2.97226 loss)
I0317 07:39:44.845635 11765 sgd_solver.cpp:106] Iteration 97700, lr = 0.02
I0317 07:40:59.247624 11765 solver.cpp:228] Iteration 97800, loss = 2.72657
I0317 07:40:59.247766 11765 solver.cpp:244]     Train net output #0: loss = 2.72657 (* 1 = 2.72657 loss)
I0317 07:40:59.297958 11765 sgd_solver.cpp:106] Iteration 97800, lr = 0.02
I0317 07:42:20.396361 11765 solver.cpp:228] Iteration 97900, loss = 2.56407
I0317 07:42:20.396525 11765 solver.cpp:244]     Train net output #0: loss = 2.56407 (* 1 = 2.56407 loss)
I0317 07:42:20.452148 11765 sgd_solver.cpp:106] Iteration 97900, lr = 0.02
I0317 07:43:38.208680 11765 solver.cpp:337] Iteration 98000, Testing net (#0)
I0317 07:44:51.608664 11765 solver.cpp:404]     Test net output #0: accuracy_top-1 = 0.37034
I0317 07:44:51.608830 11765 solver.cpp:404]     Test net output #1: accuracy_top-5 = 0.633339
I0317 07:44:51.608865 11765 solver.cpp:404]     Test net output #2: loss = 2.89997 (* 1 = 2.89997 loss)
I0317 07:44:52.254637 11765 solver.cpp:228] Iteration 98000, loss = 2.68935
I0317 07:44:52.254678 11765 solver.cpp:244]     Train net output #0: loss = 2.68935 (* 1 = 2.68935 loss)
I0317 07:44:52.313980 11765 sgd_solver.cpp:106] Iteration 98000, lr = 0.02
I0317 07:46:07.215204 11765 solver.cpp:228] Iteration 98100, loss = 2.68548
I0317 07:46:07.215401 11765 solver.cpp:244]     Train net output #0: loss = 2.68548 (* 1 = 2.68548 loss)
I0317 07:46:07.314038 11765 sgd_solver.cpp:106] Iteration 98100, lr = 0.02
I0317 07:47:21.282559 11765 solver.cpp:228] Iteration 98200, loss = 2.57168
I0317 07:47:21.282704 11765 solver.cpp:244]     Train net output #0: loss = 2.57168 (* 1 = 2.57168 loss)
I0317 07:47:21.342339 11765 sgd_solver.cpp:106] Iteration 98200, lr = 0.02
I0317 07:48:36.325182 11765 solver.cpp:228] Iteration 98300, loss = 2.66888
I0317 07:48:36.325353 11765 solver.cpp:244]     Train net output #0: loss = 2.66888 (* 1 = 2.66888 loss)
I0317 07:48:36.373729 11765 sgd_solver.cpp:106] Iteration 98300, lr = 0.02
I0317 07:49:52.179308 11765 solver.cpp:228] Iteration 98400, loss = 2.69787
I0317 07:49:52.179817 11765 solver.cpp:244]     Train net output #0: loss = 2.69787 (* 1 = 2.69787 loss)
I0317 07:49:52.180084 11765 sgd_solver.cpp:106] Iteration 98400, lr = 0.02
I0317 07:51:09.142446 11765 solver.cpp:228] Iteration 98500, loss = 2.80794
I0317 07:51:09.142598 11765 solver.cpp:244]     Train net output #0: loss = 2.80794 (* 1 = 2.80794 loss)
I0317 07:51:09.172632 11765 sgd_solver.cpp:106] Iteration 98500, lr = 0.02
I0317 07:52:24.231048 11765 solver.cpp:228] Iteration 98600, loss = 2.86923
I0317 07:52:24.231204 11765 solver.cpp:244]     Train net output #0: loss = 2.86923 (* 1 = 2.86923 loss)
I0317 07:52:24.260506 11765 sgd_solver.cpp:106] Iteration 98600, lr = 0.02
I0317 07:53:42.089700 11765 solver.cpp:228] Iteration 98700, loss = 3.11294
I0317 07:53:42.091675 11765 solver.cpp:244]     Train net output #0: loss = 3.11294 (* 1 = 3.11294 loss)
I0317 07:53:42.115964 11765 sgd_solver.cpp:106] Iteration 98700, lr = 0.02
I0317 07:55:01.095149 11765 solver.cpp:228] Iteration 98800, loss = 2.78488
I0317 07:55:01.095753 11765 solver.cpp:244]     Train net output #0: loss = 2.78488 (* 1 = 2.78488 loss)
I0317 07:55:01.105306 11765 sgd_solver.cpp:106] Iteration 98800, lr = 0.02
I0317 07:56:25.434288 11765 solver.cpp:228] Iteration 98900, loss = 2.58794
I0317 07:56:25.434497 11765 solver.cpp:244]     Train net output #0: loss = 2.58794 (* 1 = 2.58794 loss)
I0317 07:56:25.495645 11765 sgd_solver.cpp:106] Iteration 98900, lr = 0.02
