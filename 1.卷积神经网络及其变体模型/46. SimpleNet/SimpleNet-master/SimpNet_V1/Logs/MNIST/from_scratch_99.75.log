
G:\Caffe\examples\mnist>REM going to the caffe root 

G:\Caffe\examples\mnist>CD ../../ 

G:\Caffe>SET TOOLS=Build/x64/Release 

G:\Caffe>"Build/x64/Release/caffe.exe" train --solver=examples/mnist/lenet_solver.prototxt 
I0414 05:17:59.022251 17564 caffe.cpp:219] Using GPUs 0
I0414 05:17:59.200271 17564 caffe.cpp:224] GPU 0: GeForce GTX 980
I0414 05:17:59.476013 17564 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0414 05:17:59.499013 17564 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 600
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.005
snapshot: 600
snapshot_prefix: "examples/mnist/snaps/lenet"
solver_mode: GPU
device_id: 0
net: "examples/mnist/lenet_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 5000
stepvalue: 9500
stepvalue: 22000
stepvalue: 29600
stepvalue: 32000
stepvalue: 37000
type: "AdaDelta"
I0414 05:17:59.500012 17564 solver.cpp:87] Creating training net from net file: examples/mnist/lenet_train_test.prototxt
I0414 05:17:59.501013 17564 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/mnist/lenet_train_test.prototxt
I0414 05:17:59.501013 17564 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0414 05:17:59.501013 17564 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0414 05:17:59.501013 17564 net.cpp:51] Initializing net from parameters: 
name: "SlimNet_FX2_5M"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "scale1"
  top: "scale1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "drop1_0"
  type: "Dropout"
  bottom: "scale1_0"
  top: "scale1_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "drop2_0"
  type: "Dropout"
  bottom: "scale2"
  top: "scale2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "drop2_2"
  type: "Dropout"
  bottom: "scale2_2"
  top: "scale2_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "scale3"
  top: "scale3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "scale4"
  top: "scale4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "drop4_1"
  type: "Dropout"
  bottom: "scale4_1"
  top: "scale4_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "drop4_2"
  type: "Dropout"
  bottom: "scale4_2"
  top: "scale4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "drop4_0"
  type: "Dropout"
  bottom: "scale4_0"
  top: "scale4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 2
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "drop4_3"
  type: "Dropout"
  bottom: "cccp4"
  top: "cccp4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 2
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4_5"
  type: "Dropout"
  bottom: "poolcp5"
  top: "poolcp5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0414 05:17:59.502014 17564 layer_factory.cpp:58] Creating layer mnist
I0414 05:17:59.507016 17564 db_lmdb.cpp:40] Opened lmdb examples/mnist/mnist_train_lmdb_norm2
I0414 05:17:59.507016 17564 net.cpp:84] Creating Layer mnist
I0414 05:17:59.507016 17564 net.cpp:380] mnist -> data
I0414 05:17:59.507016 17564 net.cpp:380] mnist -> label
I0414 05:17:59.507016 17564 data_layer.cpp:45] output data size: 100,1,28,28
I0414 05:17:59.510013 17564 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0414 05:17:59.510013 17564 net.cpp:122] Setting up mnist
I0414 05:17:59.510013 17564 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0414 05:17:59.510013 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:17:59.510013 17564 net.cpp:137] Memory required for data: 314000
I0414 05:17:59.510013 17564 layer_factory.cpp:58] Creating layer label_mnist_1_split
I0414 05:17:59.510013 17564 net.cpp:84] Creating Layer label_mnist_1_split
I0414 05:17:59.510013 17564 net.cpp:406] label_mnist_1_split <- label
I0414 05:17:59.510013 17564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0414 05:17:59.511014 17564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0414 05:17:59.511014 17564 net.cpp:122] Setting up label_mnist_1_split
I0414 05:17:59.511014 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:17:59.511014 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:17:59.511014 17564 net.cpp:137] Memory required for data: 314800
I0414 05:17:59.511014 17564 layer_factory.cpp:58] Creating layer conv1
I0414 05:17:59.511014 17564 net.cpp:84] Creating Layer conv1
I0414 05:17:59.511014 17564 net.cpp:406] conv1 <- data
I0414 05:17:59.511014 17564 net.cpp:380] conv1 -> conv1
I0414 05:17:59.512015 15984 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0414 05:17:59.944028 17564 net.cpp:122] Setting up conv1
I0414 05:17:59.944028 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:17:59.944028 17564 net.cpp:137] Memory required for data: 20385200
I0414 05:17:59.944028 17564 layer_factory.cpp:58] Creating layer bn1
I0414 05:17:59.944028 17564 net.cpp:84] Creating Layer bn1
I0414 05:17:59.944028 17564 net.cpp:406] bn1 <- conv1
I0414 05:17:59.944028 17564 net.cpp:380] bn1 -> bn1
I0414 05:17:59.944028 17564 net.cpp:122] Setting up bn1
I0414 05:17:59.944028 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:17:59.944028 17564 net.cpp:137] Memory required for data: 40455600
I0414 05:17:59.944028 17564 layer_factory.cpp:58] Creating layer scale1
I0414 05:17:59.944028 17564 net.cpp:84] Creating Layer scale1
I0414 05:17:59.944028 17564 net.cpp:406] scale1 <- bn1
I0414 05:17:59.944028 17564 net.cpp:380] scale1 -> scale1
I0414 05:17:59.944028 17564 layer_factory.cpp:58] Creating layer scale1
I0414 05:17:59.944028 17564 net.cpp:122] Setting up scale1
I0414 05:17:59.944028 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:17:59.944028 17564 net.cpp:137] Memory required for data: 60526000
I0414 05:17:59.944028 17564 layer_factory.cpp:58] Creating layer relu1
I0414 05:17:59.944028 17564 net.cpp:84] Creating Layer relu1
I0414 05:17:59.944028 17564 net.cpp:406] relu1 <- scale1
I0414 05:17:59.944028 17564 net.cpp:367] relu1 -> scale1 (in-place)
I0414 05:17:59.944028 17564 net.cpp:122] Setting up relu1
I0414 05:17:59.944028 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:17:59.944028 17564 net.cpp:137] Memory required for data: 80596400
I0414 05:17:59.945014 17564 layer_factory.cpp:58] Creating layer drop2_1
I0414 05:17:59.945014 17564 net.cpp:84] Creating Layer drop2_1
I0414 05:17:59.945014 17564 net.cpp:406] drop2_1 <- scale1
I0414 05:17:59.945014 17564 net.cpp:367] drop2_1 -> scale1 (in-place)
I0414 05:17:59.945014 17564 net.cpp:122] Setting up drop2_1
I0414 05:17:59.945014 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:17:59.945014 17564 net.cpp:137] Memory required for data: 100666800
I0414 05:17:59.945014 17564 layer_factory.cpp:58] Creating layer conv1_0
I0414 05:17:59.945014 17564 net.cpp:84] Creating Layer conv1_0
I0414 05:17:59.945014 17564 net.cpp:406] conv1_0 <- scale1
I0414 05:17:59.945014 17564 net.cpp:380] conv1_0 -> conv1_0
I0414 05:17:59.946013 17564 net.cpp:122] Setting up conv1_0
I0414 05:17:59.946013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.946013 17564 net.cpp:137] Memory required for data: 140807600
I0414 05:17:59.946013 17564 layer_factory.cpp:58] Creating layer bn1_0
I0414 05:17:59.946013 17564 net.cpp:84] Creating Layer bn1_0
I0414 05:17:59.946013 17564 net.cpp:406] bn1_0 <- conv1_0
I0414 05:17:59.947013 17564 net.cpp:380] bn1_0 -> bn1_0
I0414 05:17:59.947013 17564 net.cpp:122] Setting up bn1_0
I0414 05:17:59.947013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.947013 17564 net.cpp:137] Memory required for data: 180948400
I0414 05:17:59.947013 17564 layer_factory.cpp:58] Creating layer scale1_0
I0414 05:17:59.947013 17564 net.cpp:84] Creating Layer scale1_0
I0414 05:17:59.947013 17564 net.cpp:406] scale1_0 <- bn1_0
I0414 05:17:59.947013 17564 net.cpp:380] scale1_0 -> scale1_0
I0414 05:17:59.947013 17564 layer_factory.cpp:58] Creating layer scale1_0
I0414 05:17:59.947013 17564 net.cpp:122] Setting up scale1_0
I0414 05:17:59.947013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.947013 17564 net.cpp:137] Memory required for data: 221089200
I0414 05:17:59.947013 17564 layer_factory.cpp:58] Creating layer relu1_0
I0414 05:17:59.947013 17564 net.cpp:84] Creating Layer relu1_0
I0414 05:17:59.947013 17564 net.cpp:406] relu1_0 <- scale1_0
I0414 05:17:59.947013 17564 net.cpp:367] relu1_0 -> scale1_0 (in-place)
I0414 05:17:59.947013 17564 net.cpp:122] Setting up relu1_0
I0414 05:17:59.947013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.947013 17564 net.cpp:137] Memory required for data: 261230000
I0414 05:17:59.947013 17564 layer_factory.cpp:58] Creating layer drop1_0
I0414 05:17:59.947013 17564 net.cpp:84] Creating Layer drop1_0
I0414 05:17:59.947013 17564 net.cpp:406] drop1_0 <- scale1_0
I0414 05:17:59.947013 17564 net.cpp:367] drop1_0 -> scale1_0 (in-place)
I0414 05:17:59.947013 17564 net.cpp:122] Setting up drop1_0
I0414 05:17:59.947013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.947013 17564 net.cpp:137] Memory required for data: 301370800
I0414 05:17:59.948014 17564 layer_factory.cpp:58] Creating layer conv2
I0414 05:17:59.948014 17564 net.cpp:84] Creating Layer conv2
I0414 05:17:59.948014 17564 net.cpp:406] conv2 <- scale1_0
I0414 05:17:59.948014 17564 net.cpp:380] conv2 -> conv2
I0414 05:17:59.951014 17564 net.cpp:122] Setting up conv2
I0414 05:17:59.951014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.951014 17564 net.cpp:137] Memory required for data: 341511600
I0414 05:17:59.951014 17564 layer_factory.cpp:58] Creating layer bn2
I0414 05:17:59.951014 17564 net.cpp:84] Creating Layer bn2
I0414 05:17:59.951014 17564 net.cpp:406] bn2 <- conv2
I0414 05:17:59.951014 17564 net.cpp:380] bn2 -> bn2
I0414 05:17:59.951014 17564 net.cpp:122] Setting up bn2
I0414 05:17:59.951014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.951014 17564 net.cpp:137] Memory required for data: 381652400
I0414 05:17:59.951014 17564 layer_factory.cpp:58] Creating layer scale2
I0414 05:17:59.951014 17564 net.cpp:84] Creating Layer scale2
I0414 05:17:59.951014 17564 net.cpp:406] scale2 <- bn2
I0414 05:17:59.951014 17564 net.cpp:380] scale2 -> scale2
I0414 05:17:59.951014 17564 layer_factory.cpp:58] Creating layer scale2
I0414 05:17:59.951014 17564 net.cpp:122] Setting up scale2
I0414 05:17:59.951014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.951014 17564 net.cpp:137] Memory required for data: 421793200
I0414 05:17:59.951014 17564 layer_factory.cpp:58] Creating layer relu2
I0414 05:17:59.951014 17564 net.cpp:84] Creating Layer relu2
I0414 05:17:59.951014 17564 net.cpp:406] relu2 <- scale2
I0414 05:17:59.951014 17564 net.cpp:367] relu2 -> scale2 (in-place)
I0414 05:17:59.952013 17564 net.cpp:122] Setting up relu2
I0414 05:17:59.952013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.952013 17564 net.cpp:137] Memory required for data: 461934000
I0414 05:17:59.952013 17564 layer_factory.cpp:58] Creating layer drop2_0
I0414 05:17:59.952013 17564 net.cpp:84] Creating Layer drop2_0
I0414 05:17:59.952013 17564 net.cpp:406] drop2_0 <- scale2
I0414 05:17:59.952013 17564 net.cpp:367] drop2_0 -> scale2 (in-place)
I0414 05:17:59.952013 17564 net.cpp:122] Setting up drop2_0
I0414 05:17:59.952013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.952013 17564 net.cpp:137] Memory required for data: 502074800
I0414 05:17:59.952013 17564 layer_factory.cpp:58] Creating layer conv2_1
I0414 05:17:59.952013 17564 net.cpp:84] Creating Layer conv2_1
I0414 05:17:59.952013 17564 net.cpp:406] conv2_1 <- scale2
I0414 05:17:59.952013 17564 net.cpp:380] conv2_1 -> conv2_1
I0414 05:17:59.955014 17564 net.cpp:122] Setting up conv2_1
I0414 05:17:59.955014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.955014 17564 net.cpp:137] Memory required for data: 542215600
I0414 05:17:59.955014 17564 layer_factory.cpp:58] Creating layer bn2_1
I0414 05:17:59.955014 17564 net.cpp:84] Creating Layer bn2_1
I0414 05:17:59.955014 17564 net.cpp:406] bn2_1 <- conv2_1
I0414 05:17:59.955014 17564 net.cpp:380] bn2_1 -> bn2_1
I0414 05:17:59.955014 17564 net.cpp:122] Setting up bn2_1
I0414 05:17:59.955014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.955014 17564 net.cpp:137] Memory required for data: 582356400
I0414 05:17:59.955014 17564 layer_factory.cpp:58] Creating layer scale2_1
I0414 05:17:59.955014 17564 net.cpp:84] Creating Layer scale2_1
I0414 05:17:59.955014 17564 net.cpp:406] scale2_1 <- bn2_1
I0414 05:17:59.955014 17564 net.cpp:380] scale2_1 -> scale2_1
I0414 05:17:59.955014 17564 layer_factory.cpp:58] Creating layer scale2_1
I0414 05:17:59.956013 17564 net.cpp:122] Setting up scale2_1
I0414 05:17:59.956013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.956013 17564 net.cpp:137] Memory required for data: 622497200
I0414 05:17:59.956013 17564 layer_factory.cpp:58] Creating layer relu2_1
I0414 05:17:59.956013 17564 net.cpp:84] Creating Layer relu2_1
I0414 05:17:59.956013 17564 net.cpp:406] relu2_1 <- scale2_1
I0414 05:17:59.956013 17564 net.cpp:367] relu2_1 -> scale2_1 (in-place)
I0414 05:17:59.956013 17564 net.cpp:122] Setting up relu2_1
I0414 05:17:59.956013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:17:59.956013 17564 net.cpp:137] Memory required for data: 662638000
I0414 05:17:59.956013 17564 layer_factory.cpp:58] Creating layer pool2_1
I0414 05:17:59.956013 17564 net.cpp:84] Creating Layer pool2_1
I0414 05:17:59.956013 17564 net.cpp:406] pool2_1 <- scale2_1
I0414 05:17:59.956013 17564 net.cpp:380] pool2_1 -> pool2_1
I0414 05:17:59.956013 17564 net.cpp:122] Setting up pool2_1
I0414 05:17:59.956013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.956013 17564 net.cpp:137] Memory required for data: 672673200
I0414 05:17:59.956013 17564 layer_factory.cpp:58] Creating layer drop2_1
I0414 05:17:59.956013 17564 net.cpp:84] Creating Layer drop2_1
I0414 05:17:59.956013 17564 net.cpp:406] drop2_1 <- pool2_1
I0414 05:17:59.956013 17564 net.cpp:367] drop2_1 -> pool2_1 (in-place)
I0414 05:17:59.956013 17564 net.cpp:122] Setting up drop2_1
I0414 05:17:59.956013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.956013 17564 net.cpp:137] Memory required for data: 682708400
I0414 05:17:59.956013 17564 layer_factory.cpp:58] Creating layer conv2_2
I0414 05:17:59.956013 17564 net.cpp:84] Creating Layer conv2_2
I0414 05:17:59.956013 17564 net.cpp:406] conv2_2 <- pool2_1
I0414 05:17:59.956013 17564 net.cpp:380] conv2_2 -> conv2_2
I0414 05:17:59.960037 17564 net.cpp:122] Setting up conv2_2
I0414 05:17:59.960037 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.960037 17564 net.cpp:137] Memory required for data: 692743600
I0414 05:17:59.960037 17564 layer_factory.cpp:58] Creating layer bn2_2
I0414 05:17:59.960037 17564 net.cpp:84] Creating Layer bn2_2
I0414 05:17:59.960037 17564 net.cpp:406] bn2_2 <- conv2_2
I0414 05:17:59.960037 17564 net.cpp:380] bn2_2 -> bn2_2
I0414 05:17:59.960037 17564 net.cpp:122] Setting up bn2_2
I0414 05:17:59.960037 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.960037 17564 net.cpp:137] Memory required for data: 702778800
I0414 05:17:59.960037 17564 layer_factory.cpp:58] Creating layer scale2_2
I0414 05:17:59.960037 17564 net.cpp:84] Creating Layer scale2_2
I0414 05:17:59.960037 17564 net.cpp:406] scale2_2 <- bn2_2
I0414 05:17:59.960037 17564 net.cpp:380] scale2_2 -> scale2_2
I0414 05:17:59.960037 17564 layer_factory.cpp:58] Creating layer scale2_2
I0414 05:17:59.960037 17564 net.cpp:122] Setting up scale2_2
I0414 05:17:59.960037 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.960037 17564 net.cpp:137] Memory required for data: 712814000
I0414 05:17:59.960037 17564 layer_factory.cpp:58] Creating layer relu2_2
I0414 05:17:59.960037 17564 net.cpp:84] Creating Layer relu2_2
I0414 05:17:59.960037 17564 net.cpp:406] relu2_2 <- scale2_2
I0414 05:17:59.960037 17564 net.cpp:367] relu2_2 -> scale2_2 (in-place)
I0414 05:17:59.961032 17564 net.cpp:122] Setting up relu2_2
I0414 05:17:59.961032 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.961032 17564 net.cpp:137] Memory required for data: 722849200
I0414 05:17:59.961032 17564 layer_factory.cpp:58] Creating layer drop2_2
I0414 05:17:59.961032 17564 net.cpp:84] Creating Layer drop2_2
I0414 05:17:59.961032 17564 net.cpp:406] drop2_2 <- scale2_2
I0414 05:17:59.961032 17564 net.cpp:367] drop2_2 -> scale2_2 (in-place)
I0414 05:17:59.961032 17564 net.cpp:122] Setting up drop2_2
I0414 05:17:59.961032 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.961032 17564 net.cpp:137] Memory required for data: 732884400
I0414 05:17:59.961032 17564 layer_factory.cpp:58] Creating layer conv3
I0414 05:17:59.961032 17564 net.cpp:84] Creating Layer conv3
I0414 05:17:59.961032 17564 net.cpp:406] conv3 <- scale2_2
I0414 05:17:59.961032 17564 net.cpp:380] conv3 -> conv3
I0414 05:17:59.964027 17564 net.cpp:122] Setting up conv3
I0414 05:17:59.964027 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.964027 17564 net.cpp:137] Memory required for data: 742919600
I0414 05:17:59.964027 17564 layer_factory.cpp:58] Creating layer bn3
I0414 05:17:59.964027 17564 net.cpp:84] Creating Layer bn3
I0414 05:17:59.964027 17564 net.cpp:406] bn3 <- conv3
I0414 05:17:59.964027 17564 net.cpp:380] bn3 -> bn3
I0414 05:17:59.964027 17564 net.cpp:122] Setting up bn3
I0414 05:17:59.964027 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.964027 17564 net.cpp:137] Memory required for data: 752954800
I0414 05:17:59.964027 17564 layer_factory.cpp:58] Creating layer scale3
I0414 05:17:59.964027 17564 net.cpp:84] Creating Layer scale3
I0414 05:17:59.964027 17564 net.cpp:406] scale3 <- bn3
I0414 05:17:59.964027 17564 net.cpp:380] scale3 -> scale3
I0414 05:17:59.964027 17564 layer_factory.cpp:58] Creating layer scale3
I0414 05:17:59.964027 17564 net.cpp:122] Setting up scale3
I0414 05:17:59.964027 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.964027 17564 net.cpp:137] Memory required for data: 762990000
I0414 05:17:59.964027 17564 layer_factory.cpp:58] Creating layer relu3
I0414 05:17:59.964027 17564 net.cpp:84] Creating Layer relu3
I0414 05:17:59.964027 17564 net.cpp:406] relu3 <- scale3
I0414 05:17:59.964027 17564 net.cpp:367] relu3 -> scale3 (in-place)
I0414 05:17:59.965028 17564 net.cpp:122] Setting up relu3
I0414 05:17:59.965028 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.965028 17564 net.cpp:137] Memory required for data: 773025200
I0414 05:17:59.965028 17564 layer_factory.cpp:58] Creating layer drop3
I0414 05:17:59.965028 17564 net.cpp:84] Creating Layer drop3
I0414 05:17:59.965028 17564 net.cpp:406] drop3 <- scale3
I0414 05:17:59.965028 17564 net.cpp:367] drop3 -> scale3 (in-place)
I0414 05:17:59.965028 17564 net.cpp:122] Setting up drop3
I0414 05:17:59.965028 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:17:59.965028 17564 net.cpp:137] Memory required for data: 783060400
I0414 05:17:59.965028 17564 layer_factory.cpp:58] Creating layer conv4
I0414 05:17:59.965028 17564 net.cpp:84] Creating Layer conv4
I0414 05:17:59.965028 17564 net.cpp:406] conv4 <- scale3
I0414 05:17:59.965028 17564 net.cpp:380] conv4 -> conv4
I0414 05:17:59.969023 17564 net.cpp:122] Setting up conv4
I0414 05:17:59.969023 17564 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0414 05:17:59.969023 17564 net.cpp:137] Memory required for data: 803130800
I0414 05:17:59.969023 17564 layer_factory.cpp:58] Creating layer pool4
I0414 05:17:59.969023 17564 net.cpp:84] Creating Layer pool4
I0414 05:17:59.969023 17564 net.cpp:406] pool4 <- conv4
I0414 05:17:59.969023 17564 net.cpp:380] pool4 -> pool4
I0414 05:17:59.969023 17564 net.cpp:122] Setting up pool4
I0414 05:17:59.969023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.969023 17564 net.cpp:137] Memory required for data: 808148400
I0414 05:17:59.969023 17564 layer_factory.cpp:58] Creating layer bn4
I0414 05:17:59.969023 17564 net.cpp:84] Creating Layer bn4
I0414 05:17:59.969023 17564 net.cpp:406] bn4 <- pool4
I0414 05:17:59.969023 17564 net.cpp:380] bn4 -> bn4
I0414 05:17:59.969023 17564 net.cpp:122] Setting up bn4
I0414 05:17:59.969023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.969023 17564 net.cpp:137] Memory required for data: 813166000
I0414 05:17:59.969023 17564 layer_factory.cpp:58] Creating layer scale4
I0414 05:17:59.969023 17564 net.cpp:84] Creating Layer scale4
I0414 05:17:59.969023 17564 net.cpp:406] scale4 <- bn4
I0414 05:17:59.969023 17564 net.cpp:380] scale4 -> scale4
I0414 05:17:59.969023 17564 layer_factory.cpp:58] Creating layer scale4
I0414 05:17:59.969023 17564 net.cpp:122] Setting up scale4
I0414 05:17:59.969023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.969023 17564 net.cpp:137] Memory required for data: 818183600
I0414 05:17:59.969023 17564 layer_factory.cpp:58] Creating layer relu4
I0414 05:17:59.969023 17564 net.cpp:84] Creating Layer relu4
I0414 05:17:59.969023 17564 net.cpp:406] relu4 <- scale4
I0414 05:17:59.970023 17564 net.cpp:367] relu4 -> scale4 (in-place)
I0414 05:17:59.970023 17564 net.cpp:122] Setting up relu4
I0414 05:17:59.970023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.970023 17564 net.cpp:137] Memory required for data: 823201200
I0414 05:17:59.970023 17564 layer_factory.cpp:58] Creating layer drop4
I0414 05:17:59.970023 17564 net.cpp:84] Creating Layer drop4
I0414 05:17:59.970023 17564 net.cpp:406] drop4 <- scale4
I0414 05:17:59.970023 17564 net.cpp:367] drop4 -> scale4 (in-place)
I0414 05:17:59.970023 17564 net.cpp:122] Setting up drop4
I0414 05:17:59.970023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.970023 17564 net.cpp:137] Memory required for data: 828218800
I0414 05:17:59.970023 17564 layer_factory.cpp:58] Creating layer conv4_1
I0414 05:17:59.970023 17564 net.cpp:84] Creating Layer conv4_1
I0414 05:17:59.970023 17564 net.cpp:406] conv4_1 <- scale4
I0414 05:17:59.970023 17564 net.cpp:380] conv4_1 -> conv4_1
I0414 05:17:59.977028 17564 net.cpp:122] Setting up conv4_1
I0414 05:17:59.978014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.978014 17564 net.cpp:137] Memory required for data: 833236400
I0414 05:17:59.978014 17564 layer_factory.cpp:58] Creating layer bn4_1
I0414 05:17:59.978014 17564 net.cpp:84] Creating Layer bn4_1
I0414 05:17:59.978014 17564 net.cpp:406] bn4_1 <- conv4_1
I0414 05:17:59.978014 17564 net.cpp:380] bn4_1 -> bn4_1
I0414 05:17:59.978014 17564 net.cpp:122] Setting up bn4_1
I0414 05:17:59.978014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.978014 17564 net.cpp:137] Memory required for data: 838254000
I0414 05:17:59.978014 17564 layer_factory.cpp:58] Creating layer scale4_1
I0414 05:17:59.978014 17564 net.cpp:84] Creating Layer scale4_1
I0414 05:17:59.978014 17564 net.cpp:406] scale4_1 <- bn4_1
I0414 05:17:59.978014 17564 net.cpp:380] scale4_1 -> scale4_1
I0414 05:17:59.978014 17564 layer_factory.cpp:58] Creating layer scale4_1
I0414 05:17:59.978014 17564 net.cpp:122] Setting up scale4_1
I0414 05:17:59.978014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.978014 17564 net.cpp:137] Memory required for data: 843271600
I0414 05:17:59.978014 17564 layer_factory.cpp:58] Creating layer relu4_1
I0414 05:17:59.978014 17564 net.cpp:84] Creating Layer relu4_1
I0414 05:17:59.978014 17564 net.cpp:406] relu4_1 <- scale4_1
I0414 05:17:59.978014 17564 net.cpp:367] relu4_1 -> scale4_1 (in-place)
I0414 05:17:59.978014 17564 net.cpp:122] Setting up relu4_1
I0414 05:17:59.978014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.978014 17564 net.cpp:137] Memory required for data: 848289200
I0414 05:17:59.978014 17564 layer_factory.cpp:58] Creating layer drop4_1
I0414 05:17:59.978014 17564 net.cpp:84] Creating Layer drop4_1
I0414 05:17:59.978014 17564 net.cpp:406] drop4_1 <- scale4_1
I0414 05:17:59.978014 17564 net.cpp:367] drop4_1 -> scale4_1 (in-place)
I0414 05:17:59.979023 17564 net.cpp:122] Setting up drop4_1
I0414 05:17:59.979023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.979023 17564 net.cpp:137] Memory required for data: 853306800
I0414 05:17:59.979023 17564 layer_factory.cpp:58] Creating layer conv4_2
I0414 05:17:59.979023 17564 net.cpp:84] Creating Layer conv4_2
I0414 05:17:59.979023 17564 net.cpp:406] conv4_2 <- scale4_1
I0414 05:17:59.979023 17564 net.cpp:380] conv4_2 -> conv4_2
I0414 05:17:59.985029 17564 net.cpp:122] Setting up conv4_2
I0414 05:17:59.985029 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.985029 17564 net.cpp:137] Memory required for data: 858324400
I0414 05:17:59.985029 17564 layer_factory.cpp:58] Creating layer bn4_2
I0414 05:17:59.985029 17564 net.cpp:84] Creating Layer bn4_2
I0414 05:17:59.985029 17564 net.cpp:406] bn4_2 <- conv4_2
I0414 05:17:59.985029 17564 net.cpp:380] bn4_2 -> bn4_2
I0414 05:17:59.986023 17564 net.cpp:122] Setting up bn4_2
I0414 05:17:59.986023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.986023 17564 net.cpp:137] Memory required for data: 863342000
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer scale4_2
I0414 05:17:59.986023 17564 net.cpp:84] Creating Layer scale4_2
I0414 05:17:59.986023 17564 net.cpp:406] scale4_2 <- bn4_2
I0414 05:17:59.986023 17564 net.cpp:380] scale4_2 -> scale4_2
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer scale4_2
I0414 05:17:59.986023 17564 net.cpp:122] Setting up scale4_2
I0414 05:17:59.986023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.986023 17564 net.cpp:137] Memory required for data: 868359600
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer relu4_2
I0414 05:17:59.986023 17564 net.cpp:84] Creating Layer relu4_2
I0414 05:17:59.986023 17564 net.cpp:406] relu4_2 <- scale4_2
I0414 05:17:59.986023 17564 net.cpp:367] relu4_2 -> scale4_2 (in-place)
I0414 05:17:59.986023 17564 net.cpp:122] Setting up relu4_2
I0414 05:17:59.986023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.986023 17564 net.cpp:137] Memory required for data: 873377200
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer drop4_2
I0414 05:17:59.986023 17564 net.cpp:84] Creating Layer drop4_2
I0414 05:17:59.986023 17564 net.cpp:406] drop4_2 <- scale4_2
I0414 05:17:59.986023 17564 net.cpp:367] drop4_2 -> scale4_2 (in-place)
I0414 05:17:59.986023 17564 net.cpp:122] Setting up drop4_2
I0414 05:17:59.986023 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:17:59.986023 17564 net.cpp:137] Memory required for data: 878394800
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer pool4_2
I0414 05:17:59.986023 17564 net.cpp:84] Creating Layer pool4_2
I0414 05:17:59.986023 17564 net.cpp:406] pool4_2 <- scale4_2
I0414 05:17:59.986023 17564 net.cpp:380] pool4_2 -> pool4_2
I0414 05:17:59.986023 17564 net.cpp:122] Setting up pool4_2
I0414 05:17:59.986023 17564 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0414 05:17:59.986023 17564 net.cpp:137] Memory required for data: 880033200
I0414 05:17:59.986023 17564 layer_factory.cpp:58] Creating layer conv4_0
I0414 05:17:59.986023 17564 net.cpp:84] Creating Layer conv4_0
I0414 05:17:59.986023 17564 net.cpp:406] conv4_0 <- pool4_2
I0414 05:17:59.986023 17564 net.cpp:380] conv4_0 -> conv4_0
I0414 05:17:59.997012 17564 net.cpp:122] Setting up conv4_0
I0414 05:17:59.997012 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:17:59.997012 17564 net.cpp:137] Memory required for data: 883310000
I0414 05:17:59.997012 17564 layer_factory.cpp:58] Creating layer bn4_0
I0414 05:17:59.997012 17564 net.cpp:84] Creating Layer bn4_0
I0414 05:17:59.997012 17564 net.cpp:406] bn4_0 <- conv4_0
I0414 05:17:59.997012 17564 net.cpp:380] bn4_0 -> bn4_0
I0414 05:17:59.997012 17564 net.cpp:122] Setting up bn4_0
I0414 05:17:59.997012 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:17:59.997012 17564 net.cpp:137] Memory required for data: 886586800
I0414 05:17:59.997012 17564 layer_factory.cpp:58] Creating layer scale4_0
I0414 05:17:59.997012 17564 net.cpp:84] Creating Layer scale4_0
I0414 05:17:59.997012 17564 net.cpp:406] scale4_0 <- bn4_0
I0414 05:17:59.997012 17564 net.cpp:380] scale4_0 -> scale4_0
I0414 05:17:59.997012 17564 layer_factory.cpp:58] Creating layer scale4_0
I0414 05:17:59.997012 17564 net.cpp:122] Setting up scale4_0
I0414 05:17:59.997012 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:17:59.997012 17564 net.cpp:137] Memory required for data: 889863600
I0414 05:17:59.997012 17564 layer_factory.cpp:58] Creating layer relu4_0
I0414 05:17:59.997012 17564 net.cpp:84] Creating Layer relu4_0
I0414 05:17:59.997012 17564 net.cpp:406] relu4_0 <- scale4_0
I0414 05:17:59.997012 17564 net.cpp:367] relu4_0 -> scale4_0 (in-place)
I0414 05:17:59.998013 17564 net.cpp:122] Setting up relu4_0
I0414 05:17:59.998013 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:17:59.998013 17564 net.cpp:137] Memory required for data: 893140400
I0414 05:17:59.998013 17564 layer_factory.cpp:58] Creating layer drop4_0
I0414 05:17:59.998013 17564 net.cpp:84] Creating Layer drop4_0
I0414 05:17:59.998013 17564 net.cpp:406] drop4_0 <- scale4_0
I0414 05:17:59.998013 17564 net.cpp:367] drop4_0 -> scale4_0 (in-place)
I0414 05:17:59.998013 17564 net.cpp:122] Setting up drop4_0
I0414 05:17:59.998013 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:17:59.998013 17564 net.cpp:137] Memory required for data: 896417200
I0414 05:17:59.998013 17564 layer_factory.cpp:58] Creating layer cccp4
I0414 05:17:59.998013 17564 net.cpp:84] Creating Layer cccp4
I0414 05:17:59.998013 17564 net.cpp:406] cccp4 <- scale4_0
I0414 05:17:59.998013 17564 net.cpp:380] cccp4 -> cccp4
I0414 05:18:00.008013 17564 net.cpp:122] Setting up cccp4
I0414 05:18:00.008013 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.008013 17564 net.cpp:137] Memory required for data: 898260400
I0414 05:18:00.008013 17564 layer_factory.cpp:58] Creating layer relu_cccp4
I0414 05:18:00.008013 17564 net.cpp:84] Creating Layer relu_cccp4
I0414 05:18:00.008013 17564 net.cpp:406] relu_cccp4 <- cccp4
I0414 05:18:00.008013 17564 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0414 05:18:00.008013 17564 net.cpp:122] Setting up relu_cccp4
I0414 05:18:00.008013 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.008013 17564 net.cpp:137] Memory required for data: 900103600
I0414 05:18:00.008013 17564 layer_factory.cpp:58] Creating layer drop4_3
I0414 05:18:00.008013 17564 net.cpp:84] Creating Layer drop4_3
I0414 05:18:00.008013 17564 net.cpp:406] drop4_3 <- cccp4
I0414 05:18:00.008013 17564 net.cpp:367] drop4_3 -> cccp4 (in-place)
I0414 05:18:00.008013 17564 net.cpp:122] Setting up drop4_3
I0414 05:18:00.008013 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.008013 17564 net.cpp:137] Memory required for data: 901946800
I0414 05:18:00.008013 17564 layer_factory.cpp:58] Creating layer cccp5
I0414 05:18:00.008013 17564 net.cpp:84] Creating Layer cccp5
I0414 05:18:00.008013 17564 net.cpp:406] cccp5 <- cccp4
I0414 05:18:00.008013 17564 net.cpp:380] cccp5 -> cccp5
I0414 05:18:00.014012 17564 net.cpp:122] Setting up cccp5
I0414 05:18:00.014012 17564 net.cpp:129] Top shape: 100 256 2 2 (102400)
I0414 05:18:00.014012 17564 net.cpp:137] Memory required for data: 902356400
I0414 05:18:00.014012 17564 layer_factory.cpp:58] Creating layer relu_cccp5
I0414 05:18:00.014012 17564 net.cpp:84] Creating Layer relu_cccp5
I0414 05:18:00.014012 17564 net.cpp:406] relu_cccp5 <- cccp5
I0414 05:18:00.014012 17564 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0414 05:18:00.014012 17564 net.cpp:122] Setting up relu_cccp5
I0414 05:18:00.014012 17564 net.cpp:129] Top shape: 100 256 2 2 (102400)
I0414 05:18:00.015012 17564 net.cpp:137] Memory required for data: 902766000
I0414 05:18:00.015012 17564 layer_factory.cpp:58] Creating layer poolcp5
I0414 05:18:00.015012 17564 net.cpp:84] Creating Layer poolcp5
I0414 05:18:00.015012 17564 net.cpp:406] poolcp5 <- cccp5
I0414 05:18:00.015012 17564 net.cpp:380] poolcp5 -> poolcp5
I0414 05:18:00.015012 17564 net.cpp:122] Setting up poolcp5
I0414 05:18:00.015012 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.015012 17564 net.cpp:137] Memory required for data: 902868400
I0414 05:18:00.015012 17564 layer_factory.cpp:58] Creating layer drop4_5
I0414 05:18:00.015012 17564 net.cpp:84] Creating Layer drop4_5
I0414 05:18:00.015012 17564 net.cpp:406] drop4_5 <- poolcp5
I0414 05:18:00.015012 17564 net.cpp:367] drop4_5 -> poolcp5 (in-place)
I0414 05:18:00.015012 17564 net.cpp:122] Setting up drop4_5
I0414 05:18:00.015012 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.015012 17564 net.cpp:137] Memory required for data: 902970800
I0414 05:18:00.015012 17564 layer_factory.cpp:58] Creating layer cccp6
I0414 05:18:00.015012 17564 net.cpp:84] Creating Layer cccp6
I0414 05:18:00.015012 17564 net.cpp:406] cccp6 <- poolcp5
I0414 05:18:00.015012 17564 net.cpp:380] cccp6 -> cccp6
I0414 05:18:00.022012 17564 net.cpp:122] Setting up cccp6
I0414 05:18:00.022012 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.022012 17564 net.cpp:137] Memory required for data: 903073200
I0414 05:18:00.022012 17564 layer_factory.cpp:58] Creating layer relu_cccp6
I0414 05:18:00.022012 17564 net.cpp:84] Creating Layer relu_cccp6
I0414 05:18:00.022012 17564 net.cpp:406] relu_cccp6 <- cccp6
I0414 05:18:00.022012 17564 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0414 05:18:00.023012 17564 net.cpp:122] Setting up relu_cccp6
I0414 05:18:00.023012 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.023012 17564 net.cpp:137] Memory required for data: 903175600
I0414 05:18:00.023012 17564 layer_factory.cpp:58] Creating layer poolcp6
I0414 05:18:00.023012 17564 net.cpp:84] Creating Layer poolcp6
I0414 05:18:00.023012 17564 net.cpp:406] poolcp6 <- cccp6
I0414 05:18:00.023012 17564 net.cpp:380] poolcp6 -> poolcp6
I0414 05:18:00.023012 17564 net.cpp:122] Setting up poolcp6
I0414 05:18:00.023012 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.023012 17564 net.cpp:137] Memory required for data: 903278000
I0414 05:18:00.023012 17564 layer_factory.cpp:58] Creating layer ip1
I0414 05:18:00.023012 17564 net.cpp:84] Creating Layer ip1
I0414 05:18:00.023012 17564 net.cpp:406] ip1 <- poolcp6
I0414 05:18:00.023012 17564 net.cpp:380] ip1 -> ip1
I0414 05:18:00.023012 17564 net.cpp:122] Setting up ip1
I0414 05:18:00.023012 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.023012 17564 net.cpp:137] Memory required for data: 903282000
I0414 05:18:00.023012 17564 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0414 05:18:00.023012 17564 net.cpp:84] Creating Layer ip1_ip1_0_split
I0414 05:18:00.024013 17564 net.cpp:406] ip1_ip1_0_split <- ip1
I0414 05:18:00.024013 17564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0414 05:18:00.024013 17564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0414 05:18:00.024013 17564 net.cpp:122] Setting up ip1_ip1_0_split
I0414 05:18:00.024013 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.024013 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.024013 17564 net.cpp:137] Memory required for data: 903290000
I0414 05:18:00.024013 17564 layer_factory.cpp:58] Creating layer accuracy_training
I0414 05:18:00.024013 17564 net.cpp:84] Creating Layer accuracy_training
I0414 05:18:00.024013 17564 net.cpp:406] accuracy_training <- ip1_ip1_0_split_0
I0414 05:18:00.024013 17564 net.cpp:406] accuracy_training <- label_mnist_1_split_0
I0414 05:18:00.024013 17564 net.cpp:380] accuracy_training -> accuracy_training
I0414 05:18:00.024013 17564 net.cpp:122] Setting up accuracy_training
I0414 05:18:00.024013 17564 net.cpp:129] Top shape: (1)
I0414 05:18:00.024013 17564 net.cpp:137] Memory required for data: 903290004
I0414 05:18:00.024013 17564 layer_factory.cpp:58] Creating layer loss
I0414 05:18:00.024013 17564 net.cpp:84] Creating Layer loss
I0414 05:18:00.024013 17564 net.cpp:406] loss <- ip1_ip1_0_split_1
I0414 05:18:00.024013 17564 net.cpp:406] loss <- label_mnist_1_split_1
I0414 05:18:00.024013 17564 net.cpp:380] loss -> loss
I0414 05:18:00.024013 17564 layer_factory.cpp:58] Creating layer loss
I0414 05:18:00.024013 17564 net.cpp:122] Setting up loss
I0414 05:18:00.024013 17564 net.cpp:129] Top shape: (1)
I0414 05:18:00.024013 17564 net.cpp:132]     with loss weight 1
I0414 05:18:00.025012 17564 net.cpp:137] Memory required for data: 903290008
I0414 05:18:00.025012 17564 net.cpp:198] loss needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:200] accuracy_training does not need backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] ip1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] poolcp6 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu_cccp6 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] cccp6 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4_5 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] poolcp5 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu_cccp5 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] cccp5 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4_3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu_cccp4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] cccp4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu4_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale4_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn4_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv4_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] pool4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv4_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu4_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale4_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn4_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv4_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] pool4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv4 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv3 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop2_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu2_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale2_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn2_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv2_2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] pool2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop2_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv2 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop1_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu1_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale1_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn1_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv1_0 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] drop2_1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] relu1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] scale1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] bn1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:198] conv1 needs backward computation.
I0414 05:18:00.025012 17564 net.cpp:200] label_mnist_1_split does not need backward computation.
I0414 05:18:00.025012 17564 net.cpp:200] mnist does not need backward computation.
I0414 05:18:00.025012 17564 net.cpp:242] This network produces output accuracy_training
I0414 05:18:00.025012 17564 net.cpp:242] This network produces output loss
I0414 05:18:00.025012 17564 net.cpp:255] Network initialization done.
I0414 05:18:00.026013 17564 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/mnist/lenet_train_test.prototxt
I0414 05:18:00.026013 17564 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0414 05:18:00.026013 17564 solver.cpp:173] Creating test net (#0) specified by net file: examples/mnist/lenet_train_test.prototxt
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0414 05:18:00.026013 17564 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0414 05:18:00.026013 17564 net.cpp:51] Initializing net from parameters: 
name: "SlimNet_FX2_5M"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "scale1"
  top: "scale1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "drop1_0"
  type: "Dropout"
  bottom: "scale1_0"
  top: "scale1_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "drop2_0"
  type: "Dropout"
  bottom: "scale2"
  top: "scale2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "drop2_2"
  type: "Dropout"
  bottom: "scale2_2"
  top: "scale2_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "scale3"
  top: "scale3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "scale4"
  top: "scale4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "drop4_1"
  type: "Dropout"
  bottom: "scale4_1"
  top: "scale4_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "drop4_2"
  type: "Dropout"
  bottom: "scale4_2"
  top: "scale4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "drop4_0"
  type: "Dropout"
  bottom: "scale4_0"
  top: "scale4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 2
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "drop4_3"
  type: "Dropout"
  bottom: "cccp4"
  top: "cccp4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 2
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4_5"
  type: "Dropout"
  bottom: "poolcp5"
  top: "poolcp5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0414 05:18:00.026013 17564 layer_factory.cpp:58] Creating layer mnist
I0414 05:18:00.034014 17564 db_lmdb.cpp:40] Opened lmdb examples/mnist/mnist_test_lmdb_norm2
I0414 05:18:00.034014 17564 net.cpp:84] Creating Layer mnist
I0414 05:18:00.034014 17564 net.cpp:380] mnist -> data
I0414 05:18:00.034014 17564 net.cpp:380] mnist -> label
I0414 05:18:00.034014 17564 data_layer.cpp:45] output data size: 100,1,28,28
I0414 05:18:00.036015 17564 net.cpp:122] Setting up mnist
I0414 05:18:00.036015 17564 net.cpp:129] Top shape: 100 1 28 28 (78400)
I0414 05:18:00.036015 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:18:00.036015 17564 net.cpp:137] Memory required for data: 314000
I0414 05:18:00.036015 17564 layer_factory.cpp:58] Creating layer label_mnist_1_split
I0414 05:18:00.036015 17564 net.cpp:84] Creating Layer label_mnist_1_split
I0414 05:18:00.036015 17564 net.cpp:406] label_mnist_1_split <- label
I0414 05:18:00.036015 17564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_0
I0414 05:18:00.036015 17564 net.cpp:380] label_mnist_1_split -> label_mnist_1_split_1
I0414 05:18:00.036015 17564 net.cpp:122] Setting up label_mnist_1_split
I0414 05:18:00.036015 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:18:00.036015 17564 net.cpp:129] Top shape: 100 (100)
I0414 05:18:00.036015 17564 net.cpp:137] Memory required for data: 314800
I0414 05:18:00.036015 17564 layer_factory.cpp:58] Creating layer conv1
I0414 05:18:00.036015 17564 net.cpp:84] Creating Layer conv1
I0414 05:18:00.036015 17564 net.cpp:406] conv1 <- data
I0414 05:18:00.036015 17564 net.cpp:380] conv1 -> conv1
I0414 05:18:00.038012 17584 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0414 05:18:00.038012 17564 net.cpp:122] Setting up conv1
I0414 05:18:00.038012 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:18:00.038012 17564 net.cpp:137] Memory required for data: 20385200
I0414 05:18:00.038012 17564 layer_factory.cpp:58] Creating layer bn1
I0414 05:18:00.038012 17564 net.cpp:84] Creating Layer bn1
I0414 05:18:00.038012 17564 net.cpp:406] bn1 <- conv1
I0414 05:18:00.038012 17564 net.cpp:380] bn1 -> bn1
I0414 05:18:00.039014 17564 net.cpp:122] Setting up bn1
I0414 05:18:00.039014 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:18:00.039014 17564 net.cpp:137] Memory required for data: 40455600
I0414 05:18:00.039014 17564 layer_factory.cpp:58] Creating layer scale1
I0414 05:18:00.039014 17564 net.cpp:84] Creating Layer scale1
I0414 05:18:00.039014 17564 net.cpp:406] scale1 <- bn1
I0414 05:18:00.039014 17564 net.cpp:380] scale1 -> scale1
I0414 05:18:00.039014 17564 layer_factory.cpp:58] Creating layer scale1
I0414 05:18:00.039014 17564 net.cpp:122] Setting up scale1
I0414 05:18:00.039014 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:18:00.039014 17564 net.cpp:137] Memory required for data: 60526000
I0414 05:18:00.039014 17564 layer_factory.cpp:58] Creating layer relu1
I0414 05:18:00.039014 17564 net.cpp:84] Creating Layer relu1
I0414 05:18:00.039014 17564 net.cpp:406] relu1 <- scale1
I0414 05:18:00.039014 17564 net.cpp:367] relu1 -> scale1 (in-place)
I0414 05:18:00.040014 17564 net.cpp:122] Setting up relu1
I0414 05:18:00.040014 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:18:00.040014 17564 net.cpp:137] Memory required for data: 80596400
I0414 05:18:00.040014 17564 layer_factory.cpp:58] Creating layer drop2_1
I0414 05:18:00.040014 17564 net.cpp:84] Creating Layer drop2_1
I0414 05:18:00.040014 17564 net.cpp:406] drop2_1 <- scale1
I0414 05:18:00.040014 17564 net.cpp:367] drop2_1 -> scale1 (in-place)
I0414 05:18:00.040014 17564 net.cpp:122] Setting up drop2_1
I0414 05:18:00.040014 17564 net.cpp:129] Top shape: 100 64 28 28 (5017600)
I0414 05:18:00.040014 17564 net.cpp:137] Memory required for data: 100666800
I0414 05:18:00.040014 17564 layer_factory.cpp:58] Creating layer conv1_0
I0414 05:18:00.040014 17564 net.cpp:84] Creating Layer conv1_0
I0414 05:18:00.040014 17564 net.cpp:406] conv1_0 <- scale1
I0414 05:18:00.040014 17564 net.cpp:380] conv1_0 -> conv1_0
I0414 05:18:00.042013 17564 net.cpp:122] Setting up conv1_0
I0414 05:18:00.042013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.042013 17564 net.cpp:137] Memory required for data: 140807600
I0414 05:18:00.042013 17564 layer_factory.cpp:58] Creating layer bn1_0
I0414 05:18:00.042013 17564 net.cpp:84] Creating Layer bn1_0
I0414 05:18:00.042013 17564 net.cpp:406] bn1_0 <- conv1_0
I0414 05:18:00.042013 17564 net.cpp:380] bn1_0 -> bn1_0
I0414 05:18:00.042013 17564 net.cpp:122] Setting up bn1_0
I0414 05:18:00.042013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.042013 17564 net.cpp:137] Memory required for data: 180948400
I0414 05:18:00.042013 17564 layer_factory.cpp:58] Creating layer scale1_0
I0414 05:18:00.042013 17564 net.cpp:84] Creating Layer scale1_0
I0414 05:18:00.042013 17564 net.cpp:406] scale1_0 <- bn1_0
I0414 05:18:00.042013 17564 net.cpp:380] scale1_0 -> scale1_0
I0414 05:18:00.042013 17564 layer_factory.cpp:58] Creating layer scale1_0
I0414 05:18:00.043014 17564 net.cpp:122] Setting up scale1_0
I0414 05:18:00.043014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.043014 17564 net.cpp:137] Memory required for data: 221089200
I0414 05:18:00.043014 17564 layer_factory.cpp:58] Creating layer relu1_0
I0414 05:18:00.043014 17564 net.cpp:84] Creating Layer relu1_0
I0414 05:18:00.043014 17564 net.cpp:406] relu1_0 <- scale1_0
I0414 05:18:00.043014 17564 net.cpp:367] relu1_0 -> scale1_0 (in-place)
I0414 05:18:00.043014 17564 net.cpp:122] Setting up relu1_0
I0414 05:18:00.043014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.043014 17564 net.cpp:137] Memory required for data: 261230000
I0414 05:18:00.043014 17564 layer_factory.cpp:58] Creating layer drop1_0
I0414 05:18:00.043014 17564 net.cpp:84] Creating Layer drop1_0
I0414 05:18:00.043014 17564 net.cpp:406] drop1_0 <- scale1_0
I0414 05:18:00.043014 17564 net.cpp:367] drop1_0 -> scale1_0 (in-place)
I0414 05:18:00.043014 17564 net.cpp:122] Setting up drop1_0
I0414 05:18:00.043014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.043014 17564 net.cpp:137] Memory required for data: 301370800
I0414 05:18:00.043014 17564 layer_factory.cpp:58] Creating layer conv2
I0414 05:18:00.043014 17564 net.cpp:84] Creating Layer conv2
I0414 05:18:00.043014 17564 net.cpp:406] conv2 <- scale1_0
I0414 05:18:00.043014 17564 net.cpp:380] conv2 -> conv2
I0414 05:18:00.047013 17564 net.cpp:122] Setting up conv2
I0414 05:18:00.047013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.047013 17564 net.cpp:137] Memory required for data: 341511600
I0414 05:18:00.047013 17564 layer_factory.cpp:58] Creating layer bn2
I0414 05:18:00.047013 17564 net.cpp:84] Creating Layer bn2
I0414 05:18:00.047013 17564 net.cpp:406] bn2 <- conv2
I0414 05:18:00.047013 17564 net.cpp:380] bn2 -> bn2
I0414 05:18:00.047013 17564 net.cpp:122] Setting up bn2
I0414 05:18:00.047013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.047013 17564 net.cpp:137] Memory required for data: 381652400
I0414 05:18:00.047013 17564 layer_factory.cpp:58] Creating layer scale2
I0414 05:18:00.047013 17564 net.cpp:84] Creating Layer scale2
I0414 05:18:00.047013 17564 net.cpp:406] scale2 <- bn2
I0414 05:18:00.047013 17564 net.cpp:380] scale2 -> scale2
I0414 05:18:00.047013 17564 layer_factory.cpp:58] Creating layer scale2
I0414 05:18:00.047013 17564 net.cpp:122] Setting up scale2
I0414 05:18:00.047013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.047013 17564 net.cpp:137] Memory required for data: 421793200
I0414 05:18:00.047013 17564 layer_factory.cpp:58] Creating layer relu2
I0414 05:18:00.047013 17564 net.cpp:84] Creating Layer relu2
I0414 05:18:00.047013 17564 net.cpp:406] relu2 <- scale2
I0414 05:18:00.047013 17564 net.cpp:367] relu2 -> scale2 (in-place)
I0414 05:18:00.048014 17564 net.cpp:122] Setting up relu2
I0414 05:18:00.048014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.048014 17564 net.cpp:137] Memory required for data: 461934000
I0414 05:18:00.048014 17564 layer_factory.cpp:58] Creating layer drop2_0
I0414 05:18:00.048014 17564 net.cpp:84] Creating Layer drop2_0
I0414 05:18:00.048014 17564 net.cpp:406] drop2_0 <- scale2
I0414 05:18:00.048014 17564 net.cpp:367] drop2_0 -> scale2 (in-place)
I0414 05:18:00.048014 17564 net.cpp:122] Setting up drop2_0
I0414 05:18:00.048014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.048014 17564 net.cpp:137] Memory required for data: 502074800
I0414 05:18:00.048014 17564 layer_factory.cpp:58] Creating layer conv2_1
I0414 05:18:00.048014 17564 net.cpp:84] Creating Layer conv2_1
I0414 05:18:00.048014 17564 net.cpp:406] conv2_1 <- scale2
I0414 05:18:00.048014 17564 net.cpp:380] conv2_1 -> conv2_1
I0414 05:18:00.052013 17564 net.cpp:122] Setting up conv2_1
I0414 05:18:00.052013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.052013 17564 net.cpp:137] Memory required for data: 542215600
I0414 05:18:00.052013 17564 layer_factory.cpp:58] Creating layer bn2_1
I0414 05:18:00.052013 17564 net.cpp:84] Creating Layer bn2_1
I0414 05:18:00.052013 17564 net.cpp:406] bn2_1 <- conv2_1
I0414 05:18:00.052013 17564 net.cpp:380] bn2_1 -> bn2_1
I0414 05:18:00.052013 17564 net.cpp:122] Setting up bn2_1
I0414 05:18:00.052013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.052013 17564 net.cpp:137] Memory required for data: 582356400
I0414 05:18:00.052013 17564 layer_factory.cpp:58] Creating layer scale2_1
I0414 05:18:00.052013 17564 net.cpp:84] Creating Layer scale2_1
I0414 05:18:00.052013 17564 net.cpp:406] scale2_1 <- bn2_1
I0414 05:18:00.052013 17564 net.cpp:380] scale2_1 -> scale2_1
I0414 05:18:00.052013 17564 layer_factory.cpp:58] Creating layer scale2_1
I0414 05:18:00.052013 17564 net.cpp:122] Setting up scale2_1
I0414 05:18:00.052013 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.052013 17564 net.cpp:137] Memory required for data: 622497200
I0414 05:18:00.052013 17564 layer_factory.cpp:58] Creating layer relu2_1
I0414 05:18:00.052013 17564 net.cpp:84] Creating Layer relu2_1
I0414 05:18:00.052013 17564 net.cpp:406] relu2_1 <- scale2_1
I0414 05:18:00.052013 17564 net.cpp:367] relu2_1 -> scale2_1 (in-place)
I0414 05:18:00.053014 17564 net.cpp:122] Setting up relu2_1
I0414 05:18:00.053014 17564 net.cpp:129] Top shape: 100 128 28 28 (10035200)
I0414 05:18:00.053014 17564 net.cpp:137] Memory required for data: 662638000
I0414 05:18:00.053014 17564 layer_factory.cpp:58] Creating layer pool2_1
I0414 05:18:00.053014 17564 net.cpp:84] Creating Layer pool2_1
I0414 05:18:00.053014 17564 net.cpp:406] pool2_1 <- scale2_1
I0414 05:18:00.053014 17564 net.cpp:380] pool2_1 -> pool2_1
I0414 05:18:00.053014 17564 net.cpp:122] Setting up pool2_1
I0414 05:18:00.053014 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.053014 17564 net.cpp:137] Memory required for data: 672673200
I0414 05:18:00.053014 17564 layer_factory.cpp:58] Creating layer drop2_1
I0414 05:18:00.053014 17564 net.cpp:84] Creating Layer drop2_1
I0414 05:18:00.053014 17564 net.cpp:406] drop2_1 <- pool2_1
I0414 05:18:00.053014 17564 net.cpp:367] drop2_1 -> pool2_1 (in-place)
I0414 05:18:00.053014 17564 net.cpp:122] Setting up drop2_1
I0414 05:18:00.053014 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.053014 17564 net.cpp:137] Memory required for data: 682708400
I0414 05:18:00.053014 17564 layer_factory.cpp:58] Creating layer conv2_2
I0414 05:18:00.053014 17564 net.cpp:84] Creating Layer conv2_2
I0414 05:18:00.053014 17564 net.cpp:406] conv2_2 <- pool2_1
I0414 05:18:00.053014 17564 net.cpp:380] conv2_2 -> conv2_2
I0414 05:18:00.057013 17564 net.cpp:122] Setting up conv2_2
I0414 05:18:00.057013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.057013 17564 net.cpp:137] Memory required for data: 692743600
I0414 05:18:00.057013 17564 layer_factory.cpp:58] Creating layer bn2_2
I0414 05:18:00.057013 17564 net.cpp:84] Creating Layer bn2_2
I0414 05:18:00.057013 17564 net.cpp:406] bn2_2 <- conv2_2
I0414 05:18:00.057013 17564 net.cpp:380] bn2_2 -> bn2_2
I0414 05:18:00.057013 17564 net.cpp:122] Setting up bn2_2
I0414 05:18:00.057013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.057013 17564 net.cpp:137] Memory required for data: 702778800
I0414 05:18:00.057013 17564 layer_factory.cpp:58] Creating layer scale2_2
I0414 05:18:00.057013 17564 net.cpp:84] Creating Layer scale2_2
I0414 05:18:00.057013 17564 net.cpp:406] scale2_2 <- bn2_2
I0414 05:18:00.057013 17564 net.cpp:380] scale2_2 -> scale2_2
I0414 05:18:00.057013 17564 layer_factory.cpp:58] Creating layer scale2_2
I0414 05:18:00.057013 17564 net.cpp:122] Setting up scale2_2
I0414 05:18:00.057013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.057013 17564 net.cpp:137] Memory required for data: 712814000
I0414 05:18:00.057013 17564 layer_factory.cpp:58] Creating layer relu2_2
I0414 05:18:00.057013 17564 net.cpp:84] Creating Layer relu2_2
I0414 05:18:00.057013 17564 net.cpp:406] relu2_2 <- scale2_2
I0414 05:18:00.057013 17564 net.cpp:367] relu2_2 -> scale2_2 (in-place)
I0414 05:18:00.058013 17564 net.cpp:122] Setting up relu2_2
I0414 05:18:00.058013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.058013 17564 net.cpp:137] Memory required for data: 722849200
I0414 05:18:00.058013 17564 layer_factory.cpp:58] Creating layer drop2_2
I0414 05:18:00.058013 17564 net.cpp:84] Creating Layer drop2_2
I0414 05:18:00.058013 17564 net.cpp:406] drop2_2 <- scale2_2
I0414 05:18:00.058013 17564 net.cpp:367] drop2_2 -> scale2_2 (in-place)
I0414 05:18:00.058013 17564 net.cpp:122] Setting up drop2_2
I0414 05:18:00.058013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.058013 17564 net.cpp:137] Memory required for data: 732884400
I0414 05:18:00.058013 17564 layer_factory.cpp:58] Creating layer conv3
I0414 05:18:00.058013 17564 net.cpp:84] Creating Layer conv3
I0414 05:18:00.058013 17564 net.cpp:406] conv3 <- scale2_2
I0414 05:18:00.058013 17564 net.cpp:380] conv3 -> conv3
I0414 05:18:00.061013 17564 net.cpp:122] Setting up conv3
I0414 05:18:00.061013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.061013 17564 net.cpp:137] Memory required for data: 742919600
I0414 05:18:00.061013 17564 layer_factory.cpp:58] Creating layer bn3
I0414 05:18:00.061013 17564 net.cpp:84] Creating Layer bn3
I0414 05:18:00.061013 17564 net.cpp:406] bn3 <- conv3
I0414 05:18:00.061013 17564 net.cpp:380] bn3 -> bn3
I0414 05:18:00.061013 17564 net.cpp:122] Setting up bn3
I0414 05:18:00.061013 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.061013 17564 net.cpp:137] Memory required for data: 752954800
I0414 05:18:00.061013 17564 layer_factory.cpp:58] Creating layer scale3
I0414 05:18:00.061013 17564 net.cpp:84] Creating Layer scale3
I0414 05:18:00.061013 17564 net.cpp:406] scale3 <- bn3
I0414 05:18:00.061013 17564 net.cpp:380] scale3 -> scale3
I0414 05:18:00.061013 17564 layer_factory.cpp:58] Creating layer scale3
I0414 05:18:00.062014 17564 net.cpp:122] Setting up scale3
I0414 05:18:00.062014 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.062014 17564 net.cpp:137] Memory required for data: 762990000
I0414 05:18:00.062014 17564 layer_factory.cpp:58] Creating layer relu3
I0414 05:18:00.062014 17564 net.cpp:84] Creating Layer relu3
I0414 05:18:00.062014 17564 net.cpp:406] relu3 <- scale3
I0414 05:18:00.062014 17564 net.cpp:367] relu3 -> scale3 (in-place)
I0414 05:18:00.062014 17564 net.cpp:122] Setting up relu3
I0414 05:18:00.062014 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.062014 17564 net.cpp:137] Memory required for data: 773025200
I0414 05:18:00.062014 17564 layer_factory.cpp:58] Creating layer drop3
I0414 05:18:00.062014 17564 net.cpp:84] Creating Layer drop3
I0414 05:18:00.062014 17564 net.cpp:406] drop3 <- scale3
I0414 05:18:00.062014 17564 net.cpp:367] drop3 -> scale3 (in-place)
I0414 05:18:00.062014 17564 net.cpp:122] Setting up drop3
I0414 05:18:00.062014 17564 net.cpp:129] Top shape: 100 128 14 14 (2508800)
I0414 05:18:00.062014 17564 net.cpp:137] Memory required for data: 783060400
I0414 05:18:00.062014 17564 layer_factory.cpp:58] Creating layer conv4
I0414 05:18:00.062014 17564 net.cpp:84] Creating Layer conv4
I0414 05:18:00.062014 17564 net.cpp:406] conv4 <- scale3
I0414 05:18:00.062014 17564 net.cpp:380] conv4 -> conv4
I0414 05:18:00.067013 17564 net.cpp:122] Setting up conv4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 14 14 (5017600)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 803130800
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer pool4
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer pool4
I0414 05:18:00.067013 17564 net.cpp:406] pool4 <- conv4
I0414 05:18:00.067013 17564 net.cpp:380] pool4 -> pool4
I0414 05:18:00.067013 17564 net.cpp:122] Setting up pool4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 808148400
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer bn4
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer bn4
I0414 05:18:00.067013 17564 net.cpp:406] bn4 <- pool4
I0414 05:18:00.067013 17564 net.cpp:380] bn4 -> bn4
I0414 05:18:00.067013 17564 net.cpp:122] Setting up bn4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 813166000
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer scale4
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer scale4
I0414 05:18:00.067013 17564 net.cpp:406] scale4 <- bn4
I0414 05:18:00.067013 17564 net.cpp:380] scale4 -> scale4
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer scale4
I0414 05:18:00.067013 17564 net.cpp:122] Setting up scale4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 818183600
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer relu4
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer relu4
I0414 05:18:00.067013 17564 net.cpp:406] relu4 <- scale4
I0414 05:18:00.067013 17564 net.cpp:367] relu4 -> scale4 (in-place)
I0414 05:18:00.067013 17564 net.cpp:122] Setting up relu4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 823201200
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer drop4
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer drop4
I0414 05:18:00.067013 17564 net.cpp:406] drop4 <- scale4
I0414 05:18:00.067013 17564 net.cpp:367] drop4 -> scale4 (in-place)
I0414 05:18:00.067013 17564 net.cpp:122] Setting up drop4
I0414 05:18:00.067013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.067013 17564 net.cpp:137] Memory required for data: 828218800
I0414 05:18:00.067013 17564 layer_factory.cpp:58] Creating layer conv4_1
I0414 05:18:00.067013 17564 net.cpp:84] Creating Layer conv4_1
I0414 05:18:00.067013 17564 net.cpp:406] conv4_1 <- scale4
I0414 05:18:00.067013 17564 net.cpp:380] conv4_1 -> conv4_1
I0414 05:18:00.074014 17564 net.cpp:122] Setting up conv4_1
I0414 05:18:00.074014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.074014 17564 net.cpp:137] Memory required for data: 833236400
I0414 05:18:00.074014 17564 layer_factory.cpp:58] Creating layer bn4_1
I0414 05:18:00.074014 17564 net.cpp:84] Creating Layer bn4_1
I0414 05:18:00.074014 17564 net.cpp:406] bn4_1 <- conv4_1
I0414 05:18:00.074014 17564 net.cpp:380] bn4_1 -> bn4_1
I0414 05:18:00.074014 17564 net.cpp:122] Setting up bn4_1
I0414 05:18:00.074014 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.074014 17564 net.cpp:137] Memory required for data: 838254000
I0414 05:18:00.074014 17564 layer_factory.cpp:58] Creating layer scale4_1
I0414 05:18:00.074014 17564 net.cpp:84] Creating Layer scale4_1
I0414 05:18:00.075013 17564 net.cpp:406] scale4_1 <- bn4_1
I0414 05:18:00.075013 17564 net.cpp:380] scale4_1 -> scale4_1
I0414 05:18:00.075013 17564 layer_factory.cpp:58] Creating layer scale4_1
I0414 05:18:00.075013 17564 net.cpp:122] Setting up scale4_1
I0414 05:18:00.075013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.075013 17564 net.cpp:137] Memory required for data: 843271600
I0414 05:18:00.075013 17564 layer_factory.cpp:58] Creating layer relu4_1
I0414 05:18:00.075013 17564 net.cpp:84] Creating Layer relu4_1
I0414 05:18:00.075013 17564 net.cpp:406] relu4_1 <- scale4_1
I0414 05:18:00.075013 17564 net.cpp:367] relu4_1 -> scale4_1 (in-place)
I0414 05:18:00.075013 17564 net.cpp:122] Setting up relu4_1
I0414 05:18:00.075013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.075013 17564 net.cpp:137] Memory required for data: 848289200
I0414 05:18:00.075013 17564 layer_factory.cpp:58] Creating layer drop4_1
I0414 05:18:00.075013 17564 net.cpp:84] Creating Layer drop4_1
I0414 05:18:00.075013 17564 net.cpp:406] drop4_1 <- scale4_1
I0414 05:18:00.075013 17564 net.cpp:367] drop4_1 -> scale4_1 (in-place)
I0414 05:18:00.075013 17564 net.cpp:122] Setting up drop4_1
I0414 05:18:00.075013 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.075013 17564 net.cpp:137] Memory required for data: 853306800
I0414 05:18:00.075013 17564 layer_factory.cpp:58] Creating layer conv4_2
I0414 05:18:00.075013 17564 net.cpp:84] Creating Layer conv4_2
I0414 05:18:00.075013 17564 net.cpp:406] conv4_2 <- scale4_1
I0414 05:18:00.075013 17564 net.cpp:380] conv4_2 -> conv4_2
I0414 05:18:00.082025 17564 net.cpp:122] Setting up conv4_2
I0414 05:18:00.082025 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.082025 17564 net.cpp:137] Memory required for data: 858324400
I0414 05:18:00.082025 17564 layer_factory.cpp:58] Creating layer bn4_2
I0414 05:18:00.082025 17564 net.cpp:84] Creating Layer bn4_2
I0414 05:18:00.082025 17564 net.cpp:406] bn4_2 <- conv4_2
I0414 05:18:00.082025 17564 net.cpp:380] bn4_2 -> bn4_2
I0414 05:18:00.082025 17564 net.cpp:122] Setting up bn4_2
I0414 05:18:00.082025 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.082025 17564 net.cpp:137] Memory required for data: 863342000
I0414 05:18:00.082025 17564 layer_factory.cpp:58] Creating layer scale4_2
I0414 05:18:00.082025 17564 net.cpp:84] Creating Layer scale4_2
I0414 05:18:00.082025 17564 net.cpp:406] scale4_2 <- bn4_2
I0414 05:18:00.082025 17564 net.cpp:380] scale4_2 -> scale4_2
I0414 05:18:00.082025 17564 layer_factory.cpp:58] Creating layer scale4_2
I0414 05:18:00.082025 17564 net.cpp:122] Setting up scale4_2
I0414 05:18:00.082025 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.082025 17564 net.cpp:137] Memory required for data: 868359600
I0414 05:18:00.082025 17564 layer_factory.cpp:58] Creating layer relu4_2
I0414 05:18:00.082025 17564 net.cpp:84] Creating Layer relu4_2
I0414 05:18:00.082025 17564 net.cpp:406] relu4_2 <- scale4_2
I0414 05:18:00.082025 17564 net.cpp:367] relu4_2 -> scale4_2 (in-place)
I0414 05:18:00.083024 17564 net.cpp:122] Setting up relu4_2
I0414 05:18:00.083024 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.083024 17564 net.cpp:137] Memory required for data: 873377200
I0414 05:18:00.083024 17564 layer_factory.cpp:58] Creating layer drop4_2
I0414 05:18:00.083024 17564 net.cpp:84] Creating Layer drop4_2
I0414 05:18:00.083024 17564 net.cpp:406] drop4_2 <- scale4_2
I0414 05:18:00.083024 17564 net.cpp:367] drop4_2 -> scale4_2 (in-place)
I0414 05:18:00.083024 17564 net.cpp:122] Setting up drop4_2
I0414 05:18:00.083024 17564 net.cpp:129] Top shape: 100 256 7 7 (1254400)
I0414 05:18:00.083024 17564 net.cpp:137] Memory required for data: 878394800
I0414 05:18:00.083024 17564 layer_factory.cpp:58] Creating layer pool4_2
I0414 05:18:00.083024 17564 net.cpp:84] Creating Layer pool4_2
I0414 05:18:00.083024 17564 net.cpp:406] pool4_2 <- scale4_2
I0414 05:18:00.083024 17564 net.cpp:380] pool4_2 -> pool4_2
I0414 05:18:00.083024 17564 net.cpp:122] Setting up pool4_2
I0414 05:18:00.083024 17564 net.cpp:129] Top shape: 100 256 4 4 (409600)
I0414 05:18:00.083024 17564 net.cpp:137] Memory required for data: 880033200
I0414 05:18:00.083024 17564 layer_factory.cpp:58] Creating layer conv4_0
I0414 05:18:00.083024 17564 net.cpp:84] Creating Layer conv4_0
I0414 05:18:00.083024 17564 net.cpp:406] conv4_0 <- pool4_2
I0414 05:18:00.083024 17564 net.cpp:380] conv4_0 -> conv4_0
I0414 05:18:00.092015 17564 net.cpp:122] Setting up conv4_0
I0414 05:18:00.092015 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:18:00.092015 17564 net.cpp:137] Memory required for data: 883310000
I0414 05:18:00.092015 17564 layer_factory.cpp:58] Creating layer bn4_0
I0414 05:18:00.092015 17564 net.cpp:84] Creating Layer bn4_0
I0414 05:18:00.092015 17564 net.cpp:406] bn4_0 <- conv4_0
I0414 05:18:00.092015 17564 net.cpp:380] bn4_0 -> bn4_0
I0414 05:18:00.093014 17564 net.cpp:122] Setting up bn4_0
I0414 05:18:00.093014 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:18:00.093014 17564 net.cpp:137] Memory required for data: 886586800
I0414 05:18:00.093014 17564 layer_factory.cpp:58] Creating layer scale4_0
I0414 05:18:00.093014 17564 net.cpp:84] Creating Layer scale4_0
I0414 05:18:00.093014 17564 net.cpp:406] scale4_0 <- bn4_0
I0414 05:18:00.093014 17564 net.cpp:380] scale4_0 -> scale4_0
I0414 05:18:00.093014 17564 layer_factory.cpp:58] Creating layer scale4_0
I0414 05:18:00.093014 17564 net.cpp:122] Setting up scale4_0
I0414 05:18:00.093014 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:18:00.093014 17564 net.cpp:137] Memory required for data: 889863600
I0414 05:18:00.093014 17564 layer_factory.cpp:58] Creating layer relu4_0
I0414 05:18:00.093014 17564 net.cpp:84] Creating Layer relu4_0
I0414 05:18:00.093014 17564 net.cpp:406] relu4_0 <- scale4_0
I0414 05:18:00.093014 17564 net.cpp:367] relu4_0 -> scale4_0 (in-place)
I0414 05:18:00.094013 17564 net.cpp:122] Setting up relu4_0
I0414 05:18:00.094013 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:18:00.094013 17564 net.cpp:137] Memory required for data: 893140400
I0414 05:18:00.094013 17564 layer_factory.cpp:58] Creating layer drop4_0
I0414 05:18:00.094013 17564 net.cpp:84] Creating Layer drop4_0
I0414 05:18:00.094013 17564 net.cpp:406] drop4_0 <- scale4_0
I0414 05:18:00.094013 17564 net.cpp:367] drop4_0 -> scale4_0 (in-place)
I0414 05:18:00.094013 17564 net.cpp:122] Setting up drop4_0
I0414 05:18:00.094013 17564 net.cpp:129] Top shape: 100 512 4 4 (819200)
I0414 05:18:00.094013 17564 net.cpp:137] Memory required for data: 896417200
I0414 05:18:00.094013 17564 layer_factory.cpp:58] Creating layer cccp4
I0414 05:18:00.094013 17564 net.cpp:84] Creating Layer cccp4
I0414 05:18:00.094013 17564 net.cpp:406] cccp4 <- scale4_0
I0414 05:18:00.094013 17564 net.cpp:380] cccp4 -> cccp4
I0414 05:18:00.103015 17564 net.cpp:122] Setting up cccp4
I0414 05:18:00.103015 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.103015 17564 net.cpp:137] Memory required for data: 898260400
I0414 05:18:00.103015 17564 layer_factory.cpp:58] Creating layer relu_cccp4
I0414 05:18:00.103015 17564 net.cpp:84] Creating Layer relu_cccp4
I0414 05:18:00.103015 17564 net.cpp:406] relu_cccp4 <- cccp4
I0414 05:18:00.103015 17564 net.cpp:367] relu_cccp4 -> cccp4 (in-place)
I0414 05:18:00.104022 17564 net.cpp:122] Setting up relu_cccp4
I0414 05:18:00.104022 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.104022 17564 net.cpp:137] Memory required for data: 900103600
I0414 05:18:00.104022 17564 layer_factory.cpp:58] Creating layer drop4_3
I0414 05:18:00.104022 17564 net.cpp:84] Creating Layer drop4_3
I0414 05:18:00.104022 17564 net.cpp:406] drop4_3 <- cccp4
I0414 05:18:00.104022 17564 net.cpp:367] drop4_3 -> cccp4 (in-place)
I0414 05:18:00.104022 17564 net.cpp:122] Setting up drop4_3
I0414 05:18:00.104022 17564 net.cpp:129] Top shape: 100 512 3 3 (460800)
I0414 05:18:00.104022 17564 net.cpp:137] Memory required for data: 901946800
I0414 05:18:00.104022 17564 layer_factory.cpp:58] Creating layer cccp5
I0414 05:18:00.104022 17564 net.cpp:84] Creating Layer cccp5
I0414 05:18:00.104022 17564 net.cpp:406] cccp5 <- cccp4
I0414 05:18:00.104022 17564 net.cpp:380] cccp5 -> cccp5
I0414 05:18:00.109027 17564 net.cpp:122] Setting up cccp5
I0414 05:18:00.109027 17564 net.cpp:129] Top shape: 100 256 2 2 (102400)
I0414 05:18:00.109027 17564 net.cpp:137] Memory required for data: 902356400
I0414 05:18:00.109027 17564 layer_factory.cpp:58] Creating layer relu_cccp5
I0414 05:18:00.109027 17564 net.cpp:84] Creating Layer relu_cccp5
I0414 05:18:00.109027 17564 net.cpp:406] relu_cccp5 <- cccp5
I0414 05:18:00.109027 17564 net.cpp:367] relu_cccp5 -> cccp5 (in-place)
I0414 05:18:00.110028 17564 net.cpp:122] Setting up relu_cccp5
I0414 05:18:00.110028 17564 net.cpp:129] Top shape: 100 256 2 2 (102400)
I0414 05:18:00.110028 17564 net.cpp:137] Memory required for data: 902766000
I0414 05:18:00.110028 17564 layer_factory.cpp:58] Creating layer poolcp5
I0414 05:18:00.110028 17564 net.cpp:84] Creating Layer poolcp5
I0414 05:18:00.110028 17564 net.cpp:406] poolcp5 <- cccp5
I0414 05:18:00.110028 17564 net.cpp:380] poolcp5 -> poolcp5
I0414 05:18:00.110028 17564 net.cpp:122] Setting up poolcp5
I0414 05:18:00.110028 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.110028 17564 net.cpp:137] Memory required for data: 902868400
I0414 05:18:00.110028 17564 layer_factory.cpp:58] Creating layer drop4_5
I0414 05:18:00.110028 17564 net.cpp:84] Creating Layer drop4_5
I0414 05:18:00.110028 17564 net.cpp:406] drop4_5 <- poolcp5
I0414 05:18:00.110028 17564 net.cpp:367] drop4_5 -> poolcp5 (in-place)
I0414 05:18:00.110028 17564 net.cpp:122] Setting up drop4_5
I0414 05:18:00.110028 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.110028 17564 net.cpp:137] Memory required for data: 902970800
I0414 05:18:00.110028 17564 layer_factory.cpp:58] Creating layer cccp6
I0414 05:18:00.110028 17564 net.cpp:84] Creating Layer cccp6
I0414 05:18:00.110028 17564 net.cpp:406] cccp6 <- poolcp5
I0414 05:18:00.110028 17564 net.cpp:380] cccp6 -> cccp6
I0414 05:18:00.119032 17564 net.cpp:122] Setting up cccp6
I0414 05:18:00.119032 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.119032 17564 net.cpp:137] Memory required for data: 903073200
I0414 05:18:00.119032 17564 layer_factory.cpp:58] Creating layer relu_cccp6
I0414 05:18:00.119032 17564 net.cpp:84] Creating Layer relu_cccp6
I0414 05:18:00.119032 17564 net.cpp:406] relu_cccp6 <- cccp6
I0414 05:18:00.119032 17564 net.cpp:367] relu_cccp6 -> cccp6 (in-place)
I0414 05:18:00.119032 17564 net.cpp:122] Setting up relu_cccp6
I0414 05:18:00.119032 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.119032 17564 net.cpp:137] Memory required for data: 903175600
I0414 05:18:00.119032 17564 layer_factory.cpp:58] Creating layer poolcp6
I0414 05:18:00.119032 17564 net.cpp:84] Creating Layer poolcp6
I0414 05:18:00.119032 17564 net.cpp:406] poolcp6 <- cccp6
I0414 05:18:00.119032 17564 net.cpp:380] poolcp6 -> poolcp6
I0414 05:18:00.120028 17564 net.cpp:122] Setting up poolcp6
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: 100 256 1 1 (25600)
I0414 05:18:00.120028 17564 net.cpp:137] Memory required for data: 903278000
I0414 05:18:00.120028 17564 layer_factory.cpp:58] Creating layer ip1
I0414 05:18:00.120028 17564 net.cpp:84] Creating Layer ip1
I0414 05:18:00.120028 17564 net.cpp:406] ip1 <- poolcp6
I0414 05:18:00.120028 17564 net.cpp:380] ip1 -> ip1
I0414 05:18:00.120028 17564 net.cpp:122] Setting up ip1
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.120028 17564 net.cpp:137] Memory required for data: 903282000
I0414 05:18:00.120028 17564 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0414 05:18:00.120028 17564 net.cpp:84] Creating Layer ip1_ip1_0_split
I0414 05:18:00.120028 17564 net.cpp:406] ip1_ip1_0_split <- ip1
I0414 05:18:00.120028 17564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0414 05:18:00.120028 17564 net.cpp:380] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0414 05:18:00.120028 17564 net.cpp:122] Setting up ip1_ip1_0_split
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: 100 10 (1000)
I0414 05:18:00.120028 17564 net.cpp:137] Memory required for data: 903290000
I0414 05:18:00.120028 17564 layer_factory.cpp:58] Creating layer accuracy
I0414 05:18:00.120028 17564 net.cpp:84] Creating Layer accuracy
I0414 05:18:00.120028 17564 net.cpp:406] accuracy <- ip1_ip1_0_split_0
I0414 05:18:00.120028 17564 net.cpp:406] accuracy <- label_mnist_1_split_0
I0414 05:18:00.120028 17564 net.cpp:380] accuracy -> accuracy
I0414 05:18:00.120028 17564 net.cpp:122] Setting up accuracy
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: (1)
I0414 05:18:00.120028 17564 net.cpp:137] Memory required for data: 903290004
I0414 05:18:00.120028 17564 layer_factory.cpp:58] Creating layer loss
I0414 05:18:00.120028 17564 net.cpp:84] Creating Layer loss
I0414 05:18:00.120028 17564 net.cpp:406] loss <- ip1_ip1_0_split_1
I0414 05:18:00.120028 17564 net.cpp:406] loss <- label_mnist_1_split_1
I0414 05:18:00.120028 17564 net.cpp:380] loss -> loss
I0414 05:18:00.120028 17564 layer_factory.cpp:58] Creating layer loss
I0414 05:18:00.120028 17564 net.cpp:122] Setting up loss
I0414 05:18:00.120028 17564 net.cpp:129] Top shape: (1)
I0414 05:18:00.120028 17564 net.cpp:132]     with loss weight 1
I0414 05:18:00.120028 17564 net.cpp:137] Memory required for data: 903290008
I0414 05:18:00.120028 17564 net.cpp:198] loss needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:200] accuracy does not need backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] ip1_ip1_0_split needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] ip1 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] poolcp6 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] relu_cccp6 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] cccp6 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] drop4_5 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] poolcp5 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] relu_cccp5 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] cccp5 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] drop4_3 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] relu_cccp4 needs backward computation.
I0414 05:18:00.120028 17564 net.cpp:198] cccp4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop4_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu4_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale4_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn4_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv4_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] pool4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv4_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop4_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu4_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale4_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn4_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv4_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] pool4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv4 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop3 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu3 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale3 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn3 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv3 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop2_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu2_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale2_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn2_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv2_2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] pool2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop2_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv2 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop1_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu1_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale1_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn1_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv1_0 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] drop2_1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] relu1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] scale1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] bn1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:198] conv1 needs backward computation.
I0414 05:18:00.121028 17564 net.cpp:200] label_mnist_1_split does not need backward computation.
I0414 05:18:00.121028 17564 net.cpp:200] mnist does not need backward computation.
I0414 05:18:00.121028 17564 net.cpp:242] This network produces output accuracy
I0414 05:18:00.121028 17564 net.cpp:242] This network produces output loss
I0414 05:18:00.121028 17564 net.cpp:255] Network initialization done.
I0414 05:18:00.121028 17564 solver.cpp:56] Solver scaffolding done.
I0414 05:18:00.125028 17564 caffe.cpp:249] Starting Optimization
I0414 05:18:00.125028 17564 solver.cpp:273] Solving SlimNet_FX2_5M
I0414 05:18:00.125028 17564 solver.cpp:274] Learning Rate Policy: multistep
I0414 05:18:00.131623 17564 solver.cpp:331] Iteration 0, Testing net (#0)
I0414 05:18:00.136626 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:18:04.206166 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:18:04.371461 17564 solver.cpp:398]     Test net output #0: accuracy = 0.1053
I0414 05:18:04.371461 17564 solver.cpp:398]     Test net output #1: loss = 78.14 (* 1 = 78.14 loss)
I0414 05:18:04.654556 17564 solver.cpp:219] Iteration 0 (0 iter/s, 4.52857s/100 iters), loss = 2.31188
I0414 05:18:04.654556 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.14
I0414 05:18:04.654556 17564 solver.cpp:238]     Train net output #1: loss = 2.31188 (* 1 = 2.31188 loss)
I0414 05:18:04.654556 17564 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I0414 05:18:19.082710 17564 solver.cpp:219] Iteration 100 (6.93157 iter/s, 14.4267s/100 iters), loss = 0.613546
I0414 05:18:19.082710 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.82
I0414 05:18:19.082710 17564 solver.cpp:238]     Train net output #1: loss = 0.613546 (* 1 = 0.613546 loss)
I0414 05:18:19.082710 17564 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I0414 05:18:33.439494 17564 solver.cpp:219] Iteration 200 (6.96548 iter/s, 14.3565s/100 iters), loss = 0.214697
I0414 05:18:33.439494 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.93
I0414 05:18:33.439494 17564 solver.cpp:238]     Train net output #1: loss = 0.214697 (* 1 = 0.214697 loss)
I0414 05:18:33.439494 17564 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I0414 05:18:47.727494 17564 solver.cpp:219] Iteration 300 (6.99916 iter/s, 14.2874s/100 iters), loss = 0.0784403
I0414 05:18:47.727494 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:18:47.727494 17564 solver.cpp:238]     Train net output #1: loss = 0.0784404 (* 1 = 0.0784404 loss)
I0414 05:18:47.727494 17564 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I0414 05:19:02.019495 17564 solver.cpp:219] Iteration 400 (6.99696 iter/s, 14.2919s/100 iters), loss = 0.0942559
I0414 05:19:02.019495 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.96
I0414 05:19:02.019495 17564 solver.cpp:238]     Train net output #1: loss = 0.0942559 (* 1 = 0.0942559 loss)
I0414 05:19:02.020494 17564 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I0414 05:19:16.314494 17564 solver.cpp:219] Iteration 500 (6.99593 iter/s, 14.294s/100 iters), loss = 0.128356
I0414 05:19:16.314494 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:19:16.314494 17564 solver.cpp:238]     Train net output #1: loss = 0.128356 (* 1 = 0.128356 loss)
I0414 05:19:16.314494 17564 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I0414 05:19:29.892494 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:19:30.463495 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_600.caffemodel
I0414 05:19:30.627719 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_600.solverstate
I0414 05:19:30.699718 17564 solver.cpp:331] Iteration 600, Testing net (#0)
I0414 05:19:30.699718 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:19:34.628736 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:19:34.790720 17564 solver.cpp:398]     Test net output #0: accuracy = 0.8631
I0414 05:19:34.790720 17564 solver.cpp:398]     Test net output #1: loss = 0.406373 (* 1 = 0.406373 loss)
I0414 05:19:34.929733 17564 solver.cpp:219] Iteration 600 (5.37207 iter/s, 18.6148s/100 iters), loss = 0.129191
I0414 05:19:34.929733 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.95
I0414 05:19:34.929733 17564 solver.cpp:238]     Train net output #1: loss = 0.129192 (* 1 = 0.129192 loss)
I0414 05:19:34.929733 17564 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I0414 05:19:49.229751 17564 solver.cpp:219] Iteration 700 (6.99315 iter/s, 14.2997s/100 iters), loss = 0.13152
I0414 05:19:49.230752 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.94
I0414 05:19:49.230752 17564 solver.cpp:238]     Train net output #1: loss = 0.13152 (* 1 = 0.13152 loss)
I0414 05:19:49.230752 17564 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I0414 05:20:03.568075 17564 solver.cpp:219] Iteration 800 (6.97502 iter/s, 14.3369s/100 iters), loss = 0.0877349
I0414 05:20:03.568075 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:20:03.568075 17564 solver.cpp:238]     Train net output #1: loss = 0.087735 (* 1 = 0.087735 loss)
I0414 05:20:03.568075 17564 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I0414 05:20:17.873087 17564 solver.cpp:219] Iteration 900 (6.99088 iter/s, 14.3043s/100 iters), loss = 0.0969787
I0414 05:20:17.873087 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:20:17.873087 17564 solver.cpp:238]     Train net output #1: loss = 0.0969789 (* 1 = 0.0969789 loss)
I0414 05:20:17.873087 17564 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I0414 05:20:32.166071 17564 solver.cpp:219] Iteration 1000 (6.99643 iter/s, 14.293s/100 iters), loss = 0.0480067
I0414 05:20:32.166071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:20:32.166071 17564 solver.cpp:238]     Train net output #1: loss = 0.0480068 (* 1 = 0.0480068 loss)
I0414 05:20:32.167073 17564 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I0414 05:20:46.466071 17564 solver.cpp:219] Iteration 1100 (6.99355 iter/s, 14.2989s/100 iters), loss = 0.120769
I0414 05:20:46.466071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:20:46.466071 17564 solver.cpp:238]     Train net output #1: loss = 0.120769 (* 1 = 0.120769 loss)
I0414 05:20:46.466071 17564 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I0414 05:21:00.057081 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:21:00.627092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_1200.caffemodel
I0414 05:21:00.769078 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_1200.solverstate
I0414 05:21:00.836074 17564 solver.cpp:331] Iteration 1200, Testing net (#0)
I0414 05:21:00.836074 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:21:04.780072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:21:04.942112 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9752
I0414 05:21:04.942112 17564 solver.cpp:398]     Test net output #1: loss = 0.114179 (* 1 = 0.114179 loss)
I0414 05:21:05.082072 17564 solver.cpp:219] Iteration 1200 (5.372 iter/s, 18.615s/100 iters), loss = 0.0656633
I0414 05:21:05.082072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:21:05.082072 17564 solver.cpp:238]     Train net output #1: loss = 0.0656634 (* 1 = 0.0656634 loss)
I0414 05:21:05.082072 17564 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I0414 05:21:19.380071 17564 solver.cpp:219] Iteration 1300 (6.99416 iter/s, 14.2976s/100 iters), loss = 0.163533
I0414 05:21:19.380071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:21:19.380071 17564 solver.cpp:238]     Train net output #1: loss = 0.163533 (* 1 = 0.163533 loss)
I0414 05:21:19.380071 17564 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I0414 05:21:33.680071 17564 solver.cpp:219] Iteration 1400 (6.99328 iter/s, 14.2994s/100 iters), loss = 0.0892562
I0414 05:21:33.680071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:21:33.680071 17564 solver.cpp:238]     Train net output #1: loss = 0.0892564 (* 1 = 0.0892564 loss)
I0414 05:21:33.680071 17564 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I0414 05:21:47.979073 17564 solver.cpp:219] Iteration 1500 (6.99368 iter/s, 14.2986s/100 iters), loss = 0.087395
I0414 05:21:47.979073 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:21:47.979073 17564 solver.cpp:238]     Train net output #1: loss = 0.0873951 (* 1 = 0.0873951 loss)
I0414 05:21:47.979073 17564 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I0414 05:22:02.276072 17564 solver.cpp:219] Iteration 1600 (6.99479 iter/s, 14.2963s/100 iters), loss = 0.0351448
I0414 05:22:02.276072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:22:02.276072 17564 solver.cpp:238]     Train net output #1: loss = 0.0351449 (* 1 = 0.0351449 loss)
I0414 05:22:02.276072 17564 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I0414 05:22:16.574072 17564 solver.cpp:219] Iteration 1700 (6.99417 iter/s, 14.2976s/100 iters), loss = 0.0516924
I0414 05:22:16.574072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:22:16.574072 17564 solver.cpp:238]     Train net output #1: loss = 0.0516925 (* 1 = 0.0516925 loss)
I0414 05:22:16.574072 17564 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I0414 05:22:30.157074 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:22:30.730072 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_1800.caffemodel
I0414 05:22:30.872072 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_1800.solverstate
I0414 05:22:30.943073 17564 solver.cpp:331] Iteration 1800, Testing net (#0)
I0414 05:22:30.943073 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:22:34.877074 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:22:35.039083 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9881
I0414 05:22:35.039083 17564 solver.cpp:398]     Test net output #1: loss = 0.0514842 (* 1 = 0.0514842 loss)
I0414 05:22:35.178072 17564 solver.cpp:219] Iteration 1800 (5.37528 iter/s, 18.6037s/100 iters), loss = 0.04283
I0414 05:22:35.178072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:22:35.178072 17564 solver.cpp:238]     Train net output #1: loss = 0.0428301 (* 1 = 0.0428301 loss)
I0414 05:22:35.178072 17564 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I0414 05:22:49.507071 17564 solver.cpp:219] Iteration 1900 (6.97927 iter/s, 14.3282s/100 iters), loss = 0.0757601
I0414 05:22:49.507071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:22:49.507071 17564 solver.cpp:238]     Train net output #1: loss = 0.0757601 (* 1 = 0.0757601 loss)
I0414 05:22:49.507071 17564 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I0414 05:23:03.836074 17564 solver.cpp:219] Iteration 2000 (6.97899 iter/s, 14.3287s/100 iters), loss = 0.0460533
I0414 05:23:03.836074 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:23:03.836074 17564 solver.cpp:238]     Train net output #1: loss = 0.0460533 (* 1 = 0.0460533 loss)
I0414 05:23:03.837076 17564 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I0414 05:23:18.184077 17564 solver.cpp:219] Iteration 2100 (6.97005 iter/s, 14.3471s/100 iters), loss = 0.0429909
I0414 05:23:18.184077 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:23:18.184077 17564 solver.cpp:238]     Train net output #1: loss = 0.042991 (* 1 = 0.042991 loss)
I0414 05:23:18.184077 17564 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I0414 05:23:32.540074 17564 solver.cpp:219] Iteration 2200 (6.96585 iter/s, 14.3557s/100 iters), loss = 0.0441385
I0414 05:23:32.541074 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:23:32.541074 17564 solver.cpp:238]     Train net output #1: loss = 0.0441386 (* 1 = 0.0441386 loss)
I0414 05:23:32.541074 17564 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I0414 05:23:46.836071 17564 solver.cpp:219] Iteration 2300 (6.99566 iter/s, 14.2946s/100 iters), loss = 0.0156068
I0414 05:23:46.836071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:23:46.836071 17564 solver.cpp:238]     Train net output #1: loss = 0.0156069 (* 1 = 0.0156069 loss)
I0414 05:23:46.836071 17564 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I0414 05:24:00.452074 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:24:01.026072 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_2400.caffemodel
I0414 05:24:01.174073 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_2400.solverstate
I0414 05:24:01.244073 17564 solver.cpp:331] Iteration 2400, Testing net (#0)
I0414 05:24:01.245074 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:24:05.182073 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:24:05.345073 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9884
I0414 05:24:05.345073 17564 solver.cpp:398]     Test net output #1: loss = 0.0480845 (* 1 = 0.0480845 loss)
I0414 05:24:05.484072 17564 solver.cpp:219] Iteration 2400 (5.36271 iter/s, 18.6473s/100 iters), loss = 0.0611163
I0414 05:24:05.484072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:24:05.484072 17564 solver.cpp:238]     Train net output #1: loss = 0.0611164 (* 1 = 0.0611164 loss)
I0414 05:24:05.484072 17564 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I0414 05:24:19.789072 17564 solver.cpp:219] Iteration 2500 (6.99084 iter/s, 14.3044s/100 iters), loss = 0.082849
I0414 05:24:19.789072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:24:19.789072 17564 solver.cpp:238]     Train net output #1: loss = 0.0828491 (* 1 = 0.0828491 loss)
I0414 05:24:19.789072 17564 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I0414 05:24:34.112072 17564 solver.cpp:219] Iteration 2600 (6.98216 iter/s, 14.3222s/100 iters), loss = 0.0510868
I0414 05:24:34.112072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:24:34.112072 17564 solver.cpp:238]     Train net output #1: loss = 0.0510869 (* 1 = 0.0510869 loss)
I0414 05:24:34.112072 17564 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I0414 05:24:48.434072 17564 solver.cpp:219] Iteration 2700 (6.98245 iter/s, 14.3216s/100 iters), loss = 0.0549943
I0414 05:24:48.434072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:24:48.434072 17564 solver.cpp:238]     Train net output #1: loss = 0.0549943 (* 1 = 0.0549943 loss)
I0414 05:24:48.434072 17564 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I0414 05:25:02.732071 17564 solver.cpp:219] Iteration 2800 (6.99411 iter/s, 14.2977s/100 iters), loss = 0.026565
I0414 05:25:02.732071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:25:02.732071 17564 solver.cpp:238]     Train net output #1: loss = 0.0265651 (* 1 = 0.0265651 loss)
I0414 05:25:02.732071 17564 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I0414 05:25:17.054071 17564 solver.cpp:219] Iteration 2900 (6.98259 iter/s, 14.3213s/100 iters), loss = 0.021108
I0414 05:25:17.054071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:25:17.054071 17564 solver.cpp:238]     Train net output #1: loss = 0.0211081 (* 1 = 0.0211081 loss)
I0414 05:25:17.054071 17564 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I0414 05:25:30.643077 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:25:31.214072 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_3000.caffemodel
I0414 05:25:31.356072 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_3000.solverstate
I0414 05:25:31.423072 17564 solver.cpp:331] Iteration 3000, Testing net (#0)
I0414 05:25:31.423072 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:25:35.359072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:25:35.521072 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9902
I0414 05:25:35.521072 17564 solver.cpp:398]     Test net output #1: loss = 0.0450919 (* 1 = 0.0450919 loss)
I0414 05:25:35.660073 17564 solver.cpp:219] Iteration 3000 (5.37468 iter/s, 18.6057s/100 iters), loss = 0.0593539
I0414 05:25:35.660073 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:25:35.660073 17564 solver.cpp:238]     Train net output #1: loss = 0.059354 (* 1 = 0.059354 loss)
I0414 05:25:35.660073 17564 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I0414 05:25:49.963071 17564 solver.cpp:219] Iteration 3100 (6.99187 iter/s, 14.3023s/100 iters), loss = 0.0524319
I0414 05:25:49.963071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:25:49.963071 17564 solver.cpp:238]     Train net output #1: loss = 0.052432 (* 1 = 0.052432 loss)
I0414 05:25:49.963071 17564 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I0414 05:26:04.277071 17564 solver.cpp:219] Iteration 3200 (6.98675 iter/s, 14.3128s/100 iters), loss = 0.0789524
I0414 05:26:04.277071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.96
I0414 05:26:04.277071 17564 solver.cpp:238]     Train net output #1: loss = 0.0789525 (* 1 = 0.0789525 loss)
I0414 05:26:04.277071 17564 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I0414 05:26:18.584071 17564 solver.cpp:219] Iteration 3300 (6.98949 iter/s, 14.3072s/100 iters), loss = 0.0240637
I0414 05:26:18.584071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:26:18.584071 17564 solver.cpp:238]     Train net output #1: loss = 0.0240637 (* 1 = 0.0240637 loss)
I0414 05:26:18.584071 17564 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I0414 05:26:32.899071 17564 solver.cpp:219] Iteration 3400 (6.98608 iter/s, 14.3142s/100 iters), loss = 0.0226317
I0414 05:26:32.899071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:26:32.899071 17564 solver.cpp:238]     Train net output #1: loss = 0.0226318 (* 1 = 0.0226318 loss)
I0414 05:26:32.899071 17564 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I0414 05:26:47.192071 17564 solver.cpp:219] Iteration 3500 (6.9968 iter/s, 14.2923s/100 iters), loss = 0.0260326
I0414 05:26:47.192071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:26:47.192071 17564 solver.cpp:238]     Train net output #1: loss = 0.0260326 (* 1 = 0.0260326 loss)
I0414 05:26:47.192071 17564 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I0414 05:27:00.779073 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:27:01.350073 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_3600.caffemodel
I0414 05:27:01.500075 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_3600.solverstate
I0414 05:27:01.569075 17564 solver.cpp:331] Iteration 3600, Testing net (#0)
I0414 05:27:01.569075 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:27:05.506075 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:27:05.668071 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9876
I0414 05:27:05.669072 17564 solver.cpp:398]     Test net output #1: loss = 0.0540783 (* 1 = 0.0540783 loss)
I0414 05:27:05.808073 17564 solver.cpp:219] Iteration 3600 (5.37194 iter/s, 18.6153s/100 iters), loss = 0.0415286
I0414 05:27:05.808073 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:27:05.808073 17564 solver.cpp:238]     Train net output #1: loss = 0.0415286 (* 1 = 0.0415286 loss)
I0414 05:27:05.808073 17564 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I0414 05:27:20.108072 17564 solver.cpp:219] Iteration 3700 (6.99314 iter/s, 14.2997s/100 iters), loss = 0.0895888
I0414 05:27:20.108072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:27:20.108072 17564 solver.cpp:238]     Train net output #1: loss = 0.0895888 (* 1 = 0.0895888 loss)
I0414 05:27:20.108072 17564 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I0414 05:27:34.417071 17564 solver.cpp:219] Iteration 3800 (6.98893 iter/s, 14.3083s/100 iters), loss = 0.0317906
I0414 05:27:34.417071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:27:34.417071 17564 solver.cpp:238]     Train net output #1: loss = 0.0317906 (* 1 = 0.0317906 loss)
I0414 05:27:34.417071 17564 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I0414 05:27:48.724071 17564 solver.cpp:219] Iteration 3900 (6.9898 iter/s, 14.3066s/100 iters), loss = 0.038072
I0414 05:27:48.724071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:27:48.724071 17564 solver.cpp:238]     Train net output #1: loss = 0.038072 (* 1 = 0.038072 loss)
I0414 05:27:48.724071 17564 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I0414 05:28:03.030072 17564 solver.cpp:219] Iteration 4000 (6.99021 iter/s, 14.3057s/100 iters), loss = 0.0152903
I0414 05:28:03.031072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:28:03.031072 17564 solver.cpp:238]     Train net output #1: loss = 0.0152903 (* 1 = 0.0152903 loss)
I0414 05:28:03.031072 17564 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I0414 05:28:17.341071 17564 solver.cpp:219] Iteration 4100 (6.98804 iter/s, 14.3102s/100 iters), loss = 0.0288033
I0414 05:28:17.341071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:28:17.341071 17564 solver.cpp:238]     Train net output #1: loss = 0.0288033 (* 1 = 0.0288033 loss)
I0414 05:28:17.341071 17564 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I0414 05:28:30.948072 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:28:31.519073 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_4200.caffemodel
I0414 05:28:31.661077 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_4200.solverstate
I0414 05:28:31.727074 17564 solver.cpp:331] Iteration 4200, Testing net (#0)
I0414 05:28:31.727074 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:28:35.659072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:28:35.821072 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9803
I0414 05:28:35.821072 17564 solver.cpp:398]     Test net output #1: loss = 0.0812468 (* 1 = 0.0812468 loss)
I0414 05:28:35.960072 17564 solver.cpp:219] Iteration 4200 (5.37109 iter/s, 18.6182s/100 iters), loss = 0.0469947
I0414 05:28:35.960072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:28:35.960072 17564 solver.cpp:238]     Train net output #1: loss = 0.0469947 (* 1 = 0.0469947 loss)
I0414 05:28:35.960072 17564 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I0414 05:28:50.267072 17564 solver.cpp:219] Iteration 4300 (6.99007 iter/s, 14.306s/100 iters), loss = 0.0465136
I0414 05:28:50.267072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:28:50.267072 17564 solver.cpp:238]     Train net output #1: loss = 0.0465136 (* 1 = 0.0465136 loss)
I0414 05:28:50.267072 17564 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I0414 05:29:04.582087 17564 solver.cpp:219] Iteration 4400 (6.98581 iter/s, 14.3147s/100 iters), loss = 0.0670004
I0414 05:29:04.582087 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:29:04.582087 17564 solver.cpp:238]     Train net output #1: loss = 0.0670004 (* 1 = 0.0670004 loss)
I0414 05:29:04.582087 17564 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I0414 05:29:18.884073 17564 solver.cpp:219] Iteration 4500 (6.99245 iter/s, 14.3011s/100 iters), loss = 0.038177
I0414 05:29:18.884073 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:29:18.884073 17564 solver.cpp:238]     Train net output #1: loss = 0.038177 (* 1 = 0.038177 loss)
I0414 05:29:18.884073 17564 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I0414 05:29:33.190071 17564 solver.cpp:219] Iteration 4600 (6.99 iter/s, 14.3062s/100 iters), loss = 0.0289374
I0414 05:29:33.191072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:29:33.191072 17564 solver.cpp:238]     Train net output #1: loss = 0.0289374 (* 1 = 0.0289374 loss)
I0414 05:29:33.191072 17564 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I0414 05:29:47.510074 17564 solver.cpp:219] Iteration 4700 (6.98402 iter/s, 14.3184s/100 iters), loss = 0.0160998
I0414 05:29:47.510074 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:29:47.510074 17564 solver.cpp:238]     Train net output #1: loss = 0.0160998 (* 1 = 0.0160998 loss)
I0414 05:29:47.510074 17564 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I0414 05:30:01.129901 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:30:01.709897 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_4800.caffemodel
I0414 05:30:01.858901 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_4800.solverstate
I0414 05:30:01.931900 17564 solver.cpp:331] Iteration 4800, Testing net (#0)
I0414 05:30:01.931900 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:30:05.871906 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:30:06.033896 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9619
I0414 05:30:06.033896 17564 solver.cpp:398]     Test net output #1: loss = 0.116922 (* 1 = 0.116922 loss)
I0414 05:30:06.174896 17564 solver.cpp:219] Iteration 4800 (5.35774 iter/s, 18.6646s/100 iters), loss = 0.0330616
I0414 05:30:06.174896 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:30:06.174896 17564 solver.cpp:238]     Train net output #1: loss = 0.0330616 (* 1 = 0.0330616 loss)
I0414 05:30:06.174896 17564 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I0414 05:30:20.470897 17564 solver.cpp:219] Iteration 4900 (6.99508 iter/s, 14.2958s/100 iters), loss = 0.138573
I0414 05:30:20.470897 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.94
I0414 05:30:20.470897 17564 solver.cpp:238]     Train net output #1: loss = 0.138573 (* 1 = 0.138573 loss)
I0414 05:30:20.470897 17564 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I0414 05:30:34.764896 17564 solver.cpp:219] Iteration 5000 (6.99643 iter/s, 14.293s/100 iters), loss = 0.0425644
I0414 05:30:34.764896 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:30:34.764896 17564 solver.cpp:238]     Train net output #1: loss = 0.0425644 (* 1 = 0.0425644 loss)
I0414 05:30:34.764896 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 5000, step = 1
I0414 05:30:34.764896 17564 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I0414 05:30:49.070896 17564 solver.cpp:219] Iteration 5100 (6.99025 iter/s, 14.3056s/100 iters), loss = 0.0651128
I0414 05:30:49.070896 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:30:49.070896 17564 solver.cpp:238]     Train net output #1: loss = 0.0651127 (* 1 = 0.0651127 loss)
I0414 05:30:49.070896 17564 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I0414 05:31:03.372896 17564 solver.cpp:219] Iteration 5200 (6.99239 iter/s, 14.3013s/100 iters), loss = 0.01065
I0414 05:31:03.372896 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:31:03.372896 17564 solver.cpp:238]     Train net output #1: loss = 0.01065 (* 1 = 0.01065 loss)
I0414 05:31:03.372896 17564 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I0414 05:31:17.677912 17564 solver.cpp:219] Iteration 5300 (6.991 iter/s, 14.3041s/100 iters), loss = 0.00713251
I0414 05:31:17.677912 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:31:17.677912 17564 solver.cpp:238]     Train net output #1: loss = 0.00713249 (* 1 = 0.00713249 loss)
I0414 05:31:17.677912 17564 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I0414 05:31:31.258898 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:31:31.827898 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_5400.caffemodel
I0414 05:31:31.965898 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_5400.solverstate
I0414 05:31:32.211402 17564 solver.cpp:331] Iteration 5400, Testing net (#0)
I0414 05:31:32.211402 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:31:36.143385 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:31:36.305399 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9962
I0414 05:31:36.305399 17564 solver.cpp:398]     Test net output #1: loss = 0.0172597 (* 1 = 0.0172597 loss)
I0414 05:31:36.445400 17564 solver.cpp:219] Iteration 5400 (5.32855 iter/s, 18.7668s/100 iters), loss = 0.0112194
I0414 05:31:36.445400 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:31:36.445400 17564 solver.cpp:238]     Train net output #1: loss = 0.0112194 (* 1 = 0.0112194 loss)
I0414 05:31:36.445400 17564 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I0414 05:31:50.736570 17564 solver.cpp:219] Iteration 5500 (6.99768 iter/s, 14.2905s/100 iters), loss = 0.0103922
I0414 05:31:50.736570 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:31:50.736570 17564 solver.cpp:238]     Train net output #1: loss = 0.0103921 (* 1 = 0.0103921 loss)
I0414 05:31:50.736570 17564 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I0414 05:32:05.039794 17564 solver.cpp:219] Iteration 5600 (6.99165 iter/s, 14.3028s/100 iters), loss = 0.043823
I0414 05:32:05.039794 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.97
I0414 05:32:05.039794 17564 solver.cpp:238]     Train net output #1: loss = 0.043823 (* 1 = 0.043823 loss)
I0414 05:32:05.039794 17564 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I0414 05:32:19.331794 17564 solver.cpp:219] Iteration 5700 (6.99704 iter/s, 14.2918s/100 iters), loss = 0.0385169
I0414 05:32:19.331794 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:32:19.331794 17564 solver.cpp:238]     Train net output #1: loss = 0.0385169 (* 1 = 0.0385169 loss)
I0414 05:32:19.331794 17564 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I0414 05:32:33.626794 17564 solver.cpp:219] Iteration 5800 (6.99598 iter/s, 14.2939s/100 iters), loss = 0.00639744
I0414 05:32:33.626794 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:32:33.626794 17564 solver.cpp:238]     Train net output #1: loss = 0.00639744 (* 1 = 0.00639744 loss)
I0414 05:32:33.626794 17564 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I0414 05:32:47.922793 17564 solver.cpp:219] Iteration 5900 (6.99486 iter/s, 14.2962s/100 iters), loss = 0.00617663
I0414 05:32:47.922793 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:32:47.922793 17564 solver.cpp:238]     Train net output #1: loss = 0.00617662 (* 1 = 0.00617662 loss)
I0414 05:32:47.922793 17564 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I0414 05:33:01.506795 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:33:02.077796 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_6000.caffemodel
I0414 05:33:02.226814 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_6000.solverstate
I0414 05:33:02.294797 17564 solver.cpp:331] Iteration 6000, Testing net (#0)
I0414 05:33:02.295796 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:33:06.229795 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:33:06.391794 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9965
I0414 05:33:06.391794 17564 solver.cpp:398]     Test net output #1: loss = 0.0162427 (* 1 = 0.0162427 loss)
I0414 05:33:06.531795 17564 solver.cpp:219] Iteration 6000 (5.37392 iter/s, 18.6084s/100 iters), loss = 0.00949958
I0414 05:33:06.531795 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:33:06.531795 17564 solver.cpp:238]     Train net output #1: loss = 0.00949958 (* 1 = 0.00949958 loss)
I0414 05:33:06.531795 17564 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I0414 05:33:20.840795 17564 solver.cpp:219] Iteration 6100 (6.98903 iter/s, 14.3081s/100 iters), loss = 0.00698394
I0414 05:33:20.840795 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:33:20.840795 17564 solver.cpp:238]     Train net output #1: loss = 0.00698393 (* 1 = 0.00698393 loss)
I0414 05:33:20.840795 17564 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I0414 05:33:35.148334 17564 solver.cpp:219] Iteration 6200 (6.98982 iter/s, 14.3065s/100 iters), loss = 0.0278121
I0414 05:33:35.148334 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:33:35.148334 17564 solver.cpp:238]     Train net output #1: loss = 0.0278121 (* 1 = 0.0278121 loss)
I0414 05:33:35.148334 17564 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I0414 05:33:49.419345 17564 solver.cpp:219] Iteration 6300 (7.00716 iter/s, 14.2711s/100 iters), loss = 0.0515772
I0414 05:33:49.419345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.98
I0414 05:33:49.419345 17564 solver.cpp:238]     Train net output #1: loss = 0.0515772 (* 1 = 0.0515772 loss)
I0414 05:33:49.419345 17564 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I0414 05:34:03.699347 17564 solver.cpp:219] Iteration 6400 (7.00308 iter/s, 14.2794s/100 iters), loss = 0.00927763
I0414 05:34:03.699347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:34:03.699347 17564 solver.cpp:238]     Train net output #1: loss = 0.0092776 (* 1 = 0.0092776 loss)
I0414 05:34:03.699347 17564 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I0414 05:34:17.973346 17564 solver.cpp:219] Iteration 6500 (7.00627 iter/s, 14.2729s/100 iters), loss = 0.0105858
I0414 05:34:17.973346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:34:17.973346 17564 solver.cpp:238]     Train net output #1: loss = 0.0105858 (* 1 = 0.0105858 loss)
I0414 05:34:17.973346 17564 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I0414 05:34:31.541348 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:34:32.112346 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_6600.caffemodel
I0414 05:34:32.250346 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_6600.solverstate
I0414 05:34:32.315346 17564 solver.cpp:331] Iteration 6600, Testing net (#0)
I0414 05:34:32.315346 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:34:36.236347 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:34:36.398346 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9965
I0414 05:34:36.398346 17564 solver.cpp:398]     Test net output #1: loss = 0.0152241 (* 1 = 0.0152241 loss)
I0414 05:34:36.537359 17564 solver.cpp:219] Iteration 6600 (5.38684 iter/s, 18.5638s/100 iters), loss = 0.0063002
I0414 05:34:36.537359 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:34:36.537359 17564 solver.cpp:238]     Train net output #1: loss = 0.00630017 (* 1 = 0.00630017 loss)
I0414 05:34:36.537359 17564 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I0414 05:34:50.809346 17564 solver.cpp:219] Iteration 6700 (7.00694 iter/s, 14.2716s/100 iters), loss = 0.0222044
I0414 05:34:50.809346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:34:50.809346 17564 solver.cpp:238]     Train net output #1: loss = 0.0222044 (* 1 = 0.0222044 loss)
I0414 05:34:50.810348 17564 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I0414 05:35:05.099346 17564 solver.cpp:219] Iteration 6800 (6.9983 iter/s, 14.2892s/100 iters), loss = 0.0146059
I0414 05:35:05.099346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:35:05.099346 17564 solver.cpp:238]     Train net output #1: loss = 0.0146059 (* 1 = 0.0146059 loss)
I0414 05:35:05.099346 17564 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I0414 05:35:19.379345 17564 solver.cpp:219] Iteration 6900 (7.00337 iter/s, 14.2788s/100 iters), loss = 0.0364597
I0414 05:35:19.379345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:35:19.379345 17564 solver.cpp:238]     Train net output #1: loss = 0.0364597 (* 1 = 0.0364597 loss)
I0414 05:35:19.379345 17564 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I0414 05:35:33.644346 17564 solver.cpp:219] Iteration 7000 (7.01012 iter/s, 14.2651s/100 iters), loss = 0.0104412
I0414 05:35:33.644346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:35:33.644346 17564 solver.cpp:238]     Train net output #1: loss = 0.0104411 (* 1 = 0.0104411 loss)
I0414 05:35:33.644346 17564 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I0414 05:35:47.916345 17564 solver.cpp:219] Iteration 7100 (7.00689 iter/s, 14.2717s/100 iters), loss = 0.0134948
I0414 05:35:47.916345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:35:47.916345 17564 solver.cpp:238]     Train net output #1: loss = 0.0134948 (* 1 = 0.0134948 loss)
I0414 05:35:47.916345 17564 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I0414 05:36:01.486347 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:36:02.056350 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_7200.caffemodel
I0414 05:36:02.202368 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_7200.solverstate
I0414 05:36:02.270349 17564 solver.cpp:331] Iteration 7200, Testing net (#0)
I0414 05:36:02.270349 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:36:06.194349 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:36:06.356369 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9969
I0414 05:36:06.356369 17564 solver.cpp:398]     Test net output #1: loss = 0.015703 (* 1 = 0.015703 loss)
I0414 05:36:06.495347 17564 solver.cpp:219] Iteration 7200 (5.38273 iter/s, 18.5779s/100 iters), loss = 0.0103835
I0414 05:36:06.495347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:36:06.495347 17564 solver.cpp:238]     Train net output #1: loss = 0.0103835 (* 1 = 0.0103835 loss)
I0414 05:36:06.495347 17564 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I0414 05:36:20.753346 17564 solver.cpp:219] Iteration 7300 (7.01412 iter/s, 14.257s/100 iters), loss = 0.00900093
I0414 05:36:20.753346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:36:20.753346 17564 solver.cpp:238]     Train net output #1: loss = 0.00900092 (* 1 = 0.00900092 loss)
I0414 05:36:20.753346 17564 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I0414 05:36:35.016346 17564 solver.cpp:219] Iteration 7400 (7.01124 iter/s, 14.2628s/100 iters), loss = 0.0221522
I0414 05:36:35.016346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:36:35.016346 17564 solver.cpp:238]     Train net output #1: loss = 0.0221522 (* 1 = 0.0221522 loss)
I0414 05:36:35.016346 17564 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I0414 05:36:49.281345 17564 solver.cpp:219] Iteration 7500 (7.01019 iter/s, 14.2649s/100 iters), loss = 0.0402203
I0414 05:36:49.281345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:36:49.281345 17564 solver.cpp:238]     Train net output #1: loss = 0.0402203 (* 1 = 0.0402203 loss)
I0414 05:36:49.282346 17564 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I0414 05:37:03.562366 17564 solver.cpp:219] Iteration 7600 (7.00277 iter/s, 14.2801s/100 iters), loss = 0.0050629
I0414 05:37:03.562366 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:37:03.562366 17564 solver.cpp:238]     Train net output #1: loss = 0.00506288 (* 1 = 0.00506288 loss)
I0414 05:37:03.562366 17564 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I0414 05:37:17.813345 17564 solver.cpp:219] Iteration 7700 (7.01745 iter/s, 14.2502s/100 iters), loss = 0.0104197
I0414 05:37:17.813345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:37:17.813345 17564 solver.cpp:238]     Train net output #1: loss = 0.0104197 (* 1 = 0.0104197 loss)
I0414 05:37:17.813345 17564 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I0414 05:37:31.383347 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:37:31.952347 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_7800.caffemodel
I0414 05:37:32.091353 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_7800.solverstate
I0414 05:37:32.155346 17564 solver.cpp:331] Iteration 7800, Testing net (#0)
I0414 05:37:32.155346 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:37:36.074347 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:37:36.237346 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9965
I0414 05:37:36.237346 17564 solver.cpp:398]     Test net output #1: loss = 0.0154482 (* 1 = 0.0154482 loss)
I0414 05:37:36.376345 17564 solver.cpp:219] Iteration 7800 (5.38726 iter/s, 18.5623s/100 iters), loss = 0.00881345
I0414 05:37:36.376345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:37:36.376345 17564 solver.cpp:238]     Train net output #1: loss = 0.00881344 (* 1 = 0.00881344 loss)
I0414 05:37:36.376345 17564 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I0414 05:37:50.651345 17564 solver.cpp:219] Iteration 7900 (7.00545 iter/s, 14.2746s/100 iters), loss = 0.00954294
I0414 05:37:50.651345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:37:50.651345 17564 solver.cpp:238]     Train net output #1: loss = 0.00954292 (* 1 = 0.00954292 loss)
I0414 05:37:50.651345 17564 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I0414 05:38:04.932346 17564 solver.cpp:219] Iteration 8000 (7.00259 iter/s, 14.2804s/100 iters), loss = 0.0107141
I0414 05:38:04.932346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:38:04.932346 17564 solver.cpp:238]     Train net output #1: loss = 0.0107141 (* 1 = 0.0107141 loss)
I0414 05:38:04.932346 17564 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I0414 05:38:19.211346 17564 solver.cpp:219] Iteration 8100 (7.00335 iter/s, 14.2789s/100 iters), loss = 0.0238474
I0414 05:38:19.211346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:38:19.211346 17564 solver.cpp:238]     Train net output #1: loss = 0.0238474 (* 1 = 0.0238474 loss)
I0414 05:38:19.211346 17564 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I0414 05:38:33.482347 17564 solver.cpp:219] Iteration 8200 (7.00759 iter/s, 14.2702s/100 iters), loss = 0.00514892
I0414 05:38:33.482347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:38:33.482347 17564 solver.cpp:238]     Train net output #1: loss = 0.0051489 (* 1 = 0.0051489 loss)
I0414 05:38:33.482347 17564 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I0414 05:38:47.757346 17564 solver.cpp:219] Iteration 8300 (7.00564 iter/s, 14.2742s/100 iters), loss = 0.0078234
I0414 05:38:47.757346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:38:47.757346 17564 solver.cpp:238]     Train net output #1: loss = 0.00782338 (* 1 = 0.00782338 loss)
I0414 05:38:47.757346 17564 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I0414 05:39:01.324347 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:39:01.894348 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_8400.caffemodel
I0414 05:39:02.051357 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_8400.solverstate
I0414 05:39:02.119346 17564 solver.cpp:331] Iteration 8400, Testing net (#0)
I0414 05:39:02.119346 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:39:06.044348 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:39:06.206346 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9966
I0414 05:39:06.206346 17564 solver.cpp:398]     Test net output #1: loss = 0.0149111 (* 1 = 0.0149111 loss)
I0414 05:39:06.345345 17564 solver.cpp:219] Iteration 8400 (5.37979 iter/s, 18.5881s/100 iters), loss = 0.00602469
I0414 05:39:06.346346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:39:06.346346 17564 solver.cpp:238]     Train net output #1: loss = 0.00602467 (* 1 = 0.00602467 loss)
I0414 05:39:06.346346 17564 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I0414 05:39:20.610347 17564 solver.cpp:219] Iteration 8500 (7.01049 iter/s, 14.2643s/100 iters), loss = 0.00632977
I0414 05:39:20.610347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:39:20.610347 17564 solver.cpp:238]     Train net output #1: loss = 0.00632975 (* 1 = 0.00632975 loss)
I0414 05:39:20.610347 17564 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I0414 05:39:34.872346 17564 solver.cpp:219] Iteration 8600 (7.01191 iter/s, 14.2614s/100 iters), loss = 0.0161178
I0414 05:39:34.872346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:39:34.872346 17564 solver.cpp:238]     Train net output #1: loss = 0.0161178 (* 1 = 0.0161178 loss)
I0414 05:39:34.872346 17564 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I0414 05:39:49.146347 17564 solver.cpp:219] Iteration 8700 (7.00635 iter/s, 14.2728s/100 iters), loss = 0.0155724
I0414 05:39:49.146347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:39:49.146347 17564 solver.cpp:238]     Train net output #1: loss = 0.0155724 (* 1 = 0.0155724 loss)
I0414 05:39:49.146347 17564 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I0414 05:40:03.430346 17564 solver.cpp:219] Iteration 8800 (7.00114 iter/s, 14.2834s/100 iters), loss = 0.00490422
I0414 05:40:03.430346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:40:03.430346 17564 solver.cpp:238]     Train net output #1: loss = 0.00490421 (* 1 = 0.00490421 loss)
I0414 05:40:03.430346 17564 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I0414 05:40:17.700345 17564 solver.cpp:219] Iteration 8900 (7.00804 iter/s, 14.2693s/100 iters), loss = 0.00505398
I0414 05:40:17.700345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:40:17.700345 17564 solver.cpp:238]     Train net output #1: loss = 0.00505397 (* 1 = 0.00505397 loss)
I0414 05:40:17.700345 17564 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I0414 05:40:31.254346 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:40:31.823346 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_9000.caffemodel
I0414 05:40:31.961346 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_9000.solverstate
I0414 05:40:32.028347 17564 solver.cpp:331] Iteration 9000, Testing net (#0)
I0414 05:40:32.028347 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:40:35.948348 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:40:36.110348 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9967
I0414 05:40:36.110348 17564 solver.cpp:398]     Test net output #1: loss = 0.0156723 (* 1 = 0.0156723 loss)
I0414 05:40:36.250345 17564 solver.cpp:219] Iteration 9000 (5.39096 iter/s, 18.5496s/100 iters), loss = 0.00766605
I0414 05:40:36.250345 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:40:36.250345 17564 solver.cpp:238]     Train net output #1: loss = 0.00766606 (* 1 = 0.00766606 loss)
I0414 05:40:36.250345 17564 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I0414 05:40:50.521347 17564 solver.cpp:219] Iteration 9100 (7.00724 iter/s, 14.2709s/100 iters), loss = 0.0101375
I0414 05:40:50.521347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:40:50.521347 17564 solver.cpp:238]     Train net output #1: loss = 0.0101376 (* 1 = 0.0101376 loss)
I0414 05:40:50.521347 17564 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I0414 05:41:04.791347 17564 solver.cpp:219] Iteration 9200 (7.00814 iter/s, 14.2691s/100 iters), loss = 0.0198153
I0414 05:41:04.791347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:41:04.791347 17564 solver.cpp:238]     Train net output #1: loss = 0.0198153 (* 1 = 0.0198153 loss)
I0414 05:41:04.791347 17564 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I0414 05:41:19.042346 17564 solver.cpp:219] Iteration 9300 (7.01741 iter/s, 14.2503s/100 iters), loss = 0.0312551
I0414 05:41:19.042346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:41:19.042346 17564 solver.cpp:238]     Train net output #1: loss = 0.0312551 (* 1 = 0.0312551 loss)
I0414 05:41:19.042346 17564 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I0414 05:41:33.290346 17564 solver.cpp:219] Iteration 9400 (7.01869 iter/s, 14.2477s/100 iters), loss = 0.00843315
I0414 05:41:33.290346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:41:33.290346 17564 solver.cpp:238]     Train net output #1: loss = 0.00843317 (* 1 = 0.00843317 loss)
I0414 05:41:33.290346 17564 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I0414 05:41:47.537346 17564 solver.cpp:219] Iteration 9500 (7.01949 iter/s, 14.2461s/100 iters), loss = 0.00478595
I0414 05:41:47.537346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:41:47.537346 17564 solver.cpp:238]     Train net output #1: loss = 0.00478596 (* 1 = 0.00478596 loss)
I0414 05:41:47.537346 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 9500, step = 2
I0414 05:41:47.537346 17564 sgd_solver.cpp:105] Iteration 9500, lr = 0.001
I0414 05:42:01.097347 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:42:01.667347 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_9600.caffemodel
I0414 05:42:01.813346 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_9600.solverstate
I0414 05:42:01.887346 17564 solver.cpp:331] Iteration 9600, Testing net (#0)
I0414 05:42:01.887346 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:42:05.819347 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:42:05.981346 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9974
I0414 05:42:05.981346 17564 solver.cpp:398]     Test net output #1: loss = 0.0143711 (* 1 = 0.0143711 loss)
I0414 05:42:06.121346 17564 solver.cpp:219] Iteration 9600 (5.38107 iter/s, 18.5837s/100 iters), loss = 0.00818539
I0414 05:42:06.121346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:42:06.121346 17564 solver.cpp:238]     Train net output #1: loss = 0.00818541 (* 1 = 0.00818541 loss)
I0414 05:42:06.121346 17564 sgd_solver.cpp:105] Iteration 9600, lr = 0.001
I0414 05:42:20.399346 17564 solver.cpp:219] Iteration 9700 (7.0039 iter/s, 14.2778s/100 iters), loss = 0.0151113
I0414 05:42:20.399346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:42:20.399346 17564 solver.cpp:238]     Train net output #1: loss = 0.0151113 (* 1 = 0.0151113 loss)
I0414 05:42:20.399346 17564 sgd_solver.cpp:105] Iteration 9700, lr = 0.001
I0414 05:42:34.659346 17564 solver.cpp:219] Iteration 9800 (7.01285 iter/s, 14.2595s/100 iters), loss = 0.0164576
I0414 05:42:34.659346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:42:34.659346 17564 solver.cpp:238]     Train net output #1: loss = 0.0164577 (* 1 = 0.0164577 loss)
I0414 05:42:34.659346 17564 sgd_solver.cpp:105] Iteration 9800, lr = 0.001
I0414 05:42:48.928346 17564 solver.cpp:219] Iteration 9900 (7.00842 iter/s, 14.2685s/100 iters), loss = 0.012501
I0414 05:42:48.929347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:42:48.929347 17564 solver.cpp:238]     Train net output #1: loss = 0.012501 (* 1 = 0.012501 loss)
I0414 05:42:48.929347 17564 sgd_solver.cpp:105] Iteration 9900, lr = 0.001
I0414 05:43:03.195350 17564 solver.cpp:219] Iteration 10000 (7.00987 iter/s, 14.2656s/100 iters), loss = 0.00581546
I0414 05:43:03.195350 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:43:03.195350 17564 solver.cpp:238]     Train net output #1: loss = 0.00581548 (* 1 = 0.00581548 loss)
I0414 05:43:03.195350 17564 sgd_solver.cpp:105] Iteration 10000, lr = 0.001
I0414 05:43:17.454345 17564 solver.cpp:219] Iteration 10100 (7.01302 iter/s, 14.2592s/100 iters), loss = 0.00565646
I0414 05:43:17.455346 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:43:17.455346 17564 solver.cpp:238]     Train net output #1: loss = 0.00565648 (* 1 = 0.00565648 loss)
I0414 05:43:17.455346 17564 sgd_solver.cpp:105] Iteration 10100, lr = 0.001
I0414 05:43:31.000350 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:43:31.569347 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_10200.caffemodel
I0414 05:43:31.707346 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_10200.solverstate
I0414 05:43:31.774346 17564 solver.cpp:331] Iteration 10200, Testing net (#0)
I0414 05:43:31.774346 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:43:35.694349 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:43:35.856348 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9972
I0414 05:43:35.856348 17564 solver.cpp:398]     Test net output #1: loss = 0.0142421 (* 1 = 0.0142421 loss)
I0414 05:43:35.995347 17564 solver.cpp:219] Iteration 10200 (5.3939 iter/s, 18.5395s/100 iters), loss = 0.0062841
I0414 05:43:35.995347 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:43:35.995347 17564 solver.cpp:238]     Train net output #1: loss = 0.00628413 (* 1 = 0.00628413 loss)
I0414 05:43:35.995347 17564 sgd_solver.cpp:105] Iteration 10200, lr = 0.001
I0414 05:43:50.271993 17564 solver.cpp:219] Iteration 10300 (7.0045 iter/s, 14.2765s/100 iters), loss = 0.00707951
I0414 05:43:50.271993 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:43:50.271993 17564 solver.cpp:238]     Train net output #1: loss = 0.00707954 (* 1 = 0.00707954 loss)
I0414 05:43:50.271993 17564 sgd_solver.cpp:105] Iteration 10300, lr = 0.001
I0414 05:44:04.545984 17564 solver.cpp:219] Iteration 10400 (7.00628 iter/s, 14.2729s/100 iters), loss = 0.0208732
I0414 05:44:04.545984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:44:04.545984 17564 solver.cpp:238]     Train net output #1: loss = 0.0208732 (* 1 = 0.0208732 loss)
I0414 05:44:04.545984 17564 sgd_solver.cpp:105] Iteration 10400, lr = 0.001
I0414 05:44:18.814970 17564 solver.cpp:219] Iteration 10500 (7.00829 iter/s, 14.2688s/100 iters), loss = 0.0288908
I0414 05:44:18.814970 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:44:18.814970 17564 solver.cpp:238]     Train net output #1: loss = 0.0288908 (* 1 = 0.0288908 loss)
I0414 05:44:18.814970 17564 sgd_solver.cpp:105] Iteration 10500, lr = 0.001
I0414 05:44:33.077970 17564 solver.cpp:219] Iteration 10600 (7.01168 iter/s, 14.2619s/100 iters), loss = 0.010435
I0414 05:44:33.077970 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:44:33.077970 17564 solver.cpp:238]     Train net output #1: loss = 0.010435 (* 1 = 0.010435 loss)
I0414 05:44:33.077970 17564 sgd_solver.cpp:105] Iteration 10600, lr = 0.001
I0414 05:44:47.332969 17564 solver.cpp:219] Iteration 10700 (7.01511 iter/s, 14.2549s/100 iters), loss = 0.0067652
I0414 05:44:47.332969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:44:47.332969 17564 solver.cpp:238]     Train net output #1: loss = 0.00676523 (* 1 = 0.00676523 loss)
I0414 05:44:47.332969 17564 sgd_solver.cpp:105] Iteration 10700, lr = 0.001
I0414 05:45:00.879971 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:45:01.451969 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_10800.caffemodel
I0414 05:45:01.595970 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_10800.solverstate
I0414 05:45:01.662971 17564 solver.cpp:331] Iteration 10800, Testing net (#0)
I0414 05:45:01.662971 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:45:05.593971 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:45:05.755970 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 05:45:05.755970 17564 solver.cpp:398]     Test net output #1: loss = 0.0142211 (* 1 = 0.0142211 loss)
I0414 05:45:05.894968 17564 solver.cpp:219] Iteration 10800 (5.3875 iter/s, 18.5615s/100 iters), loss = 0.00616966
I0414 05:45:05.894968 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:45:05.894968 17564 solver.cpp:238]     Train net output #1: loss = 0.00616969 (* 1 = 0.00616969 loss)
I0414 05:45:05.894968 17564 sgd_solver.cpp:105] Iteration 10800, lr = 0.001
I0414 05:45:20.165969 17564 solver.cpp:219] Iteration 10900 (7.00737 iter/s, 14.2707s/100 iters), loss = 0.00769474
I0414 05:45:20.165969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:45:20.165969 17564 solver.cpp:238]     Train net output #1: loss = 0.00769476 (* 1 = 0.00769476 loss)
I0414 05:45:20.165969 17564 sgd_solver.cpp:105] Iteration 10900, lr = 0.001
I0414 05:45:34.436969 17564 solver.cpp:219] Iteration 11000 (7.00761 iter/s, 14.2702s/100 iters), loss = 0.017923
I0414 05:45:34.436969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:45:34.436969 17564 solver.cpp:238]     Train net output #1: loss = 0.017923 (* 1 = 0.017923 loss)
I0414 05:45:34.436969 17564 sgd_solver.cpp:105] Iteration 11000, lr = 0.001
I0414 05:45:48.730969 17564 solver.cpp:219] Iteration 11100 (6.99598 iter/s, 14.2939s/100 iters), loss = 0.0148339
I0414 05:45:48.731971 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:45:48.731971 17564 solver.cpp:238]     Train net output #1: loss = 0.0148339 (* 1 = 0.0148339 loss)
I0414 05:45:48.731971 17564 sgd_solver.cpp:105] Iteration 11100, lr = 0.001
I0414 05:46:03.014969 17564 solver.cpp:219] Iteration 11200 (7.00159 iter/s, 14.2825s/100 iters), loss = 0.00464109
I0414 05:46:03.014969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:46:03.014969 17564 solver.cpp:238]     Train net output #1: loss = 0.00464112 (* 1 = 0.00464112 loss)
I0414 05:46:03.014969 17564 sgd_solver.cpp:105] Iteration 11200, lr = 0.001
I0414 05:46:17.293968 17564 solver.cpp:219] Iteration 11300 (7.00334 iter/s, 14.2789s/100 iters), loss = 0.00564297
I0414 05:46:17.293968 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:46:17.293968 17564 solver.cpp:238]     Train net output #1: loss = 0.00564299 (* 1 = 0.00564299 loss)
I0414 05:46:17.293968 17564 sgd_solver.cpp:105] Iteration 11300, lr = 0.001
I0414 05:46:30.855970 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:46:31.423969 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_11400.caffemodel
I0414 05:46:31.564973 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_11400.solverstate
I0414 05:46:31.630970 17564 solver.cpp:331] Iteration 11400, Testing net (#0)
I0414 05:46:31.630970 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:46:35.551970 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:46:35.713979 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9968
I0414 05:46:35.713979 17564 solver.cpp:398]     Test net output #1: loss = 0.0141201 (* 1 = 0.0141201 loss)
I0414 05:46:35.852969 17564 solver.cpp:219] Iteration 11400 (5.38842 iter/s, 18.5583s/100 iters), loss = 0.00977851
I0414 05:46:35.852969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:46:35.852969 17564 solver.cpp:238]     Train net output #1: loss = 0.00977853 (* 1 = 0.00977853 loss)
I0414 05:46:35.852969 17564 sgd_solver.cpp:105] Iteration 11400, lr = 0.001
I0414 05:46:50.114969 17564 solver.cpp:219] Iteration 11500 (7.01206 iter/s, 14.2612s/100 iters), loss = 0.00640331
I0414 05:46:50.114969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:46:50.114969 17564 solver.cpp:238]     Train net output #1: loss = 0.00640334 (* 1 = 0.00640334 loss)
I0414 05:46:50.114969 17564 sgd_solver.cpp:105] Iteration 11500, lr = 0.001
I0414 05:47:04.385969 17564 solver.cpp:219] Iteration 11600 (7.00718 iter/s, 14.2711s/100 iters), loss = 0.00937082
I0414 05:47:04.385969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:47:04.385969 17564 solver.cpp:238]     Train net output #1: loss = 0.00937085 (* 1 = 0.00937085 loss)
I0414 05:47:04.385969 17564 sgd_solver.cpp:105] Iteration 11600, lr = 0.001
I0414 05:47:18.660969 17564 solver.cpp:219] Iteration 11700 (7.00551 iter/s, 14.2745s/100 iters), loss = 0.0161963
I0414 05:47:18.660969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:47:18.660969 17564 solver.cpp:238]     Train net output #1: loss = 0.0161963 (* 1 = 0.0161963 loss)
I0414 05:47:18.660969 17564 sgd_solver.cpp:105] Iteration 11700, lr = 0.001
I0414 05:47:32.934969 17564 solver.cpp:219] Iteration 11800 (7.00622 iter/s, 14.273s/100 iters), loss = 0.00527909
I0414 05:47:32.934969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:47:32.934969 17564 solver.cpp:238]     Train net output #1: loss = 0.00527913 (* 1 = 0.00527913 loss)
I0414 05:47:32.934969 17564 sgd_solver.cpp:105] Iteration 11800, lr = 0.001
I0414 05:47:47.212970 17564 solver.cpp:219] Iteration 11900 (7.00401 iter/s, 14.2775s/100 iters), loss = 0.00560971
I0414 05:47:47.212970 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:47:47.212970 17564 solver.cpp:238]     Train net output #1: loss = 0.00560974 (* 1 = 0.00560974 loss)
I0414 05:47:47.212970 17564 sgd_solver.cpp:105] Iteration 11900, lr = 0.001
I0414 05:48:00.781970 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:48:01.350970 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_12000.caffemodel
I0414 05:48:01.495970 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_12000.solverstate
I0414 05:48:01.564972 17564 solver.cpp:331] Iteration 12000, Testing net (#0)
I0414 05:48:01.564972 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:48:05.495980 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:48:05.657969 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9973
I0414 05:48:05.657969 17564 solver.cpp:398]     Test net output #1: loss = 0.0141438 (* 1 = 0.0141438 loss)
I0414 05:48:05.796969 17564 solver.cpp:219] Iteration 12000 (5.38116 iter/s, 18.5833s/100 iters), loss = 0.00852812
I0414 05:48:05.796969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:48:05.796969 17564 solver.cpp:238]     Train net output #1: loss = 0.00852814 (* 1 = 0.00852814 loss)
I0414 05:48:05.796969 17564 sgd_solver.cpp:105] Iteration 12000, lr = 0.001
I0414 05:48:20.076970 17564 solver.cpp:219] Iteration 12100 (7.0028 iter/s, 14.28s/100 iters), loss = 0.0196166
I0414 05:48:20.076970 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:48:20.076970 17564 solver.cpp:238]     Train net output #1: loss = 0.0196166 (* 1 = 0.0196166 loss)
I0414 05:48:20.076970 17564 sgd_solver.cpp:105] Iteration 12100, lr = 0.001
I0414 05:48:34.340968 17564 solver.cpp:219] Iteration 12200 (7.01094 iter/s, 14.2634s/100 iters), loss = 0.0254725
I0414 05:48:34.340968 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:48:34.340968 17564 solver.cpp:238]     Train net output #1: loss = 0.0254725 (* 1 = 0.0254725 loss)
I0414 05:48:34.340968 17564 sgd_solver.cpp:105] Iteration 12200, lr = 0.001
I0414 05:48:48.603968 17564 solver.cpp:219] Iteration 12300 (7.0116 iter/s, 14.2621s/100 iters), loss = 0.00835144
I0414 05:48:48.603968 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:48:48.603968 17564 solver.cpp:238]     Train net output #1: loss = 0.00835147 (* 1 = 0.00835147 loss)
I0414 05:48:48.603968 17564 sgd_solver.cpp:105] Iteration 12300, lr = 0.001
I0414 05:49:02.875969 17564 solver.cpp:219] Iteration 12400 (7.00699 iter/s, 14.2715s/100 iters), loss = 0.00298932
I0414 05:49:02.875969 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:49:02.875969 17564 solver.cpp:238]     Train net output #1: loss = 0.00298935 (* 1 = 0.00298935 loss)
I0414 05:49:02.875969 17564 sgd_solver.cpp:105] Iteration 12400, lr = 0.001
I0414 05:49:17.149070 17564 solver.cpp:219] Iteration 12500 (7.00634 iter/s, 14.2728s/100 iters), loss = 0.00515406
I0414 05:49:17.149070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:49:17.149070 17564 solver.cpp:238]     Train net output #1: loss = 0.00515408 (* 1 = 0.00515408 loss)
I0414 05:49:17.149070 17564 sgd_solver.cpp:105] Iteration 12500, lr = 0.001
I0414 05:49:30.699071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:49:31.268070 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_12600.caffemodel
I0414 05:49:31.407070 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_12600.solverstate
I0414 05:49:31.472070 17564 solver.cpp:331] Iteration 12600, Testing net (#0)
I0414 05:49:31.472070 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:49:35.389071 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:49:35.551070 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 05:49:35.551070 17564 solver.cpp:398]     Test net output #1: loss = 0.0140203 (* 1 = 0.0140203 loss)
I0414 05:49:35.691069 17564 solver.cpp:219] Iteration 12600 (5.39359 iter/s, 18.5405s/100 iters), loss = 0.0045433
I0414 05:49:35.691069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:49:35.691069 17564 solver.cpp:238]     Train net output #1: loss = 0.00454332 (* 1 = 0.00454332 loss)
I0414 05:49:35.691069 17564 sgd_solver.cpp:105] Iteration 12600, lr = 0.001
I0414 05:49:49.965070 17564 solver.cpp:219] Iteration 12700 (7.00588 iter/s, 14.2737s/100 iters), loss = 0.00910212
I0414 05:49:49.965070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:49:49.965070 17564 solver.cpp:238]     Train net output #1: loss = 0.00910214 (* 1 = 0.00910214 loss)
I0414 05:49:49.965070 17564 sgd_solver.cpp:105] Iteration 12700, lr = 0.001
I0414 05:50:04.247071 17564 solver.cpp:219] Iteration 12800 (7.00215 iter/s, 14.2813s/100 iters), loss = 0.0181392
I0414 05:50:04.247071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:50:04.247071 17564 solver.cpp:238]     Train net output #1: loss = 0.0181392 (* 1 = 0.0181392 loss)
I0414 05:50:04.247071 17564 sgd_solver.cpp:105] Iteration 12800, lr = 0.001
I0414 05:50:18.513070 17564 solver.cpp:219] Iteration 12900 (7.00977 iter/s, 14.2658s/100 iters), loss = 0.00976716
I0414 05:50:18.513070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:50:18.513070 17564 solver.cpp:238]     Train net output #1: loss = 0.00976718 (* 1 = 0.00976718 loss)
I0414 05:50:18.513070 17564 sgd_solver.cpp:105] Iteration 12900, lr = 0.001
I0414 05:50:32.775070 17564 solver.cpp:219] Iteration 13000 (7.01214 iter/s, 14.261s/100 iters), loss = 0.00483599
I0414 05:50:32.775070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:50:32.775070 17564 solver.cpp:238]     Train net output #1: loss = 0.00483601 (* 1 = 0.00483601 loss)
I0414 05:50:32.775070 17564 sgd_solver.cpp:105] Iteration 13000, lr = 0.001
I0414 05:50:47.050070 17564 solver.cpp:219] Iteration 13100 (7.00554 iter/s, 14.2744s/100 iters), loss = 0.00865972
I0414 05:50:47.050070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:50:47.050070 17564 solver.cpp:238]     Train net output #1: loss = 0.00865974 (* 1 = 0.00865974 loss)
I0414 05:50:47.050070 17564 sgd_solver.cpp:105] Iteration 13100, lr = 0.001
I0414 05:51:00.619071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:51:01.187072 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_13200.caffemodel
I0414 05:51:01.334074 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_13200.solverstate
I0414 05:51:01.405072 17564 solver.cpp:331] Iteration 13200, Testing net (#0)
I0414 05:51:01.405072 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:51:05.335072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:51:05.497071 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 05:51:05.497071 17564 solver.cpp:398]     Test net output #1: loss = 0.0140948 (* 1 = 0.0140948 loss)
I0414 05:51:05.635071 17564 solver.cpp:219] Iteration 13200 (5.38074 iter/s, 18.5848s/100 iters), loss = 0.00775094
I0414 05:51:05.635071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:51:05.635071 17564 solver.cpp:238]     Train net output #1: loss = 0.00775097 (* 1 = 0.00775097 loss)
I0414 05:51:05.635071 17564 sgd_solver.cpp:105] Iteration 13200, lr = 0.001
I0414 05:51:19.895069 17564 solver.cpp:219] Iteration 13300 (7.01315 iter/s, 14.2589s/100 iters), loss = 0.00772889
I0414 05:51:19.895069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:51:19.895069 17564 solver.cpp:238]     Train net output #1: loss = 0.00772892 (* 1 = 0.00772892 loss)
I0414 05:51:19.895069 17564 sgd_solver.cpp:105] Iteration 13300, lr = 0.001
I0414 05:51:34.156069 17564 solver.cpp:219] Iteration 13400 (7.0123 iter/s, 14.2606s/100 iters), loss = 0.0125161
I0414 05:51:34.156069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:51:34.156069 17564 solver.cpp:238]     Train net output #1: loss = 0.0125161 (* 1 = 0.0125161 loss)
I0414 05:51:34.156069 17564 sgd_solver.cpp:105] Iteration 13400, lr = 0.001
I0414 05:51:48.425071 17564 solver.cpp:219] Iteration 13500 (7.00856 iter/s, 14.2683s/100 iters), loss = 0.00994396
I0414 05:51:48.425071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:51:48.425071 17564 solver.cpp:238]     Train net output #1: loss = 0.00994399 (* 1 = 0.00994399 loss)
I0414 05:51:48.425071 17564 sgd_solver.cpp:105] Iteration 13500, lr = 0.001
I0414 05:52:02.696070 17564 solver.cpp:219] Iteration 13600 (7.00747 iter/s, 14.2705s/100 iters), loss = 0.00509293
I0414 05:52:02.696070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:52:02.696070 17564 solver.cpp:238]     Train net output #1: loss = 0.00509296 (* 1 = 0.00509296 loss)
I0414 05:52:02.696070 17564 sgd_solver.cpp:105] Iteration 13600, lr = 0.001
I0414 05:52:16.958070 17564 solver.cpp:219] Iteration 13700 (7.01171 iter/s, 14.2619s/100 iters), loss = 0.00383574
I0414 05:52:16.958070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:52:16.958070 17564 solver.cpp:238]     Train net output #1: loss = 0.00383578 (* 1 = 0.00383578 loss)
I0414 05:52:16.958070 17564 sgd_solver.cpp:105] Iteration 13700, lr = 0.001
I0414 05:52:30.527072 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:52:31.096071 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_13800.caffemodel
I0414 05:52:31.231070 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_13800.solverstate
I0414 05:52:31.296070 17564 solver.cpp:331] Iteration 13800, Testing net (#0)
I0414 05:52:31.296070 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:52:35.215071 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:52:35.376070 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 05:52:35.376070 17564 solver.cpp:398]     Test net output #1: loss = 0.0140734 (* 1 = 0.0140734 loss)
I0414 05:52:35.515070 17564 solver.cpp:219] Iteration 13800 (5.38909 iter/s, 18.556s/100 iters), loss = 0.00402007
I0414 05:52:35.515070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:52:35.515070 17564 solver.cpp:238]     Train net output #1: loss = 0.00402012 (* 1 = 0.00402012 loss)
I0414 05:52:35.515070 17564 sgd_solver.cpp:105] Iteration 13800, lr = 0.001
I0414 05:52:49.791070 17564 solver.cpp:219] Iteration 13900 (7.00509 iter/s, 14.2753s/100 iters), loss = 0.0116626
I0414 05:52:49.791070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:52:49.791070 17564 solver.cpp:238]     Train net output #1: loss = 0.0116626 (* 1 = 0.0116626 loss)
I0414 05:52:49.791070 17564 sgd_solver.cpp:105] Iteration 13900, lr = 0.001
I0414 05:53:04.077069 17564 solver.cpp:219] Iteration 14000 (6.99977 iter/s, 14.2862s/100 iters), loss = 0.0122946
I0414 05:53:04.078070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:53:04.078070 17564 solver.cpp:238]     Train net output #1: loss = 0.0122946 (* 1 = 0.0122946 loss)
I0414 05:53:04.078070 17564 sgd_solver.cpp:105] Iteration 14000, lr = 0.001
I0414 05:53:18.332070 17564 solver.cpp:219] Iteration 14100 (7.01543 iter/s, 14.2543s/100 iters), loss = 0.00984184
I0414 05:53:18.332070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:53:18.332070 17564 solver.cpp:238]     Train net output #1: loss = 0.0098419 (* 1 = 0.0098419 loss)
I0414 05:53:18.332070 17564 sgd_solver.cpp:105] Iteration 14100, lr = 0.001
I0414 05:53:32.590070 17564 solver.cpp:219] Iteration 14200 (7.01403 iter/s, 14.2571s/100 iters), loss = 0.00370714
I0414 05:53:32.590070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:53:32.590070 17564 solver.cpp:238]     Train net output #1: loss = 0.00370719 (* 1 = 0.00370719 loss)
I0414 05:53:32.590070 17564 sgd_solver.cpp:105] Iteration 14200, lr = 0.001
I0414 05:53:46.850070 17564 solver.cpp:219] Iteration 14300 (7.01266 iter/s, 14.2599s/100 iters), loss = 0.00597046
I0414 05:53:46.851070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:53:46.851070 17564 solver.cpp:238]     Train net output #1: loss = 0.00597051 (* 1 = 0.00597051 loss)
I0414 05:53:46.851070 17564 sgd_solver.cpp:105] Iteration 14300, lr = 0.001
I0414 05:54:00.397071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:54:00.969070 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_14400.caffemodel
I0414 05:54:01.126090 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_14400.solverstate
I0414 05:54:01.194073 17564 solver.cpp:331] Iteration 14400, Testing net (#0)
I0414 05:54:01.194073 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:54:05.121070 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:54:05.282069 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9973
I0414 05:54:05.283071 17564 solver.cpp:398]     Test net output #1: loss = 0.013978 (* 1 = 0.013978 loss)
I0414 05:54:05.422070 17564 solver.cpp:219] Iteration 14400 (5.38484 iter/s, 18.5707s/100 iters), loss = 0.00583897
I0414 05:54:05.422070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:54:05.422070 17564 solver.cpp:238]     Train net output #1: loss = 0.00583902 (* 1 = 0.00583902 loss)
I0414 05:54:05.422070 17564 sgd_solver.cpp:105] Iteration 14400, lr = 0.001
I0414 05:54:19.691071 17564 solver.cpp:219] Iteration 14500 (7.00826 iter/s, 14.2689s/100 iters), loss = 0.0202852
I0414 05:54:19.691071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:54:19.691071 17564 solver.cpp:238]     Train net output #1: loss = 0.0202853 (* 1 = 0.0202853 loss)
I0414 05:54:19.691071 17564 sgd_solver.cpp:105] Iteration 14500, lr = 0.001
I0414 05:54:33.960069 17564 solver.cpp:219] Iteration 14600 (7.00845 iter/s, 14.2685s/100 iters), loss = 0.0149639
I0414 05:54:33.960069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:54:33.960069 17564 solver.cpp:238]     Train net output #1: loss = 0.0149639 (* 1 = 0.0149639 loss)
I0414 05:54:33.960069 17564 sgd_solver.cpp:105] Iteration 14600, lr = 0.001
I0414 05:54:48.229069 17564 solver.cpp:219] Iteration 14700 (7.00875 iter/s, 14.2679s/100 iters), loss = 0.00903269
I0414 05:54:48.229069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:54:48.229069 17564 solver.cpp:238]     Train net output #1: loss = 0.00903274 (* 1 = 0.00903274 loss)
I0414 05:54:48.229069 17564 sgd_solver.cpp:105] Iteration 14700, lr = 0.001
I0414 05:55:02.511070 17564 solver.cpp:219] Iteration 14800 (7.00167 iter/s, 14.2823s/100 iters), loss = 0.00371095
I0414 05:55:02.512070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:55:02.512070 17564 solver.cpp:238]     Train net output #1: loss = 0.003711 (* 1 = 0.003711 loss)
I0414 05:55:02.512070 17564 sgd_solver.cpp:105] Iteration 14800, lr = 0.001
I0414 05:55:16.780069 17564 solver.cpp:219] Iteration 14900 (7.00898 iter/s, 14.2674s/100 iters), loss = 0.00424165
I0414 05:55:16.780069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:55:16.780069 17564 solver.cpp:238]     Train net output #1: loss = 0.0042417 (* 1 = 0.0042417 loss)
I0414 05:55:16.780069 17564 sgd_solver.cpp:105] Iteration 14900, lr = 0.001
I0414 05:55:30.333070 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:55:30.901070 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_15000.caffemodel
I0414 05:55:31.039070 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_15000.solverstate
I0414 05:55:31.106081 17564 solver.cpp:331] Iteration 15000, Testing net (#0)
I0414 05:55:31.106081 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:55:35.025070 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:55:35.187070 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9973
I0414 05:55:35.187070 17564 solver.cpp:398]     Test net output #1: loss = 0.0139862 (* 1 = 0.0139862 loss)
I0414 05:55:35.326069 17564 solver.cpp:219] Iteration 15000 (5.39211 iter/s, 18.5456s/100 iters), loss = 0.00879934
I0414 05:55:35.326069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:55:35.326069 17564 solver.cpp:238]     Train net output #1: loss = 0.00879939 (* 1 = 0.00879939 loss)
I0414 05:55:35.326069 17564 sgd_solver.cpp:105] Iteration 15000, lr = 0.001
I0414 05:55:49.590070 17564 solver.cpp:219] Iteration 15100 (7.01054 iter/s, 14.2642s/100 iters), loss = 0.0110741
I0414 05:55:49.591070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:55:49.591070 17564 solver.cpp:238]     Train net output #1: loss = 0.0110742 (* 1 = 0.0110742 loss)
I0414 05:55:49.591070 17564 sgd_solver.cpp:105] Iteration 15100, lr = 0.001
I0414 05:56:03.871070 17564 solver.cpp:219] Iteration 15200 (7.00271 iter/s, 14.2802s/100 iters), loss = 0.0171927
I0414 05:56:03.871070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:56:03.871070 17564 solver.cpp:238]     Train net output #1: loss = 0.0171927 (* 1 = 0.0171927 loss)
I0414 05:56:03.871070 17564 sgd_solver.cpp:105] Iteration 15200, lr = 0.001
I0414 05:56:18.137069 17564 solver.cpp:219] Iteration 15300 (7.00982 iter/s, 14.2657s/100 iters), loss = 0.0189531
I0414 05:56:18.138070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:56:18.138070 17564 solver.cpp:238]     Train net output #1: loss = 0.0189532 (* 1 = 0.0189532 loss)
I0414 05:56:18.138070 17564 sgd_solver.cpp:105] Iteration 15300, lr = 0.001
I0414 05:56:32.396070 17564 solver.cpp:219] Iteration 15400 (7.01375 iter/s, 14.2577s/100 iters), loss = 0.003131
I0414 05:56:32.396070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:56:32.396070 17564 solver.cpp:238]     Train net output #1: loss = 0.00313103 (* 1 = 0.00313103 loss)
I0414 05:56:32.396070 17564 sgd_solver.cpp:105] Iteration 15400, lr = 0.001
I0414 05:56:46.665069 17564 solver.cpp:219] Iteration 15500 (7.00836 iter/s, 14.2687s/100 iters), loss = 0.00495344
I0414 05:56:46.665069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:56:46.665069 17564 solver.cpp:238]     Train net output #1: loss = 0.00495347 (* 1 = 0.00495347 loss)
I0414 05:56:46.665069 17564 sgd_solver.cpp:105] Iteration 15500, lr = 0.001
I0414 05:57:00.231071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:57:00.800071 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_15600.caffemodel
I0414 05:57:00.939086 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_15600.solverstate
I0414 05:57:01.013074 17564 solver.cpp:331] Iteration 15600, Testing net (#0)
I0414 05:57:01.013074 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:57:04.946072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:57:05.108069 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9972
I0414 05:57:05.108069 17564 solver.cpp:398]     Test net output #1: loss = 0.0139346 (* 1 = 0.0139346 loss)
I0414 05:57:05.247069 17564 solver.cpp:219] Iteration 15600 (5.38159 iter/s, 18.5819s/100 iters), loss = 0.00567175
I0414 05:57:05.247069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:57:05.247069 17564 solver.cpp:238]     Train net output #1: loss = 0.00567179 (* 1 = 0.00567179 loss)
I0414 05:57:05.247069 17564 sgd_solver.cpp:105] Iteration 15600, lr = 0.001
I0414 05:57:19.510071 17564 solver.cpp:219] Iteration 15700 (7.01175 iter/s, 14.2618s/100 iters), loss = 0.0198502
I0414 05:57:19.510071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:57:19.510071 17564 solver.cpp:238]     Train net output #1: loss = 0.0198502 (* 1 = 0.0198502 loss)
I0414 05:57:19.510071 17564 sgd_solver.cpp:105] Iteration 15700, lr = 0.001
I0414 05:57:33.769069 17564 solver.cpp:219] Iteration 15800 (7.013 iter/s, 14.2592s/100 iters), loss = 0.0106442
I0414 05:57:33.769069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:57:33.770071 17564 solver.cpp:238]     Train net output #1: loss = 0.0106442 (* 1 = 0.0106442 loss)
I0414 05:57:33.770071 17564 sgd_solver.cpp:105] Iteration 15800, lr = 0.001
I0414 05:57:48.023069 17564 solver.cpp:219] Iteration 15900 (7.01611 iter/s, 14.2529s/100 iters), loss = 0.0159746
I0414 05:57:48.023069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:57:48.023069 17564 solver.cpp:238]     Train net output #1: loss = 0.0159747 (* 1 = 0.0159747 loss)
I0414 05:57:48.023069 17564 sgd_solver.cpp:105] Iteration 15900, lr = 0.001
I0414 05:58:02.299070 17564 solver.cpp:219] Iteration 16000 (7.00521 iter/s, 14.2751s/100 iters), loss = 0.00668343
I0414 05:58:02.299070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:58:02.299070 17564 solver.cpp:238]     Train net output #1: loss = 0.00668345 (* 1 = 0.00668345 loss)
I0414 05:58:02.299070 17564 sgd_solver.cpp:105] Iteration 16000, lr = 0.001
I0414 05:58:16.568070 17564 solver.cpp:219] Iteration 16100 (7.00834 iter/s, 14.2687s/100 iters), loss = 0.00739864
I0414 05:58:16.568070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:58:16.568070 17564 solver.cpp:238]     Train net output #1: loss = 0.00739866 (* 1 = 0.00739866 loss)
I0414 05:58:16.568070 17564 sgd_solver.cpp:105] Iteration 16100, lr = 0.001
I0414 05:58:30.116071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:58:30.684070 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_16200.caffemodel
I0414 05:58:30.824070 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_16200.solverstate
I0414 05:58:30.889070 17564 solver.cpp:331] Iteration 16200, Testing net (#0)
I0414 05:58:30.890071 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 05:58:34.809072 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 05:58:34.971071 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 05:58:34.971071 17564 solver.cpp:398]     Test net output #1: loss = 0.014014 (* 1 = 0.014014 loss)
I0414 05:58:35.110070 17564 solver.cpp:219] Iteration 16200 (5.39332 iter/s, 18.5414s/100 iters), loss = 0.0055835
I0414 05:58:35.110070 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:58:35.110070 17564 solver.cpp:238]     Train net output #1: loss = 0.00558353 (* 1 = 0.00558353 loss)
I0414 05:58:35.110070 17564 sgd_solver.cpp:105] Iteration 16200, lr = 0.001
I0414 05:58:49.372071 17564 solver.cpp:219] Iteration 16300 (7.01196 iter/s, 14.2614s/100 iters), loss = 0.0175076
I0414 05:58:49.372071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 05:58:49.372071 17564 solver.cpp:238]     Train net output #1: loss = 0.0175076 (* 1 = 0.0175076 loss)
I0414 05:58:49.372071 17564 sgd_solver.cpp:105] Iteration 16300, lr = 0.001
I0414 05:59:03.652072 17564 solver.cpp:219] Iteration 16400 (7.00298 iter/s, 14.2796s/100 iters), loss = 0.0146865
I0414 05:59:03.652072 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:59:03.652072 17564 solver.cpp:238]     Train net output #1: loss = 0.0146866 (* 1 = 0.0146866 loss)
I0414 05:59:03.652072 17564 sgd_solver.cpp:105] Iteration 16400, lr = 0.001
I0414 05:59:17.908069 17564 solver.cpp:219] Iteration 16500 (7.01504 iter/s, 14.2551s/100 iters), loss = 0.0089179
I0414 05:59:17.908069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:59:17.908069 17564 solver.cpp:238]     Train net output #1: loss = 0.00891793 (* 1 = 0.00891793 loss)
I0414 05:59:17.908069 17564 sgd_solver.cpp:105] Iteration 16500, lr = 0.001
I0414 05:59:32.157069 17564 solver.cpp:219] Iteration 16600 (7.01846 iter/s, 14.2481s/100 iters), loss = 0.00466775
I0414 05:59:32.157069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:59:32.157069 17564 solver.cpp:238]     Train net output #1: loss = 0.00466778 (* 1 = 0.00466778 loss)
I0414 05:59:32.157069 17564 sgd_solver.cpp:105] Iteration 16600, lr = 0.001
I0414 05:59:46.418071 17564 solver.cpp:219] Iteration 16700 (7.01226 iter/s, 14.2607s/100 iters), loss = 0.00537763
I0414 05:59:46.418071 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 05:59:46.418071 17564 solver.cpp:238]     Train net output #1: loss = 0.00537765 (* 1 = 0.00537765 loss)
I0414 05:59:46.418071 17564 sgd_solver.cpp:105] Iteration 16700, lr = 0.001
I0414 05:59:59.962071 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:00:00.529070 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_16800.caffemodel
I0414 06:00:00.670094 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_16800.solverstate
I0414 06:00:00.735072 17564 solver.cpp:331] Iteration 16800, Testing net (#0)
I0414 06:00:00.735072 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:00:04.666071 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:00:04.828089 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9975
I0414 06:00:04.828089 17564 solver.cpp:398]     Test net output #1: loss = 0.0140012 (* 1 = 0.0140012 loss)
I0414 06:00:04.966069 17564 solver.cpp:219] Iteration 16800 (5.39157 iter/s, 18.5475s/100 iters), loss = 0.00566136
I0414 06:00:04.966069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:00:04.966069 17564 solver.cpp:238]     Train net output #1: loss = 0.00566139 (* 1 = 0.00566139 loss)
I0414 06:00:04.966069 17564 sgd_solver.cpp:105] Iteration 16800, lr = 0.001
I0414 06:00:19.222069 17564 solver.cpp:219] Iteration 16900 (7.01481 iter/s, 14.2556s/100 iters), loss = 0.0127043
I0414 06:00:19.222069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:00:19.222069 17564 solver.cpp:238]     Train net output #1: loss = 0.0127043 (* 1 = 0.0127043 loss)
I0414 06:00:19.222069 17564 sgd_solver.cpp:105] Iteration 16900, lr = 0.001
I0414 06:00:33.473069 17564 solver.cpp:219] Iteration 17000 (7.01731 iter/s, 14.2505s/100 iters), loss = 0.0168779
I0414 06:00:33.473069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:00:33.473069 17564 solver.cpp:238]     Train net output #1: loss = 0.0168779 (* 1 = 0.0168779 loss)
I0414 06:00:33.473069 17564 sgd_solver.cpp:105] Iteration 17000, lr = 0.001
I0414 06:00:47.737083 17564 solver.cpp:219] Iteration 17100 (7.01089 iter/s, 14.2635s/100 iters), loss = 0.0122552
I0414 06:00:47.737083 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:00:47.737083 17564 solver.cpp:238]     Train net output #1: loss = 0.0122552 (* 1 = 0.0122552 loss)
I0414 06:00:47.737083 17564 sgd_solver.cpp:105] Iteration 17100, lr = 0.001
I0414 06:01:02.003077 17564 solver.cpp:219] Iteration 17200 (7.01032 iter/s, 14.2647s/100 iters), loss = 0.0042762
I0414 06:01:02.003077 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:01:02.003077 17564 solver.cpp:238]     Train net output #1: loss = 0.00427622 (* 1 = 0.00427622 loss)
I0414 06:01:02.003077 17564 sgd_solver.cpp:105] Iteration 17200, lr = 0.001
I0414 06:01:16.267069 17564 solver.cpp:219] Iteration 17300 (7.01101 iter/s, 14.2633s/100 iters), loss = 0.00376111
I0414 06:01:16.267069 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:01:16.267069 17564 solver.cpp:238]     Train net output #1: loss = 0.00376113 (* 1 = 0.00376113 loss)
I0414 06:01:16.267069 17564 sgd_solver.cpp:105] Iteration 17300, lr = 0.001
I0414 06:01:29.824152 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:01:30.392153 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_17400.caffemodel
I0414 06:01:30.532153 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_17400.solverstate
I0414 06:01:30.599153 17564 solver.cpp:331] Iteration 17400, Testing net (#0)
I0414 06:01:30.599153 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:01:34.519155 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:01:34.681155 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:01:34.681155 17564 solver.cpp:398]     Test net output #1: loss = 0.0140065 (* 1 = 0.0140065 loss)
I0414 06:01:34.819152 17564 solver.cpp:219] Iteration 17400 (5.39016 iter/s, 18.5523s/100 iters), loss = 0.00790827
I0414 06:01:34.820152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:01:34.820152 17564 solver.cpp:238]     Train net output #1: loss = 0.0079083 (* 1 = 0.0079083 loss)
I0414 06:01:34.820152 17564 sgd_solver.cpp:105] Iteration 17400, lr = 0.001
I0414 06:01:49.092152 17564 solver.cpp:219] Iteration 17500 (7.00656 iter/s, 14.2723s/100 iters), loss = 0.0172829
I0414 06:01:49.092152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:01:49.092152 17564 solver.cpp:238]     Train net output #1: loss = 0.0172829 (* 1 = 0.0172829 loss)
I0414 06:01:49.092152 17564 sgd_solver.cpp:105] Iteration 17500, lr = 0.001
I0414 06:02:03.383152 17564 solver.cpp:219] Iteration 17600 (6.99764 iter/s, 14.2905s/100 iters), loss = 0.0151104
I0414 06:02:03.384153 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:02:03.384153 17564 solver.cpp:238]     Train net output #1: loss = 0.0151105 (* 1 = 0.0151105 loss)
I0414 06:02:03.384153 17564 sgd_solver.cpp:105] Iteration 17600, lr = 0.001
I0414 06:02:17.646152 17564 solver.cpp:219] Iteration 17700 (7.01167 iter/s, 14.2619s/100 iters), loss = 0.0285534
I0414 06:02:17.646152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:02:17.646152 17564 solver.cpp:238]     Train net output #1: loss = 0.0285534 (* 1 = 0.0285534 loss)
I0414 06:02:17.646152 17564 sgd_solver.cpp:105] Iteration 17700, lr = 0.001
I0414 06:02:31.908152 17564 solver.cpp:219] Iteration 17800 (7.01197 iter/s, 14.2613s/100 iters), loss = 0.00474197
I0414 06:02:31.908152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:02:31.908152 17564 solver.cpp:238]     Train net output #1: loss = 0.004742 (* 1 = 0.004742 loss)
I0414 06:02:31.908152 17564 sgd_solver.cpp:105] Iteration 17800, lr = 0.001
I0414 06:02:46.181151 17564 solver.cpp:219] Iteration 17900 (7.00623 iter/s, 14.273s/100 iters), loss = 0.00549377
I0414 06:02:46.182152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:02:46.182152 17564 solver.cpp:238]     Train net output #1: loss = 0.0054938 (* 1 = 0.0054938 loss)
I0414 06:02:46.182152 17564 sgd_solver.cpp:105] Iteration 17900, lr = 0.001
I0414 06:02:59.735153 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:03:00.305153 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_18000.caffemodel
I0414 06:03:00.444152 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_18000.solverstate
I0414 06:03:00.509152 17564 solver.cpp:331] Iteration 18000, Testing net (#0)
I0414 06:03:00.509152 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:03:04.442152 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:03:04.604152 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:03:04.604152 17564 solver.cpp:398]     Test net output #1: loss = 0.0139849 (* 1 = 0.0139849 loss)
I0414 06:03:04.743152 17564 solver.cpp:219] Iteration 18000 (5.38777 iter/s, 18.5606s/100 iters), loss = 0.00719397
I0414 06:03:04.743152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:03:04.743152 17564 solver.cpp:238]     Train net output #1: loss = 0.00719399 (* 1 = 0.00719399 loss)
I0414 06:03:04.743152 17564 sgd_solver.cpp:105] Iteration 18000, lr = 0.001
I0414 06:03:19.013152 17564 solver.cpp:219] Iteration 18100 (7.00759 iter/s, 14.2702s/100 iters), loss = 0.00981843
I0414 06:03:19.014153 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:03:19.014153 17564 solver.cpp:238]     Train net output #1: loss = 0.00981846 (* 1 = 0.00981846 loss)
I0414 06:03:19.014153 17564 sgd_solver.cpp:105] Iteration 18100, lr = 0.001
I0414 06:03:33.279151 17564 solver.cpp:219] Iteration 18200 (7.01042 iter/s, 14.2645s/100 iters), loss = 0.0120041
I0414 06:03:33.279151 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:03:33.279151 17564 solver.cpp:238]     Train net output #1: loss = 0.0120041 (* 1 = 0.0120041 loss)
I0414 06:03:33.279151 17564 sgd_solver.cpp:105] Iteration 18200, lr = 0.001
I0414 06:03:47.542152 17564 solver.cpp:219] Iteration 18300 (7.01102 iter/s, 14.2633s/100 iters), loss = 0.0197767
I0414 06:03:47.543153 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:03:47.543153 17564 solver.cpp:238]     Train net output #1: loss = 0.0197767 (* 1 = 0.0197767 loss)
I0414 06:03:47.543153 17564 sgd_solver.cpp:105] Iteration 18300, lr = 0.001
I0414 06:04:01.814152 17564 solver.cpp:219] Iteration 18400 (7.00706 iter/s, 14.2713s/100 iters), loss = 0.00656553
I0414 06:04:01.814152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:04:01.815152 17564 solver.cpp:238]     Train net output #1: loss = 0.00656555 (* 1 = 0.00656555 loss)
I0414 06:04:01.815152 17564 sgd_solver.cpp:105] Iteration 18400, lr = 0.001
I0414 06:04:16.082168 17564 solver.cpp:219] Iteration 18500 (7.00932 iter/s, 14.2667s/100 iters), loss = 0.00384879
I0414 06:04:16.082168 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:04:16.082168 17564 solver.cpp:238]     Train net output #1: loss = 0.00384881 (* 1 = 0.00384881 loss)
I0414 06:04:16.082168 17564 sgd_solver.cpp:105] Iteration 18500, lr = 0.001
I0414 06:04:29.635152 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:04:30.204152 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_18600.caffemodel
I0414 06:04:30.341156 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_18600.solverstate
I0414 06:04:30.406152 17564 solver.cpp:331] Iteration 18600, Testing net (#0)
I0414 06:04:30.406152 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:04:34.325153 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:04:34.487152 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:04:34.487152 17564 solver.cpp:398]     Test net output #1: loss = 0.0140998 (* 1 = 0.0140998 loss)
I0414 06:04:34.625151 17564 solver.cpp:219] Iteration 18600 (5.39291 iter/s, 18.5429s/100 iters), loss = 0.0044158
I0414 06:04:34.625151 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:04:34.625151 17564 solver.cpp:238]     Train net output #1: loss = 0.00441583 (* 1 = 0.00441583 loss)
I0414 06:04:34.625151 17564 sgd_solver.cpp:105] Iteration 18600, lr = 0.001
I0414 06:04:48.886152 17564 solver.cpp:219] Iteration 18700 (7.01247 iter/s, 14.2603s/100 iters), loss = 0.0130364
I0414 06:04:48.886152 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:04:48.886152 17564 solver.cpp:238]     Train net output #1: loss = 0.0130364 (* 1 = 0.0130364 loss)
I0414 06:04:48.886152 17564 sgd_solver.cpp:105] Iteration 18700, lr = 0.001
I0414 06:05:03.157234 17564 solver.cpp:219] Iteration 18800 (7.00738 iter/s, 14.2707s/100 iters), loss = 0.0197789
I0414 06:05:03.157234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:05:03.157234 17564 solver.cpp:238]     Train net output #1: loss = 0.0197789 (* 1 = 0.0197789 loss)
I0414 06:05:03.157234 17564 sgd_solver.cpp:105] Iteration 18800, lr = 0.001
I0414 06:05:17.429234 17564 solver.cpp:219] Iteration 18900 (7.00727 iter/s, 14.2709s/100 iters), loss = 0.0144142
I0414 06:05:17.429234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:05:17.429234 17564 solver.cpp:238]     Train net output #1: loss = 0.0144142 (* 1 = 0.0144142 loss)
I0414 06:05:17.429234 17564 sgd_solver.cpp:105] Iteration 18900, lr = 0.001
I0414 06:05:31.693233 17564 solver.cpp:219] Iteration 19000 (7.01087 iter/s, 14.2636s/100 iters), loss = 0.00285951
I0414 06:05:31.693233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:05:31.693233 17564 solver.cpp:238]     Train net output #1: loss = 0.00285953 (* 1 = 0.00285953 loss)
I0414 06:05:31.693233 17564 sgd_solver.cpp:105] Iteration 19000, lr = 0.001
I0414 06:05:45.952234 17564 solver.cpp:219] Iteration 19100 (7.01343 iter/s, 14.2584s/100 iters), loss = 0.00496234
I0414 06:05:45.952234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:05:45.952234 17564 solver.cpp:238]     Train net output #1: loss = 0.00496236 (* 1 = 0.00496236 loss)
I0414 06:05:45.952234 17564 sgd_solver.cpp:105] Iteration 19100, lr = 0.001
I0414 06:05:59.502233 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:06:00.070235 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_19200.caffemodel
I0414 06:06:00.210239 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_19200.solverstate
I0414 06:06:00.275236 17564 solver.cpp:331] Iteration 19200, Testing net (#0)
I0414 06:06:00.275236 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:06:04.205238 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:06:04.366233 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9972
I0414 06:06:04.366233 17564 solver.cpp:398]     Test net output #1: loss = 0.0140155 (* 1 = 0.0140155 loss)
I0414 06:06:04.505234 17564 solver.cpp:219] Iteration 19200 (5.39016 iter/s, 18.5523s/100 iters), loss = 0.00790007
I0414 06:06:04.505234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:06:04.505234 17564 solver.cpp:238]     Train net output #1: loss = 0.00790009 (* 1 = 0.00790009 loss)
I0414 06:06:04.505234 17564 sgd_solver.cpp:105] Iteration 19200, lr = 0.001
I0414 06:06:18.760233 17564 solver.cpp:219] Iteration 19300 (7.01526 iter/s, 14.2546s/100 iters), loss = 0.0144786
I0414 06:06:18.760233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:06:18.760233 17564 solver.cpp:238]     Train net output #1: loss = 0.0144786 (* 1 = 0.0144786 loss)
I0414 06:06:18.760233 17564 sgd_solver.cpp:105] Iteration 19300, lr = 0.001
I0414 06:06:33.014233 17564 solver.cpp:219] Iteration 19400 (7.0157 iter/s, 14.2537s/100 iters), loss = 0.0143443
I0414 06:06:33.014233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:06:33.014233 17564 solver.cpp:238]     Train net output #1: loss = 0.0143443 (* 1 = 0.0143443 loss)
I0414 06:06:33.014233 17564 sgd_solver.cpp:105] Iteration 19400, lr = 0.001
I0414 06:06:47.265233 17564 solver.cpp:219] Iteration 19500 (7.01767 iter/s, 14.2498s/100 iters), loss = 0.0210844
I0414 06:06:47.265233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:06:47.265233 17564 solver.cpp:238]     Train net output #1: loss = 0.0210844 (* 1 = 0.0210844 loss)
I0414 06:06:47.265233 17564 sgd_solver.cpp:105] Iteration 19500, lr = 0.001
I0414 06:07:01.522235 17564 solver.cpp:219] Iteration 19600 (7.01428 iter/s, 14.2566s/100 iters), loss = 0.00527079
I0414 06:07:01.522235 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:07:01.522235 17564 solver.cpp:238]     Train net output #1: loss = 0.00527081 (* 1 = 0.00527081 loss)
I0414 06:07:01.522235 17564 sgd_solver.cpp:105] Iteration 19600, lr = 0.001
I0414 06:07:15.796233 17564 solver.cpp:219] Iteration 19700 (7.00573 iter/s, 14.274s/100 iters), loss = 0.00744557
I0414 06:07:15.796233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:07:15.797235 17564 solver.cpp:238]     Train net output #1: loss = 0.00744558 (* 1 = 0.00744558 loss)
I0414 06:07:15.797235 17564 sgd_solver.cpp:105] Iteration 19700, lr = 0.001
I0414 06:07:29.355235 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:07:29.925235 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_19800.caffemodel
I0414 06:07:30.071249 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_19800.solverstate
I0414 06:07:30.137236 17564 solver.cpp:331] Iteration 19800, Testing net (#0)
I0414 06:07:30.138236 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:07:34.059236 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:07:34.221235 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:07:34.221235 17564 solver.cpp:398]     Test net output #1: loss = 0.0139885 (* 1 = 0.0139885 loss)
I0414 06:07:34.360234 17564 solver.cpp:219] Iteration 19800 (5.38706 iter/s, 18.563s/100 iters), loss = 0.00898169
I0414 06:07:34.360234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:07:34.360234 17564 solver.cpp:238]     Train net output #1: loss = 0.0089817 (* 1 = 0.0089817 loss)
I0414 06:07:34.360234 17564 sgd_solver.cpp:105] Iteration 19800, lr = 0.001
I0414 06:07:48.620234 17564 solver.cpp:219] Iteration 19900 (7.01299 iter/s, 14.2593s/100 iters), loss = 0.0152065
I0414 06:07:48.620234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:07:48.620234 17564 solver.cpp:238]     Train net output #1: loss = 0.0152066 (* 1 = 0.0152066 loss)
I0414 06:07:48.620234 17564 sgd_solver.cpp:105] Iteration 19900, lr = 0.001
I0414 06:08:02.891233 17564 solver.cpp:219] Iteration 20000 (7.00744 iter/s, 14.2705s/100 iters), loss = 0.0234979
I0414 06:08:02.891233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:08:02.891233 17564 solver.cpp:238]     Train net output #1: loss = 0.0234979 (* 1 = 0.0234979 loss)
I0414 06:08:02.891233 17564 sgd_solver.cpp:105] Iteration 20000, lr = 0.001
I0414 06:08:17.171233 17564 solver.cpp:219] Iteration 20100 (7.00293 iter/s, 14.2797s/100 iters), loss = 0.0178927
I0414 06:08:17.171233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:08:17.171233 17564 solver.cpp:238]     Train net output #1: loss = 0.0178927 (* 1 = 0.0178927 loss)
I0414 06:08:17.171233 17564 sgd_solver.cpp:105] Iteration 20100, lr = 0.001
I0414 06:08:31.430233 17564 solver.cpp:219] Iteration 20200 (7.01373 iter/s, 14.2578s/100 iters), loss = 0.0037562
I0414 06:08:31.430233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:08:31.430233 17564 solver.cpp:238]     Train net output #1: loss = 0.00375621 (* 1 = 0.00375621 loss)
I0414 06:08:31.430233 17564 sgd_solver.cpp:105] Iteration 20200, lr = 0.001
I0414 06:08:45.712232 17564 solver.cpp:219] Iteration 20300 (7.00174 iter/s, 14.2822s/100 iters), loss = 0.00426625
I0414 06:08:45.712232 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:08:45.712232 17564 solver.cpp:238]     Train net output #1: loss = 0.00426626 (* 1 = 0.00426626 loss)
I0414 06:08:45.712232 17564 sgd_solver.cpp:105] Iteration 20300, lr = 0.001
I0414 06:08:59.275234 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:08:59.844234 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_20400.caffemodel
I0414 06:08:59.984233 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_20400.solverstate
I0414 06:09:00.052233 17564 solver.cpp:331] Iteration 20400, Testing net (#0)
I0414 06:09:00.052233 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:09:03.982234 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:09:04.144234 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:09:04.144234 17564 solver.cpp:398]     Test net output #1: loss = 0.0140578 (* 1 = 0.0140578 loss)
I0414 06:09:04.282233 17564 solver.cpp:219] Iteration 20400 (5.38518 iter/s, 18.5695s/100 iters), loss = 0.00908947
I0414 06:09:04.282233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:09:04.283234 17564 solver.cpp:238]     Train net output #1: loss = 0.00908948 (* 1 = 0.00908948 loss)
I0414 06:09:04.283234 17564 sgd_solver.cpp:105] Iteration 20400, lr = 0.001
I0414 06:09:18.555233 17564 solver.cpp:219] Iteration 20500 (7.00682 iter/s, 14.2718s/100 iters), loss = 0.00986974
I0414 06:09:18.555233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:09:18.555233 17564 solver.cpp:238]     Train net output #1: loss = 0.00986975 (* 1 = 0.00986975 loss)
I0414 06:09:18.555233 17564 sgd_solver.cpp:105] Iteration 20500, lr = 0.001
I0414 06:09:32.819233 17564 solver.cpp:219] Iteration 20600 (7.01074 iter/s, 14.2638s/100 iters), loss = 0.0144588
I0414 06:09:32.819233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:09:32.819233 17564 solver.cpp:238]     Train net output #1: loss = 0.0144589 (* 1 = 0.0144589 loss)
I0414 06:09:32.819233 17564 sgd_solver.cpp:105] Iteration 20600, lr = 0.001
I0414 06:09:47.103235 17564 solver.cpp:219] Iteration 20700 (7.00109 iter/s, 14.2835s/100 iters), loss = 0.0259247
I0414 06:09:47.103235 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:09:47.103235 17564 solver.cpp:238]     Train net output #1: loss = 0.0259247 (* 1 = 0.0259247 loss)
I0414 06:09:47.103235 17564 sgd_solver.cpp:105] Iteration 20700, lr = 0.001
I0414 06:10:01.375252 17564 solver.cpp:219] Iteration 20800 (7.00711 iter/s, 14.2712s/100 iters), loss = 0.00410713
I0414 06:10:01.375252 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:10:01.375252 17564 solver.cpp:238]     Train net output #1: loss = 0.00410714 (* 1 = 0.00410714 loss)
I0414 06:10:01.375252 17564 sgd_solver.cpp:105] Iteration 20800, lr = 0.001
I0414 06:10:15.654233 17564 solver.cpp:219] Iteration 20900 (7.00366 iter/s, 14.2782s/100 iters), loss = 0.00682929
I0414 06:10:15.654233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:10:15.654233 17564 solver.cpp:238]     Train net output #1: loss = 0.0068293 (* 1 = 0.0068293 loss)
I0414 06:10:15.654233 17564 sgd_solver.cpp:105] Iteration 20900, lr = 0.001
I0414 06:10:29.213244 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:10:29.781234 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_21000.caffemodel
I0414 06:10:29.920235 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_21000.solverstate
I0414 06:10:29.986234 17564 solver.cpp:331] Iteration 21000, Testing net (#0)
I0414 06:10:29.986234 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:10:33.908236 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:10:34.070235 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:10:34.070235 17564 solver.cpp:398]     Test net output #1: loss = 0.014076 (* 1 = 0.014076 loss)
I0414 06:10:34.208233 17564 solver.cpp:219] Iteration 21000 (5.38985 iter/s, 18.5534s/100 iters), loss = 0.0104512
I0414 06:10:34.208233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:10:34.208233 17564 solver.cpp:238]     Train net output #1: loss = 0.0104513 (* 1 = 0.0104513 loss)
I0414 06:10:34.208233 17564 sgd_solver.cpp:105] Iteration 21000, lr = 0.001
I0414 06:10:48.470233 17564 solver.cpp:219] Iteration 21100 (7.01163 iter/s, 14.262s/100 iters), loss = 0.00833048
I0414 06:10:48.470233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:10:48.470233 17564 solver.cpp:238]     Train net output #1: loss = 0.00833049 (* 1 = 0.00833049 loss)
I0414 06:10:48.471235 17564 sgd_solver.cpp:105] Iteration 21100, lr = 0.001
I0414 06:11:02.754233 17564 solver.cpp:219] Iteration 21200 (7.00117 iter/s, 14.2833s/100 iters), loss = 0.00961967
I0414 06:11:02.754233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:11:02.754233 17564 solver.cpp:238]     Train net output #1: loss = 0.00961968 (* 1 = 0.00961968 loss)
I0414 06:11:02.754233 17564 sgd_solver.cpp:105] Iteration 21200, lr = 0.001
I0414 06:11:17.026234 17564 solver.cpp:219] Iteration 21300 (7.00704 iter/s, 14.2714s/100 iters), loss = 0.00831608
I0414 06:11:17.026234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:11:17.026234 17564 solver.cpp:238]     Train net output #1: loss = 0.00831609 (* 1 = 0.00831609 loss)
I0414 06:11:17.026234 17564 sgd_solver.cpp:105] Iteration 21300, lr = 0.001
I0414 06:11:31.292233 17564 solver.cpp:219] Iteration 21400 (7.01023 iter/s, 14.2649s/100 iters), loss = 0.0053442
I0414 06:11:31.292233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:11:31.292233 17564 solver.cpp:238]     Train net output #1: loss = 0.00534421 (* 1 = 0.00534421 loss)
I0414 06:11:31.292233 17564 sgd_solver.cpp:105] Iteration 21400, lr = 0.001
I0414 06:11:45.569236 17564 solver.cpp:219] Iteration 21500 (7.0046 iter/s, 14.2763s/100 iters), loss = 0.00466768
I0414 06:11:45.569236 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:11:45.569236 17564 solver.cpp:238]     Train net output #1: loss = 0.0046677 (* 1 = 0.0046677 loss)
I0414 06:11:45.569236 17564 sgd_solver.cpp:105] Iteration 21500, lr = 0.001
I0414 06:11:59.129235 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:11:59.697234 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_21600.caffemodel
I0414 06:11:59.836233 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_21600.solverstate
I0414 06:11:59.902233 17564 solver.cpp:331] Iteration 21600, Testing net (#0)
I0414 06:11:59.902233 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:12:03.830235 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:12:03.993237 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:12:03.993237 17564 solver.cpp:398]     Test net output #1: loss = 0.0139888 (* 1 = 0.0139888 loss)
I0414 06:12:04.133234 17564 solver.cpp:219] Iteration 21600 (5.38697 iter/s, 18.5633s/100 iters), loss = 0.0114588
I0414 06:12:04.133234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:12:04.133234 17564 solver.cpp:238]     Train net output #1: loss = 0.0114589 (* 1 = 0.0114589 loss)
I0414 06:12:04.133234 17564 sgd_solver.cpp:105] Iteration 21600, lr = 0.001
I0414 06:12:18.396251 17564 solver.cpp:219] Iteration 21700 (7.01117 iter/s, 14.263s/100 iters), loss = 0.00678915
I0414 06:12:18.396251 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:12:18.396251 17564 solver.cpp:238]     Train net output #1: loss = 0.00678917 (* 1 = 0.00678917 loss)
I0414 06:12:18.396251 17564 sgd_solver.cpp:105] Iteration 21700, lr = 0.001
I0414 06:12:32.670233 17564 solver.cpp:219] Iteration 21800 (7.00597 iter/s, 14.2735s/100 iters), loss = 0.0140024
I0414 06:12:32.670233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:12:32.670233 17564 solver.cpp:238]     Train net output #1: loss = 0.0140024 (* 1 = 0.0140024 loss)
I0414 06:12:32.670233 17564 sgd_solver.cpp:105] Iteration 21800, lr = 0.001
I0414 06:12:46.949234 17564 solver.cpp:219] Iteration 21900 (7.00392 iter/s, 14.2777s/100 iters), loss = 0.0147655
I0414 06:12:46.949234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:12:46.949234 17564 solver.cpp:238]     Train net output #1: loss = 0.0147656 (* 1 = 0.0147656 loss)
I0414 06:12:46.949234 17564 sgd_solver.cpp:105] Iteration 21900, lr = 0.001
I0414 06:13:01.217234 17564 solver.cpp:219] Iteration 22000 (7.0089 iter/s, 14.2676s/100 iters), loss = 0.00479152
I0414 06:13:01.217234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:13:01.217234 17564 solver.cpp:238]     Train net output #1: loss = 0.00479154 (* 1 = 0.00479154 loss)
I0414 06:13:01.217234 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 22000, step = 3
I0414 06:13:01.217234 17564 sgd_solver.cpp:105] Iteration 22000, lr = 0.0001
I0414 06:13:15.503233 17564 solver.cpp:219] Iteration 22100 (7.00003 iter/s, 14.2857s/100 iters), loss = 0.00433187
I0414 06:13:15.503233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:13:15.503233 17564 solver.cpp:238]     Train net output #1: loss = 0.00433189 (* 1 = 0.00433189 loss)
I0414 06:13:15.503233 17564 sgd_solver.cpp:105] Iteration 22100, lr = 0.0001
I0414 06:13:29.061234 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:13:29.629233 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_22200.caffemodel
I0414 06:13:29.772238 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_22200.solverstate
I0414 06:13:29.839236 17564 solver.cpp:331] Iteration 22200, Testing net (#0)
I0414 06:13:29.839236 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:13:33.758235 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:13:33.920236 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9972
I0414 06:13:33.920236 17564 solver.cpp:398]     Test net output #1: loss = 0.0141426 (* 1 = 0.0141426 loss)
I0414 06:13:34.058248 17564 solver.cpp:219] Iteration 22200 (5.38948 iter/s, 18.5547s/100 iters), loss = 0.00460718
I0414 06:13:34.058248 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:13:34.058248 17564 solver.cpp:238]     Train net output #1: loss = 0.0046072 (* 1 = 0.0046072 loss)
I0414 06:13:34.058248 17564 sgd_solver.cpp:105] Iteration 22200, lr = 0.0001
I0414 06:13:48.317234 17564 solver.cpp:219] Iteration 22300 (7.01369 iter/s, 14.2578s/100 iters), loss = 0.0145083
I0414 06:13:48.317234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:13:48.317234 17564 solver.cpp:238]     Train net output #1: loss = 0.0145083 (* 1 = 0.0145083 loss)
I0414 06:13:48.317234 17564 sgd_solver.cpp:105] Iteration 22300, lr = 0.0001
I0414 06:14:02.582236 17564 solver.cpp:219] Iteration 22400 (7.01049 iter/s, 14.2643s/100 iters), loss = 0.00883621
I0414 06:14:02.582236 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:14:02.582236 17564 solver.cpp:238]     Train net output #1: loss = 0.00883623 (* 1 = 0.00883623 loss)
I0414 06:14:02.582236 17564 sgd_solver.cpp:105] Iteration 22400, lr = 0.0001
I0414 06:14:16.855233 17564 solver.cpp:219] Iteration 22500 (7.00631 iter/s, 14.2728s/100 iters), loss = 0.00730017
I0414 06:14:16.855233 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:14:16.855233 17564 solver.cpp:238]     Train net output #1: loss = 0.00730019 (* 1 = 0.00730019 loss)
I0414 06:14:16.855233 17564 sgd_solver.cpp:105] Iteration 22500, lr = 0.0001
I0414 06:14:31.121233 17564 solver.cpp:219] Iteration 22600 (7.0098 iter/s, 14.2657s/100 iters), loss = 0.00566526
I0414 06:14:31.122234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:14:31.122234 17564 solver.cpp:238]     Train net output #1: loss = 0.00566528 (* 1 = 0.00566528 loss)
I0414 06:14:31.122234 17564 sgd_solver.cpp:105] Iteration 22600, lr = 0.0001
I0414 06:14:45.383234 17564 solver.cpp:219] Iteration 22700 (7.01233 iter/s, 14.2606s/100 iters), loss = 0.0052415
I0414 06:14:45.383234 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:14:45.383234 17564 solver.cpp:238]     Train net output #1: loss = 0.00524152 (* 1 = 0.00524152 loss)
I0414 06:14:45.383234 17564 sgd_solver.cpp:105] Iteration 22700, lr = 0.0001
I0414 06:14:58.944234 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:14:59.512234 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_22800.caffemodel
I0414 06:14:59.654239 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_22800.solverstate
I0414 06:14:59.825316 17564 solver.cpp:331] Iteration 22800, Testing net (#0)
I0414 06:14:59.825316 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:15:03.764315 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:15:03.927337 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:15:03.927337 17564 solver.cpp:398]     Test net output #1: loss = 0.0141343 (* 1 = 0.0141343 loss)
I0414 06:15:04.066329 17564 solver.cpp:219] Iteration 22800 (5.35249 iter/s, 18.6829s/100 iters), loss = 0.00484911
I0414 06:15:04.066329 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:15:04.066329 17564 solver.cpp:238]     Train net output #1: loss = 0.00484914 (* 1 = 0.00484914 loss)
I0414 06:15:04.066329 17564 sgd_solver.cpp:105] Iteration 22800, lr = 0.0001
I0414 06:15:18.337363 17564 solver.cpp:219] Iteration 22900 (7.00725 iter/s, 14.2709s/100 iters), loss = 0.0194601
I0414 06:15:18.337363 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:15:18.338364 17564 solver.cpp:238]     Train net output #1: loss = 0.0194601 (* 1 = 0.0194601 loss)
I0414 06:15:18.338364 17564 sgd_solver.cpp:105] Iteration 22900, lr = 0.0001
I0414 06:15:32.594364 17564 solver.cpp:219] Iteration 23000 (7.01472 iter/s, 14.2557s/100 iters), loss = 0.0273978
I0414 06:15:32.594364 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:15:32.594364 17564 solver.cpp:238]     Train net output #1: loss = 0.0273978 (* 1 = 0.0273978 loss)
I0414 06:15:32.594364 17564 sgd_solver.cpp:105] Iteration 23000, lr = 0.0001
I0414 06:15:46.867363 17564 solver.cpp:219] Iteration 23100 (7.0065 iter/s, 14.2725s/100 iters), loss = 0.00897739
I0414 06:15:46.867363 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:15:46.867363 17564 solver.cpp:238]     Train net output #1: loss = 0.00897744 (* 1 = 0.00897744 loss)
I0414 06:15:46.867363 17564 sgd_solver.cpp:105] Iteration 23100, lr = 0.0001
I0414 06:16:01.128365 17564 solver.cpp:219] Iteration 23200 (7.01237 iter/s, 14.2605s/100 iters), loss = 0.00686166
I0414 06:16:01.128365 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:16:01.128365 17564 solver.cpp:238]     Train net output #1: loss = 0.0068617 (* 1 = 0.0068617 loss)
I0414 06:16:01.128365 17564 sgd_solver.cpp:105] Iteration 23200, lr = 0.0001
I0414 06:16:15.402364 17564 solver.cpp:219] Iteration 23300 (7.00613 iter/s, 14.2732s/100 iters), loss = 0.00330052
I0414 06:16:15.402364 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:16:15.402364 17564 solver.cpp:238]     Train net output #1: loss = 0.00330058 (* 1 = 0.00330058 loss)
I0414 06:16:15.402364 17564 sgd_solver.cpp:105] Iteration 23300, lr = 0.0001
I0414 06:16:28.948364 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:16:29.516365 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_23400.caffemodel
I0414 06:16:29.659369 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_23400.solverstate
I0414 06:16:29.794440 17564 solver.cpp:331] Iteration 23400, Testing net (#0)
I0414 06:16:29.795441 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:16:33.715441 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:16:33.877439 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:16:33.877439 17564 solver.cpp:398]     Test net output #1: loss = 0.0140965 (* 1 = 0.0140965 loss)
I0414 06:16:34.017437 17564 solver.cpp:219] Iteration 23400 (5.37219 iter/s, 18.6144s/100 iters), loss = 0.00624401
I0414 06:16:34.017437 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:16:34.017437 17564 solver.cpp:238]     Train net output #1: loss = 0.00624408 (* 1 = 0.00624408 loss)
I0414 06:16:34.017437 17564 sgd_solver.cpp:105] Iteration 23400, lr = 0.0001
I0414 06:16:48.278504 17564 solver.cpp:219] Iteration 23500 (7.01239 iter/s, 14.2605s/100 iters), loss = 0.0124511
I0414 06:16:48.278504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:16:48.278504 17564 solver.cpp:238]     Train net output #1: loss = 0.0124511 (* 1 = 0.0124511 loss)
I0414 06:16:48.278504 17564 sgd_solver.cpp:105] Iteration 23500, lr = 0.0001
I0414 06:17:02.555505 17564 solver.cpp:219] Iteration 23600 (7.00458 iter/s, 14.2764s/100 iters), loss = 0.00922016
I0414 06:17:02.555505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:17:02.555505 17564 solver.cpp:238]     Train net output #1: loss = 0.00922023 (* 1 = 0.00922023 loss)
I0414 06:17:02.555505 17564 sgd_solver.cpp:105] Iteration 23600, lr = 0.0001
I0414 06:17:16.819504 17564 solver.cpp:219] Iteration 23700 (7.01068 iter/s, 14.2639s/100 iters), loss = 0.0077801
I0414 06:17:16.819504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:17:16.819504 17564 solver.cpp:238]     Train net output #1: loss = 0.00778017 (* 1 = 0.00778017 loss)
I0414 06:17:16.819504 17564 sgd_solver.cpp:105] Iteration 23700, lr = 0.0001
I0414 06:17:31.067518 17564 solver.cpp:219] Iteration 23800 (7.01865 iter/s, 14.2478s/100 iters), loss = 0.00645904
I0414 06:17:31.067518 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:17:31.067518 17564 solver.cpp:238]     Train net output #1: loss = 0.00645911 (* 1 = 0.00645911 loss)
I0414 06:17:31.067518 17564 sgd_solver.cpp:105] Iteration 23800, lr = 0.0001
I0414 06:17:45.319504 17564 solver.cpp:219] Iteration 23900 (7.01698 iter/s, 14.2511s/100 iters), loss = 0.00418733
I0414 06:17:45.319504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:17:45.319504 17564 solver.cpp:238]     Train net output #1: loss = 0.0041874 (* 1 = 0.0041874 loss)
I0414 06:17:45.319504 17564 sgd_solver.cpp:105] Iteration 23900, lr = 0.0001
I0414 06:17:58.870506 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:17:59.438505 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_24000.caffemodel
I0414 06:17:59.579505 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_24000.solverstate
I0414 06:17:59.691504 17564 solver.cpp:331] Iteration 24000, Testing net (#0)
I0414 06:17:59.691504 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:18:03.618508 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:18:03.780505 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:18:03.780505 17564 solver.cpp:398]     Test net output #1: loss = 0.0140826 (* 1 = 0.0140826 loss)
I0414 06:18:03.919519 17564 solver.cpp:219] Iteration 24000 (5.37649 iter/s, 18.5995s/100 iters), loss = 0.0072344
I0414 06:18:03.919519 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:18:03.919519 17564 solver.cpp:238]     Train net output #1: loss = 0.00723447 (* 1 = 0.00723447 loss)
I0414 06:18:03.919519 17564 sgd_solver.cpp:105] Iteration 24000, lr = 0.0001
I0414 06:18:18.195504 17564 solver.cpp:219] Iteration 24100 (7.00517 iter/s, 14.2752s/100 iters), loss = 0.00852547
I0414 06:18:18.195504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:18:18.195504 17564 solver.cpp:238]     Train net output #1: loss = 0.00852554 (* 1 = 0.00852554 loss)
I0414 06:18:18.195504 17564 sgd_solver.cpp:105] Iteration 24100, lr = 0.0001
I0414 06:18:32.461504 17564 solver.cpp:219] Iteration 24200 (7.01012 iter/s, 14.2651s/100 iters), loss = 0.0245651
I0414 06:18:32.461504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:18:32.461504 17564 solver.cpp:238]     Train net output #1: loss = 0.0245652 (* 1 = 0.0245652 loss)
I0414 06:18:32.461504 17564 sgd_solver.cpp:105] Iteration 24200, lr = 0.0001
I0414 06:18:46.733505 17564 solver.cpp:219] Iteration 24300 (7.00704 iter/s, 14.2714s/100 iters), loss = 0.0123311
I0414 06:18:46.733505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:18:46.733505 17564 solver.cpp:238]     Train net output #1: loss = 0.0123312 (* 1 = 0.0123312 loss)
I0414 06:18:46.733505 17564 sgd_solver.cpp:105] Iteration 24300, lr = 0.0001
I0414 06:19:01.015506 17564 solver.cpp:219] Iteration 24400 (7.00178 iter/s, 14.2821s/100 iters), loss = 0.00472298
I0414 06:19:01.015506 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:19:01.015506 17564 solver.cpp:238]     Train net output #1: loss = 0.00472306 (* 1 = 0.00472306 loss)
I0414 06:19:01.015506 17564 sgd_solver.cpp:105] Iteration 24400, lr = 0.0001
I0414 06:19:15.304505 17564 solver.cpp:219] Iteration 24500 (6.99895 iter/s, 14.2879s/100 iters), loss = 0.00425732
I0414 06:19:15.304505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:19:15.304505 17564 solver.cpp:238]     Train net output #1: loss = 0.00425739 (* 1 = 0.00425739 loss)
I0414 06:19:15.304505 17564 sgd_solver.cpp:105] Iteration 24500, lr = 0.0001
I0414 06:19:28.875505 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:19:29.444505 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_24600.caffemodel
I0414 06:19:29.584506 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_24600.solverstate
I0414 06:19:29.651507 17564 solver.cpp:331] Iteration 24600, Testing net (#0)
I0414 06:19:29.651507 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:19:33.572505 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:19:33.733505 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:19:33.733505 17564 solver.cpp:398]     Test net output #1: loss = 0.0140462 (* 1 = 0.0140462 loss)
I0414 06:19:33.873504 17564 solver.cpp:219] Iteration 24600 (5.38557 iter/s, 18.5681s/100 iters), loss = 0.0155916
I0414 06:19:33.873504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:19:33.873504 17564 solver.cpp:238]     Train net output #1: loss = 0.0155917 (* 1 = 0.0155917 loss)
I0414 06:19:33.873504 17564 sgd_solver.cpp:105] Iteration 24600, lr = 0.0001
I0414 06:19:48.141505 17564 solver.cpp:219] Iteration 24700 (7.00894 iter/s, 14.2675s/100 iters), loss = 0.00714955
I0414 06:19:48.141505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:19:48.141505 17564 solver.cpp:238]     Train net output #1: loss = 0.00714963 (* 1 = 0.00714963 loss)
I0414 06:19:48.141505 17564 sgd_solver.cpp:105] Iteration 24700, lr = 0.0001
I0414 06:20:02.426506 17564 solver.cpp:219] Iteration 24800 (7.00062 iter/s, 14.2844s/100 iters), loss = 0.0144844
I0414 06:20:02.426506 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:20:02.426506 17564 solver.cpp:238]     Train net output #1: loss = 0.0144845 (* 1 = 0.0144845 loss)
I0414 06:20:02.426506 17564 sgd_solver.cpp:105] Iteration 24800, lr = 0.0001
I0414 06:20:16.706504 17564 solver.cpp:219] Iteration 24900 (7.0032 iter/s, 14.2792s/100 iters), loss = 0.0215901
I0414 06:20:16.706504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:20:16.706504 17564 solver.cpp:238]     Train net output #1: loss = 0.0215901 (* 1 = 0.0215901 loss)
I0414 06:20:16.706504 17564 sgd_solver.cpp:105] Iteration 24900, lr = 0.0001
I0414 06:20:30.961504 17564 solver.cpp:219] Iteration 25000 (7.01531 iter/s, 14.2545s/100 iters), loss = 0.0030265
I0414 06:20:30.961504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:20:30.961504 17564 solver.cpp:238]     Train net output #1: loss = 0.00302657 (* 1 = 0.00302657 loss)
I0414 06:20:30.961504 17564 sgd_solver.cpp:105] Iteration 25000, lr = 0.0001
I0414 06:20:45.222504 17564 solver.cpp:219] Iteration 25100 (7.0124 iter/s, 14.2605s/100 iters), loss = 0.00851979
I0414 06:20:45.222504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:20:45.222504 17564 solver.cpp:238]     Train net output #1: loss = 0.00851986 (* 1 = 0.00851986 loss)
I0414 06:20:45.222504 17564 sgd_solver.cpp:105] Iteration 25100, lr = 0.0001
I0414 06:20:58.777505 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:20:59.346505 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_25200.caffemodel
I0414 06:20:59.484505 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_25200.solverstate
I0414 06:20:59.551506 17564 solver.cpp:331] Iteration 25200, Testing net (#0)
I0414 06:20:59.602505 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:21:03.530508 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:21:03.692504 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:21:03.692504 17564 solver.cpp:398]     Test net output #1: loss = 0.0140869 (* 1 = 0.0140869 loss)
I0414 06:21:03.831504 17564 solver.cpp:219] Iteration 25200 (5.37366 iter/s, 18.6093s/100 iters), loss = 0.0060051
I0414 06:21:03.832505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:21:03.832505 17564 solver.cpp:238]     Train net output #1: loss = 0.00600518 (* 1 = 0.00600518 loss)
I0414 06:21:03.832505 17564 sgd_solver.cpp:105] Iteration 25200, lr = 0.0001
I0414 06:21:18.101506 17564 solver.cpp:219] Iteration 25300 (7.00839 iter/s, 14.2686s/100 iters), loss = 0.00756681
I0414 06:21:18.101506 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:21:18.101506 17564 solver.cpp:238]     Train net output #1: loss = 0.00756688 (* 1 = 0.00756688 loss)
I0414 06:21:18.101506 17564 sgd_solver.cpp:105] Iteration 25300, lr = 0.0001
I0414 06:21:32.377504 17564 solver.cpp:219] Iteration 25400 (7.00488 iter/s, 14.2758s/100 iters), loss = 0.007476
I0414 06:21:32.377504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:21:32.377504 17564 solver.cpp:238]     Train net output #1: loss = 0.00747608 (* 1 = 0.00747608 loss)
I0414 06:21:32.377504 17564 sgd_solver.cpp:105] Iteration 25400, lr = 0.0001
I0414 06:21:46.659504 17564 solver.cpp:219] Iteration 25500 (7.00197 iter/s, 14.2817s/100 iters), loss = 0.0132247
I0414 06:21:46.659504 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:21:46.659504 17564 solver.cpp:238]     Train net output #1: loss = 0.0132248 (* 1 = 0.0132248 loss)
I0414 06:21:46.659504 17564 sgd_solver.cpp:105] Iteration 25500, lr = 0.0001
I0414 06:22:00.917505 17564 solver.cpp:219] Iteration 25600 (7.01375 iter/s, 14.2577s/100 iters), loss = 0.00526377
I0414 06:22:00.917505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:22:00.917505 17564 solver.cpp:238]     Train net output #1: loss = 0.00526385 (* 1 = 0.00526385 loss)
I0414 06:22:00.917505 17564 sgd_solver.cpp:105] Iteration 25600, lr = 0.0001
I0414 06:22:15.210505 17564 solver.cpp:219] Iteration 25700 (6.99713 iter/s, 14.2916s/100 iters), loss = 0.00597817
I0414 06:22:15.210505 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:22:15.210505 17564 solver.cpp:238]     Train net output #1: loss = 0.00597825 (* 1 = 0.00597825 loss)
I0414 06:22:15.210505 17564 sgd_solver.cpp:105] Iteration 25700, lr = 0.0001
I0414 06:22:28.769505 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:22:29.338505 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_25800.caffemodel
I0414 06:22:29.477505 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_25800.solverstate
I0414 06:22:29.750934 17564 solver.cpp:331] Iteration 25800, Testing net (#0)
I0414 06:22:29.750934 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:22:33.679940 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:22:33.841919 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:22:33.841919 17564 solver.cpp:398]     Test net output #1: loss = 0.0140427 (* 1 = 0.0140427 loss)
I0414 06:22:33.980932 17564 solver.cpp:219] Iteration 25800 (5.32772 iter/s, 18.7698s/100 iters), loss = 0.00655035
I0414 06:22:33.980932 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:22:33.980932 17564 solver.cpp:238]     Train net output #1: loss = 0.00655043 (* 1 = 0.00655043 loss)
I0414 06:22:33.980932 17564 sgd_solver.cpp:105] Iteration 25800, lr = 0.0001
I0414 06:22:48.245934 17564 solver.cpp:219] Iteration 25900 (7.01025 iter/s, 14.2648s/100 iters), loss = 0.00853302
I0414 06:22:48.245934 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:22:48.245934 17564 solver.cpp:238]     Train net output #1: loss = 0.0085331 (* 1 = 0.0085331 loss)
I0414 06:22:48.245934 17564 sgd_solver.cpp:105] Iteration 25900, lr = 0.0001
I0414 06:23:02.517984 17564 solver.cpp:219] Iteration 26000 (7.00712 iter/s, 14.2712s/100 iters), loss = 0.0153518
I0414 06:23:02.517984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:23:02.517984 17564 solver.cpp:238]     Train net output #1: loss = 0.0153519 (* 1 = 0.0153519 loss)
I0414 06:23:02.517984 17564 sgd_solver.cpp:105] Iteration 26000, lr = 0.0001
I0414 06:23:16.796983 17564 solver.cpp:219] Iteration 26100 (7.00372 iter/s, 14.2781s/100 iters), loss = 0.0115245
I0414 06:23:16.796983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:23:16.796983 17564 solver.cpp:238]     Train net output #1: loss = 0.0115246 (* 1 = 0.0115246 loss)
I0414 06:23:16.796983 17564 sgd_solver.cpp:105] Iteration 26100, lr = 0.0001
I0414 06:23:31.069983 17564 solver.cpp:219] Iteration 26200 (7.00649 iter/s, 14.2725s/100 iters), loss = 0.0049117
I0414 06:23:31.069983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:23:31.069983 17564 solver.cpp:238]     Train net output #1: loss = 0.00491179 (* 1 = 0.00491179 loss)
I0414 06:23:31.069983 17564 sgd_solver.cpp:105] Iteration 26200, lr = 0.0001
I0414 06:23:45.349982 17564 solver.cpp:219] Iteration 26300 (7.00291 iter/s, 14.2798s/100 iters), loss = 0.00440815
I0414 06:23:45.349982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:23:45.349982 17564 solver.cpp:238]     Train net output #1: loss = 0.00440824 (* 1 = 0.00440824 loss)
I0414 06:23:45.349982 17564 sgd_solver.cpp:105] Iteration 26300, lr = 0.0001
I0414 06:23:58.912983 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:23:59.482983 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_26400.caffemodel
I0414 06:23:59.623984 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_26400.solverstate
I0414 06:23:59.691984 17564 solver.cpp:331] Iteration 26400, Testing net (#0)
I0414 06:23:59.692986 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:24:03.617985 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:24:03.778982 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:24:03.778982 17564 solver.cpp:398]     Test net output #1: loss = 0.0140799 (* 1 = 0.0140799 loss)
I0414 06:24:03.918984 17564 solver.cpp:219] Iteration 26400 (5.38548 iter/s, 18.5685s/100 iters), loss = 0.00775807
I0414 06:24:03.918984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:24:03.918984 17564 solver.cpp:238]     Train net output #1: loss = 0.00775814 (* 1 = 0.00775814 loss)
I0414 06:24:03.918984 17564 sgd_solver.cpp:105] Iteration 26400, lr = 0.0001
I0414 06:24:18.174983 17564 solver.cpp:219] Iteration 26500 (7.01479 iter/s, 14.2556s/100 iters), loss = 0.0121456
I0414 06:24:18.174983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:24:18.174983 17564 solver.cpp:238]     Train net output #1: loss = 0.0121457 (* 1 = 0.0121457 loss)
I0414 06:24:18.174983 17564 sgd_solver.cpp:105] Iteration 26500, lr = 0.0001
I0414 06:24:32.438982 17564 solver.cpp:219] Iteration 26600 (7.01117 iter/s, 14.263s/100 iters), loss = 0.00907232
I0414 06:24:32.438982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:24:32.438982 17564 solver.cpp:238]     Train net output #1: loss = 0.0090724 (* 1 = 0.0090724 loss)
I0414 06:24:32.438982 17564 sgd_solver.cpp:105] Iteration 26600, lr = 0.0001
I0414 06:24:46.692982 17564 solver.cpp:219] Iteration 26700 (7.01569 iter/s, 14.2538s/100 iters), loss = 0.00594473
I0414 06:24:46.692982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:24:46.692982 17564 solver.cpp:238]     Train net output #1: loss = 0.00594482 (* 1 = 0.00594482 loss)
I0414 06:24:46.692982 17564 sgd_solver.cpp:105] Iteration 26700, lr = 0.0001
I0414 06:25:00.946982 17564 solver.cpp:219] Iteration 26800 (7.0156 iter/s, 14.254s/100 iters), loss = 0.00386583
I0414 06:25:00.947983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:25:00.947983 17564 solver.cpp:238]     Train net output #1: loss = 0.00386591 (* 1 = 0.00386591 loss)
I0414 06:25:00.947983 17564 sgd_solver.cpp:105] Iteration 26800, lr = 0.0001
I0414 06:25:15.228982 17564 solver.cpp:219] Iteration 26900 (7.0021 iter/s, 14.2814s/100 iters), loss = 0.00957935
I0414 06:25:15.228982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:25:15.228982 17564 solver.cpp:238]     Train net output #1: loss = 0.00957943 (* 1 = 0.00957943 loss)
I0414 06:25:15.229984 17564 sgd_solver.cpp:105] Iteration 26900, lr = 0.0001
I0414 06:25:28.773983 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:25:29.341984 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_27000.caffemodel
I0414 06:25:29.477984 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_27000.solverstate
I0414 06:25:29.553983 17564 solver.cpp:331] Iteration 27000, Testing net (#0)
I0414 06:25:29.553983 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:25:33.475985 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:25:33.637986 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:25:33.637986 17564 solver.cpp:398]     Test net output #1: loss = 0.0140961 (* 1 = 0.0140961 loss)
I0414 06:25:33.775982 17564 solver.cpp:219] Iteration 27000 (5.39189 iter/s, 18.5464s/100 iters), loss = 0.00572087
I0414 06:25:33.775982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:25:33.775982 17564 solver.cpp:238]     Train net output #1: loss = 0.00572095 (* 1 = 0.00572095 loss)
I0414 06:25:33.775982 17564 sgd_solver.cpp:105] Iteration 27000, lr = 0.0001
I0414 06:25:48.040982 17564 solver.cpp:219] Iteration 27100 (7.01048 iter/s, 14.2644s/100 iters), loss = 0.0144622
I0414 06:25:48.040982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:25:48.040982 17564 solver.cpp:238]     Train net output #1: loss = 0.0144623 (* 1 = 0.0144623 loss)
I0414 06:25:48.040982 17564 sgd_solver.cpp:105] Iteration 27100, lr = 0.0001
I0414 06:26:02.329983 17564 solver.cpp:219] Iteration 27200 (6.99893 iter/s, 14.2879s/100 iters), loss = 0.00802498
I0414 06:26:02.329983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:26:02.329983 17564 solver.cpp:238]     Train net output #1: loss = 0.00802505 (* 1 = 0.00802505 loss)
I0414 06:26:02.329983 17564 sgd_solver.cpp:105] Iteration 27200, lr = 0.0001
I0414 06:26:16.598983 17564 solver.cpp:219] Iteration 27300 (7.00842 iter/s, 14.2685s/100 iters), loss = 0.0151035
I0414 06:26:16.598983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:26:16.598983 17564 solver.cpp:238]     Train net output #1: loss = 0.0151035 (* 1 = 0.0151035 loss)
I0414 06:26:16.598983 17564 sgd_solver.cpp:105] Iteration 27300, lr = 0.0001
I0414 06:26:30.865983 17564 solver.cpp:219] Iteration 27400 (7.00955 iter/s, 14.2663s/100 iters), loss = 0.00573537
I0414 06:26:30.865983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:26:30.865983 17564 solver.cpp:238]     Train net output #1: loss = 0.00573545 (* 1 = 0.00573545 loss)
I0414 06:26:30.865983 17564 sgd_solver.cpp:105] Iteration 27400, lr = 0.0001
I0414 06:26:45.131983 17564 solver.cpp:219] Iteration 27500 (7.00962 iter/s, 14.2661s/100 iters), loss = 0.0038987
I0414 06:26:45.132984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:26:45.132984 17564 solver.cpp:238]     Train net output #1: loss = 0.00389878 (* 1 = 0.00389878 loss)
I0414 06:26:45.132984 17564 sgd_solver.cpp:105] Iteration 27500, lr = 0.0001
I0414 06:26:58.700984 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:26:59.271983 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_27600.caffemodel
I0414 06:26:59.423007 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_27600.solverstate
I0414 06:26:59.490986 17564 solver.cpp:331] Iteration 27600, Testing net (#0)
I0414 06:26:59.491986 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:27:03.415983 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:27:03.578985 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:27:03.578985 17564 solver.cpp:398]     Test net output #1: loss = 0.0140561 (* 1 = 0.0140561 loss)
I0414 06:27:03.717002 17564 solver.cpp:219] Iteration 27600 (5.38093 iter/s, 18.5841s/100 iters), loss = 0.00893679
I0414 06:27:03.717002 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:27:03.717002 17564 solver.cpp:238]     Train net output #1: loss = 0.00893686 (* 1 = 0.00893686 loss)
I0414 06:27:03.717002 17564 sgd_solver.cpp:105] Iteration 27600, lr = 0.0001
I0414 06:27:17.986984 17564 solver.cpp:219] Iteration 27700 (7.00824 iter/s, 14.2689s/100 iters), loss = 0.00623211
I0414 06:27:17.986984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:27:17.986984 17564 solver.cpp:238]     Train net output #1: loss = 0.00623218 (* 1 = 0.00623218 loss)
I0414 06:27:17.986984 17564 sgd_solver.cpp:105] Iteration 27700, lr = 0.0001
I0414 06:27:32.245982 17564 solver.cpp:219] Iteration 27800 (7.0132 iter/s, 14.2588s/100 iters), loss = 0.0131781
I0414 06:27:32.245982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:27:32.245982 17564 solver.cpp:238]     Train net output #1: loss = 0.0131782 (* 1 = 0.0131782 loss)
I0414 06:27:32.245982 17564 sgd_solver.cpp:105] Iteration 27800, lr = 0.0001
I0414 06:27:46.492982 17564 solver.cpp:219] Iteration 27900 (7.01914 iter/s, 14.2468s/100 iters), loss = 0.0084466
I0414 06:27:46.493983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:27:46.493983 17564 solver.cpp:238]     Train net output #1: loss = 0.00844667 (* 1 = 0.00844667 loss)
I0414 06:27:46.493983 17564 sgd_solver.cpp:105] Iteration 27900, lr = 0.0001
I0414 06:28:00.743998 17564 solver.cpp:219] Iteration 28000 (7.01755 iter/s, 14.25s/100 iters), loss = 0.004075
I0414 06:28:00.743998 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:28:00.743998 17564 solver.cpp:238]     Train net output #1: loss = 0.00407507 (* 1 = 0.00407507 loss)
I0414 06:28:00.743998 17564 sgd_solver.cpp:105] Iteration 28000, lr = 0.0001
I0414 06:28:15.015983 17564 solver.cpp:219] Iteration 28100 (7.00698 iter/s, 14.2715s/100 iters), loss = 0.00402899
I0414 06:28:15.015983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:28:15.015983 17564 solver.cpp:238]     Train net output #1: loss = 0.00402907 (* 1 = 0.00402907 loss)
I0414 06:28:15.015983 17564 sgd_solver.cpp:105] Iteration 28100, lr = 0.0001
I0414 06:28:28.568984 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:28:29.137984 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_28200.caffemodel
I0414 06:28:29.276984 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_28200.solverstate
I0414 06:28:29.341984 17564 solver.cpp:331] Iteration 28200, Testing net (#0)
I0414 06:28:29.341984 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:28:33.263984 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:28:33.425986 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9969
I0414 06:28:33.425986 17564 solver.cpp:398]     Test net output #1: loss = 0.0140721 (* 1 = 0.0140721 loss)
I0414 06:28:33.564985 17564 solver.cpp:219] Iteration 28200 (5.39145 iter/s, 18.5479s/100 iters), loss = 0.0102768
I0414 06:28:33.564985 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:28:33.564985 17564 solver.cpp:238]     Train net output #1: loss = 0.0102769 (* 1 = 0.0102769 loss)
I0414 06:28:33.564985 17564 sgd_solver.cpp:105] Iteration 28200, lr = 0.0001
I0414 06:28:47.840982 17564 solver.cpp:219] Iteration 28300 (7.00501 iter/s, 14.2755s/100 iters), loss = 0.00398218
I0414 06:28:47.840982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:28:47.840982 17564 solver.cpp:238]     Train net output #1: loss = 0.00398225 (* 1 = 0.00398225 loss)
I0414 06:28:47.840982 17564 sgd_solver.cpp:105] Iteration 28300, lr = 0.0001
I0414 06:29:02.114986 17564 solver.cpp:219] Iteration 28400 (7.00593 iter/s, 14.2736s/100 iters), loss = 0.0135089
I0414 06:29:02.114986 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:29:02.114986 17564 solver.cpp:238]     Train net output #1: loss = 0.013509 (* 1 = 0.013509 loss)
I0414 06:29:02.114986 17564 sgd_solver.cpp:105] Iteration 28400, lr = 0.0001
I0414 06:29:16.384982 17564 solver.cpp:219] Iteration 28500 (7.00788 iter/s, 14.2696s/100 iters), loss = 0.0198006
I0414 06:29:16.384982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:29:16.384982 17564 solver.cpp:238]     Train net output #1: loss = 0.0198007 (* 1 = 0.0198007 loss)
I0414 06:29:16.384982 17564 sgd_solver.cpp:105] Iteration 28500, lr = 0.0001
I0414 06:29:30.632983 17564 solver.cpp:219] Iteration 28600 (7.01873 iter/s, 14.2476s/100 iters), loss = 0.00479044
I0414 06:29:30.632983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:29:30.632983 17564 solver.cpp:238]     Train net output #1: loss = 0.00479051 (* 1 = 0.00479051 loss)
I0414 06:29:30.632983 17564 sgd_solver.cpp:105] Iteration 28600, lr = 0.0001
I0414 06:29:44.898983 17564 solver.cpp:219] Iteration 28700 (7.00997 iter/s, 14.2654s/100 iters), loss = 0.00437431
I0414 06:29:44.898983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:29:44.898983 17564 solver.cpp:238]     Train net output #1: loss = 0.00437438 (* 1 = 0.00437438 loss)
I0414 06:29:44.898983 17564 sgd_solver.cpp:105] Iteration 28700, lr = 0.0001
I0414 06:29:58.477985 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:29:59.046986 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_28800.caffemodel
I0414 06:29:59.188983 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_28800.solverstate
I0414 06:29:59.255983 17564 solver.cpp:331] Iteration 28800, Testing net (#0)
I0414 06:29:59.255983 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:30:03.176985 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:30:03.338984 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:30:03.338984 17564 solver.cpp:398]     Test net output #1: loss = 0.0140891 (* 1 = 0.0140891 loss)
I0414 06:30:03.476984 17564 solver.cpp:219] Iteration 28800 (5.38286 iter/s, 18.5775s/100 iters), loss = 0.005536
I0414 06:30:03.476984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:30:03.476984 17564 solver.cpp:238]     Train net output #1: loss = 0.00553607 (* 1 = 0.00553607 loss)
I0414 06:30:03.476984 17564 sgd_solver.cpp:105] Iteration 28800, lr = 0.0001
I0414 06:30:17.756002 17564 solver.cpp:219] Iteration 28900 (7.00386 iter/s, 14.2779s/100 iters), loss = 0.011145
I0414 06:30:17.756002 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:30:17.756002 17564 solver.cpp:238]     Train net output #1: loss = 0.0111451 (* 1 = 0.0111451 loss)
I0414 06:30:17.756002 17564 sgd_solver.cpp:105] Iteration 28900, lr = 0.0001
I0414 06:30:32.045984 17564 solver.cpp:219] Iteration 29000 (6.99818 iter/s, 14.2894s/100 iters), loss = 0.00741216
I0414 06:30:32.045984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:30:32.045984 17564 solver.cpp:238]     Train net output #1: loss = 0.00741224 (* 1 = 0.00741224 loss)
I0414 06:30:32.045984 17564 sgd_solver.cpp:105] Iteration 29000, lr = 0.0001
I0414 06:30:46.332983 17564 solver.cpp:219] Iteration 29100 (6.99977 iter/s, 14.2862s/100 iters), loss = 0.00783317
I0414 06:30:46.332983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:30:46.332983 17564 solver.cpp:238]     Train net output #1: loss = 0.00783325 (* 1 = 0.00783325 loss)
I0414 06:30:46.332983 17564 sgd_solver.cpp:105] Iteration 29100, lr = 0.0001
I0414 06:31:00.634984 17564 solver.cpp:219] Iteration 29200 (6.99195 iter/s, 14.3022s/100 iters), loss = 0.00436144
I0414 06:31:00.634984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:31:00.634984 17564 solver.cpp:238]     Train net output #1: loss = 0.00436152 (* 1 = 0.00436152 loss)
I0414 06:31:00.635983 17564 sgd_solver.cpp:105] Iteration 29200, lr = 0.0001
I0414 06:31:14.928982 17564 solver.cpp:219] Iteration 29300 (6.99629 iter/s, 14.2933s/100 iters), loss = 0.00458651
I0414 06:31:14.928982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:31:14.928982 17564 solver.cpp:238]     Train net output #1: loss = 0.00458659 (* 1 = 0.00458659 loss)
I0414 06:31:14.928982 17564 sgd_solver.cpp:105] Iteration 29300, lr = 0.0001
I0414 06:31:28.525984 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:31:29.095993 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_29400.caffemodel
I0414 06:31:29.236991 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_29400.solverstate
I0414 06:31:29.310983 17564 solver.cpp:331] Iteration 29400, Testing net (#0)
I0414 06:31:29.310983 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:31:33.226984 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:31:33.388983 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:31:33.388983 17564 solver.cpp:398]     Test net output #1: loss = 0.0140591 (* 1 = 0.0140591 loss)
I0414 06:31:33.527982 17564 solver.cpp:219] Iteration 29400 (5.37684 iter/s, 18.5983s/100 iters), loss = 0.0111289
I0414 06:31:33.527982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:31:33.527982 17564 solver.cpp:238]     Train net output #1: loss = 0.011129 (* 1 = 0.011129 loss)
I0414 06:31:33.527982 17564 sgd_solver.cpp:105] Iteration 29400, lr = 0.0001
I0414 06:31:47.842983 17564 solver.cpp:219] Iteration 29500 (6.98602 iter/s, 14.3143s/100 iters), loss = 0.0123572
I0414 06:31:47.842983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:31:47.842983 17564 solver.cpp:238]     Train net output #1: loss = 0.0123573 (* 1 = 0.0123573 loss)
I0414 06:31:47.842983 17564 sgd_solver.cpp:105] Iteration 29500, lr = 0.0001
I0414 06:32:02.136982 17564 solver.cpp:219] Iteration 29600 (6.99648 iter/s, 14.2929s/100 iters), loss = 0.0281714
I0414 06:32:02.136982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:32:02.136982 17564 solver.cpp:238]     Train net output #1: loss = 0.0281715 (* 1 = 0.0281715 loss)
I0414 06:32:02.136982 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 29600, step = 4
I0414 06:32:02.136982 17564 sgd_solver.cpp:105] Iteration 29600, lr = 1e-05
I0414 06:32:16.427983 17564 solver.cpp:219] Iteration 29700 (6.99731 iter/s, 14.2912s/100 iters), loss = 0.0152393
I0414 06:32:16.427983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:32:16.427983 17564 solver.cpp:238]     Train net output #1: loss = 0.0152394 (* 1 = 0.0152394 loss)
I0414 06:32:16.428983 17564 sgd_solver.cpp:105] Iteration 29700, lr = 1e-05
I0414 06:32:30.691982 17564 solver.cpp:219] Iteration 29800 (7.011 iter/s, 14.2633s/100 iters), loss = 0.008008
I0414 06:32:30.691982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:32:30.691982 17564 solver.cpp:238]     Train net output #1: loss = 0.00800807 (* 1 = 0.00800807 loss)
I0414 06:32:30.691982 17564 sgd_solver.cpp:105] Iteration 29800, lr = 1e-05
I0414 06:32:44.939996 17564 solver.cpp:219] Iteration 29900 (7.01875 iter/s, 14.2476s/100 iters), loss = 0.00411325
I0414 06:32:44.939996 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:32:44.939996 17564 solver.cpp:238]     Train net output #1: loss = 0.00411331 (* 1 = 0.00411331 loss)
I0414 06:32:44.939996 17564 sgd_solver.cpp:105] Iteration 29900, lr = 1e-05
I0414 06:32:58.500983 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:32:59.069983 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_30000.caffemodel
I0414 06:32:59.208984 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_30000.solverstate
I0414 06:32:59.272984 17564 solver.cpp:331] Iteration 30000, Testing net (#0)
I0414 06:32:59.272984 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:33:03.199985 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:33:03.361984 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:33:03.361984 17564 solver.cpp:398]     Test net output #1: loss = 0.0140575 (* 1 = 0.0140575 loss)
I0414 06:33:03.500986 17564 solver.cpp:219] Iteration 30000 (5.38803 iter/s, 18.5597s/100 iters), loss = 0.00609391
I0414 06:33:03.500986 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:33:03.500986 17564 solver.cpp:238]     Train net output #1: loss = 0.00609398 (* 1 = 0.00609398 loss)
I0414 06:33:03.500986 17564 sgd_solver.cpp:105] Iteration 30000, lr = 1e-05
I0414 06:33:17.776983 17564 solver.cpp:219] Iteration 30100 (7.00471 iter/s, 14.2761s/100 iters), loss = 0.00979823
I0414 06:33:17.776983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:33:17.776983 17564 solver.cpp:238]     Train net output #1: loss = 0.00979829 (* 1 = 0.00979829 loss)
I0414 06:33:17.776983 17564 sgd_solver.cpp:105] Iteration 30100, lr = 1e-05
I0414 06:33:32.044982 17564 solver.cpp:219] Iteration 30200 (7.00898 iter/s, 14.2674s/100 iters), loss = 0.0082874
I0414 06:33:32.044982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:33:32.044982 17564 solver.cpp:238]     Train net output #1: loss = 0.00828746 (* 1 = 0.00828746 loss)
I0414 06:33:32.044982 17564 sgd_solver.cpp:105] Iteration 30200, lr = 1e-05
I0414 06:33:46.311982 17564 solver.cpp:219] Iteration 30300 (7.00989 iter/s, 14.2656s/100 iters), loss = 0.00964548
I0414 06:33:46.311982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:33:46.311982 17564 solver.cpp:238]     Train net output #1: loss = 0.00964554 (* 1 = 0.00964554 loss)
I0414 06:33:46.311982 17564 sgd_solver.cpp:105] Iteration 30300, lr = 1e-05
I0414 06:34:00.575983 17564 solver.cpp:219] Iteration 30400 (7.01091 iter/s, 14.2635s/100 iters), loss = 0.00362176
I0414 06:34:00.575983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:34:00.575983 17564 solver.cpp:238]     Train net output #1: loss = 0.00362182 (* 1 = 0.00362182 loss)
I0414 06:34:00.575983 17564 sgd_solver.cpp:105] Iteration 30400, lr = 1e-05
I0414 06:34:14.855983 17564 solver.cpp:219] Iteration 30500 (7.00281 iter/s, 14.28s/100 iters), loss = 0.00629956
I0414 06:34:14.855983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:34:14.855983 17564 solver.cpp:238]     Train net output #1: loss = 0.00629962 (* 1 = 0.00629962 loss)
I0414 06:34:14.855983 17564 sgd_solver.cpp:105] Iteration 30500, lr = 1e-05
I0414 06:34:28.416983 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:34:28.983983 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_30600.caffemodel
I0414 06:34:29.122988 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_30600.solverstate
I0414 06:34:29.187985 17564 solver.cpp:331] Iteration 30600, Testing net (#0)
I0414 06:34:29.187985 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:34:33.107985 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:34:33.269984 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:34:33.269984 17564 solver.cpp:398]     Test net output #1: loss = 0.0140863 (* 1 = 0.0140863 loss)
I0414 06:34:33.407982 17564 solver.cpp:219] Iteration 30600 (5.39035 iter/s, 18.5517s/100 iters), loss = 0.00883728
I0414 06:34:33.407982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:34:33.407982 17564 solver.cpp:238]     Train net output #1: loss = 0.00883734 (* 1 = 0.00883734 loss)
I0414 06:34:33.407982 17564 sgd_solver.cpp:105] Iteration 30600, lr = 1e-05
I0414 06:34:47.670984 17564 solver.cpp:219] Iteration 30700 (7.01158 iter/s, 14.2621s/100 iters), loss = 0.0175655
I0414 06:34:47.670984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:34:47.670984 17564 solver.cpp:238]     Train net output #1: loss = 0.0175655 (* 1 = 0.0175655 loss)
I0414 06:34:47.670984 17564 sgd_solver.cpp:105] Iteration 30700, lr = 1e-05
I0414 06:35:01.940982 17564 solver.cpp:219] Iteration 30800 (7.00815 iter/s, 14.2691s/100 iters), loss = 0.0226499
I0414 06:35:01.940982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:35:01.940982 17564 solver.cpp:238]     Train net output #1: loss = 0.02265 (* 1 = 0.02265 loss)
I0414 06:35:01.940982 17564 sgd_solver.cpp:105] Iteration 30800, lr = 1e-05
I0414 06:35:16.216982 17564 solver.cpp:219] Iteration 30900 (7.00496 iter/s, 14.2756s/100 iters), loss = 0.00973365
I0414 06:35:16.216982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:35:16.216982 17564 solver.cpp:238]     Train net output #1: loss = 0.00973371 (* 1 = 0.00973371 loss)
I0414 06:35:16.216982 17564 sgd_solver.cpp:105] Iteration 30900, lr = 1e-05
I0414 06:35:30.483983 17564 solver.cpp:219] Iteration 31000 (7.00957 iter/s, 14.2662s/100 iters), loss = 0.0037955
I0414 06:35:30.483983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:35:30.483983 17564 solver.cpp:238]     Train net output #1: loss = 0.00379556 (* 1 = 0.00379556 loss)
I0414 06:35:30.483983 17564 sgd_solver.cpp:105] Iteration 31000, lr = 1e-05
I0414 06:35:44.748982 17564 solver.cpp:219] Iteration 31100 (7.0101 iter/s, 14.2651s/100 iters), loss = 0.00642594
I0414 06:35:44.748982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:35:44.748982 17564 solver.cpp:238]     Train net output #1: loss = 0.006426 (* 1 = 0.006426 loss)
I0414 06:35:44.748982 17564 sgd_solver.cpp:105] Iteration 31100, lr = 1e-05
I0414 06:35:58.306982 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:35:58.874984 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_31200.caffemodel
I0414 06:35:59.017983 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_31200.solverstate
I0414 06:35:59.086984 17564 solver.cpp:331] Iteration 31200, Testing net (#0)
I0414 06:35:59.087985 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:36:03.012984 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:36:03.174991 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:36:03.174991 17564 solver.cpp:398]     Test net output #1: loss = 0.0140748 (* 1 = 0.0140748 loss)
I0414 06:36:03.315984 17564 solver.cpp:219] Iteration 31200 (5.3862 iter/s, 18.566s/100 iters), loss = 0.00908739
I0414 06:36:03.315984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:36:03.315984 17564 solver.cpp:238]     Train net output #1: loss = 0.00908746 (* 1 = 0.00908746 loss)
I0414 06:36:03.315984 17564 sgd_solver.cpp:105] Iteration 31200, lr = 1e-05
I0414 06:36:17.594982 17564 solver.cpp:219] Iteration 31300 (7.00348 iter/s, 14.2786s/100 iters), loss = 0.0113898
I0414 06:36:17.594982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:36:17.594982 17564 solver.cpp:238]     Train net output #1: loss = 0.0113898 (* 1 = 0.0113898 loss)
I0414 06:36:17.594982 17564 sgd_solver.cpp:105] Iteration 31300, lr = 1e-05
I0414 06:36:31.875982 17564 solver.cpp:219] Iteration 31400 (7.00256 iter/s, 14.2805s/100 iters), loss = 0.0150404
I0414 06:36:31.875982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:36:31.875982 17564 solver.cpp:238]     Train net output #1: loss = 0.0150405 (* 1 = 0.0150405 loss)
I0414 06:36:31.875982 17564 sgd_solver.cpp:105] Iteration 31400, lr = 1e-05
I0414 06:36:46.147982 17564 solver.cpp:219] Iteration 31500 (7.00727 iter/s, 14.2709s/100 iters), loss = 0.0134632
I0414 06:36:46.147982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:36:46.147982 17564 solver.cpp:238]     Train net output #1: loss = 0.0134633 (* 1 = 0.0134633 loss)
I0414 06:36:46.147982 17564 sgd_solver.cpp:105] Iteration 31500, lr = 1e-05
I0414 06:37:00.419982 17564 solver.cpp:219] Iteration 31600 (7.00687 iter/s, 14.2717s/100 iters), loss = 0.0073982
I0414 06:37:00.419982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:37:00.419982 17564 solver.cpp:238]     Train net output #1: loss = 0.00739827 (* 1 = 0.00739827 loss)
I0414 06:37:00.419982 17564 sgd_solver.cpp:105] Iteration 31600, lr = 1e-05
I0414 06:37:14.696982 17564 solver.cpp:219] Iteration 31700 (7.00447 iter/s, 14.2766s/100 iters), loss = 0.00355368
I0414 06:37:14.696982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:37:14.696982 17564 solver.cpp:238]     Train net output #1: loss = 0.00355374 (* 1 = 0.00355374 loss)
I0414 06:37:14.696982 17564 sgd_solver.cpp:105] Iteration 31700, lr = 1e-05
I0414 06:37:28.252002 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:37:28.819983 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_31800.caffemodel
I0414 06:37:28.958983 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_31800.solverstate
I0414 06:37:29.028983 17564 solver.cpp:331] Iteration 31800, Testing net (#0)
I0414 06:37:29.028983 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:37:32.947984 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:37:33.109983 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:37:33.109983 17564 solver.cpp:398]     Test net output #1: loss = 0.0140449 (* 1 = 0.0140449 loss)
I0414 06:37:33.248982 17564 solver.cpp:219] Iteration 31800 (5.39044 iter/s, 18.5514s/100 iters), loss = 0.00429972
I0414 06:37:33.248982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:37:33.248982 17564 solver.cpp:238]     Train net output #1: loss = 0.00429979 (* 1 = 0.00429979 loss)
I0414 06:37:33.248982 17564 sgd_solver.cpp:105] Iteration 31800, lr = 1e-05
I0414 06:37:47.525982 17564 solver.cpp:219] Iteration 31900 (7.00456 iter/s, 14.2764s/100 iters), loss = 0.00629057
I0414 06:37:47.525982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:37:47.525982 17564 solver.cpp:238]     Train net output #1: loss = 0.00629064 (* 1 = 0.00629064 loss)
I0414 06:37:47.525982 17564 sgd_solver.cpp:105] Iteration 31900, lr = 1e-05
I0414 06:38:01.796003 17564 solver.cpp:219] Iteration 32000 (7.0081 iter/s, 14.2692s/100 iters), loss = 0.0240448
I0414 06:38:01.796003 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:38:01.796003 17564 solver.cpp:238]     Train net output #1: loss = 0.0240449 (* 1 = 0.0240449 loss)
I0414 06:38:01.796003 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 5
I0414 06:38:01.796003 17564 sgd_solver.cpp:105] Iteration 32000, lr = 1e-06
I0414 06:38:16.059983 17564 solver.cpp:219] Iteration 32100 (7.01076 iter/s, 14.2638s/100 iters), loss = 0.0113692
I0414 06:38:16.059983 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:38:16.059983 17564 solver.cpp:238]     Train net output #1: loss = 0.0113693 (* 1 = 0.0113693 loss)
I0414 06:38:16.059983 17564 sgd_solver.cpp:105] Iteration 32100, lr = 1e-06
I0414 06:38:30.313982 17564 solver.cpp:219] Iteration 32200 (7.01588 iter/s, 14.2534s/100 iters), loss = 0.00432765
I0414 06:38:30.313982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:38:30.313982 17564 solver.cpp:238]     Train net output #1: loss = 0.00432771 (* 1 = 0.00432771 loss)
I0414 06:38:30.313982 17564 sgd_solver.cpp:105] Iteration 32200, lr = 1e-06
I0414 06:38:44.568984 17564 solver.cpp:219] Iteration 32300 (7.01564 iter/s, 14.2539s/100 iters), loss = 0.0056662
I0414 06:38:44.568984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:38:44.568984 17564 solver.cpp:238]     Train net output #1: loss = 0.00566627 (* 1 = 0.00566627 loss)
I0414 06:38:44.568984 17564 sgd_solver.cpp:105] Iteration 32300, lr = 1e-06
I0414 06:38:58.115984 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:38:58.683984 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_32400.caffemodel
I0414 06:38:58.823983 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_32400.solverstate
I0414 06:38:58.889983 17564 solver.cpp:331] Iteration 32400, Testing net (#0)
I0414 06:38:58.889983 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:39:02.815984 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:39:02.978986 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:39:02.978986 17564 solver.cpp:398]     Test net output #1: loss = 0.0140714 (* 1 = 0.0140714 loss)
I0414 06:39:03.117982 17564 solver.cpp:219] Iteration 32400 (5.39126 iter/s, 18.5485s/100 iters), loss = 0.00875843
I0414 06:39:03.117982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:39:03.117982 17564 solver.cpp:238]     Train net output #1: loss = 0.0087585 (* 1 = 0.0087585 loss)
I0414 06:39:03.117982 17564 sgd_solver.cpp:105] Iteration 32400, lr = 1e-06
I0414 06:39:17.384984 17564 solver.cpp:219] Iteration 32500 (7.00952 iter/s, 14.2663s/100 iters), loss = 0.00872423
I0414 06:39:17.384984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:39:17.384984 17564 solver.cpp:238]     Train net output #1: loss = 0.0087243 (* 1 = 0.0087243 loss)
I0414 06:39:17.384984 17564 sgd_solver.cpp:105] Iteration 32500, lr = 1e-06
I0414 06:39:31.656982 17564 solver.cpp:219] Iteration 32600 (7.00684 iter/s, 14.2718s/100 iters), loss = 0.0110037
I0414 06:39:31.656982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:39:31.656982 17564 solver.cpp:238]     Train net output #1: loss = 0.0110037 (* 1 = 0.0110037 loss)
I0414 06:39:31.656982 17564 sgd_solver.cpp:105] Iteration 32600, lr = 1e-06
I0414 06:39:45.922982 17564 solver.cpp:219] Iteration 32700 (7.00974 iter/s, 14.2659s/100 iters), loss = 0.0173452
I0414 06:39:45.923984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:39:45.923984 17564 solver.cpp:238]     Train net output #1: loss = 0.0173453 (* 1 = 0.0173453 loss)
I0414 06:39:45.923984 17564 sgd_solver.cpp:105] Iteration 32700, lr = 1e-06
I0414 06:40:00.189982 17564 solver.cpp:219] Iteration 32800 (7.00987 iter/s, 14.2656s/100 iters), loss = 0.00406033
I0414 06:40:00.189982 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:40:00.189982 17564 solver.cpp:238]     Train net output #1: loss = 0.00406039 (* 1 = 0.00406039 loss)
I0414 06:40:00.189982 17564 sgd_solver.cpp:105] Iteration 32800, lr = 1e-06
I0414 06:40:14.473984 17564 solver.cpp:219] Iteration 32900 (7.00074 iter/s, 14.2842s/100 iters), loss = 0.00361808
I0414 06:40:14.473984 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:40:14.473984 17564 solver.cpp:238]     Train net output #1: loss = 0.00361815 (* 1 = 0.00361815 loss)
I0414 06:40:14.473984 17564 sgd_solver.cpp:105] Iteration 32900, lr = 1e-06
I0414 06:40:28.029043 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:40:28.596045 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_33000.caffemodel
I0414 06:40:28.740048 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_33000.solverstate
I0414 06:40:28.804045 17564 solver.cpp:331] Iteration 33000, Testing net (#0)
I0414 06:40:28.804045 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:40:32.724043 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:40:32.885043 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:40:32.885043 17564 solver.cpp:398]     Test net output #1: loss = 0.014073 (* 1 = 0.014073 loss)
I0414 06:40:33.024042 17564 solver.cpp:219] Iteration 33000 (5.39106 iter/s, 18.5492s/100 iters), loss = 0.00561976
I0414 06:40:33.024042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:40:33.024042 17564 solver.cpp:238]     Train net output #1: loss = 0.00561984 (* 1 = 0.00561984 loss)
I0414 06:40:33.024042 17564 sgd_solver.cpp:105] Iteration 33000, lr = 1e-06
I0414 06:40:47.293042 17564 solver.cpp:219] Iteration 33100 (7.00881 iter/s, 14.2678s/100 iters), loss = 0.00529699
I0414 06:40:47.293042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:40:47.293042 17564 solver.cpp:238]     Train net output #1: loss = 0.00529705 (* 1 = 0.00529705 loss)
I0414 06:40:47.293042 17564 sgd_solver.cpp:105] Iteration 33100, lr = 1e-06
I0414 06:41:01.558043 17564 solver.cpp:219] Iteration 33200 (7.01033 iter/s, 14.2647s/100 iters), loss = 0.0142128
I0414 06:41:01.558043 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:41:01.558043 17564 solver.cpp:238]     Train net output #1: loss = 0.0142129 (* 1 = 0.0142129 loss)
I0414 06:41:01.558043 17564 sgd_solver.cpp:105] Iteration 33200, lr = 1e-06
I0414 06:41:15.832042 17564 solver.cpp:219] Iteration 33300 (7.00594 iter/s, 14.2736s/100 iters), loss = 0.020034
I0414 06:41:15.832042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:41:15.832042 17564 solver.cpp:238]     Train net output #1: loss = 0.0200341 (* 1 = 0.0200341 loss)
I0414 06:41:15.832042 17564 sgd_solver.cpp:105] Iteration 33300, lr = 1e-06
I0414 06:41:30.093042 17564 solver.cpp:219] Iteration 33400 (7.01259 iter/s, 14.2601s/100 iters), loss = 0.00532133
I0414 06:41:30.093042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:41:30.093042 17564 solver.cpp:238]     Train net output #1: loss = 0.0053214 (* 1 = 0.0053214 loss)
I0414 06:41:30.093042 17564 sgd_solver.cpp:105] Iteration 33400, lr = 1e-06
I0414 06:41:44.352042 17564 solver.cpp:219] Iteration 33500 (7.01318 iter/s, 14.2589s/100 iters), loss = 0.00284509
I0414 06:41:44.352042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:41:44.352042 17564 solver.cpp:238]     Train net output #1: loss = 0.00284516 (* 1 = 0.00284516 loss)
I0414 06:41:44.352042 17564 sgd_solver.cpp:105] Iteration 33500, lr = 1e-06
I0414 06:41:57.903053 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:41:58.472044 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_33600.caffemodel
I0414 06:41:58.609046 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_33600.solverstate
I0414 06:41:58.676045 17564 solver.cpp:331] Iteration 33600, Testing net (#0)
I0414 06:41:58.676045 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:42:02.601043 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:42:02.763043 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:42:02.763043 17564 solver.cpp:398]     Test net output #1: loss = 0.0141064 (* 1 = 0.0141064 loss)
I0414 06:42:02.903064 17564 solver.cpp:219] Iteration 33600 (5.39085 iter/s, 18.5499s/100 iters), loss = 0.00907978
I0414 06:42:02.903064 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:42:02.903064 17564 solver.cpp:238]     Train net output #1: loss = 0.00907985 (* 1 = 0.00907985 loss)
I0414 06:42:02.903064 17564 sgd_solver.cpp:105] Iteration 33600, lr = 1e-06
I0414 06:42:17.176043 17564 solver.cpp:219] Iteration 33700 (7.00639 iter/s, 14.2727s/100 iters), loss = 0.0118986
I0414 06:42:17.176043 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:42:17.176043 17564 solver.cpp:238]     Train net output #1: loss = 0.0118986 (* 1 = 0.0118986 loss)
I0414 06:42:17.176043 17564 sgd_solver.cpp:105] Iteration 33700, lr = 1e-06
I0414 06:42:31.438042 17564 solver.cpp:219] Iteration 33800 (7.01169 iter/s, 14.2619s/100 iters), loss = 0.00907106
I0414 06:42:31.438042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:42:31.438042 17564 solver.cpp:238]     Train net output #1: loss = 0.00907113 (* 1 = 0.00907113 loss)
I0414 06:42:31.438042 17564 sgd_solver.cpp:105] Iteration 33800, lr = 1e-06
I0414 06:42:45.702042 17564 solver.cpp:219] Iteration 33900 (7.01088 iter/s, 14.2635s/100 iters), loss = 0.0143848
I0414 06:42:45.703042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:42:45.703042 17564 solver.cpp:238]     Train net output #1: loss = 0.0143848 (* 1 = 0.0143848 loss)
I0414 06:42:45.703042 17564 sgd_solver.cpp:105] Iteration 33900, lr = 1e-06
I0414 06:42:59.958042 17564 solver.cpp:219] Iteration 34000 (7.01509 iter/s, 14.255s/100 iters), loss = 0.00500468
I0414 06:42:59.958042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:42:59.958042 17564 solver.cpp:238]     Train net output #1: loss = 0.00500475 (* 1 = 0.00500475 loss)
I0414 06:42:59.958042 17564 sgd_solver.cpp:105] Iteration 34000, lr = 1e-06
I0414 06:43:14.234042 17564 solver.cpp:219] Iteration 34100 (7.00519 iter/s, 14.2751s/100 iters), loss = 0.0038439
I0414 06:43:14.234042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:43:14.234042 17564 solver.cpp:238]     Train net output #1: loss = 0.00384397 (* 1 = 0.00384397 loss)
I0414 06:43:14.234042 17564 sgd_solver.cpp:105] Iteration 34100, lr = 1e-06
I0414 06:43:27.786043 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:43:28.354043 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_34200.caffemodel
I0414 06:43:28.493042 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_34200.solverstate
I0414 06:43:28.559044 17564 solver.cpp:331] Iteration 34200, Testing net (#0)
I0414 06:43:28.559044 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:43:32.479044 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:43:32.641062 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:43:32.641062 17564 solver.cpp:398]     Test net output #1: loss = 0.0140497 (* 1 = 0.0140497 loss)
I0414 06:43:32.780042 17564 solver.cpp:219] Iteration 34200 (5.39208 iter/s, 18.5457s/100 iters), loss = 0.00975166
I0414 06:43:32.780042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:43:32.780042 17564 solver.cpp:238]     Train net output #1: loss = 0.00975172 (* 1 = 0.00975172 loss)
I0414 06:43:32.780042 17564 sgd_solver.cpp:105] Iteration 34200, lr = 1e-06
I0414 06:43:47.052042 17564 solver.cpp:219] Iteration 34300 (7.00699 iter/s, 14.2715s/100 iters), loss = 0.0173202
I0414 06:43:47.052042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:43:47.052042 17564 solver.cpp:238]     Train net output #1: loss = 0.0173203 (* 1 = 0.0173203 loss)
I0414 06:43:47.052042 17564 sgd_solver.cpp:105] Iteration 34300, lr = 1e-06
I0414 06:44:01.314044 17564 solver.cpp:219] Iteration 34400 (7.01183 iter/s, 14.2616s/100 iters), loss = 0.0148111
I0414 06:44:01.314044 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:44:01.314044 17564 solver.cpp:238]     Train net output #1: loss = 0.0148112 (* 1 = 0.0148112 loss)
I0414 06:44:01.314044 17564 sgd_solver.cpp:105] Iteration 34400, lr = 1e-06
I0414 06:44:15.598043 17564 solver.cpp:219] Iteration 34500 (7.00135 iter/s, 14.283s/100 iters), loss = 0.00789556
I0414 06:44:15.598043 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:44:15.598043 17564 solver.cpp:238]     Train net output #1: loss = 0.00789563 (* 1 = 0.00789563 loss)
I0414 06:44:15.598043 17564 sgd_solver.cpp:105] Iteration 34500, lr = 1e-06
I0414 06:44:29.869042 17564 solver.cpp:219] Iteration 34600 (7.00732 iter/s, 14.2708s/100 iters), loss = 0.005495
I0414 06:44:29.869042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:44:29.869042 17564 solver.cpp:238]     Train net output #1: loss = 0.00549507 (* 1 = 0.00549507 loss)
I0414 06:44:29.869042 17564 sgd_solver.cpp:105] Iteration 34600, lr = 1e-06
I0414 06:44:44.137042 17564 solver.cpp:219] Iteration 34700 (7.00887 iter/s, 14.2676s/100 iters), loss = 0.00635493
I0414 06:44:44.137042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:44:44.137042 17564 solver.cpp:238]     Train net output #1: loss = 0.006355 (* 1 = 0.006355 loss)
I0414 06:44:44.137042 17564 sgd_solver.cpp:105] Iteration 34700, lr = 1e-06
I0414 06:44:57.691042 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:44:58.261044 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_34800.caffemodel
I0414 06:44:58.399044 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_34800.solverstate
I0414 06:44:58.465044 17564 solver.cpp:331] Iteration 34800, Testing net (#0)
I0414 06:44:58.465044 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:45:02.389044 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:45:02.551043 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:45:02.551043 17564 solver.cpp:398]     Test net output #1: loss = 0.0140766 (* 1 = 0.0140766 loss)
I0414 06:45:02.689043 17564 solver.cpp:219] Iteration 34800 (5.39041 iter/s, 18.5515s/100 iters), loss = 0.0101581
I0414 06:45:02.689043 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:45:02.690042 17564 solver.cpp:238]     Train net output #1: loss = 0.0101581 (* 1 = 0.0101581 loss)
I0414 06:45:02.690042 17564 sgd_solver.cpp:105] Iteration 34800, lr = 1e-06
I0414 06:45:16.957042 17564 solver.cpp:219] Iteration 34900 (7.00918 iter/s, 14.267s/100 iters), loss = 0.0149483
I0414 06:45:16.957042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:45:16.957042 17564 solver.cpp:238]     Train net output #1: loss = 0.0149484 (* 1 = 0.0149484 loss)
I0414 06:45:16.957042 17564 sgd_solver.cpp:105] Iteration 34900, lr = 1e-06
I0414 06:45:31.226042 17564 solver.cpp:219] Iteration 35000 (7.00831 iter/s, 14.2688s/100 iters), loss = 0.0146501
I0414 06:45:31.226042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:45:31.226042 17564 solver.cpp:238]     Train net output #1: loss = 0.0146502 (* 1 = 0.0146502 loss)
I0414 06:45:31.226042 17564 sgd_solver.cpp:105] Iteration 35000, lr = 1e-06
I0414 06:45:45.503042 17564 solver.cpp:219] Iteration 35100 (7.0047 iter/s, 14.2761s/100 iters), loss = 0.0127392
I0414 06:45:45.503042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:45:45.503042 17564 solver.cpp:238]     Train net output #1: loss = 0.0127393 (* 1 = 0.0127393 loss)
I0414 06:45:45.503042 17564 sgd_solver.cpp:105] Iteration 35100, lr = 1e-06
I0414 06:45:59.776042 17564 solver.cpp:219] Iteration 35200 (7.00656 iter/s, 14.2723s/100 iters), loss = 0.0046291
I0414 06:45:59.776042 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:45:59.776042 17564 solver.cpp:238]     Train net output #1: loss = 0.00462917 (* 1 = 0.00462917 loss)
I0414 06:45:59.776042 17564 sgd_solver.cpp:105] Iteration 35200, lr = 1e-06
I0414 06:46:14.052058 17564 solver.cpp:219] Iteration 35300 (7.00517 iter/s, 14.2752s/100 iters), loss = 0.00531249
I0414 06:46:14.052058 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:46:14.052058 17564 solver.cpp:238]     Train net output #1: loss = 0.00531256 (* 1 = 0.00531256 loss)
I0414 06:46:14.052058 17564 sgd_solver.cpp:105] Iteration 35300, lr = 1e-06
I0414 06:46:27.613092 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:46:28.183092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_35400.caffemodel
I0414 06:46:28.321092 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_35400.solverstate
I0414 06:46:28.387092 17564 solver.cpp:331] Iteration 35400, Testing net (#0)
I0414 06:46:28.387092 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:46:32.307091 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:46:32.469115 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:46:32.469115 17564 solver.cpp:398]     Test net output #1: loss = 0.0140388 (* 1 = 0.0140388 loss)
I0414 06:46:32.608093 17564 solver.cpp:219] Iteration 35400 (5.3892 iter/s, 18.5556s/100 iters), loss = 0.0052452
I0414 06:46:32.608093 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:46:32.608093 17564 solver.cpp:238]     Train net output #1: loss = 0.00524528 (* 1 = 0.00524528 loss)
I0414 06:46:32.608093 17564 sgd_solver.cpp:105] Iteration 35400, lr = 1e-06
I0414 06:46:46.882091 17564 solver.cpp:219] Iteration 35500 (7.00589 iter/s, 14.2737s/100 iters), loss = 0.00897924
I0414 06:46:46.882091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:46:46.882091 17564 solver.cpp:238]     Train net output #1: loss = 0.00897931 (* 1 = 0.00897931 loss)
I0414 06:46:46.882091 17564 sgd_solver.cpp:105] Iteration 35500, lr = 1e-06
I0414 06:47:01.158092 17564 solver.cpp:219] Iteration 35600 (7.00528 iter/s, 14.2749s/100 iters), loss = 0.0193351
I0414 06:47:01.158092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:47:01.158092 17564 solver.cpp:238]     Train net output #1: loss = 0.0193352 (* 1 = 0.0193352 loss)
I0414 06:47:01.158092 17564 sgd_solver.cpp:105] Iteration 35600, lr = 1e-06
I0414 06:47:15.445091 17564 solver.cpp:219] Iteration 35700 (6.99945 iter/s, 14.2868s/100 iters), loss = 0.0151706
I0414 06:47:15.445091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:47:15.445091 17564 solver.cpp:238]     Train net output #1: loss = 0.0151707 (* 1 = 0.0151707 loss)
I0414 06:47:15.445091 17564 sgd_solver.cpp:105] Iteration 35700, lr = 1e-06
I0414 06:47:29.720091 17564 solver.cpp:219] Iteration 35800 (7.00581 iter/s, 14.2739s/100 iters), loss = 0.00586555
I0414 06:47:29.720091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:47:29.720091 17564 solver.cpp:238]     Train net output #1: loss = 0.00586561 (* 1 = 0.00586561 loss)
I0414 06:47:29.720091 17564 sgd_solver.cpp:105] Iteration 35800, lr = 1e-06
I0414 06:47:43.993091 17564 solver.cpp:219] Iteration 35900 (7.0062 iter/s, 14.2731s/100 iters), loss = 0.0044324
I0414 06:47:43.993091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:47:43.993091 17564 solver.cpp:238]     Train net output #1: loss = 0.00443246 (* 1 = 0.00443246 loss)
I0414 06:47:43.993091 17564 sgd_solver.cpp:105] Iteration 35900, lr = 1e-06
I0414 06:47:57.541092 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:47:58.109092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_36000.caffemodel
I0414 06:47:58.261112 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_36000.solverstate
I0414 06:47:58.327095 17564 solver.cpp:331] Iteration 36000, Testing net (#0)
I0414 06:47:58.327095 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:48:02.257092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:48:02.419092 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:48:02.419092 17564 solver.cpp:398]     Test net output #1: loss = 0.0140377 (* 1 = 0.0140377 loss)
I0414 06:48:02.558092 17564 solver.cpp:219] Iteration 36000 (5.38673 iter/s, 18.5641s/100 iters), loss = 0.00813874
I0414 06:48:02.558092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:48:02.558092 17564 solver.cpp:238]     Train net output #1: loss = 0.00813881 (* 1 = 0.00813881 loss)
I0414 06:48:02.558092 17564 sgd_solver.cpp:105] Iteration 36000, lr = 1e-06
I0414 06:48:16.835091 17564 solver.cpp:219] Iteration 36100 (7.00473 iter/s, 14.2761s/100 iters), loss = 0.0143362
I0414 06:48:16.835091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:48:16.835091 17564 solver.cpp:238]     Train net output #1: loss = 0.0143362 (* 1 = 0.0143362 loss)
I0414 06:48:16.835091 17564 sgd_solver.cpp:105] Iteration 36100, lr = 1e-06
I0414 06:48:31.096107 17564 solver.cpp:219] Iteration 36200 (7.01207 iter/s, 14.2611s/100 iters), loss = 0.00878279
I0414 06:48:31.096107 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:48:31.096107 17564 solver.cpp:238]     Train net output #1: loss = 0.00878287 (* 1 = 0.00878287 loss)
I0414 06:48:31.096107 17564 sgd_solver.cpp:105] Iteration 36200, lr = 1e-06
I0414 06:48:45.368091 17564 solver.cpp:219] Iteration 36300 (7.00725 iter/s, 14.2709s/100 iters), loss = 0.0168047
I0414 06:48:45.368091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:48:45.368091 17564 solver.cpp:238]     Train net output #1: loss = 0.0168048 (* 1 = 0.0168048 loss)
I0414 06:48:45.368091 17564 sgd_solver.cpp:105] Iteration 36300, lr = 1e-06
I0414 06:48:59.636092 17564 solver.cpp:219] Iteration 36400 (7.00903 iter/s, 14.2673s/100 iters), loss = 0.00608556
I0414 06:48:59.636092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:48:59.636092 17564 solver.cpp:238]     Train net output #1: loss = 0.00608563 (* 1 = 0.00608563 loss)
I0414 06:48:59.636092 17564 sgd_solver.cpp:105] Iteration 36400, lr = 1e-06
I0414 06:49:13.924091 17564 solver.cpp:219] Iteration 36500 (6.99919 iter/s, 14.2874s/100 iters), loss = 0.00483256
I0414 06:49:13.924091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:49:13.924091 17564 solver.cpp:238]     Train net output #1: loss = 0.00483263 (* 1 = 0.00483263 loss)
I0414 06:49:13.924091 17564 sgd_solver.cpp:105] Iteration 36500, lr = 1e-06
I0414 06:49:27.480092 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:49:28.049101 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_36600.caffemodel
I0414 06:49:28.185114 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_36600.solverstate
I0414 06:49:28.251111 17564 solver.cpp:331] Iteration 36600, Testing net (#0)
I0414 06:49:28.251111 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:49:32.171092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:49:32.333092 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:49:32.333092 17564 solver.cpp:398]     Test net output #1: loss = 0.0140471 (* 1 = 0.0140471 loss)
I0414 06:49:32.471091 17564 solver.cpp:219] Iteration 36600 (5.39176 iter/s, 18.5468s/100 iters), loss = 0.00555656
I0414 06:49:32.471091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:49:32.471091 17564 solver.cpp:238]     Train net output #1: loss = 0.00555663 (* 1 = 0.00555663 loss)
I0414 06:49:32.471091 17564 sgd_solver.cpp:105] Iteration 36600, lr = 1e-06
I0414 06:49:46.728091 17564 solver.cpp:219] Iteration 36700 (7.01439 iter/s, 14.2564s/100 iters), loss = 0.0159034
I0414 06:49:46.728091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:49:46.728091 17564 solver.cpp:238]     Train net output #1: loss = 0.0159034 (* 1 = 0.0159034 loss)
I0414 06:49:46.728091 17564 sgd_solver.cpp:105] Iteration 36700, lr = 1e-06
I0414 06:50:00.992094 17564 solver.cpp:219] Iteration 36800 (7.01096 iter/s, 14.2634s/100 iters), loss = 0.0118935
I0414 06:50:00.992094 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:50:00.992094 17564 solver.cpp:238]     Train net output #1: loss = 0.0118935 (* 1 = 0.0118935 loss)
I0414 06:50:00.992094 17564 sgd_solver.cpp:105] Iteration 36800, lr = 1e-06
I0414 06:50:15.261091 17564 solver.cpp:219] Iteration 36900 (7.00853 iter/s, 14.2683s/100 iters), loss = 0.00603722
I0414 06:50:15.262092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:50:15.262092 17564 solver.cpp:238]     Train net output #1: loss = 0.0060373 (* 1 = 0.0060373 loss)
I0414 06:50:15.262092 17564 sgd_solver.cpp:105] Iteration 36900, lr = 1e-06
I0414 06:50:29.520092 17564 solver.cpp:219] Iteration 37000 (7.0138 iter/s, 14.2576s/100 iters), loss = 0.00528711
I0414 06:50:29.520092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:50:29.520092 17564 solver.cpp:238]     Train net output #1: loss = 0.00528719 (* 1 = 0.00528719 loss)
I0414 06:50:29.520092 17564 sgd_solver.cpp:46] MultiStep Status: Iteration 37000, step = 6
I0414 06:50:29.520092 17564 sgd_solver.cpp:105] Iteration 37000, lr = 1e-07
I0414 06:50:43.781091 17564 solver.cpp:219] Iteration 37100 (7.01207 iter/s, 14.2611s/100 iters), loss = 0.00373375
I0414 06:50:43.781091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:50:43.781091 17564 solver.cpp:238]     Train net output #1: loss = 0.00373382 (* 1 = 0.00373382 loss)
I0414 06:50:43.781091 17564 sgd_solver.cpp:105] Iteration 37100, lr = 1e-07
I0414 06:50:57.322093 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:50:57.891093 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_37200.caffemodel
I0414 06:50:58.040092 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_37200.solverstate
I0414 06:50:58.108093 17564 solver.cpp:331] Iteration 37200, Testing net (#0)
I0414 06:50:58.108093 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:51:02.033097 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:51:02.195093 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:51:02.195093 17564 solver.cpp:398]     Test net output #1: loss = 0.0140467 (* 1 = 0.0140467 loss)
I0414 06:51:02.334094 17564 solver.cpp:219] Iteration 37200 (5.39023 iter/s, 18.5521s/100 iters), loss = 0.00454737
I0414 06:51:02.334094 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:51:02.334094 17564 solver.cpp:238]     Train net output #1: loss = 0.00454745 (* 1 = 0.00454745 loss)
I0414 06:51:02.334094 17564 sgd_solver.cpp:105] Iteration 37200, lr = 1e-07
I0414 06:51:16.605093 17564 solver.cpp:219] Iteration 37300 (7.0074 iter/s, 14.2706s/100 iters), loss = 0.0232381
I0414 06:51:16.605093 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:51:16.605093 17564 solver.cpp:238]     Train net output #1: loss = 0.0232382 (* 1 = 0.0232382 loss)
I0414 06:51:16.605093 17564 sgd_solver.cpp:105] Iteration 37300, lr = 1e-07
I0414 06:51:30.870091 17564 solver.cpp:219] Iteration 37400 (7.01046 iter/s, 14.2644s/100 iters), loss = 0.0219251
I0414 06:51:30.870091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:51:30.870091 17564 solver.cpp:238]     Train net output #1: loss = 0.0219251 (* 1 = 0.0219251 loss)
I0414 06:51:30.870091 17564 sgd_solver.cpp:105] Iteration 37400, lr = 1e-07
I0414 06:51:45.135092 17564 solver.cpp:219] Iteration 37500 (7.01075 iter/s, 14.2638s/100 iters), loss = 0.0163606
I0414 06:51:45.135092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:51:45.135092 17564 solver.cpp:238]     Train net output #1: loss = 0.0163607 (* 1 = 0.0163607 loss)
I0414 06:51:45.135092 17564 sgd_solver.cpp:105] Iteration 37500, lr = 1e-07
I0414 06:51:59.390091 17564 solver.cpp:219] Iteration 37600 (7.01517 iter/s, 14.2548s/100 iters), loss = 0.00726592
I0414 06:51:59.390091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:51:59.390091 17564 solver.cpp:238]     Train net output #1: loss = 0.007266 (* 1 = 0.007266 loss)
I0414 06:51:59.390091 17564 sgd_solver.cpp:105] Iteration 37600, lr = 1e-07
I0414 06:52:13.663091 17564 solver.cpp:219] Iteration 37700 (7.00627 iter/s, 14.2729s/100 iters), loss = 0.00387087
I0414 06:52:13.663091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:52:13.663091 17564 solver.cpp:238]     Train net output #1: loss = 0.00387095 (* 1 = 0.00387095 loss)
I0414 06:52:13.663091 17564 sgd_solver.cpp:105] Iteration 37700, lr = 1e-07
I0414 06:52:27.221093 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:52:27.789093 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_37800.caffemodel
I0414 06:52:27.932092 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_37800.solverstate
I0414 06:52:28.001093 17564 solver.cpp:331] Iteration 37800, Testing net (#0)
I0414 06:52:28.001093 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:52:31.923094 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:52:32.085091 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:52:32.085091 17564 solver.cpp:398]     Test net output #1: loss = 0.014051 (* 1 = 0.014051 loss)
I0414 06:52:32.224092 17564 solver.cpp:219] Iteration 37800 (5.38794 iter/s, 18.56s/100 iters), loss = 0.00825866
I0414 06:52:32.224092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:52:32.224092 17564 solver.cpp:238]     Train net output #1: loss = 0.00825873 (* 1 = 0.00825873 loss)
I0414 06:52:32.224092 17564 sgd_solver.cpp:105] Iteration 37800, lr = 1e-07
I0414 06:52:46.487092 17564 solver.cpp:219] Iteration 37900 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.0078051
I0414 06:52:46.487092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:52:46.487092 17564 solver.cpp:238]     Train net output #1: loss = 0.00780518 (* 1 = 0.00780518 loss)
I0414 06:52:46.487092 17564 sgd_solver.cpp:105] Iteration 37900, lr = 1e-07
I0414 06:53:00.751091 17564 solver.cpp:219] Iteration 38000 (7.01058 iter/s, 14.2642s/100 iters), loss = 0.0174922
I0414 06:53:00.752092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:53:00.752092 17564 solver.cpp:238]     Train net output #1: loss = 0.0174922 (* 1 = 0.0174922 loss)
I0414 06:53:00.752092 17564 sgd_solver.cpp:105] Iteration 38000, lr = 1e-07
I0414 06:53:15.039091 17564 solver.cpp:219] Iteration 38100 (6.99939 iter/s, 14.287s/100 iters), loss = 0.00707727
I0414 06:53:15.039091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:53:15.039091 17564 solver.cpp:238]     Train net output #1: loss = 0.00707734 (* 1 = 0.00707734 loss)
I0414 06:53:15.039091 17564 sgd_solver.cpp:105] Iteration 38100, lr = 1e-07
I0414 06:53:29.313091 17564 solver.cpp:219] Iteration 38200 (7.00608 iter/s, 14.2733s/100 iters), loss = 0.00439981
I0414 06:53:29.313091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:53:29.313091 17564 solver.cpp:238]     Train net output #1: loss = 0.00439989 (* 1 = 0.00439989 loss)
I0414 06:53:29.313091 17564 sgd_solver.cpp:105] Iteration 38200, lr = 1e-07
I0414 06:53:43.579092 17564 solver.cpp:219] Iteration 38300 (7.00984 iter/s, 14.2657s/100 iters), loss = 0.00364708
I0414 06:53:43.579092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:53:43.579092 17564 solver.cpp:238]     Train net output #1: loss = 0.00364715 (* 1 = 0.00364715 loss)
I0414 06:53:43.579092 17564 sgd_solver.cpp:105] Iteration 38300, lr = 1e-07
I0414 06:53:57.138094 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:53:57.709091 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_38400.caffemodel
I0414 06:53:57.848109 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_38400.solverstate
I0414 06:53:57.915094 17564 solver.cpp:331] Iteration 38400, Testing net (#0)
I0414 06:53:57.915094 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:54:01.834094 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:54:01.996093 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:54:01.996093 17564 solver.cpp:398]     Test net output #1: loss = 0.014083 (* 1 = 0.014083 loss)
I0414 06:54:02.135093 17564 solver.cpp:219] Iteration 38400 (5.38931 iter/s, 18.5552s/100 iters), loss = 0.0142007
I0414 06:54:02.135093 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:54:02.135093 17564 solver.cpp:238]     Train net output #1: loss = 0.0142008 (* 1 = 0.0142008 loss)
I0414 06:54:02.135093 17564 sgd_solver.cpp:105] Iteration 38400, lr = 1e-07
I0414 06:54:16.422091 17564 solver.cpp:219] Iteration 38500 (6.99968 iter/s, 14.2864s/100 iters), loss = 0.0230497
I0414 06:54:16.422091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:54:16.422091 17564 solver.cpp:238]     Train net output #1: loss = 0.0230498 (* 1 = 0.0230498 loss)
I0414 06:54:16.422091 17564 sgd_solver.cpp:105] Iteration 38500, lr = 1e-07
I0414 06:54:30.701092 17564 solver.cpp:219] Iteration 38600 (7.0036 iter/s, 14.2784s/100 iters), loss = 0.0101458
I0414 06:54:30.701092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:54:30.701092 17564 solver.cpp:238]     Train net output #1: loss = 0.0101459 (* 1 = 0.0101459 loss)
I0414 06:54:30.701092 17564 sgd_solver.cpp:105] Iteration 38600, lr = 1e-07
I0414 06:54:44.959091 17564 solver.cpp:219] Iteration 38700 (7.01394 iter/s, 14.2573s/100 iters), loss = 0.0116608
I0414 06:54:44.959091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:54:44.959091 17564 solver.cpp:238]     Train net output #1: loss = 0.0116609 (* 1 = 0.0116609 loss)
I0414 06:54:44.959091 17564 sgd_solver.cpp:105] Iteration 38700, lr = 1e-07
I0414 06:54:59.227092 17564 solver.cpp:219] Iteration 38800 (7.00871 iter/s, 14.268s/100 iters), loss = 0.00548922
I0414 06:54:59.227092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:54:59.227092 17564 solver.cpp:238]     Train net output #1: loss = 0.0054893 (* 1 = 0.0054893 loss)
I0414 06:54:59.227092 17564 sgd_solver.cpp:105] Iteration 38800, lr = 1e-07
I0414 06:55:13.496091 17564 solver.cpp:219] Iteration 38900 (7.00851 iter/s, 14.2684s/100 iters), loss = 0.00643004
I0414 06:55:13.496091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:55:13.496091 17564 solver.cpp:238]     Train net output #1: loss = 0.00643013 (* 1 = 0.00643013 loss)
I0414 06:55:13.496091 17564 sgd_solver.cpp:105] Iteration 38900, lr = 1e-07
I0414 06:55:27.049093 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:55:27.618098 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_39000.caffemodel
I0414 06:55:27.756109 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_39000.solverstate
I0414 06:55:27.822094 17564 solver.cpp:331] Iteration 39000, Testing net (#0)
I0414 06:55:27.822094 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:55:31.743093 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:55:31.905098 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:55:31.905098 17564 solver.cpp:398]     Test net output #1: loss = 0.0140785 (* 1 = 0.0140785 loss)
I0414 06:55:32.044091 17564 solver.cpp:219] Iteration 39000 (5.39179 iter/s, 18.5467s/100 iters), loss = 0.0126298
I0414 06:55:32.044091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:55:32.044091 17564 solver.cpp:238]     Train net output #1: loss = 0.0126299 (* 1 = 0.0126299 loss)
I0414 06:55:32.044091 17564 sgd_solver.cpp:105] Iteration 39000, lr = 1e-07
I0414 06:55:46.323091 17564 solver.cpp:219] Iteration 39100 (7.00333 iter/s, 14.2789s/100 iters), loss = 0.00631862
I0414 06:55:46.323091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:55:46.323091 17564 solver.cpp:238]     Train net output #1: loss = 0.00631872 (* 1 = 0.00631872 loss)
I0414 06:55:46.323091 17564 sgd_solver.cpp:105] Iteration 39100, lr = 1e-07
I0414 06:56:00.596091 17564 solver.cpp:219] Iteration 39200 (7.00658 iter/s, 14.2723s/100 iters), loss = 0.0205748
I0414 06:56:00.596091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:56:00.596091 17564 solver.cpp:238]     Train net output #1: loss = 0.0205749 (* 1 = 0.0205749 loss)
I0414 06:56:00.596091 17564 sgd_solver.cpp:105] Iteration 39200, lr = 1e-07
I0414 06:56:14.887091 17564 solver.cpp:219] Iteration 39300 (6.9978 iter/s, 14.2902s/100 iters), loss = 0.0189215
I0414 06:56:14.887091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:56:14.887091 17564 solver.cpp:238]     Train net output #1: loss = 0.0189216 (* 1 = 0.0189216 loss)
I0414 06:56:14.887091 17564 sgd_solver.cpp:105] Iteration 39300, lr = 1e-07
I0414 06:56:29.155092 17564 solver.cpp:219] Iteration 39400 (7.00898 iter/s, 14.2674s/100 iters), loss = 0.00723219
I0414 06:56:29.155092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:56:29.155092 17564 solver.cpp:238]     Train net output #1: loss = 0.00723229 (* 1 = 0.00723229 loss)
I0414 06:56:29.155092 17564 sgd_solver.cpp:105] Iteration 39400, lr = 1e-07
I0414 06:56:43.427091 17564 solver.cpp:219] Iteration 39500 (7.00681 iter/s, 14.2718s/100 iters), loss = 0.00477974
I0414 06:56:43.427091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:56:43.427091 17564 solver.cpp:238]     Train net output #1: loss = 0.00477985 (* 1 = 0.00477985 loss)
I0414 06:56:43.427091 17564 sgd_solver.cpp:105] Iteration 39500, lr = 1e-07
I0414 06:56:56.987092 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:56:57.556092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_39600.caffemodel
I0414 06:56:57.694108 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_39600.solverstate
I0414 06:56:57.760094 17564 solver.cpp:331] Iteration 39600, Testing net (#0)
I0414 06:56:57.760094 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:57:01.684092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:57:01.846093 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 06:57:01.846093 17564 solver.cpp:398]     Test net output #1: loss = 0.0140885 (* 1 = 0.0140885 loss)
I0414 06:57:01.986093 17564 solver.cpp:219] Iteration 39600 (5.3885 iter/s, 18.558s/100 iters), loss = 0.00757258
I0414 06:57:01.986093 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:57:01.986093 17564 solver.cpp:238]     Train net output #1: loss = 0.00757268 (* 1 = 0.00757268 loss)
I0414 06:57:01.986093 17564 sgd_solver.cpp:105] Iteration 39600, lr = 1e-07
I0414 06:57:16.287091 17564 solver.cpp:219] Iteration 39700 (6.99272 iter/s, 14.3006s/100 iters), loss = 0.0263205
I0414 06:57:16.287091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:57:16.287091 17564 solver.cpp:238]     Train net output #1: loss = 0.0263206 (* 1 = 0.0263206 loss)
I0414 06:57:16.287091 17564 sgd_solver.cpp:105] Iteration 39700, lr = 1e-07
I0414 06:57:30.567091 17564 solver.cpp:219] Iteration 39800 (7.00305 iter/s, 14.2795s/100 iters), loss = 0.00790361
I0414 06:57:30.567091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:57:30.567091 17564 solver.cpp:238]     Train net output #1: loss = 0.00790371 (* 1 = 0.00790371 loss)
I0414 06:57:30.567091 17564 sgd_solver.cpp:105] Iteration 39800, lr = 1e-07
I0414 06:57:44.838091 17564 solver.cpp:219] Iteration 39900 (7.00751 iter/s, 14.2704s/100 iters), loss = 0.0163418
I0414 06:57:44.838091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:57:44.838091 17564 solver.cpp:238]     Train net output #1: loss = 0.0163419 (* 1 = 0.0163419 loss)
I0414 06:57:44.838091 17564 sgd_solver.cpp:105] Iteration 39900, lr = 1e-07
I0414 06:57:59.109091 17564 solver.cpp:219] Iteration 40000 (7.00726 iter/s, 14.2709s/100 iters), loss = 0.00508141
I0414 06:57:59.109091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:57:59.109091 17564 solver.cpp:238]     Train net output #1: loss = 0.00508151 (* 1 = 0.00508151 loss)
I0414 06:57:59.109091 17564 sgd_solver.cpp:105] Iteration 40000, lr = 1e-07
I0414 06:58:13.390092 17564 solver.cpp:219] Iteration 40100 (7.00277 iter/s, 14.2801s/100 iters), loss = 0.00363694
I0414 06:58:13.390092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:58:13.390092 17564 solver.cpp:238]     Train net output #1: loss = 0.00363704 (* 1 = 0.00363704 loss)
I0414 06:58:13.390092 17564 sgd_solver.cpp:105] Iteration 40100, lr = 1e-07
I0414 06:58:26.947091 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:58:27.515092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_40200.caffemodel
I0414 06:58:27.656091 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_40200.solverstate
I0414 06:58:27.722093 17564 solver.cpp:331] Iteration 40200, Testing net (#0)
I0414 06:58:27.723093 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 06:58:31.643092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:58:31.804091 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 06:58:31.804091 17564 solver.cpp:398]     Test net output #1: loss = 0.0140737 (* 1 = 0.0140737 loss)
I0414 06:58:31.943091 17564 solver.cpp:219] Iteration 40200 (5.39011 iter/s, 18.5525s/100 iters), loss = 0.00940238
I0414 06:58:31.943091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:58:31.943091 17564 solver.cpp:238]     Train net output #1: loss = 0.00940248 (* 1 = 0.00940248 loss)
I0414 06:58:31.943091 17564 sgd_solver.cpp:105] Iteration 40200, lr = 1e-07
I0414 06:58:46.216086 17564 solver.cpp:219] Iteration 40300 (7.0066 iter/s, 14.2723s/100 iters), loss = 0.0124112
I0414 06:58:46.216086 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:58:46.216086 17564 solver.cpp:238]     Train net output #1: loss = 0.0124113 (* 1 = 0.0124113 loss)
I0414 06:58:46.216086 17564 sgd_solver.cpp:105] Iteration 40300, lr = 1e-07
I0414 06:59:00.503108 17564 solver.cpp:219] Iteration 40400 (6.99978 iter/s, 14.2862s/100 iters), loss = 0.00845335
I0414 06:59:00.503108 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:59:00.503108 17564 solver.cpp:238]     Train net output #1: loss = 0.00845346 (* 1 = 0.00845346 loss)
I0414 06:59:00.503108 17564 sgd_solver.cpp:105] Iteration 40400, lr = 1e-07
I0414 06:59:14.783092 17564 solver.cpp:219] Iteration 40500 (7.00279 iter/s, 14.28s/100 iters), loss = 0.0184505
I0414 06:59:14.783092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 06:59:14.783092 17564 solver.cpp:238]     Train net output #1: loss = 0.0184506 (* 1 = 0.0184506 loss)
I0414 06:59:14.783092 17564 sgd_solver.cpp:105] Iteration 40500, lr = 1e-07
I0414 06:59:29.051091 17564 solver.cpp:219] Iteration 40600 (7.00924 iter/s, 14.2669s/100 iters), loss = 0.00487335
I0414 06:59:29.051091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:59:29.051091 17564 solver.cpp:238]     Train net output #1: loss = 0.00487346 (* 1 = 0.00487346 loss)
I0414 06:59:29.051091 17564 sgd_solver.cpp:105] Iteration 40600, lr = 1e-07
I0414 06:59:43.320091 17564 solver.cpp:219] Iteration 40700 (7.00817 iter/s, 14.2691s/100 iters), loss = 0.00540371
I0414 06:59:43.320091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 06:59:43.320091 17564 solver.cpp:238]     Train net output #1: loss = 0.00540382 (* 1 = 0.00540382 loss)
I0414 06:59:43.320091 17564 sgd_solver.cpp:105] Iteration 40700, lr = 1e-07
I0414 06:59:56.878093 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 06:59:57.447093 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_40800.caffemodel
I0414 06:59:57.586092 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_40800.solverstate
I0414 06:59:57.654094 17564 solver.cpp:331] Iteration 40800, Testing net (#0)
I0414 06:59:57.654094 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:00:01.580092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:00:01.742092 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:00:01.742092 17564 solver.cpp:398]     Test net output #1: loss = 0.0140729 (* 1 = 0.0140729 loss)
I0414 07:00:01.881093 17564 solver.cpp:219] Iteration 40800 (5.38793 iter/s, 18.56s/100 iters), loss = 0.00483339
I0414 07:00:01.881093 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:00:01.881093 17564 solver.cpp:238]     Train net output #1: loss = 0.00483349 (* 1 = 0.00483349 loss)
I0414 07:00:01.881093 17564 sgd_solver.cpp:105] Iteration 40800, lr = 1e-07
I0414 07:00:16.163091 17564 solver.cpp:219] Iteration 40900 (7.0024 iter/s, 14.2808s/100 iters), loss = 0.00611611
I0414 07:00:16.163091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:00:16.163091 17564 solver.cpp:238]     Train net output #1: loss = 0.00611621 (* 1 = 0.00611621 loss)
I0414 07:00:16.163091 17564 sgd_solver.cpp:105] Iteration 40900, lr = 1e-07
I0414 07:00:30.422091 17564 solver.cpp:219] Iteration 41000 (7.01296 iter/s, 14.2593s/100 iters), loss = 0.0179696
I0414 07:00:30.422091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:00:30.422091 17564 solver.cpp:238]     Train net output #1: loss = 0.0179697 (* 1 = 0.0179697 loss)
I0414 07:00:30.422091 17564 sgd_solver.cpp:105] Iteration 41000, lr = 1e-07
I0414 07:00:44.675091 17564 solver.cpp:219] Iteration 41100 (7.01629 iter/s, 14.2526s/100 iters), loss = 0.0173564
I0414 07:00:44.676091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:00:44.676091 17564 solver.cpp:238]     Train net output #1: loss = 0.0173565 (* 1 = 0.0173565 loss)
I0414 07:00:44.676091 17564 sgd_solver.cpp:105] Iteration 41100, lr = 1e-07
I0414 07:00:58.941092 17564 solver.cpp:219] Iteration 41200 (7.01008 iter/s, 14.2652s/100 iters), loss = 0.00413223
I0414 07:00:58.941092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:00:58.941092 17564 solver.cpp:238]     Train net output #1: loss = 0.00413234 (* 1 = 0.00413234 loss)
I0414 07:00:58.941092 17564 sgd_solver.cpp:105] Iteration 41200, lr = 1e-07
I0414 07:01:13.231091 17564 solver.cpp:219] Iteration 41300 (6.99828 iter/s, 14.2892s/100 iters), loss = 0.0057906
I0414 07:01:13.231091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:01:13.231091 17564 solver.cpp:238]     Train net output #1: loss = 0.00579071 (* 1 = 0.00579071 loss)
I0414 07:01:13.231091 17564 sgd_solver.cpp:105] Iteration 41300, lr = 1e-07
I0414 07:01:26.785092 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:01:27.352092 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_41400.caffemodel
I0414 07:01:27.493093 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_41400.solverstate
I0414 07:01:27.558091 17564 solver.cpp:331] Iteration 41400, Testing net (#0)
I0414 07:01:27.558091 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:01:31.478092 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:01:31.639091 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:01:31.639091 17564 solver.cpp:398]     Test net output #1: loss = 0.0140476 (* 1 = 0.0140476 loss)
I0414 07:01:31.778091 17564 solver.cpp:219] Iteration 41400 (5.39189 iter/s, 18.5464s/100 iters), loss = 0.0073137
I0414 07:01:31.778091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:01:31.778091 17564 solver.cpp:238]     Train net output #1: loss = 0.00731381 (* 1 = 0.00731381 loss)
I0414 07:01:31.778091 17564 sgd_solver.cpp:105] Iteration 41400, lr = 1e-07
I0414 07:01:46.044091 17564 solver.cpp:219] Iteration 41500 (7.00986 iter/s, 14.2656s/100 iters), loss = 0.00793023
I0414 07:01:46.044091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:01:46.044091 17564 solver.cpp:238]     Train net output #1: loss = 0.00793034 (* 1 = 0.00793034 loss)
I0414 07:01:46.044091 17564 sgd_solver.cpp:105] Iteration 41500, lr = 1e-07
I0414 07:02:00.320106 17564 solver.cpp:219] Iteration 41600 (7.00494 iter/s, 14.2756s/100 iters), loss = 0.0116821
I0414 07:02:00.320106 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:02:00.320106 17564 solver.cpp:238]     Train net output #1: loss = 0.0116822 (* 1 = 0.0116822 loss)
I0414 07:02:00.320106 17564 sgd_solver.cpp:105] Iteration 41600, lr = 1e-07
I0414 07:02:14.600092 17564 solver.cpp:219] Iteration 41700 (7.00322 iter/s, 14.2791s/100 iters), loss = 0.00578953
I0414 07:02:14.600092 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:02:14.600092 17564 solver.cpp:238]     Train net output #1: loss = 0.00578963 (* 1 = 0.00578963 loss)
I0414 07:02:14.600092 17564 sgd_solver.cpp:105] Iteration 41700, lr = 1e-07
I0414 07:02:28.868091 17564 solver.cpp:219] Iteration 41800 (7.00878 iter/s, 14.2678s/100 iters), loss = 0.00636127
I0414 07:02:28.868091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:02:28.868091 17564 solver.cpp:238]     Train net output #1: loss = 0.00636137 (* 1 = 0.00636137 loss)
I0414 07:02:28.869092 17564 sgd_solver.cpp:105] Iteration 41800, lr = 1e-07
I0414 07:02:43.156091 17564 solver.cpp:219] Iteration 41900 (6.99951 iter/s, 14.2867s/100 iters), loss = 0.00655999
I0414 07:02:43.156091 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:02:43.156091 17564 solver.cpp:238]     Train net output #1: loss = 0.00656009 (* 1 = 0.00656009 loss)
I0414 07:02:43.156091 17564 sgd_solver.cpp:105] Iteration 41900, lr = 1e-07
I0414 07:02:56.716192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:02:57.285192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_42000.caffemodel
I0414 07:02:57.424203 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_42000.solverstate
I0414 07:02:57.491191 17564 solver.cpp:331] Iteration 42000, Testing net (#0)
I0414 07:02:57.492192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:03:01.420194 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:03:01.583192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:03:01.583192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140693 (* 1 = 0.0140693 loss)
I0414 07:03:01.722193 17564 solver.cpp:219] Iteration 42000 (5.38613 iter/s, 18.5662s/100 iters), loss = 0.00768118
I0414 07:03:01.722193 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:03:01.722193 17564 solver.cpp:238]     Train net output #1: loss = 0.00768128 (* 1 = 0.00768128 loss)
I0414 07:03:01.723192 17564 sgd_solver.cpp:105] Iteration 42000, lr = 1e-07
I0414 07:03:15.988191 17564 solver.cpp:219] Iteration 42100 (7.00992 iter/s, 14.2655s/100 iters), loss = 0.00916536
I0414 07:03:15.989192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:03:15.989192 17564 solver.cpp:238]     Train net output #1: loss = 0.00916546 (* 1 = 0.00916546 loss)
I0414 07:03:15.989192 17564 sgd_solver.cpp:105] Iteration 42100, lr = 1e-07
I0414 07:03:30.251191 17564 solver.cpp:219] Iteration 42200 (7.01189 iter/s, 14.2615s/100 iters), loss = 0.0104543
I0414 07:03:30.251191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:03:30.251191 17564 solver.cpp:238]     Train net output #1: loss = 0.0104544 (* 1 = 0.0104544 loss)
I0414 07:03:30.251191 17564 sgd_solver.cpp:105] Iteration 42200, lr = 1e-07
I0414 07:03:44.499191 17564 solver.cpp:219] Iteration 42300 (7.01873 iter/s, 14.2476s/100 iters), loss = 0.00839448
I0414 07:03:44.499191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:03:44.499191 17564 solver.cpp:238]     Train net output #1: loss = 0.00839458 (* 1 = 0.00839458 loss)
I0414 07:03:44.499191 17564 sgd_solver.cpp:105] Iteration 42300, lr = 1e-07
I0414 07:03:58.757191 17564 solver.cpp:219] Iteration 42400 (7.0137 iter/s, 14.2578s/100 iters), loss = 0.00575915
I0414 07:03:58.757191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:03:58.757191 17564 solver.cpp:238]     Train net output #1: loss = 0.00575925 (* 1 = 0.00575925 loss)
I0414 07:03:58.757191 17564 sgd_solver.cpp:105] Iteration 42400, lr = 1e-07
I0414 07:04:13.026191 17564 solver.cpp:219] Iteration 42500 (7.00853 iter/s, 14.2683s/100 iters), loss = 0.00373489
I0414 07:04:13.026191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:04:13.026191 17564 solver.cpp:238]     Train net output #1: loss = 0.00373498 (* 1 = 0.00373498 loss)
I0414 07:04:13.026191 17564 sgd_solver.cpp:105] Iteration 42500, lr = 1e-07
I0414 07:04:26.579202 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:04:27.147192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_42600.caffemodel
I0414 07:04:27.282196 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_42600.solverstate
I0414 07:04:27.346194 17564 solver.cpp:331] Iteration 42600, Testing net (#0)
I0414 07:04:27.346194 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:04:31.273193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:04:31.435192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:04:31.435192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140616 (* 1 = 0.0140616 loss)
I0414 07:04:31.575191 17564 solver.cpp:219] Iteration 42600 (5.39139 iter/s, 18.5481s/100 iters), loss = 0.00600263
I0414 07:04:31.575191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:04:31.575191 17564 solver.cpp:238]     Train net output #1: loss = 0.00600273 (* 1 = 0.00600273 loss)
I0414 07:04:31.575191 17564 sgd_solver.cpp:105] Iteration 42600, lr = 1e-07
I0414 07:04:45.861191 17564 solver.cpp:219] Iteration 42700 (7.00009 iter/s, 14.2855s/100 iters), loss = 0.0120457
I0414 07:04:45.861191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:04:45.861191 17564 solver.cpp:238]     Train net output #1: loss = 0.0120458 (* 1 = 0.0120458 loss)
I0414 07:04:45.861191 17564 sgd_solver.cpp:105] Iteration 42700, lr = 1e-07
I0414 07:05:00.130192 17564 solver.cpp:219] Iteration 42800 (7.00834 iter/s, 14.2687s/100 iters), loss = 0.0136161
I0414 07:05:00.130192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:05:00.130192 17564 solver.cpp:238]     Train net output #1: loss = 0.0136162 (* 1 = 0.0136162 loss)
I0414 07:05:00.130192 17564 sgd_solver.cpp:105] Iteration 42800, lr = 1e-07
I0414 07:05:14.407191 17564 solver.cpp:219] Iteration 42900 (7.00456 iter/s, 14.2764s/100 iters), loss = 0.0111752
I0414 07:05:14.407191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:05:14.407191 17564 solver.cpp:238]     Train net output #1: loss = 0.0111753 (* 1 = 0.0111753 loss)
I0414 07:05:14.407191 17564 sgd_solver.cpp:105] Iteration 42900, lr = 1e-07
I0414 07:05:28.669191 17564 solver.cpp:219] Iteration 43000 (7.01187 iter/s, 14.2615s/100 iters), loss = 0.00387847
I0414 07:05:28.669191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:05:28.669191 17564 solver.cpp:238]     Train net output #1: loss = 0.00387856 (* 1 = 0.00387856 loss)
I0414 07:05:28.669191 17564 sgd_solver.cpp:105] Iteration 43000, lr = 1e-07
I0414 07:05:42.946192 17564 solver.cpp:219] Iteration 43100 (7.00438 iter/s, 14.2768s/100 iters), loss = 0.00364622
I0414 07:05:42.946192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:05:42.947191 17564 solver.cpp:238]     Train net output #1: loss = 0.00364631 (* 1 = 0.00364631 loss)
I0414 07:05:42.947191 17564 sgd_solver.cpp:105] Iteration 43100, lr = 1e-07
I0414 07:05:56.516192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:05:57.086195 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_43200.caffemodel
I0414 07:05:57.244204 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_43200.solverstate
I0414 07:05:57.314195 17564 solver.cpp:331] Iteration 43200, Testing net (#0)
I0414 07:05:57.314195 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:06:01.238193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:06:01.401192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:06:01.401192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140731 (* 1 = 0.0140731 loss)
I0414 07:06:01.540191 17564 solver.cpp:219] Iteration 43200 (5.37848 iter/s, 18.5926s/100 iters), loss = 0.00720902
I0414 07:06:01.540191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:06:01.540191 17564 solver.cpp:238]     Train net output #1: loss = 0.00720911 (* 1 = 0.00720911 loss)
I0414 07:06:01.540191 17564 sgd_solver.cpp:105] Iteration 43200, lr = 1e-07
I0414 07:06:15.810191 17564 solver.cpp:219] Iteration 43300 (7.00764 iter/s, 14.2701s/100 iters), loss = 0.00925226
I0414 07:06:15.811192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:06:15.811192 17564 solver.cpp:238]     Train net output #1: loss = 0.00925236 (* 1 = 0.00925236 loss)
I0414 07:06:15.811192 17564 sgd_solver.cpp:105] Iteration 43300, lr = 1e-07
I0414 07:06:30.073192 17564 solver.cpp:219] Iteration 43400 (7.01186 iter/s, 14.2616s/100 iters), loss = 0.0114669
I0414 07:06:30.073192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:06:30.073192 17564 solver.cpp:238]     Train net output #1: loss = 0.011467 (* 1 = 0.011467 loss)
I0414 07:06:30.073192 17564 sgd_solver.cpp:105] Iteration 43400, lr = 1e-07
I0414 07:06:44.335191 17564 solver.cpp:219] Iteration 43500 (7.01168 iter/s, 14.2619s/100 iters), loss = 0.00694928
I0414 07:06:44.335191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:06:44.335191 17564 solver.cpp:238]     Train net output #1: loss = 0.00694938 (* 1 = 0.00694938 loss)
I0414 07:06:44.335191 17564 sgd_solver.cpp:105] Iteration 43500, lr = 1e-07
I0414 07:06:58.590191 17564 solver.cpp:219] Iteration 43600 (7.01521 iter/s, 14.2547s/100 iters), loss = 0.00601838
I0414 07:06:58.590191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:06:58.590191 17564 solver.cpp:238]     Train net output #1: loss = 0.00601848 (* 1 = 0.00601848 loss)
I0414 07:06:58.590191 17564 sgd_solver.cpp:105] Iteration 43600, lr = 1e-07
I0414 07:07:12.868191 17564 solver.cpp:219] Iteration 43700 (7.0042 iter/s, 14.2771s/100 iters), loss = 0.00431927
I0414 07:07:12.868191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:07:12.868191 17564 solver.cpp:238]     Train net output #1: loss = 0.00431938 (* 1 = 0.00431938 loss)
I0414 07:07:12.868191 17564 sgd_solver.cpp:105] Iteration 43700, lr = 1e-07
I0414 07:07:26.414191 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:07:26.984191 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_43800.caffemodel
I0414 07:07:27.128208 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_43800.solverstate
I0414 07:07:27.192194 17564 solver.cpp:331] Iteration 43800, Testing net (#0)
I0414 07:07:27.192194 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:07:31.113193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:07:31.274191 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:07:31.274191 17564 solver.cpp:398]     Test net output #1: loss = 0.0140937 (* 1 = 0.0140937 loss)
I0414 07:07:31.413192 17564 solver.cpp:219] Iteration 43800 (5.39255 iter/s, 18.5441s/100 iters), loss = 0.00788188
I0414 07:07:31.413192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:07:31.413192 17564 solver.cpp:238]     Train net output #1: loss = 0.00788198 (* 1 = 0.00788198 loss)
I0414 07:07:31.413192 17564 sgd_solver.cpp:105] Iteration 43800, lr = 1e-07
I0414 07:07:45.664206 17564 solver.cpp:219] Iteration 43900 (7.01698 iter/s, 14.2511s/100 iters), loss = 0.00972496
I0414 07:07:45.664206 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:07:45.665205 17564 solver.cpp:238]     Train net output #1: loss = 0.00972506 (* 1 = 0.00972506 loss)
I0414 07:07:45.665205 17564 sgd_solver.cpp:105] Iteration 43900, lr = 1e-07
I0414 07:07:59.925191 17564 solver.cpp:219] Iteration 44000 (7.01257 iter/s, 14.2601s/100 iters), loss = 0.0119664
I0414 07:07:59.925191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:07:59.925191 17564 solver.cpp:238]     Train net output #1: loss = 0.0119665 (* 1 = 0.0119665 loss)
I0414 07:07:59.925191 17564 sgd_solver.cpp:105] Iteration 44000, lr = 1e-07
I0414 07:08:14.203191 17564 solver.cpp:219] Iteration 44100 (7.00397 iter/s, 14.2776s/100 iters), loss = 0.00866778
I0414 07:08:14.203191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:08:14.203191 17564 solver.cpp:238]     Train net output #1: loss = 0.00866788 (* 1 = 0.00866788 loss)
I0414 07:08:14.203191 17564 sgd_solver.cpp:105] Iteration 44100, lr = 1e-07
I0414 07:08:28.465191 17564 solver.cpp:219] Iteration 44200 (7.01191 iter/s, 14.2614s/100 iters), loss = 0.00367779
I0414 07:08:28.465191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:08:28.465191 17564 solver.cpp:238]     Train net output #1: loss = 0.0036779 (* 1 = 0.0036779 loss)
I0414 07:08:28.465191 17564 sgd_solver.cpp:105] Iteration 44200, lr = 1e-07
I0414 07:08:42.727191 17564 solver.cpp:219] Iteration 44300 (7.01215 iter/s, 14.261s/100 iters), loss = 0.0035369
I0414 07:08:42.727191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:08:42.727191 17564 solver.cpp:238]     Train net output #1: loss = 0.003537 (* 1 = 0.003537 loss)
I0414 07:08:42.727191 17564 sgd_solver.cpp:105] Iteration 44300, lr = 1e-07
I0414 07:08:56.271191 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:08:56.839192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_44400.caffemodel
I0414 07:08:56.978193 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_44400.solverstate
I0414 07:08:57.044193 17564 solver.cpp:331] Iteration 44400, Testing net (#0)
I0414 07:08:57.044193 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:09:00.964193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:09:01.126193 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:09:01.126193 17564 solver.cpp:398]     Test net output #1: loss = 0.014054 (* 1 = 0.014054 loss)
I0414 07:09:01.265192 17564 solver.cpp:219] Iteration 44400 (5.39432 iter/s, 18.538s/100 iters), loss = 0.00724754
I0414 07:09:01.265192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:09:01.265192 17564 solver.cpp:238]     Train net output #1: loss = 0.00724765 (* 1 = 0.00724765 loss)
I0414 07:09:01.265192 17564 sgd_solver.cpp:105] Iteration 44400, lr = 1e-07
I0414 07:09:15.536191 17564 solver.cpp:219] Iteration 44500 (7.00763 iter/s, 14.2702s/100 iters), loss = 0.00824919
I0414 07:09:15.536191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:09:15.536191 17564 solver.cpp:238]     Train net output #1: loss = 0.00824929 (* 1 = 0.00824929 loss)
I0414 07:09:15.536191 17564 sgd_solver.cpp:105] Iteration 44500, lr = 1e-07
I0414 07:09:29.797191 17564 solver.cpp:219] Iteration 44600 (7.01227 iter/s, 14.2607s/100 iters), loss = 0.0071589
I0414 07:09:29.797191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:09:29.797191 17564 solver.cpp:238]     Train net output #1: loss = 0.007159 (* 1 = 0.007159 loss)
I0414 07:09:29.797191 17564 sgd_solver.cpp:105] Iteration 44600, lr = 1e-07
I0414 07:09:44.051192 17564 solver.cpp:219] Iteration 44700 (7.01595 iter/s, 14.2532s/100 iters), loss = 0.0138141
I0414 07:09:44.051192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:09:44.051192 17564 solver.cpp:238]     Train net output #1: loss = 0.0138142 (* 1 = 0.0138142 loss)
I0414 07:09:44.051192 17564 sgd_solver.cpp:105] Iteration 44700, lr = 1e-07
I0414 07:09:58.307191 17564 solver.cpp:219] Iteration 44800 (7.01492 iter/s, 14.2553s/100 iters), loss = 0.0066571
I0414 07:09:58.307191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:09:58.307191 17564 solver.cpp:238]     Train net output #1: loss = 0.0066572 (* 1 = 0.0066572 loss)
I0414 07:09:58.307191 17564 sgd_solver.cpp:105] Iteration 44800, lr = 1e-07
I0414 07:10:12.583191 17564 solver.cpp:219] Iteration 44900 (7.00531 iter/s, 14.2749s/100 iters), loss = 0.00497778
I0414 07:10:12.583191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:10:12.583191 17564 solver.cpp:238]     Train net output #1: loss = 0.00497788 (* 1 = 0.00497788 loss)
I0414 07:10:12.583191 17564 sgd_solver.cpp:105] Iteration 44900, lr = 1e-07
I0414 07:10:26.135192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:10:26.703192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_45000.caffemodel
I0414 07:10:26.842197 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_45000.solverstate
I0414 07:10:26.906191 17564 solver.cpp:331] Iteration 45000, Testing net (#0)
I0414 07:10:26.907192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:10:30.828192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:10:30.989192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:10:30.989192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140419 (* 1 = 0.0140419 loss)
I0414 07:10:31.129192 17564 solver.cpp:219] Iteration 45000 (5.39217 iter/s, 18.5454s/100 iters), loss = 0.00615539
I0414 07:10:31.129192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:10:31.129192 17564 solver.cpp:238]     Train net output #1: loss = 0.00615549 (* 1 = 0.00615549 loss)
I0414 07:10:31.129192 17564 sgd_solver.cpp:105] Iteration 45000, lr = 1e-07
I0414 07:10:45.406191 17564 solver.cpp:219] Iteration 45100 (7.00446 iter/s, 14.2766s/100 iters), loss = 0.0104183
I0414 07:10:45.406191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:10:45.406191 17564 solver.cpp:238]     Train net output #1: loss = 0.0104184 (* 1 = 0.0104184 loss)
I0414 07:10:45.406191 17564 sgd_solver.cpp:105] Iteration 45100, lr = 1e-07
I0414 07:10:59.682191 17564 solver.cpp:219] Iteration 45200 (7.00513 iter/s, 14.2753s/100 iters), loss = 0.0216855
I0414 07:10:59.682191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:10:59.682191 17564 solver.cpp:238]     Train net output #1: loss = 0.0216856 (* 1 = 0.0216856 loss)
I0414 07:10:59.682191 17564 sgd_solver.cpp:105] Iteration 45200, lr = 1e-07
I0414 07:11:13.966192 17564 solver.cpp:219] Iteration 45300 (7.00075 iter/s, 14.2842s/100 iters), loss = 0.011938
I0414 07:11:13.966192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:11:13.966192 17564 solver.cpp:238]     Train net output #1: loss = 0.0119381 (* 1 = 0.0119381 loss)
I0414 07:11:13.966192 17564 sgd_solver.cpp:105] Iteration 45300, lr = 1e-07
I0414 07:11:28.236191 17564 solver.cpp:219] Iteration 45400 (7.00814 iter/s, 14.2691s/100 iters), loss = 0.00451577
I0414 07:11:28.236191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:11:28.236191 17564 solver.cpp:238]     Train net output #1: loss = 0.00451587 (* 1 = 0.00451587 loss)
I0414 07:11:28.236191 17564 sgd_solver.cpp:105] Iteration 45400, lr = 1e-07
I0414 07:11:42.507191 17564 solver.cpp:219] Iteration 45500 (7.00731 iter/s, 14.2708s/100 iters), loss = 0.00965171
I0414 07:11:42.508191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:11:42.508191 17564 solver.cpp:238]     Train net output #1: loss = 0.00965182 (* 1 = 0.00965182 loss)
I0414 07:11:42.508191 17564 sgd_solver.cpp:105] Iteration 45500, lr = 1e-07
I0414 07:11:56.074192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:11:56.644192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_45600.caffemodel
I0414 07:11:56.786198 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_45600.solverstate
I0414 07:11:56.849195 17564 solver.cpp:331] Iteration 45600, Testing net (#0)
I0414 07:11:56.849195 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:12:00.769193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:12:00.931192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:12:00.931192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140868 (* 1 = 0.0140868 loss)
I0414 07:12:01.070194 17564 solver.cpp:219] Iteration 45600 (5.38743 iter/s, 18.5617s/100 iters), loss = 0.0059153
I0414 07:12:01.070194 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:12:01.070194 17564 solver.cpp:238]     Train net output #1: loss = 0.00591541 (* 1 = 0.00591541 loss)
I0414 07:12:01.070194 17564 sgd_solver.cpp:105] Iteration 45600, lr = 1e-07
I0414 07:12:15.351191 17564 solver.cpp:219] Iteration 45700 (7.00267 iter/s, 14.2803s/100 iters), loss = 0.00709172
I0414 07:12:15.351191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:12:15.351191 17564 solver.cpp:238]     Train net output #1: loss = 0.00709183 (* 1 = 0.00709183 loss)
I0414 07:12:15.351191 17564 sgd_solver.cpp:105] Iteration 45700, lr = 1e-07
I0414 07:12:29.614192 17564 solver.cpp:219] Iteration 45800 (7.01155 iter/s, 14.2622s/100 iters), loss = 0.0142113
I0414 07:12:29.614192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:12:29.614192 17564 solver.cpp:238]     Train net output #1: loss = 0.0142114 (* 1 = 0.0142114 loss)
I0414 07:12:29.614192 17564 sgd_solver.cpp:105] Iteration 45800, lr = 1e-07
I0414 07:12:43.873191 17564 solver.cpp:219] Iteration 45900 (7.01332 iter/s, 14.2586s/100 iters), loss = 0.0165877
I0414 07:12:43.873191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:12:43.873191 17564 solver.cpp:238]     Train net output #1: loss = 0.0165878 (* 1 = 0.0165878 loss)
I0414 07:12:43.873191 17564 sgd_solver.cpp:105] Iteration 45900, lr = 1e-07
I0414 07:12:58.131192 17564 solver.cpp:219] Iteration 46000 (7.01398 iter/s, 14.2572s/100 iters), loss = 0.00439048
I0414 07:12:58.131192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:12:58.131192 17564 solver.cpp:238]     Train net output #1: loss = 0.00439058 (* 1 = 0.00439058 loss)
I0414 07:12:58.131192 17564 sgd_solver.cpp:105] Iteration 46000, lr = 1e-07
I0414 07:13:12.410192 17564 solver.cpp:219] Iteration 46100 (7.00359 iter/s, 14.2784s/100 iters), loss = 0.00317057
I0414 07:13:12.410192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:13:12.410192 17564 solver.cpp:238]     Train net output #1: loss = 0.00317067 (* 1 = 0.00317067 loss)
I0414 07:13:12.410192 17564 sgd_solver.cpp:105] Iteration 46100, lr = 1e-07
I0414 07:13:25.980201 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:13:26.548192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_46200.caffemodel
I0414 07:13:26.691195 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_46200.solverstate
I0414 07:13:26.755199 17564 solver.cpp:331] Iteration 46200, Testing net (#0)
I0414 07:13:26.755199 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:13:30.677211 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:13:30.838191 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:13:30.838191 17564 solver.cpp:398]     Test net output #1: loss = 0.0140774 (* 1 = 0.0140774 loss)
I0414 07:13:30.977191 17564 solver.cpp:219] Iteration 46200 (5.38587 iter/s, 18.5671s/100 iters), loss = 0.00394771
I0414 07:13:30.977191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:13:30.977191 17564 solver.cpp:238]     Train net output #1: loss = 0.00394781 (* 1 = 0.00394781 loss)
I0414 07:13:30.977191 17564 sgd_solver.cpp:105] Iteration 46200, lr = 1e-07
I0414 07:13:45.233191 17564 solver.cpp:219] Iteration 46300 (7.01522 iter/s, 14.2547s/100 iters), loss = 0.0083352
I0414 07:13:45.233191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:13:45.233191 17564 solver.cpp:238]     Train net output #1: loss = 0.0083353 (* 1 = 0.0083353 loss)
I0414 07:13:45.233191 17564 sgd_solver.cpp:105] Iteration 46300, lr = 1e-07
I0414 07:13:59.493191 17564 solver.cpp:219] Iteration 46400 (7.01273 iter/s, 14.2598s/100 iters), loss = 0.0106069
I0414 07:13:59.493191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:13:59.493191 17564 solver.cpp:238]     Train net output #1: loss = 0.010607 (* 1 = 0.010607 loss)
I0414 07:13:59.493191 17564 sgd_solver.cpp:105] Iteration 46400, lr = 1e-07
I0414 07:14:13.758191 17564 solver.cpp:219] Iteration 46500 (7.01027 iter/s, 14.2648s/100 iters), loss = 0.0118
I0414 07:14:13.758191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:14:13.758191 17564 solver.cpp:238]     Train net output #1: loss = 0.0118001 (* 1 = 0.0118001 loss)
I0414 07:14:13.758191 17564 sgd_solver.cpp:105] Iteration 46500, lr = 1e-07
I0414 07:14:28.017191 17564 solver.cpp:219] Iteration 46600 (7.01333 iter/s, 14.2586s/100 iters), loss = 0.00392385
I0414 07:14:28.017191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:14:28.017191 17564 solver.cpp:238]     Train net output #1: loss = 0.00392396 (* 1 = 0.00392396 loss)
I0414 07:14:28.017191 17564 sgd_solver.cpp:105] Iteration 46600, lr = 1e-07
I0414 07:14:42.279191 17564 solver.cpp:219] Iteration 46700 (7.01214 iter/s, 14.261s/100 iters), loss = 0.00400767
I0414 07:14:42.279191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:14:42.279191 17564 solver.cpp:238]     Train net output #1: loss = 0.00400777 (* 1 = 0.00400777 loss)
I0414 07:14:42.279191 17564 sgd_solver.cpp:105] Iteration 46700, lr = 1e-07
I0414 07:14:55.821192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:14:56.389192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_46800.caffemodel
I0414 07:14:56.527192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_46800.solverstate
I0414 07:14:56.591192 17564 solver.cpp:331] Iteration 46800, Testing net (#0)
I0414 07:14:56.591192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:15:00.512202 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:15:00.673205 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:15:00.673205 17564 solver.cpp:398]     Test net output #1: loss = 0.0140663 (* 1 = 0.0140663 loss)
I0414 07:15:00.812191 17564 solver.cpp:219] Iteration 46800 (5.39602 iter/s, 18.5322s/100 iters), loss = 0.00634784
I0414 07:15:00.812191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:15:00.812191 17564 solver.cpp:238]     Train net output #1: loss = 0.00634794 (* 1 = 0.00634794 loss)
I0414 07:15:00.812191 17564 sgd_solver.cpp:105] Iteration 46800, lr = 1e-07
I0414 07:15:15.077193 17564 solver.cpp:219] Iteration 46900 (7.01036 iter/s, 14.2646s/100 iters), loss = 0.012113
I0414 07:15:15.077193 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:15:15.077193 17564 solver.cpp:238]     Train net output #1: loss = 0.0121131 (* 1 = 0.0121131 loss)
I0414 07:15:15.077193 17564 sgd_solver.cpp:105] Iteration 46900, lr = 1e-07
I0414 07:15:29.334192 17564 solver.cpp:219] Iteration 47000 (7.01418 iter/s, 14.2568s/100 iters), loss = 0.0219832
I0414 07:15:29.334192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:15:29.334192 17564 solver.cpp:238]     Train net output #1: loss = 0.0219833 (* 1 = 0.0219833 loss)
I0414 07:15:29.334192 17564 sgd_solver.cpp:105] Iteration 47000, lr = 1e-07
I0414 07:15:43.587191 17564 solver.cpp:219] Iteration 47100 (7.01626 iter/s, 14.2526s/100 iters), loss = 0.0110656
I0414 07:15:43.587191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:15:43.587191 17564 solver.cpp:238]     Train net output #1: loss = 0.0110657 (* 1 = 0.0110657 loss)
I0414 07:15:43.587191 17564 sgd_solver.cpp:105] Iteration 47100, lr = 1e-07
I0414 07:15:57.832191 17564 solver.cpp:219] Iteration 47200 (7.02058 iter/s, 14.2438s/100 iters), loss = 0.00514025
I0414 07:15:57.832191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:15:57.832191 17564 solver.cpp:238]     Train net output #1: loss = 0.00514035 (* 1 = 0.00514035 loss)
I0414 07:15:57.832191 17564 sgd_solver.cpp:105] Iteration 47200, lr = 1e-07
I0414 07:16:12.094192 17564 solver.cpp:219] Iteration 47300 (7.01174 iter/s, 14.2618s/100 iters), loss = 0.00975081
I0414 07:16:12.094192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:16:12.094192 17564 solver.cpp:238]     Train net output #1: loss = 0.00975091 (* 1 = 0.00975091 loss)
I0414 07:16:12.094192 17564 sgd_solver.cpp:105] Iteration 47300, lr = 1e-07
I0414 07:16:25.649194 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:16:26.218192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_47400.caffemodel
I0414 07:16:26.359192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_47400.solverstate
I0414 07:16:26.423192 17564 solver.cpp:331] Iteration 47400, Testing net (#0)
I0414 07:16:26.423192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:16:30.344202 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:16:30.506193 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:16:30.506193 17564 solver.cpp:398]     Test net output #1: loss = 0.014058 (* 1 = 0.014058 loss)
I0414 07:16:30.645192 17564 solver.cpp:219] Iteration 47400 (5.39085 iter/s, 18.55s/100 iters), loss = 0.00494925
I0414 07:16:30.645192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:16:30.645192 17564 solver.cpp:238]     Train net output #1: loss = 0.00494935 (* 1 = 0.00494935 loss)
I0414 07:16:30.645192 17564 sgd_solver.cpp:105] Iteration 47400, lr = 1e-07
I0414 07:16:44.918191 17564 solver.cpp:219] Iteration 47500 (7.00637 iter/s, 14.2727s/100 iters), loss = 0.0111448
I0414 07:16:44.918191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:16:44.918191 17564 solver.cpp:238]     Train net output #1: loss = 0.0111449 (* 1 = 0.0111449 loss)
I0414 07:16:44.918191 17564 sgd_solver.cpp:105] Iteration 47500, lr = 1e-07
I0414 07:16:59.181191 17564 solver.cpp:219] Iteration 47600 (7.0114 iter/s, 14.2625s/100 iters), loss = 0.00958602
I0414 07:16:59.181191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:16:59.181191 17564 solver.cpp:238]     Train net output #1: loss = 0.00958613 (* 1 = 0.00958613 loss)
I0414 07:16:59.181191 17564 sgd_solver.cpp:105] Iteration 47600, lr = 1e-07
I0414 07:17:13.465191 17564 solver.cpp:219] Iteration 47700 (7.00094 iter/s, 14.2838s/100 iters), loss = 0.0206183
I0414 07:17:13.465191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:17:13.466192 17564 solver.cpp:238]     Train net output #1: loss = 0.0206184 (* 1 = 0.0206184 loss)
I0414 07:17:13.466192 17564 sgd_solver.cpp:105] Iteration 47700, lr = 1e-07
I0414 07:17:27.730191 17564 solver.cpp:219] Iteration 47800 (7.0106 iter/s, 14.2641s/100 iters), loss = 0.00442381
I0414 07:17:27.730191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:17:27.730191 17564 solver.cpp:238]     Train net output #1: loss = 0.00442391 (* 1 = 0.00442391 loss)
I0414 07:17:27.730191 17564 sgd_solver.cpp:105] Iteration 47800, lr = 1e-07
I0414 07:17:41.996193 17564 solver.cpp:219] Iteration 47900 (7.00977 iter/s, 14.2658s/100 iters), loss = 0.00474008
I0414 07:17:41.997193 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:17:41.997193 17564 solver.cpp:238]     Train net output #1: loss = 0.00474019 (* 1 = 0.00474019 loss)
I0414 07:17:41.997193 17564 sgd_solver.cpp:105] Iteration 47900, lr = 1e-07
I0414 07:17:55.557193 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:17:56.125205 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_48000.caffemodel
I0414 07:17:56.266209 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_48000.solverstate
I0414 07:17:56.330194 17564 solver.cpp:331] Iteration 48000, Testing net (#0)
I0414 07:17:56.330194 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:18:00.251191 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:18:00.412191 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:18:00.412191 17564 solver.cpp:398]     Test net output #1: loss = 0.0140688 (* 1 = 0.0140688 loss)
I0414 07:18:00.551192 17564 solver.cpp:219] Iteration 48000 (5.38973 iter/s, 18.5538s/100 iters), loss = 0.00805992
I0414 07:18:00.551192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:18:00.551192 17564 solver.cpp:238]     Train net output #1: loss = 0.00806003 (* 1 = 0.00806003 loss)
I0414 07:18:00.551192 17564 sgd_solver.cpp:105] Iteration 48000, lr = 1e-07
I0414 07:18:14.826191 17564 solver.cpp:219] Iteration 48100 (7.00563 iter/s, 14.2742s/100 iters), loss = 0.0102005
I0414 07:18:14.826191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:18:14.826191 17564 solver.cpp:238]     Train net output #1: loss = 0.0102006 (* 1 = 0.0102006 loss)
I0414 07:18:14.826191 17564 sgd_solver.cpp:105] Iteration 48100, lr = 1e-07
I0414 07:18:29.089206 17564 solver.cpp:219] Iteration 48200 (7.01134 iter/s, 14.2626s/100 iters), loss = 0.0173558
I0414 07:18:29.089206 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:18:29.089206 17564 solver.cpp:238]     Train net output #1: loss = 0.0173559 (* 1 = 0.0173559 loss)
I0414 07:18:29.089206 17564 sgd_solver.cpp:105] Iteration 48200, lr = 1e-07
I0414 07:18:43.346191 17564 solver.cpp:219] Iteration 48300 (7.01433 iter/s, 14.2565s/100 iters), loss = 0.00784314
I0414 07:18:43.346191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:18:43.346191 17564 solver.cpp:238]     Train net output #1: loss = 0.00784324 (* 1 = 0.00784324 loss)
I0414 07:18:43.346191 17564 sgd_solver.cpp:105] Iteration 48300, lr = 1e-07
I0414 07:18:57.602191 17564 solver.cpp:219] Iteration 48400 (7.01464 iter/s, 14.2559s/100 iters), loss = 0.00795066
I0414 07:18:57.602191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:18:57.602191 17564 solver.cpp:238]     Train net output #1: loss = 0.00795076 (* 1 = 0.00795076 loss)
I0414 07:18:57.602191 17564 sgd_solver.cpp:105] Iteration 48400, lr = 1e-07
I0414 07:19:11.875192 17564 solver.cpp:219] Iteration 48500 (7.00681 iter/s, 14.2718s/100 iters), loss = 0.00378012
I0414 07:19:11.875192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:19:11.875192 17564 solver.cpp:238]     Train net output #1: loss = 0.00378022 (* 1 = 0.00378022 loss)
I0414 07:19:11.875192 17564 sgd_solver.cpp:105] Iteration 48500, lr = 1e-07
I0414 07:19:25.436192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:19:26.003192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_48600.caffemodel
I0414 07:19:26.143193 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_48600.solverstate
I0414 07:19:26.222192 17564 solver.cpp:331] Iteration 48600, Testing net (#0)
I0414 07:19:26.222192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:19:30.140193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:19:30.302192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:19:30.302192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140753 (* 1 = 0.0140753 loss)
I0414 07:19:30.441191 17564 solver.cpp:219] Iteration 48600 (5.38655 iter/s, 18.5647s/100 iters), loss = 0.00676917
I0414 07:19:30.441191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:19:30.441191 17564 solver.cpp:238]     Train net output #1: loss = 0.00676926 (* 1 = 0.00676926 loss)
I0414 07:19:30.441191 17564 sgd_solver.cpp:105] Iteration 48600, lr = 1e-07
I0414 07:19:44.702191 17564 solver.cpp:219] Iteration 48700 (7.01209 iter/s, 14.2611s/100 iters), loss = 0.0106643
I0414 07:19:44.702191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:19:44.702191 17564 solver.cpp:238]     Train net output #1: loss = 0.0106644 (* 1 = 0.0106644 loss)
I0414 07:19:44.702191 17564 sgd_solver.cpp:105] Iteration 48700, lr = 1e-07
I0414 07:19:58.967191 17564 solver.cpp:219] Iteration 48800 (7.01042 iter/s, 14.2645s/100 iters), loss = 0.016843
I0414 07:19:58.967191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:19:58.967191 17564 solver.cpp:238]     Train net output #1: loss = 0.0168431 (* 1 = 0.0168431 loss)
I0414 07:19:58.967191 17564 sgd_solver.cpp:105] Iteration 48800, lr = 1e-07
I0414 07:20:13.236191 17564 solver.cpp:219] Iteration 48900 (7.00859 iter/s, 14.2682s/100 iters), loss = 0.0107
I0414 07:20:13.236191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:20:13.236191 17564 solver.cpp:238]     Train net output #1: loss = 0.0107001 (* 1 = 0.0107001 loss)
I0414 07:20:13.236191 17564 sgd_solver.cpp:105] Iteration 48900, lr = 1e-07
I0414 07:20:27.496191 17564 solver.cpp:219] Iteration 49000 (7.01281 iter/s, 14.2596s/100 iters), loss = 0.0055556
I0414 07:20:27.496191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:20:27.496191 17564 solver.cpp:238]     Train net output #1: loss = 0.0055557 (* 1 = 0.0055557 loss)
I0414 07:20:27.496191 17564 sgd_solver.cpp:105] Iteration 49000, lr = 1e-07
I0414 07:20:41.746191 17564 solver.cpp:219] Iteration 49100 (7.0178 iter/s, 14.2495s/100 iters), loss = 0.00536885
I0414 07:20:41.746191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:20:41.746191 17564 solver.cpp:238]     Train net output #1: loss = 0.00536895 (* 1 = 0.00536895 loss)
I0414 07:20:41.746191 17564 sgd_solver.cpp:105] Iteration 49100, lr = 1e-07
I0414 07:20:55.304193 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:20:55.872191 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_49200.caffemodel
I0414 07:20:56.013192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_49200.solverstate
I0414 07:20:56.078191 17564 solver.cpp:331] Iteration 49200, Testing net (#0)
I0414 07:20:56.078191 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:20:59.999192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:21:00.161195 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:21:00.161195 17564 solver.cpp:398]     Test net output #1: loss = 0.0140367 (* 1 = 0.0140367 loss)
I0414 07:21:00.300191 17564 solver.cpp:219] Iteration 49200 (5.39 iter/s, 18.5529s/100 iters), loss = 0.00526306
I0414 07:21:00.300191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:21:00.300191 17564 solver.cpp:238]     Train net output #1: loss = 0.00526316 (* 1 = 0.00526316 loss)
I0414 07:21:00.300191 17564 sgd_solver.cpp:105] Iteration 49200, lr = 1e-07
I0414 07:21:14.571192 17564 solver.cpp:219] Iteration 49300 (7.00752 iter/s, 14.2704s/100 iters), loss = 0.0160207
I0414 07:21:14.571192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:21:14.571192 17564 solver.cpp:238]     Train net output #1: loss = 0.0160208 (* 1 = 0.0160208 loss)
I0414 07:21:14.571192 17564 sgd_solver.cpp:105] Iteration 49300, lr = 1e-07
I0414 07:21:28.830191 17564 solver.cpp:219] Iteration 49400 (7.01307 iter/s, 14.2591s/100 iters), loss = 0.0118004
I0414 07:21:28.830191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:21:28.830191 17564 solver.cpp:238]     Train net output #1: loss = 0.0118005 (* 1 = 0.0118005 loss)
I0414 07:21:28.830191 17564 sgd_solver.cpp:105] Iteration 49400, lr = 1e-07
I0414 07:21:43.086191 17564 solver.cpp:219] Iteration 49500 (7.01489 iter/s, 14.2554s/100 iters), loss = 0.00857407
I0414 07:21:43.086191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:21:43.086191 17564 solver.cpp:238]     Train net output #1: loss = 0.00857416 (* 1 = 0.00857416 loss)
I0414 07:21:43.086191 17564 sgd_solver.cpp:105] Iteration 49500, lr = 1e-07
I0414 07:21:57.353191 17564 solver.cpp:219] Iteration 49600 (7.00967 iter/s, 14.266s/100 iters), loss = 0.00445036
I0414 07:21:57.353191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:21:57.353191 17564 solver.cpp:238]     Train net output #1: loss = 0.00445046 (* 1 = 0.00445046 loss)
I0414 07:21:57.353191 17564 sgd_solver.cpp:105] Iteration 49600, lr = 1e-07
I0414 07:22:11.614190 17564 solver.cpp:219] Iteration 49700 (7.01229 iter/s, 14.2607s/100 iters), loss = 0.00429497
I0414 07:22:11.614190 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:22:11.614190 17564 solver.cpp:238]     Train net output #1: loss = 0.00429506 (* 1 = 0.00429506 loss)
I0414 07:22:11.614190 17564 sgd_solver.cpp:105] Iteration 49700, lr = 1e-07
I0414 07:22:25.170192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:22:25.737192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_49800.caffemodel
I0414 07:22:25.876193 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_49800.solverstate
I0414 07:22:25.941192 17564 solver.cpp:331] Iteration 49800, Testing net (#0)
I0414 07:22:25.941192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:22:29.861192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:22:30.023192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:22:30.023192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140359 (* 1 = 0.0140359 loss)
I0414 07:22:30.163206 17564 solver.cpp:219] Iteration 49800 (5.39138 iter/s, 18.5481s/100 iters), loss = 0.00459591
I0414 07:22:30.163206 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:22:30.163206 17564 solver.cpp:238]     Train net output #1: loss = 0.00459602 (* 1 = 0.00459602 loss)
I0414 07:22:30.163206 17564 sgd_solver.cpp:105] Iteration 49800, lr = 1e-07
I0414 07:22:44.441192 17564 solver.cpp:219] Iteration 49900 (7.0038 iter/s, 14.278s/100 iters), loss = 0.0122404
I0414 07:22:44.441192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:22:44.441192 17564 solver.cpp:238]     Train net output #1: loss = 0.0122405 (* 1 = 0.0122405 loss)
I0414 07:22:44.441192 17564 sgd_solver.cpp:105] Iteration 49900, lr = 1e-07
I0414 07:22:58.710207 17564 solver.cpp:219] Iteration 50000 (7.00834 iter/s, 14.2687s/100 iters), loss = 0.0141028
I0414 07:22:58.711207 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:22:58.711207 17564 solver.cpp:238]     Train net output #1: loss = 0.0141029 (* 1 = 0.0141029 loss)
I0414 07:22:58.711207 17564 sgd_solver.cpp:105] Iteration 50000, lr = 1e-07
I0414 07:23:12.995193 17564 solver.cpp:219] Iteration 50100 (7.00089 iter/s, 14.2839s/100 iters), loss = 0.00684423
I0414 07:23:12.995193 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:23:12.995193 17564 solver.cpp:238]     Train net output #1: loss = 0.00684432 (* 1 = 0.00684432 loss)
I0414 07:23:12.995193 17564 sgd_solver.cpp:105] Iteration 50100, lr = 1e-07
I0414 07:23:27.264191 17564 solver.cpp:219] Iteration 50200 (7.00851 iter/s, 14.2684s/100 iters), loss = 0.0039588
I0414 07:23:27.264191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:23:27.264191 17564 solver.cpp:238]     Train net output #1: loss = 0.00395889 (* 1 = 0.00395889 loss)
I0414 07:23:27.264191 17564 sgd_solver.cpp:105] Iteration 50200, lr = 1e-07
I0414 07:23:41.527191 17564 solver.cpp:219] Iteration 50300 (7.01165 iter/s, 14.262s/100 iters), loss = 0.00460626
I0414 07:23:41.527191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:23:41.527191 17564 solver.cpp:238]     Train net output #1: loss = 0.00460635 (* 1 = 0.00460635 loss)
I0414 07:23:41.527191 17564 sgd_solver.cpp:105] Iteration 50300, lr = 1e-07
I0414 07:23:55.087193 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:23:55.655192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_50400.caffemodel
I0414 07:23:55.792192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_50400.solverstate
I0414 07:23:55.858194 17564 solver.cpp:331] Iteration 50400, Testing net (#0)
I0414 07:23:55.859202 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:23:59.778193 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:23:59.939198 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:23:59.939198 17564 solver.cpp:398]     Test net output #1: loss = 0.0140622 (* 1 = 0.0140622 loss)
I0414 07:24:00.078191 17564 solver.cpp:219] Iteration 50400 (5.39058 iter/s, 18.5509s/100 iters), loss = 0.00859646
I0414 07:24:00.078191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:24:00.078191 17564 solver.cpp:238]     Train net output #1: loss = 0.00859656 (* 1 = 0.00859656 loss)
I0414 07:24:00.078191 17564 sgd_solver.cpp:105] Iteration 50400, lr = 1e-07
I0414 07:24:14.359191 17564 solver.cpp:219] Iteration 50500 (7.00254 iter/s, 14.2805s/100 iters), loss = 0.0074008
I0414 07:24:14.359191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:24:14.359191 17564 solver.cpp:238]     Train net output #1: loss = 0.0074009 (* 1 = 0.0074009 loss)
I0414 07:24:14.359191 17564 sgd_solver.cpp:105] Iteration 50500, lr = 1e-07
I0414 07:24:28.615191 17564 solver.cpp:219] Iteration 50600 (7.01482 iter/s, 14.2555s/100 iters), loss = 0.0182635
I0414 07:24:28.615191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:24:28.615191 17564 solver.cpp:238]     Train net output #1: loss = 0.0182636 (* 1 = 0.0182636 loss)
I0414 07:24:28.615191 17564 sgd_solver.cpp:105] Iteration 50600, lr = 1e-07
I0414 07:24:42.870192 17564 solver.cpp:219] Iteration 50700 (7.01529 iter/s, 14.2546s/100 iters), loss = 0.0167972
I0414 07:24:42.871191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:24:42.871191 17564 solver.cpp:238]     Train net output #1: loss = 0.0167973 (* 1 = 0.0167973 loss)
I0414 07:24:42.871191 17564 sgd_solver.cpp:105] Iteration 50700, lr = 1e-07
I0414 07:24:57.143191 17564 solver.cpp:219] Iteration 50800 (7.00651 iter/s, 14.2724s/100 iters), loss = 0.00468648
I0414 07:24:57.144192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:24:57.144192 17564 solver.cpp:238]     Train net output #1: loss = 0.00468657 (* 1 = 0.00468657 loss)
I0414 07:24:57.144192 17564 sgd_solver.cpp:105] Iteration 50800, lr = 1e-07
I0414 07:25:11.419191 17564 solver.cpp:219] Iteration 50900 (7.00509 iter/s, 14.2753s/100 iters), loss = 0.00427073
I0414 07:25:11.419191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:25:11.419191 17564 solver.cpp:238]     Train net output #1: loss = 0.00427082 (* 1 = 0.00427082 loss)
I0414 07:25:11.419191 17564 sgd_solver.cpp:105] Iteration 50900, lr = 1e-07
I0414 07:25:24.999191 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:25:25.568197 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_51000.caffemodel
I0414 07:25:25.712196 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_51000.solverstate
I0414 07:25:25.781193 17564 solver.cpp:331] Iteration 51000, Testing net (#0)
I0414 07:25:25.781193 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:25:29.701192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:25:29.863193 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:25:29.863193 17564 solver.cpp:398]     Test net output #1: loss = 0.0140732 (* 1 = 0.0140732 loss)
I0414 07:25:30.002192 17564 solver.cpp:219] Iteration 51000 (5.38158 iter/s, 18.5819s/100 iters), loss = 0.0056696
I0414 07:25:30.002192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:25:30.002192 17564 solver.cpp:238]     Train net output #1: loss = 0.00566971 (* 1 = 0.00566971 loss)
I0414 07:25:30.002192 17564 sgd_solver.cpp:105] Iteration 51000, lr = 1e-07
I0414 07:25:44.285192 17564 solver.cpp:219] Iteration 51100 (7.00134 iter/s, 14.283s/100 iters), loss = 0.00632916
I0414 07:25:44.286192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:25:44.286192 17564 solver.cpp:238]     Train net output #1: loss = 0.00632927 (* 1 = 0.00632927 loss)
I0414 07:25:44.286192 17564 sgd_solver.cpp:105] Iteration 51100, lr = 1e-07
I0414 07:25:58.585191 17564 solver.cpp:219] Iteration 51200 (6.99351 iter/s, 14.299s/100 iters), loss = 0.0138231
I0414 07:25:58.585191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:25:58.585191 17564 solver.cpp:238]     Train net output #1: loss = 0.0138232 (* 1 = 0.0138232 loss)
I0414 07:25:58.585191 17564 sgd_solver.cpp:105] Iteration 51200, lr = 1e-07
I0414 07:26:12.873191 17564 solver.cpp:219] Iteration 51300 (6.99937 iter/s, 14.287s/100 iters), loss = 0.0122498
I0414 07:26:12.873191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:26:12.873191 17564 solver.cpp:238]     Train net output #1: loss = 0.0122499 (* 1 = 0.0122499 loss)
I0414 07:26:12.873191 17564 sgd_solver.cpp:105] Iteration 51300, lr = 1e-07
I0414 07:26:27.158191 17564 solver.cpp:219] Iteration 51400 (7.00039 iter/s, 14.2849s/100 iters), loss = 0.00362494
I0414 07:26:27.158191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:26:27.158191 17564 solver.cpp:238]     Train net output #1: loss = 0.00362504 (* 1 = 0.00362504 loss)
I0414 07:26:27.158191 17564 sgd_solver.cpp:105] Iteration 51400, lr = 1e-07
I0414 07:26:41.447192 17564 solver.cpp:219] Iteration 51500 (6.9986 iter/s, 14.2886s/100 iters), loss = 0.00394241
I0414 07:26:41.447192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:26:41.447192 17564 solver.cpp:238]     Train net output #1: loss = 0.00394252 (* 1 = 0.00394252 loss)
I0414 07:26:41.447192 17564 sgd_solver.cpp:105] Iteration 51500, lr = 1e-07
I0414 07:26:55.024194 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:26:55.593191 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_51600.caffemodel
I0414 07:26:55.734210 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_51600.solverstate
I0414 07:26:55.800191 17564 solver.cpp:331] Iteration 51600, Testing net (#0)
I0414 07:26:55.800191 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:26:59.720192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:26:59.881191 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:26:59.881191 17564 solver.cpp:398]     Test net output #1: loss = 0.0140622 (* 1 = 0.0140622 loss)
I0414 07:27:00.020191 17564 solver.cpp:219] Iteration 51600 (5.38441 iter/s, 18.5721s/100 iters), loss = 0.00865043
I0414 07:27:00.020191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:27:00.020191 17564 solver.cpp:238]     Train net output #1: loss = 0.00865054 (* 1 = 0.00865054 loss)
I0414 07:27:00.020191 17564 sgd_solver.cpp:105] Iteration 51600, lr = 1e-07
I0414 07:27:14.297191 17564 solver.cpp:219] Iteration 51700 (7.00453 iter/s, 14.2765s/100 iters), loss = 0.00795352
I0414 07:27:14.297191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:27:14.297191 17564 solver.cpp:238]     Train net output #1: loss = 0.00795364 (* 1 = 0.00795364 loss)
I0414 07:27:14.297191 17564 sgd_solver.cpp:105] Iteration 51700, lr = 1e-07
I0414 07:27:28.572191 17564 solver.cpp:219] Iteration 51800 (7.00572 iter/s, 14.274s/100 iters), loss = 0.0145494
I0414 07:27:28.572191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:27:28.572191 17564 solver.cpp:238]     Train net output #1: loss = 0.0145495 (* 1 = 0.0145495 loss)
I0414 07:27:28.572191 17564 sgd_solver.cpp:105] Iteration 51800, lr = 1e-07
I0414 07:27:42.847192 17564 solver.cpp:219] Iteration 51900 (7.00518 iter/s, 14.2751s/100 iters), loss = 0.00771889
I0414 07:27:42.847192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:27:42.847192 17564 solver.cpp:238]     Train net output #1: loss = 0.00771901 (* 1 = 0.00771901 loss)
I0414 07:27:42.847192 17564 sgd_solver.cpp:105] Iteration 51900, lr = 1e-07
I0414 07:27:57.129191 17564 solver.cpp:219] Iteration 52000 (7.0021 iter/s, 14.2814s/100 iters), loss = 0.00481092
I0414 07:27:57.129191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:27:57.129191 17564 solver.cpp:238]     Train net output #1: loss = 0.00481103 (* 1 = 0.00481103 loss)
I0414 07:27:57.129191 17564 sgd_solver.cpp:105] Iteration 52000, lr = 1e-07
I0414 07:28:11.436192 17564 solver.cpp:219] Iteration 52100 (6.99029 iter/s, 14.3056s/100 iters), loss = 0.00533739
I0414 07:28:11.436192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:28:11.436192 17564 solver.cpp:238]     Train net output #1: loss = 0.00533751 (* 1 = 0.00533751 loss)
I0414 07:28:11.436192 17564 sgd_solver.cpp:105] Iteration 52100, lr = 1e-07
I0414 07:28:25.019201 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:28:25.589191 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_52200.caffemodel
I0414 07:28:25.728194 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_52200.solverstate
I0414 07:28:25.792194 17564 solver.cpp:331] Iteration 52200, Testing net (#0)
I0414 07:28:25.792194 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:28:29.716194 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:28:29.877192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:28:29.877192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140426 (* 1 = 0.0140426 loss)
I0414 07:28:30.016192 17564 solver.cpp:219] Iteration 52200 (5.38226 iter/s, 18.5796s/100 iters), loss = 0.0042427
I0414 07:28:30.016192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:28:30.016192 17564 solver.cpp:238]     Train net output #1: loss = 0.00424283 (* 1 = 0.00424283 loss)
I0414 07:28:30.016192 17564 sgd_solver.cpp:105] Iteration 52200, lr = 1e-07
I0414 07:28:44.294191 17564 solver.cpp:219] Iteration 52300 (7.00388 iter/s, 14.2778s/100 iters), loss = 0.0125214
I0414 07:28:44.294191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:28:44.294191 17564 solver.cpp:238]     Train net output #1: loss = 0.0125216 (* 1 = 0.0125216 loss)
I0414 07:28:44.294191 17564 sgd_solver.cpp:105] Iteration 52300, lr = 1e-07
I0414 07:28:58.564191 17564 solver.cpp:219] Iteration 52400 (7.00826 iter/s, 14.2689s/100 iters), loss = 0.0104289
I0414 07:28:58.564191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:28:58.564191 17564 solver.cpp:238]     Train net output #1: loss = 0.0104291 (* 1 = 0.0104291 loss)
I0414 07:28:58.564191 17564 sgd_solver.cpp:105] Iteration 52400, lr = 1e-07
I0414 07:29:12.867192 17564 solver.cpp:219] Iteration 52500 (6.99138 iter/s, 14.3033s/100 iters), loss = 0.0169242
I0414 07:29:12.868192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:29:12.868192 17564 solver.cpp:238]     Train net output #1: loss = 0.0169243 (* 1 = 0.0169243 loss)
I0414 07:29:12.868192 17564 sgd_solver.cpp:105] Iteration 52500, lr = 1e-07
I0414 07:29:27.159191 17564 solver.cpp:219] Iteration 52600 (6.99763 iter/s, 14.2906s/100 iters), loss = 0.00554498
I0414 07:29:27.159191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:29:27.159191 17564 solver.cpp:238]     Train net output #1: loss = 0.0055451 (* 1 = 0.0055451 loss)
I0414 07:29:27.159191 17564 sgd_solver.cpp:105] Iteration 52600, lr = 1e-07
I0414 07:29:41.444191 17564 solver.cpp:219] Iteration 52700 (7.00022 iter/s, 14.2853s/100 iters), loss = 0.00363484
I0414 07:29:41.444191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:29:41.445192 17564 solver.cpp:238]     Train net output #1: loss = 0.00363496 (* 1 = 0.00363496 loss)
I0414 07:29:41.445192 17564 sgd_solver.cpp:105] Iteration 52700, lr = 1e-07
I0414 07:29:55.018193 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:29:55.586192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_52800.caffemodel
I0414 07:29:55.727192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_52800.solverstate
I0414 07:29:55.793192 17564 solver.cpp:331] Iteration 52800, Testing net (#0)
I0414 07:29:55.793192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:29:59.711194 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:29:59.873201 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:29:59.873201 17564 solver.cpp:398]     Test net output #1: loss = 0.014089 (* 1 = 0.014089 loss)
I0414 07:30:00.011191 17564 solver.cpp:219] Iteration 52800 (5.38612 iter/s, 18.5662s/100 iters), loss = 0.00663101
I0414 07:30:00.011191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:30:00.011191 17564 solver.cpp:238]     Train net output #1: loss = 0.00663112 (* 1 = 0.00663112 loss)
I0414 07:30:00.011191 17564 sgd_solver.cpp:105] Iteration 52800, lr = 1e-07
I0414 07:30:14.282191 17564 solver.cpp:219] Iteration 52900 (7.00767 iter/s, 14.2701s/100 iters), loss = 0.00977823
I0414 07:30:14.282191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:30:14.282191 17564 solver.cpp:238]     Train net output #1: loss = 0.00977835 (* 1 = 0.00977835 loss)
I0414 07:30:14.282191 17564 sgd_solver.cpp:105] Iteration 52900, lr = 1e-07
I0414 07:30:28.548192 17564 solver.cpp:219] Iteration 53000 (7.00996 iter/s, 14.2654s/100 iters), loss = 0.0133179
I0414 07:30:28.548192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:30:28.548192 17564 solver.cpp:238]     Train net output #1: loss = 0.013318 (* 1 = 0.013318 loss)
I0414 07:30:28.548192 17564 sgd_solver.cpp:105] Iteration 53000, lr = 1e-07
I0414 07:30:42.816191 17564 solver.cpp:219] Iteration 53100 (7.00921 iter/s, 14.2669s/100 iters), loss = 0.0125591
I0414 07:30:42.816191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:30:42.816191 17564 solver.cpp:238]     Train net output #1: loss = 0.0125592 (* 1 = 0.0125592 loss)
I0414 07:30:42.816191 17564 sgd_solver.cpp:105] Iteration 53100, lr = 1e-07
I0414 07:30:57.078191 17564 solver.cpp:219] Iteration 53200 (7.01154 iter/s, 14.2622s/100 iters), loss = 0.0031333
I0414 07:30:57.079192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:30:57.079192 17564 solver.cpp:238]     Train net output #1: loss = 0.00313341 (* 1 = 0.00313341 loss)
I0414 07:30:57.079192 17564 sgd_solver.cpp:105] Iteration 53200, lr = 1e-07
I0414 07:31:11.349191 17564 solver.cpp:219] Iteration 53300 (7.00781 iter/s, 14.2698s/100 iters), loss = 0.00539088
I0414 07:31:11.349191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:31:11.349191 17564 solver.cpp:238]     Train net output #1: loss = 0.00539099 (* 1 = 0.00539099 loss)
I0414 07:31:11.349191 17564 sgd_solver.cpp:105] Iteration 53300, lr = 1e-07
I0414 07:31:24.898191 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:31:25.467191 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_53400.caffemodel
I0414 07:31:25.605192 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_53400.solverstate
I0414 07:31:25.668192 17564 solver.cpp:331] Iteration 53400, Testing net (#0)
I0414 07:31:25.668192 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:31:29.591192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:31:29.752192 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:31:29.752192 17564 solver.cpp:398]     Test net output #1: loss = 0.0140463 (* 1 = 0.0140463 loss)
I0414 07:31:29.891191 17564 solver.cpp:219] Iteration 53400 (5.39326 iter/s, 18.5417s/100 iters), loss = 0.00588192
I0414 07:31:29.891191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:31:29.891191 17564 solver.cpp:238]     Train net output #1: loss = 0.00588202 (* 1 = 0.00588202 loss)
I0414 07:31:29.891191 17564 sgd_solver.cpp:105] Iteration 53400, lr = 1e-07
I0414 07:31:44.164191 17564 solver.cpp:219] Iteration 53500 (7.00676 iter/s, 14.2719s/100 iters), loss = 0.00961721
I0414 07:31:44.164191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:31:44.164191 17564 solver.cpp:238]     Train net output #1: loss = 0.00961731 (* 1 = 0.00961731 loss)
I0414 07:31:44.164191 17564 sgd_solver.cpp:105] Iteration 53500, lr = 1e-07
I0414 07:31:58.433207 17564 solver.cpp:219] Iteration 53600 (7.00846 iter/s, 14.2685s/100 iters), loss = 0.0102223
I0414 07:31:58.433207 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:31:58.433207 17564 solver.cpp:238]     Train net output #1: loss = 0.0102224 (* 1 = 0.0102224 loss)
I0414 07:31:58.433207 17564 sgd_solver.cpp:105] Iteration 53600, lr = 1e-07
I0414 07:32:12.699193 17564 solver.cpp:219] Iteration 53700 (7.00977 iter/s, 14.2658s/100 iters), loss = 0.0178485
I0414 07:32:12.699193 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:32:12.699193 17564 solver.cpp:238]     Train net output #1: loss = 0.0178486 (* 1 = 0.0178486 loss)
I0414 07:32:12.699193 17564 sgd_solver.cpp:105] Iteration 53700, lr = 1e-07
I0414 07:32:26.951191 17564 solver.cpp:219] Iteration 53800 (7.01688 iter/s, 14.2514s/100 iters), loss = 0.00427052
I0414 07:32:26.951191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:32:26.951191 17564 solver.cpp:238]     Train net output #1: loss = 0.00427063 (* 1 = 0.00427063 loss)
I0414 07:32:26.951191 17564 sgd_solver.cpp:105] Iteration 53800, lr = 1e-07
I0414 07:32:41.212191 17564 solver.cpp:219] Iteration 53900 (7.01246 iter/s, 14.2603s/100 iters), loss = 0.00470737
I0414 07:32:41.212191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:32:41.212191 17564 solver.cpp:238]     Train net output #1: loss = 0.00470748 (* 1 = 0.00470748 loss)
I0414 07:32:41.212191 17564 sgd_solver.cpp:105] Iteration 53900, lr = 1e-07
I0414 07:32:54.763192 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:32:55.331192 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_54000.caffemodel
I0414 07:32:55.471194 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_54000.solverstate
I0414 07:32:55.534191 17564 solver.cpp:331] Iteration 54000, Testing net (#0)
I0414 07:32:55.534191 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:32:59.454192 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:32:59.616200 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:32:59.616200 17564 solver.cpp:398]     Test net output #1: loss = 0.0140743 (* 1 = 0.0140743 loss)
I0414 07:32:59.755192 17564 solver.cpp:219] Iteration 54000 (5.39302 iter/s, 18.5425s/100 iters), loss = 0.00796511
I0414 07:32:59.755192 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:32:59.755192 17564 solver.cpp:238]     Train net output #1: loss = 0.00796521 (* 1 = 0.00796521 loss)
I0414 07:32:59.755192 17564 sgd_solver.cpp:105] Iteration 54000, lr = 1e-07
I0414 07:33:14.036191 17564 solver.cpp:219] Iteration 54100 (7.00252 iter/s, 14.2806s/100 iters), loss = 0.0250367
I0414 07:33:14.036191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:33:14.036191 17564 solver.cpp:238]     Train net output #1: loss = 0.0250368 (* 1 = 0.0250368 loss)
I0414 07:33:14.036191 17564 sgd_solver.cpp:105] Iteration 54100, lr = 1e-07
I0414 07:33:28.304191 17564 solver.cpp:219] Iteration 54200 (7.00931 iter/s, 14.2667s/100 iters), loss = 0.0171829
I0414 07:33:28.304191 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:33:28.304191 17564 solver.cpp:238]     Train net output #1: loss = 0.017183 (* 1 = 0.017183 loss)
I0414 07:33:28.304191 17564 sgd_solver.cpp:105] Iteration 54200, lr = 1e-07
I0414 07:33:42.569275 17564 solver.cpp:219] Iteration 54300 (7.01038 iter/s, 14.2646s/100 iters), loss = 0.00980548
I0414 07:33:42.569275 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:33:42.569275 17564 solver.cpp:238]     Train net output #1: loss = 0.00980558 (* 1 = 0.00980558 loss)
I0414 07:33:42.569275 17564 sgd_solver.cpp:105] Iteration 54300, lr = 1e-07
I0414 07:33:56.841276 17564 solver.cpp:219] Iteration 54400 (7.00683 iter/s, 14.2718s/100 iters), loss = 0.00477993
I0414 07:33:56.841276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:33:56.841276 17564 solver.cpp:238]     Train net output #1: loss = 0.00478003 (* 1 = 0.00478003 loss)
I0414 07:33:56.841276 17564 sgd_solver.cpp:105] Iteration 54400, lr = 1e-07
I0414 07:34:11.111275 17564 solver.cpp:219] Iteration 54500 (7.00788 iter/s, 14.2697s/100 iters), loss = 0.00651783
I0414 07:34:11.111275 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:34:11.111275 17564 solver.cpp:238]     Train net output #1: loss = 0.00651794 (* 1 = 0.00651794 loss)
I0414 07:34:11.111275 17564 sgd_solver.cpp:105] Iteration 54500, lr = 1e-07
I0414 07:34:24.657279 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:34:25.227277 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_54600.caffemodel
I0414 07:34:25.366276 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_54600.solverstate
I0414 07:34:25.429276 17564 solver.cpp:331] Iteration 54600, Testing net (#0)
I0414 07:34:25.429276 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:34:29.352277 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:34:29.513276 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:34:29.513276 17564 solver.cpp:398]     Test net output #1: loss = 0.0140808 (* 1 = 0.0140808 loss)
I0414 07:34:29.652276 17564 solver.cpp:219] Iteration 54600 (5.39366 iter/s, 18.5403s/100 iters), loss = 0.00700909
I0414 07:34:29.652276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:34:29.652276 17564 solver.cpp:238]     Train net output #1: loss = 0.00700919 (* 1 = 0.00700919 loss)
I0414 07:34:29.652276 17564 sgd_solver.cpp:105] Iteration 54600, lr = 1e-07
I0414 07:34:43.915276 17564 solver.cpp:219] Iteration 54700 (7.01139 iter/s, 14.2625s/100 iters), loss = 0.0132092
I0414 07:34:43.915276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:34:43.915276 17564 solver.cpp:238]     Train net output #1: loss = 0.0132092 (* 1 = 0.0132092 loss)
I0414 07:34:43.915276 17564 sgd_solver.cpp:105] Iteration 54700, lr = 1e-07
I0414 07:34:58.174275 17564 solver.cpp:219] Iteration 54800 (7.01317 iter/s, 14.2589s/100 iters), loss = 0.00747008
I0414 07:34:58.175276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:34:58.175276 17564 solver.cpp:238]     Train net output #1: loss = 0.00747018 (* 1 = 0.00747018 loss)
I0414 07:34:58.175276 17564 sgd_solver.cpp:105] Iteration 54800, lr = 1e-07
I0414 07:35:12.455276 17564 solver.cpp:219] Iteration 54900 (7.00284 iter/s, 14.2799s/100 iters), loss = 0.0120952
I0414 07:35:12.455276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:35:12.455276 17564 solver.cpp:238]     Train net output #1: loss = 0.0120953 (* 1 = 0.0120953 loss)
I0414 07:35:12.455276 17564 sgd_solver.cpp:105] Iteration 54900, lr = 1e-07
I0414 07:35:26.727277 17564 solver.cpp:219] Iteration 55000 (7.00678 iter/s, 14.2719s/100 iters), loss = 0.00372599
I0414 07:35:26.728276 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:35:26.728276 17564 solver.cpp:238]     Train net output #1: loss = 0.00372608 (* 1 = 0.00372608 loss)
I0414 07:35:26.728276 17564 sgd_solver.cpp:105] Iteration 55000, lr = 1e-07
I0414 07:35:40.997278 17564 solver.cpp:219] Iteration 55100 (7.00806 iter/s, 14.2693s/100 iters), loss = 0.00492186
I0414 07:35:40.997278 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:35:40.997278 17564 solver.cpp:238]     Train net output #1: loss = 0.00492196 (* 1 = 0.00492196 loss)
I0414 07:35:40.998276 17564 sgd_solver.cpp:105] Iteration 55100, lr = 1e-07
I0414 07:35:54.552340 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:35:55.122339 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_55200.caffemodel
I0414 07:35:55.260340 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_55200.solverstate
I0414 07:35:55.325340 17564 solver.cpp:331] Iteration 55200, Testing net (#0)
I0414 07:35:55.325340 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:35:59.245339 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:35:59.406338 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:35:59.406338 17564 solver.cpp:398]     Test net output #1: loss = 0.0140557 (* 1 = 0.0140557 loss)
I0414 07:35:59.545352 17564 solver.cpp:219] Iteration 55200 (5.39173 iter/s, 18.5469s/100 iters), loss = 0.00386131
I0414 07:35:59.545352 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:35:59.545352 17564 solver.cpp:238]     Train net output #1: loss = 0.0038614 (* 1 = 0.0038614 loss)
I0414 07:35:59.545352 17564 sgd_solver.cpp:105] Iteration 55200, lr = 1e-07
I0414 07:36:13.828338 17564 solver.cpp:219] Iteration 55300 (7.00159 iter/s, 14.2825s/100 iters), loss = 0.00835594
I0414 07:36:13.828338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:36:13.828338 17564 solver.cpp:238]     Train net output #1: loss = 0.00835602 (* 1 = 0.00835602 loss)
I0414 07:36:13.828338 17564 sgd_solver.cpp:105] Iteration 55300, lr = 1e-07
I0414 07:36:28.099339 17564 solver.cpp:219] Iteration 55400 (7.00765 iter/s, 14.2701s/100 iters), loss = 0.0151029
I0414 07:36:28.099339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:36:28.099339 17564 solver.cpp:238]     Train net output #1: loss = 0.0151029 (* 1 = 0.0151029 loss)
I0414 07:36:28.099339 17564 sgd_solver.cpp:105] Iteration 55400, lr = 1e-07
I0414 07:36:42.365339 17564 solver.cpp:219] Iteration 55500 (7.0098 iter/s, 14.2657s/100 iters), loss = 0.0129075
I0414 07:36:42.365339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:36:42.365339 17564 solver.cpp:238]     Train net output #1: loss = 0.0129076 (* 1 = 0.0129076 loss)
I0414 07:36:42.365339 17564 sgd_solver.cpp:105] Iteration 55500, lr = 1e-07
I0414 07:36:56.636340 17564 solver.cpp:219] Iteration 55600 (7.00722 iter/s, 14.271s/100 iters), loss = 0.00631434
I0414 07:36:56.637341 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:36:56.637341 17564 solver.cpp:238]     Train net output #1: loss = 0.00631442 (* 1 = 0.00631442 loss)
I0414 07:36:56.637341 17564 sgd_solver.cpp:105] Iteration 55600, lr = 1e-07
I0414 07:37:10.913338 17564 solver.cpp:219] Iteration 55700 (7.00486 iter/s, 14.2758s/100 iters), loss = 0.00514558
I0414 07:37:10.913338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:37:10.913338 17564 solver.cpp:238]     Train net output #1: loss = 0.00514566 (* 1 = 0.00514566 loss)
I0414 07:37:10.913338 17564 sgd_solver.cpp:105] Iteration 55700, lr = 1e-07
I0414 07:37:24.479339 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:37:25.049340 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_55800.caffemodel
I0414 07:37:25.186339 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_55800.solverstate
I0414 07:37:25.251338 17564 solver.cpp:331] Iteration 55800, Testing net (#0)
I0414 07:37:25.251338 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:37:29.171340 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:37:29.333343 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:37:29.333343 17564 solver.cpp:398]     Test net output #1: loss = 0.0140575 (* 1 = 0.0140575 loss)
I0414 07:37:29.471339 17564 solver.cpp:219] Iteration 55800 (5.38851 iter/s, 18.558s/100 iters), loss = 0.0071264
I0414 07:37:29.472340 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:37:29.472340 17564 solver.cpp:238]     Train net output #1: loss = 0.00712648 (* 1 = 0.00712648 loss)
I0414 07:37:29.472340 17564 sgd_solver.cpp:105] Iteration 55800, lr = 1e-07
I0414 07:37:43.738339 17564 solver.cpp:219] Iteration 55900 (7.0096 iter/s, 14.2661s/100 iters), loss = 0.00747598
I0414 07:37:43.738339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:37:43.738339 17564 solver.cpp:238]     Train net output #1: loss = 0.00747606 (* 1 = 0.00747606 loss)
I0414 07:37:43.738339 17564 sgd_solver.cpp:105] Iteration 55900, lr = 1e-07
I0414 07:37:58.005338 17564 solver.cpp:219] Iteration 56000 (7.0096 iter/s, 14.2661s/100 iters), loss = 0.0131278
I0414 07:37:58.005338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:37:58.005338 17564 solver.cpp:238]     Train net output #1: loss = 0.0131278 (* 1 = 0.0131278 loss)
I0414 07:37:58.005338 17564 sgd_solver.cpp:105] Iteration 56000, lr = 1e-07
I0414 07:38:12.290338 17564 solver.cpp:219] Iteration 56100 (7.00059 iter/s, 14.2845s/100 iters), loss = 0.0166993
I0414 07:38:12.290338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:38:12.290338 17564 solver.cpp:238]     Train net output #1: loss = 0.0166993 (* 1 = 0.0166993 loss)
I0414 07:38:12.290338 17564 sgd_solver.cpp:105] Iteration 56100, lr = 1e-07
I0414 07:38:26.576339 17564 solver.cpp:219] Iteration 56200 (7.00011 iter/s, 14.2855s/100 iters), loss = 0.00433581
I0414 07:38:26.576339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:38:26.576339 17564 solver.cpp:238]     Train net output #1: loss = 0.00433589 (* 1 = 0.00433589 loss)
I0414 07:38:26.576339 17564 sgd_solver.cpp:105] Iteration 56200, lr = 1e-07
I0414 07:38:40.845338 17564 solver.cpp:219] Iteration 56300 (7.0083 iter/s, 14.2688s/100 iters), loss = 0.00359041
I0414 07:38:40.845338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:38:40.845338 17564 solver.cpp:238]     Train net output #1: loss = 0.00359048 (* 1 = 0.00359048 loss)
I0414 07:38:40.845338 17564 sgd_solver.cpp:105] Iteration 56300, lr = 1e-07
I0414 07:38:54.414340 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:38:54.984354 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_56400.caffemodel
I0414 07:38:55.126338 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_56400.solverstate
I0414 07:38:55.191339 17564 solver.cpp:331] Iteration 56400, Testing net (#0)
I0414 07:38:55.191339 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:38:59.112339 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:38:59.273339 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:38:59.273339 17564 solver.cpp:398]     Test net output #1: loss = 0.014062 (* 1 = 0.014062 loss)
I0414 07:38:59.412338 17564 solver.cpp:219] Iteration 56400 (5.38628 iter/s, 18.5657s/100 iters), loss = 0.00693995
I0414 07:38:59.412338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:38:59.412338 17564 solver.cpp:238]     Train net output #1: loss = 0.00694002 (* 1 = 0.00694002 loss)
I0414 07:38:59.412338 17564 sgd_solver.cpp:105] Iteration 56400, lr = 1e-07
I0414 07:39:13.701339 17564 solver.cpp:219] Iteration 56500 (6.99857 iter/s, 14.2886s/100 iters), loss = 0.0107943
I0414 07:39:13.701339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:39:13.701339 17564 solver.cpp:238]     Train net output #1: loss = 0.0107944 (* 1 = 0.0107944 loss)
I0414 07:39:13.701339 17564 sgd_solver.cpp:105] Iteration 56500, lr = 1e-07
I0414 07:39:27.969338 17564 solver.cpp:219] Iteration 56600 (7.00878 iter/s, 14.2678s/100 iters), loss = 0.0155494
I0414 07:39:27.969338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:39:27.969338 17564 solver.cpp:238]     Train net output #1: loss = 0.0155495 (* 1 = 0.0155495 loss)
I0414 07:39:27.969338 17564 sgd_solver.cpp:105] Iteration 56600, lr = 1e-07
I0414 07:39:42.237339 17564 solver.cpp:219] Iteration 56700 (7.00909 iter/s, 14.2672s/100 iters), loss = 0.0111611
I0414 07:39:42.237339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:39:42.237339 17564 solver.cpp:238]     Train net output #1: loss = 0.0111612 (* 1 = 0.0111612 loss)
I0414 07:39:42.237339 17564 sgd_solver.cpp:105] Iteration 56700, lr = 1e-07
I0414 07:39:56.514338 17564 solver.cpp:219] Iteration 56800 (7.00465 iter/s, 14.2762s/100 iters), loss = 0.00519744
I0414 07:39:56.514338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:39:56.514338 17564 solver.cpp:238]     Train net output #1: loss = 0.00519751 (* 1 = 0.00519751 loss)
I0414 07:39:56.514338 17564 sgd_solver.cpp:105] Iteration 56800, lr = 1e-07
I0414 07:40:10.792338 17564 solver.cpp:219] Iteration 56900 (7.00376 iter/s, 14.278s/100 iters), loss = 0.00484558
I0414 07:40:10.792338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:40:10.793339 17564 solver.cpp:238]     Train net output #1: loss = 0.00484565 (* 1 = 0.00484565 loss)
I0414 07:40:10.793339 17564 sgd_solver.cpp:105] Iteration 56900, lr = 1e-07
I0414 07:40:24.345340 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:40:24.913338 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_57000.caffemodel
I0414 07:40:25.056349 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_57000.solverstate
I0414 07:40:25.121340 17564 solver.cpp:331] Iteration 57000, Testing net (#0)
I0414 07:40:25.121340 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:40:29.042340 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:40:29.203354 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:40:29.203354 17564 solver.cpp:398]     Test net output #1: loss = 0.0140763 (* 1 = 0.0140763 loss)
I0414 07:40:29.342339 17564 solver.cpp:219] Iteration 57000 (5.39124 iter/s, 18.5486s/100 iters), loss = 0.00360444
I0414 07:40:29.342339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:40:29.342339 17564 solver.cpp:238]     Train net output #1: loss = 0.00360451 (* 1 = 0.00360451 loss)
I0414 07:40:29.342339 17564 sgd_solver.cpp:105] Iteration 57000, lr = 1e-07
I0414 07:40:43.599339 17564 solver.cpp:219] Iteration 57100 (7.01424 iter/s, 14.2567s/100 iters), loss = 0.012332
I0414 07:40:43.599339 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:40:43.599339 17564 solver.cpp:238]     Train net output #1: loss = 0.0123321 (* 1 = 0.0123321 loss)
I0414 07:40:43.599339 17564 sgd_solver.cpp:105] Iteration 57100, lr = 1e-07
I0414 07:40:57.861338 17564 solver.cpp:219] Iteration 57200 (7.01199 iter/s, 14.2613s/100 iters), loss = 0.00878433
I0414 07:40:57.861338 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:40:57.861338 17564 solver.cpp:238]     Train net output #1: loss = 0.00878439 (* 1 = 0.00878439 loss)
I0414 07:40:57.861338 17564 sgd_solver.cpp:105] Iteration 57200, lr = 1e-07
I0414 07:41:12.132391 17564 solver.cpp:219] Iteration 57300 (7.00739 iter/s, 14.2706s/100 iters), loss = 0.0160707
I0414 07:41:12.132391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:41:12.132391 17564 solver.cpp:238]     Train net output #1: loss = 0.0160708 (* 1 = 0.0160708 loss)
I0414 07:41:12.132391 17564 sgd_solver.cpp:105] Iteration 57300, lr = 1e-07
I0414 07:41:26.391391 17564 solver.cpp:219] Iteration 57400 (7.01325 iter/s, 14.2587s/100 iters), loss = 0.00449282
I0414 07:41:26.391391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:41:26.391391 17564 solver.cpp:238]     Train net output #1: loss = 0.00449289 (* 1 = 0.00449289 loss)
I0414 07:41:26.391391 17564 sgd_solver.cpp:105] Iteration 57400, lr = 1e-07
I0414 07:41:40.655391 17564 solver.cpp:219] Iteration 57500 (7.01079 iter/s, 14.2637s/100 iters), loss = 0.00763832
I0414 07:41:40.655391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:41:40.656393 17564 solver.cpp:238]     Train net output #1: loss = 0.00763839 (* 1 = 0.00763839 loss)
I0414 07:41:40.656393 17564 sgd_solver.cpp:105] Iteration 57500, lr = 1e-07
I0414 07:41:54.207393 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:41:54.774392 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_57600.caffemodel
I0414 07:41:54.913393 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_57600.solverstate
I0414 07:41:54.979393 17564 solver.cpp:331] Iteration 57600, Testing net (#0)
I0414 07:41:54.979393 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:41:58.898392 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:41:59.060391 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:41:59.060391 17564 solver.cpp:398]     Test net output #1: loss = 0.0140698 (* 1 = 0.0140698 loss)
I0414 07:41:59.199391 17564 solver.cpp:219] Iteration 57600 (5.39287 iter/s, 18.543s/100 iters), loss = 0.00599749
I0414 07:41:59.199391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:41:59.199391 17564 solver.cpp:238]     Train net output #1: loss = 0.00599756 (* 1 = 0.00599756 loss)
I0414 07:41:59.199391 17564 sgd_solver.cpp:105] Iteration 57600, lr = 1e-07
I0414 07:42:13.476394 17564 solver.cpp:219] Iteration 57700 (7.00473 iter/s, 14.2761s/100 iters), loss = 0.00928213
I0414 07:42:13.476394 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:42:13.476394 17564 solver.cpp:238]     Train net output #1: loss = 0.0092822 (* 1 = 0.0092822 loss)
I0414 07:42:13.476394 17564 sgd_solver.cpp:105] Iteration 57700, lr = 1e-07
I0414 07:42:27.746392 17564 solver.cpp:219] Iteration 57800 (7.00801 iter/s, 14.2694s/100 iters), loss = 0.0104395
I0414 07:42:27.746392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:42:27.746392 17564 solver.cpp:238]     Train net output #1: loss = 0.0104396 (* 1 = 0.0104396 loss)
I0414 07:42:27.746392 17564 sgd_solver.cpp:105] Iteration 57800, lr = 1e-07
I0414 07:42:42.008391 17564 solver.cpp:219] Iteration 57900 (7.01181 iter/s, 14.2617s/100 iters), loss = 0.0124596
I0414 07:42:42.008391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:42:42.008391 17564 solver.cpp:238]     Train net output #1: loss = 0.0124597 (* 1 = 0.0124597 loss)
I0414 07:42:42.008391 17564 sgd_solver.cpp:105] Iteration 57900, lr = 1e-07
I0414 07:42:56.269392 17564 solver.cpp:219] Iteration 58000 (7.01261 iter/s, 14.26s/100 iters), loss = 0.00654279
I0414 07:42:56.269392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:42:56.269392 17564 solver.cpp:238]     Train net output #1: loss = 0.00654285 (* 1 = 0.00654285 loss)
I0414 07:42:56.269392 17564 sgd_solver.cpp:105] Iteration 58000, lr = 1e-07
I0414 07:43:10.547391 17564 solver.cpp:219] Iteration 58100 (7.00385 iter/s, 14.2779s/100 iters), loss = 0.00310107
I0414 07:43:10.547391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:43:10.547391 17564 solver.cpp:238]     Train net output #1: loss = 0.00310113 (* 1 = 0.00310113 loss)
I0414 07:43:10.547391 17564 sgd_solver.cpp:105] Iteration 58100, lr = 1e-07
I0414 07:43:24.114392 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:43:24.683393 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_58200.caffemodel
I0414 07:43:24.825407 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_58200.solverstate
I0414 07:43:24.891422 17564 solver.cpp:331] Iteration 58200, Testing net (#0)
I0414 07:43:24.891422 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:43:28.808393 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:43:28.970392 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:43:28.970392 17564 solver.cpp:398]     Test net output #1: loss = 0.014071 (* 1 = 0.014071 loss)
I0414 07:43:29.109405 17564 solver.cpp:219] Iteration 58200 (5.38762 iter/s, 18.5611s/100 iters), loss = 0.012586
I0414 07:43:29.109405 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:43:29.109405 17564 solver.cpp:238]     Train net output #1: loss = 0.0125861 (* 1 = 0.0125861 loss)
I0414 07:43:29.109405 17564 sgd_solver.cpp:105] Iteration 58200, lr = 1e-07
I0414 07:43:43.382391 17564 solver.cpp:219] Iteration 58300 (7.00622 iter/s, 14.273s/100 iters), loss = 0.00978733
I0414 07:43:43.383397 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:43:43.383397 17564 solver.cpp:238]     Train net output #1: loss = 0.00978739 (* 1 = 0.00978739 loss)
I0414 07:43:43.383397 17564 sgd_solver.cpp:105] Iteration 58300, lr = 1e-07
I0414 07:43:57.633391 17564 solver.cpp:219] Iteration 58400 (7.01747 iter/s, 14.2502s/100 iters), loss = 0.0141259
I0414 07:43:57.633391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:43:57.633391 17564 solver.cpp:238]     Train net output #1: loss = 0.014126 (* 1 = 0.014126 loss)
I0414 07:43:57.633391 17564 sgd_solver.cpp:105] Iteration 58400, lr = 1e-07
I0414 07:44:11.900393 17564 solver.cpp:219] Iteration 58500 (7.0097 iter/s, 14.2659s/100 iters), loss = 0.0147466
I0414 07:44:11.900393 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:44:11.900393 17564 solver.cpp:238]     Train net output #1: loss = 0.0147467 (* 1 = 0.0147467 loss)
I0414 07:44:11.900393 17564 sgd_solver.cpp:105] Iteration 58500, lr = 1e-07
I0414 07:44:26.155391 17564 solver.cpp:219] Iteration 58600 (7.01528 iter/s, 14.2546s/100 iters), loss = 0.00433462
I0414 07:44:26.155391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:44:26.155391 17564 solver.cpp:238]     Train net output #1: loss = 0.00433468 (* 1 = 0.00433468 loss)
I0414 07:44:26.155391 17564 sgd_solver.cpp:105] Iteration 58600, lr = 1e-07
I0414 07:44:40.414391 17564 solver.cpp:219] Iteration 58700 (7.01347 iter/s, 14.2583s/100 iters), loss = 0.00397368
I0414 07:44:40.414391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:44:40.414391 17564 solver.cpp:238]     Train net output #1: loss = 0.00397374 (* 1 = 0.00397374 loss)
I0414 07:44:40.414391 17564 sgd_solver.cpp:105] Iteration 58700, lr = 1e-07
I0414 07:44:53.963393 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:44:54.532392 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_58800.caffemodel
I0414 07:44:54.672413 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_58800.solverstate
I0414 07:44:54.740393 17564 solver.cpp:331] Iteration 58800, Testing net (#0)
I0414 07:44:54.740393 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:44:58.656394 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:44:58.818400 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:44:58.818400 17564 solver.cpp:398]     Test net output #1: loss = 0.0140491 (* 1 = 0.0140491 loss)
I0414 07:44:58.956392 17564 solver.cpp:219] Iteration 58800 (5.39337 iter/s, 18.5413s/100 iters), loss = 0.00522364
I0414 07:44:58.956392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:44:58.956392 17564 solver.cpp:238]     Train net output #1: loss = 0.00522369 (* 1 = 0.00522369 loss)
I0414 07:44:58.956392 17564 sgd_solver.cpp:105] Iteration 58800, lr = 1e-07
I0414 07:45:13.234391 17564 solver.cpp:219] Iteration 58900 (7.00411 iter/s, 14.2773s/100 iters), loss = 0.00752297
I0414 07:45:13.234391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:45:13.234391 17564 solver.cpp:238]     Train net output #1: loss = 0.00752302 (* 1 = 0.00752302 loss)
I0414 07:45:13.234391 17564 sgd_solver.cpp:105] Iteration 58900, lr = 1e-07
I0414 07:45:27.497391 17564 solver.cpp:219] Iteration 59000 (7.01158 iter/s, 14.2621s/100 iters), loss = 0.0113026
I0414 07:45:27.497391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:45:27.497391 17564 solver.cpp:238]     Train net output #1: loss = 0.0113027 (* 1 = 0.0113027 loss)
I0414 07:45:27.497391 17564 sgd_solver.cpp:105] Iteration 59000, lr = 1e-07
I0414 07:45:41.759410 17564 solver.cpp:219] Iteration 59100 (7.01189 iter/s, 14.2615s/100 iters), loss = 0.00877052
I0414 07:45:41.759410 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:45:41.759410 17564 solver.cpp:238]     Train net output #1: loss = 0.00877057 (* 1 = 0.00877057 loss)
I0414 07:45:41.759410 17564 sgd_solver.cpp:105] Iteration 59100, lr = 1e-07
I0414 07:45:56.027391 17564 solver.cpp:219] Iteration 59200 (7.00898 iter/s, 14.2674s/100 iters), loss = 0.00500648
I0414 07:45:56.027391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:45:56.027391 17564 solver.cpp:238]     Train net output #1: loss = 0.00500653 (* 1 = 0.00500653 loss)
I0414 07:45:56.027391 17564 sgd_solver.cpp:105] Iteration 59200, lr = 1e-07
I0414 07:46:10.308393 17564 solver.cpp:219] Iteration 59300 (7.00242 iter/s, 14.2808s/100 iters), loss = 0.00377463
I0414 07:46:10.308393 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:46:10.308393 17564 solver.cpp:238]     Train net output #1: loss = 0.00377468 (* 1 = 0.00377468 loss)
I0414 07:46:10.308393 17564 sgd_solver.cpp:105] Iteration 59300, lr = 1e-07
I0414 07:46:23.875393 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:46:24.443392 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_59400.caffemodel
I0414 07:46:24.582392 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_59400.solverstate
I0414 07:46:24.651393 17564 solver.cpp:331] Iteration 59400, Testing net (#0)
I0414 07:46:24.651393 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:46:28.570394 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:46:28.732393 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:46:28.732393 17564 solver.cpp:398]     Test net output #1: loss = 0.0140705 (* 1 = 0.0140705 loss)
I0414 07:46:28.871392 17564 solver.cpp:219] Iteration 59400 (5.38733 iter/s, 18.5621s/100 iters), loss = 0.00810534
I0414 07:46:28.871392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:46:28.871392 17564 solver.cpp:238]     Train net output #1: loss = 0.00810539 (* 1 = 0.00810539 loss)
I0414 07:46:28.871392 17564 sgd_solver.cpp:105] Iteration 59400, lr = 1e-07
I0414 07:46:43.138392 17564 solver.cpp:219] Iteration 59500 (7.00938 iter/s, 14.2666s/100 iters), loss = 0.0102758
I0414 07:46:43.138392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:46:43.138392 17564 solver.cpp:238]     Train net output #1: loss = 0.0102759 (* 1 = 0.0102759 loss)
I0414 07:46:43.138392 17564 sgd_solver.cpp:105] Iteration 59500, lr = 1e-07
I0414 07:46:57.408391 17564 solver.cpp:219] Iteration 59600 (7.00769 iter/s, 14.27s/100 iters), loss = 0.0144017
I0414 07:46:57.409392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:46:57.409392 17564 solver.cpp:238]     Train net output #1: loss = 0.0144017 (* 1 = 0.0144017 loss)
I0414 07:46:57.409392 17564 sgd_solver.cpp:105] Iteration 59600, lr = 1e-07
I0414 07:47:11.689393 17564 solver.cpp:219] Iteration 59700 (7.00262 iter/s, 14.2804s/100 iters), loss = 0.0200848
I0414 07:47:11.689393 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:47:11.689393 17564 solver.cpp:238]     Train net output #1: loss = 0.0200848 (* 1 = 0.0200848 loss)
I0414 07:47:11.689393 17564 sgd_solver.cpp:105] Iteration 59700, lr = 1e-07
I0414 07:47:25.966392 17564 solver.cpp:219] Iteration 59800 (7.00477 iter/s, 14.276s/100 iters), loss = 0.00497417
I0414 07:47:25.966392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:47:25.966392 17564 solver.cpp:238]     Train net output #1: loss = 0.00497422 (* 1 = 0.00497422 loss)
I0414 07:47:25.966392 17564 sgd_solver.cpp:105] Iteration 59800, lr = 1e-07
I0414 07:47:40.232391 17564 solver.cpp:219] Iteration 59900 (7.00986 iter/s, 14.2656s/100 iters), loss = 0.00547071
I0414 07:47:40.232391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:47:40.232391 17564 solver.cpp:238]     Train net output #1: loss = 0.00547075 (* 1 = 0.00547075 loss)
I0414 07:47:40.232391 17564 sgd_solver.cpp:105] Iteration 59900, lr = 1e-07
I0414 07:47:53.798393 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:47:54.367393 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_60000.caffemodel
I0414 07:47:54.508393 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_60000.solverstate
I0414 07:47:54.570392 17564 solver.cpp:331] Iteration 60000, Testing net (#0)
I0414 07:47:54.570392 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:47:58.489393 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:47:58.651394 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9972
I0414 07:47:58.651394 17564 solver.cpp:398]     Test net output #1: loss = 0.0140802 (* 1 = 0.0140802 loss)
I0414 07:47:58.790391 17564 solver.cpp:219] Iteration 60000 (5.38884 iter/s, 18.5569s/100 iters), loss = 0.00616586
I0414 07:47:58.790391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:47:58.790391 17564 solver.cpp:238]     Train net output #1: loss = 0.0061659 (* 1 = 0.0061659 loss)
I0414 07:47:58.790391 17564 sgd_solver.cpp:105] Iteration 60000, lr = 1e-07
I0414 07:48:13.073391 17564 solver.cpp:219] Iteration 60100 (7.00161 iter/s, 14.2824s/100 iters), loss = 0.0166882
I0414 07:48:13.073391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:48:13.073391 17564 solver.cpp:238]     Train net output #1: loss = 0.0166883 (* 1 = 0.0166883 loss)
I0414 07:48:13.073391 17564 sgd_solver.cpp:105] Iteration 60100, lr = 1e-07
I0414 07:48:27.328392 17564 solver.cpp:219] Iteration 60200 (7.01494 iter/s, 14.2553s/100 iters), loss = 0.0099521
I0414 07:48:27.329392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:48:27.329392 17564 solver.cpp:238]     Train net output #1: loss = 0.00995214 (* 1 = 0.00995214 loss)
I0414 07:48:27.329392 17564 sgd_solver.cpp:105] Iteration 60200, lr = 1e-07
I0414 07:48:41.590391 17564 solver.cpp:219] Iteration 60300 (7.01201 iter/s, 14.2612s/100 iters), loss = 0.0137775
I0414 07:48:41.590391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:48:41.590391 17564 solver.cpp:238]     Train net output #1: loss = 0.0137776 (* 1 = 0.0137776 loss)
I0414 07:48:41.590391 17564 sgd_solver.cpp:105] Iteration 60300, lr = 1e-07
I0414 07:48:55.844393 17564 solver.cpp:219] Iteration 60400 (7.01575 iter/s, 14.2536s/100 iters), loss = 0.0106527
I0414 07:48:55.845392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:48:55.845392 17564 solver.cpp:238]     Train net output #1: loss = 0.0106527 (* 1 = 0.0106527 loss)
I0414 07:48:55.845392 17564 sgd_solver.cpp:105] Iteration 60400, lr = 1e-07
I0414 07:49:10.119391 17564 solver.cpp:219] Iteration 60500 (7.00595 iter/s, 14.2736s/100 iters), loss = 0.00483132
I0414 07:49:10.119391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:49:10.119391 17564 solver.cpp:238]     Train net output #1: loss = 0.00483135 (* 1 = 0.00483135 loss)
I0414 07:49:10.119391 17564 sgd_solver.cpp:105] Iteration 60500, lr = 1e-07
I0414 07:49:23.663393 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:49:24.232393 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_60600.caffemodel
I0414 07:49:24.371393 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_60600.solverstate
I0414 07:49:24.434393 17564 solver.cpp:331] Iteration 60600, Testing net (#0)
I0414 07:49:24.434393 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:49:28.357401 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:49:28.519392 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:49:28.519392 17564 solver.cpp:398]     Test net output #1: loss = 0.0140557 (* 1 = 0.0140557 loss)
I0414 07:49:28.658391 17564 solver.cpp:219] Iteration 60600 (5.39424 iter/s, 18.5383s/100 iters), loss = 0.0084703
I0414 07:49:28.658391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:49:28.658391 17564 solver.cpp:238]     Train net output #1: loss = 0.00847033 (* 1 = 0.00847033 loss)
I0414 07:49:28.658391 17564 sgd_solver.cpp:105] Iteration 60600, lr = 1e-07
I0414 07:49:42.900391 17564 solver.cpp:219] Iteration 60700 (7.02145 iter/s, 14.2421s/100 iters), loss = 0.0104054
I0414 07:49:42.900391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:49:42.900391 17564 solver.cpp:238]     Train net output #1: loss = 0.0104054 (* 1 = 0.0104054 loss)
I0414 07:49:42.900391 17564 sgd_solver.cpp:105] Iteration 60700, lr = 1e-07
I0414 07:49:57.151391 17564 solver.cpp:219] Iteration 60800 (7.01751 iter/s, 14.2501s/100 iters), loss = 0.0109974
I0414 07:49:57.151391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:49:57.151391 17564 solver.cpp:238]     Train net output #1: loss = 0.0109974 (* 1 = 0.0109974 loss)
I0414 07:49:57.151391 17564 sgd_solver.cpp:105] Iteration 60800, lr = 1e-07
I0414 07:50:11.419391 17564 solver.cpp:219] Iteration 60900 (7.00883 iter/s, 14.2677s/100 iters), loss = 0.0148318
I0414 07:50:11.419391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:50:11.419391 17564 solver.cpp:238]     Train net output #1: loss = 0.0148318 (* 1 = 0.0148318 loss)
I0414 07:50:11.419391 17564 sgd_solver.cpp:105] Iteration 60900, lr = 1e-07
I0414 07:50:25.671391 17564 solver.cpp:219] Iteration 61000 (7.01695 iter/s, 14.2512s/100 iters), loss = 0.00400742
I0414 07:50:25.671391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:50:25.671391 17564 solver.cpp:238]     Train net output #1: loss = 0.00400746 (* 1 = 0.00400746 loss)
I0414 07:50:25.671391 17564 sgd_solver.cpp:105] Iteration 61000, lr = 1e-07
I0414 07:50:39.953392 17564 solver.cpp:219] Iteration 61100 (7.00225 iter/s, 14.2811s/100 iters), loss = 0.00585218
I0414 07:50:39.953392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:50:39.953392 17564 solver.cpp:238]     Train net output #1: loss = 0.00585222 (* 1 = 0.00585222 loss)
I0414 07:50:39.953392 17564 sgd_solver.cpp:105] Iteration 61100, lr = 1e-07
I0414 07:50:53.524392 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:50:54.093392 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_61200.caffemodel
I0414 07:50:54.234392 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_61200.solverstate
I0414 07:50:54.297394 17564 solver.cpp:331] Iteration 61200, Testing net (#0)
I0414 07:50:54.297394 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:50:58.216393 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:50:58.377391 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:50:58.377391 17564 solver.cpp:398]     Test net output #1: loss = 0.0140831 (* 1 = 0.0140831 loss)
I0414 07:50:58.516391 17564 solver.cpp:219] Iteration 61200 (5.387 iter/s, 18.5632s/100 iters), loss = 0.00652571
I0414 07:50:58.516391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:50:58.516391 17564 solver.cpp:238]     Train net output #1: loss = 0.00652574 (* 1 = 0.00652574 loss)
I0414 07:50:58.516391 17564 sgd_solver.cpp:105] Iteration 61200, lr = 1e-07
I0414 07:51:12.811391 17564 solver.cpp:219] Iteration 61300 (6.99577 iter/s, 14.2943s/100 iters), loss = 0.00616577
I0414 07:51:12.811391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:51:12.811391 17564 solver.cpp:238]     Train net output #1: loss = 0.00616579 (* 1 = 0.00616579 loss)
I0414 07:51:12.811391 17564 sgd_solver.cpp:105] Iteration 61300, lr = 1e-07
I0414 07:51:27.084393 17564 solver.cpp:219] Iteration 61400 (7.00677 iter/s, 14.2719s/100 iters), loss = 0.0148013
I0414 07:51:27.084393 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:51:27.084393 17564 solver.cpp:238]     Train net output #1: loss = 0.0148014 (* 1 = 0.0148014 loss)
I0414 07:51:27.084393 17564 sgd_solver.cpp:105] Iteration 61400, lr = 1e-07
I0414 07:51:41.350391 17564 solver.cpp:219] Iteration 61500 (7.00961 iter/s, 14.2661s/100 iters), loss = 0.00907528
I0414 07:51:41.351393 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:51:41.351393 17564 solver.cpp:238]     Train net output #1: loss = 0.00907531 (* 1 = 0.00907531 loss)
I0414 07:51:41.351393 17564 sgd_solver.cpp:105] Iteration 61500, lr = 1e-07
I0414 07:51:55.618391 17564 solver.cpp:219] Iteration 61600 (7.00921 iter/s, 14.2669s/100 iters), loss = 0.00754711
I0414 07:51:55.618391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:51:55.618391 17564 solver.cpp:238]     Train net output #1: loss = 0.00754714 (* 1 = 0.00754714 loss)
I0414 07:51:55.618391 17564 sgd_solver.cpp:105] Iteration 61600, lr = 1e-07
I0414 07:52:09.906391 17564 solver.cpp:219] Iteration 61700 (6.99901 iter/s, 14.2877s/100 iters), loss = 0.00396579
I0414 07:52:09.906391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:52:09.906391 17564 solver.cpp:238]     Train net output #1: loss = 0.00396581 (* 1 = 0.00396581 loss)
I0414 07:52:09.906391 17564 sgd_solver.cpp:105] Iteration 61700, lr = 1e-07
I0414 07:52:23.474392 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:52:24.043392 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_61800.caffemodel
I0414 07:52:24.182392 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_61800.solverstate
I0414 07:52:24.245393 17564 solver.cpp:331] Iteration 61800, Testing net (#0)
I0414 07:52:24.245393 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:52:28.164399 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:52:28.325392 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:52:28.325392 17564 solver.cpp:398]     Test net output #1: loss = 0.014047 (* 1 = 0.014047 loss)
I0414 07:52:28.464391 17564 solver.cpp:219] Iteration 61800 (5.38885 iter/s, 18.5568s/100 iters), loss = 0.00584658
I0414 07:52:28.464391 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:52:28.464391 17564 solver.cpp:238]     Train net output #1: loss = 0.00584661 (* 1 = 0.00584661 loss)
I0414 07:52:28.464391 17564 sgd_solver.cpp:105] Iteration 61800, lr = 1e-07
I0414 07:52:42.726392 17564 solver.cpp:219] Iteration 61900 (7.01167 iter/s, 14.2619s/100 iters), loss = 0.0152752
I0414 07:52:42.726392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:52:42.726392 17564 solver.cpp:238]     Train net output #1: loss = 0.0152752 (* 1 = 0.0152752 loss)
I0414 07:52:42.726392 17564 sgd_solver.cpp:105] Iteration 61900, lr = 1e-07
I0414 07:52:56.986392 17564 solver.cpp:219] Iteration 62000 (7.01288 iter/s, 14.2595s/100 iters), loss = 0.0140481
I0414 07:52:56.986392 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:52:56.986392 17564 solver.cpp:238]     Train net output #1: loss = 0.0140481 (* 1 = 0.0140481 loss)
I0414 07:52:56.986392 17564 sgd_solver.cpp:105] Iteration 62000, lr = 1e-07
I0414 07:53:11.251415 17564 solver.cpp:219] Iteration 62100 (7.01048 iter/s, 14.2644s/100 iters), loss = 0.0103688
I0414 07:53:11.251415 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:53:11.251415 17564 solver.cpp:238]     Train net output #1: loss = 0.0103689 (* 1 = 0.0103689 loss)
I0414 07:53:11.251415 17564 sgd_solver.cpp:105] Iteration 62100, lr = 1e-07
I0414 07:53:25.520452 17564 solver.cpp:219] Iteration 62200 (7.00852 iter/s, 14.2684s/100 iters), loss = 0.00369253
I0414 07:53:25.520452 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:53:25.520452 17564 solver.cpp:238]     Train net output #1: loss = 0.00369256 (* 1 = 0.00369256 loss)
I0414 07:53:25.520452 17564 sgd_solver.cpp:105] Iteration 62200, lr = 1e-07
I0414 07:53:39.801452 17564 solver.cpp:219] Iteration 62300 (7.0024 iter/s, 14.2808s/100 iters), loss = 0.00441809
I0414 07:53:39.802451 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:53:39.802451 17564 solver.cpp:238]     Train net output #1: loss = 0.00441812 (* 1 = 0.00441812 loss)
I0414 07:53:39.802451 17564 sgd_solver.cpp:105] Iteration 62300, lr = 1e-07
I0414 07:53:53.369452 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:53:53.936452 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_62400.caffemodel
I0414 07:53:54.085454 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_62400.solverstate
I0414 07:53:54.149456 17564 solver.cpp:331] Iteration 62400, Testing net (#0)
I0414 07:53:54.149456 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:53:58.067453 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:53:58.229454 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:53:58.229454 17564 solver.cpp:398]     Test net output #1: loss = 0.0140525 (* 1 = 0.0140525 loss)
I0414 07:53:58.368451 17564 solver.cpp:219] Iteration 62400 (5.38623 iter/s, 18.5659s/100 iters), loss = 0.00499458
I0414 07:53:58.368451 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:53:58.368451 17564 solver.cpp:238]     Train net output #1: loss = 0.00499461 (* 1 = 0.00499461 loss)
I0414 07:53:58.368451 17564 sgd_solver.cpp:105] Iteration 62400, lr = 1e-07
I0414 07:54:12.659452 17564 solver.cpp:219] Iteration 62500 (6.99756 iter/s, 14.2907s/100 iters), loss = 0.0141079
I0414 07:54:12.659452 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:54:12.659452 17564 solver.cpp:238]     Train net output #1: loss = 0.0141079 (* 1 = 0.0141079 loss)
I0414 07:54:12.659452 17564 sgd_solver.cpp:105] Iteration 62500, lr = 1e-07
I0414 07:54:26.919451 17564 solver.cpp:219] Iteration 62600 (7.01322 iter/s, 14.2588s/100 iters), loss = 0.00795037
I0414 07:54:26.919451 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:54:26.919451 17564 solver.cpp:238]     Train net output #1: loss = 0.0079504 (* 1 = 0.0079504 loss)
I0414 07:54:26.919451 17564 sgd_solver.cpp:105] Iteration 62600, lr = 1e-07
I0414 07:54:41.177451 17564 solver.cpp:219] Iteration 62700 (7.01363 iter/s, 14.258s/100 iters), loss = 0.0122148
I0414 07:54:41.177451 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:54:41.177451 17564 solver.cpp:238]     Train net output #1: loss = 0.0122148 (* 1 = 0.0122148 loss)
I0414 07:54:41.177451 17564 sgd_solver.cpp:105] Iteration 62700, lr = 1e-07
I0414 07:54:55.431452 17564 solver.cpp:219] Iteration 62800 (7.0161 iter/s, 14.2529s/100 iters), loss = 0.00283195
I0414 07:54:55.431452 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:54:55.431452 17564 solver.cpp:238]     Train net output #1: loss = 0.00283199 (* 1 = 0.00283199 loss)
I0414 07:54:55.431452 17564 sgd_solver.cpp:105] Iteration 62800, lr = 1e-07
I0414 07:55:09.693451 17564 solver.cpp:219] Iteration 62900 (7.01151 iter/s, 14.2623s/100 iters), loss = 0.0056969
I0414 07:55:09.693451 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:55:09.693451 17564 solver.cpp:238]     Train net output #1: loss = 0.00569694 (* 1 = 0.00569694 loss)
I0414 07:55:09.694453 17564 sgd_solver.cpp:105] Iteration 62900, lr = 1e-07
I0414 07:55:23.246453 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:55:23.814457 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_63000.caffemodel
I0414 07:55:23.962467 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_63000.solverstate
I0414 07:55:24.072561 17564 solver.cpp:331] Iteration 63000, Testing net (#0)
I0414 07:55:24.072561 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:55:27.993563 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:55:28.155575 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:55:28.155575 17564 solver.cpp:398]     Test net output #1: loss = 0.0140775 (* 1 = 0.0140775 loss)
I0414 07:55:28.294575 17564 solver.cpp:219] Iteration 63000 (5.37631 iter/s, 18.6001s/100 iters), loss = 0.00695684
I0414 07:55:28.294575 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:55:28.294575 17564 solver.cpp:238]     Train net output #1: loss = 0.00695688 (* 1 = 0.00695688 loss)
I0414 07:55:28.294575 17564 sgd_solver.cpp:105] Iteration 63000, lr = 1e-07
I0414 07:55:42.559691 17564 solver.cpp:219] Iteration 63100 (7.01015 iter/s, 14.265s/100 iters), loss = 0.0163449
I0414 07:55:42.560693 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:55:42.560693 17564 solver.cpp:238]     Train net output #1: loss = 0.0163449 (* 1 = 0.0163449 loss)
I0414 07:55:42.560693 17564 sgd_solver.cpp:105] Iteration 63100, lr = 1e-07
I0414 07:55:56.826705 17564 solver.cpp:219] Iteration 63200 (7.00942 iter/s, 14.2665s/100 iters), loss = 0.0113413
I0414 07:55:56.827706 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:55:56.827706 17564 solver.cpp:238]     Train net output #1: loss = 0.0113414 (* 1 = 0.0113414 loss)
I0414 07:55:56.827706 17564 sgd_solver.cpp:105] Iteration 63200, lr = 1e-07
I0414 07:56:11.098691 17564 solver.cpp:219] Iteration 63300 (7.00711 iter/s, 14.2712s/100 iters), loss = 0.015022
I0414 07:56:11.098691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:56:11.098691 17564 solver.cpp:238]     Train net output #1: loss = 0.015022 (* 1 = 0.015022 loss)
I0414 07:56:11.098691 17564 sgd_solver.cpp:105] Iteration 63300, lr = 1e-07
I0414 07:56:25.359691 17564 solver.cpp:219] Iteration 63400 (7.01258 iter/s, 14.2601s/100 iters), loss = 0.00387216
I0414 07:56:25.359691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:56:25.359691 17564 solver.cpp:238]     Train net output #1: loss = 0.0038722 (* 1 = 0.0038722 loss)
I0414 07:56:25.359691 17564 sgd_solver.cpp:105] Iteration 63400, lr = 1e-07
I0414 07:56:39.618691 17564 solver.cpp:219] Iteration 63500 (7.01334 iter/s, 14.2585s/100 iters), loss = 0.00579234
I0414 07:56:39.618691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:56:39.618691 17564 solver.cpp:238]     Train net output #1: loss = 0.00579238 (* 1 = 0.00579238 loss)
I0414 07:56:39.618691 17564 sgd_solver.cpp:105] Iteration 63500, lr = 1e-07
I0414 07:56:53.174691 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:56:53.742692 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_63600.caffemodel
I0414 07:56:53.882695 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_63600.solverstate
I0414 07:56:53.946705 17564 solver.cpp:331] Iteration 63600, Testing net (#0)
I0414 07:56:53.946705 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:56:57.869693 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:56:58.031692 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:56:58.031692 17564 solver.cpp:398]     Test net output #1: loss = 0.0140516 (* 1 = 0.0140516 loss)
I0414 07:56:58.170691 17564 solver.cpp:219] Iteration 63600 (5.39051 iter/s, 18.5511s/100 iters), loss = 0.00711577
I0414 07:56:58.170691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:56:58.170691 17564 solver.cpp:238]     Train net output #1: loss = 0.00711581 (* 1 = 0.00711581 loss)
I0414 07:56:58.170691 17564 sgd_solver.cpp:105] Iteration 63600, lr = 1e-07
I0414 07:57:12.455691 17564 solver.cpp:219] Iteration 63700 (7.00071 iter/s, 14.2843s/100 iters), loss = 0.00941608
I0414 07:57:12.455691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:57:12.455691 17564 solver.cpp:238]     Train net output #1: loss = 0.00941612 (* 1 = 0.00941612 loss)
I0414 07:57:12.455691 17564 sgd_solver.cpp:105] Iteration 63700, lr = 1e-07
I0414 07:57:26.729692 17564 solver.cpp:219] Iteration 63800 (7.00589 iter/s, 14.2737s/100 iters), loss = 0.0123437
I0414 07:57:26.729692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:57:26.729692 17564 solver.cpp:238]     Train net output #1: loss = 0.0123438 (* 1 = 0.0123438 loss)
I0414 07:57:26.729692 17564 sgd_solver.cpp:105] Iteration 63800, lr = 1e-07
I0414 07:57:41.005692 17564 solver.cpp:219] Iteration 63900 (7.00481 iter/s, 14.2759s/100 iters), loss = 0.0195803
I0414 07:57:41.005692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 07:57:41.005692 17564 solver.cpp:238]     Train net output #1: loss = 0.0195803 (* 1 = 0.0195803 loss)
I0414 07:57:41.005692 17564 sgd_solver.cpp:105] Iteration 63900, lr = 1e-07
I0414 07:57:55.285691 17564 solver.cpp:219] Iteration 64000 (7.00317 iter/s, 14.2792s/100 iters), loss = 0.00517163
I0414 07:57:55.285691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:57:55.285691 17564 solver.cpp:238]     Train net output #1: loss = 0.00517166 (* 1 = 0.00517166 loss)
I0414 07:57:55.285691 17564 sgd_solver.cpp:105] Iteration 64000, lr = 1e-07
I0414 07:58:09.560691 17564 solver.cpp:219] Iteration 64100 (7.00573 iter/s, 14.274s/100 iters), loss = 0.00707393
I0414 07:58:09.560691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:58:09.560691 17564 solver.cpp:238]     Train net output #1: loss = 0.00707396 (* 1 = 0.00707396 loss)
I0414 07:58:09.560691 17564 sgd_solver.cpp:105] Iteration 64100, lr = 1e-07
I0414 07:58:23.127692 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:58:23.695693 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_64200.caffemodel
I0414 07:58:23.836707 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_64200.solverstate
I0414 07:58:23.903694 17564 solver.cpp:331] Iteration 64200, Testing net (#0)
I0414 07:58:23.903694 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:58:27.824692 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:58:27.985692 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 07:58:27.985692 17564 solver.cpp:398]     Test net output #1: loss = 0.0140737 (* 1 = 0.0140737 loss)
I0414 07:58:28.124691 17564 solver.cpp:219] Iteration 64200 (5.3868 iter/s, 18.5639s/100 iters), loss = 0.00799856
I0414 07:58:28.124691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:58:28.124691 17564 solver.cpp:238]     Train net output #1: loss = 0.0079986 (* 1 = 0.0079986 loss)
I0414 07:58:28.124691 17564 sgd_solver.cpp:105] Iteration 64200, lr = 1e-07
I0414 07:58:42.388691 17564 solver.cpp:219] Iteration 64300 (7.011 iter/s, 14.2633s/100 iters), loss = 0.0133969
I0414 07:58:42.388691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:58:42.388691 17564 solver.cpp:238]     Train net output #1: loss = 0.0133969 (* 1 = 0.0133969 loss)
I0414 07:58:42.388691 17564 sgd_solver.cpp:105] Iteration 64300, lr = 1e-07
I0414 07:58:56.655691 17564 solver.cpp:219] Iteration 64400 (7.00949 iter/s, 14.2664s/100 iters), loss = 0.0139276
I0414 07:58:56.655691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:58:56.655691 17564 solver.cpp:238]     Train net output #1: loss = 0.0139276 (* 1 = 0.0139276 loss)
I0414 07:58:56.655691 17564 sgd_solver.cpp:105] Iteration 64400, lr = 1e-07
I0414 07:59:10.940691 17564 solver.cpp:219] Iteration 64500 (7.00039 iter/s, 14.2849s/100 iters), loss = 0.00923379
I0414 07:59:10.940691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:59:10.940691 17564 solver.cpp:238]     Train net output #1: loss = 0.00923383 (* 1 = 0.00923383 loss)
I0414 07:59:10.940691 17564 sgd_solver.cpp:105] Iteration 64500, lr = 1e-07
I0414 07:59:25.211693 17564 solver.cpp:219] Iteration 64600 (7.00761 iter/s, 14.2702s/100 iters), loss = 0.00603989
I0414 07:59:25.211693 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:59:25.211693 17564 solver.cpp:238]     Train net output #1: loss = 0.00603991 (* 1 = 0.00603991 loss)
I0414 07:59:25.211693 17564 sgd_solver.cpp:105] Iteration 64600, lr = 1e-07
I0414 07:59:39.480691 17564 solver.cpp:219] Iteration 64700 (7.00867 iter/s, 14.268s/100 iters), loss = 0.00334052
I0414 07:59:39.480691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:59:39.480691 17564 solver.cpp:238]     Train net output #1: loss = 0.00334055 (* 1 = 0.00334055 loss)
I0414 07:59:39.480691 17564 sgd_solver.cpp:105] Iteration 64700, lr = 1e-07
I0414 07:59:53.035702 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:59:53.603693 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_64800.caffemodel
I0414 07:59:53.746692 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_64800.solverstate
I0414 07:59:53.815692 17564 solver.cpp:331] Iteration 64800, Testing net (#0)
I0414 07:59:53.816692 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 07:59:57.736692 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 07:59:57.898715 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 07:59:57.898715 17564 solver.cpp:398]     Test net output #1: loss = 0.0140448 (* 1 = 0.0140448 loss)
I0414 07:59:58.037691 17564 solver.cpp:219] Iteration 64800 (5.38901 iter/s, 18.5563s/100 iters), loss = 0.00843491
I0414 07:59:58.037691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 07:59:58.037691 17564 solver.cpp:238]     Train net output #1: loss = 0.00843493 (* 1 = 0.00843493 loss)
I0414 07:59:58.037691 17564 sgd_solver.cpp:105] Iteration 64800, lr = 1e-07
I0414 08:00:12.309691 17564 solver.cpp:219] Iteration 64900 (7.00686 iter/s, 14.2717s/100 iters), loss = 0.00578974
I0414 08:00:12.309691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:00:12.309691 17564 solver.cpp:238]     Train net output #1: loss = 0.00578977 (* 1 = 0.00578977 loss)
I0414 08:00:12.309691 17564 sgd_solver.cpp:105] Iteration 64900, lr = 1e-07
I0414 08:00:26.571691 17564 solver.cpp:219] Iteration 65000 (7.01175 iter/s, 14.2618s/100 iters), loss = 0.0109895
I0414 08:00:26.571691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:00:26.571691 17564 solver.cpp:238]     Train net output #1: loss = 0.0109895 (* 1 = 0.0109895 loss)
I0414 08:00:26.571691 17564 sgd_solver.cpp:105] Iteration 65000, lr = 1e-07
I0414 08:00:40.829692 17564 solver.cpp:219] Iteration 65100 (7.01412 iter/s, 14.2569s/100 iters), loss = 0.00742956
I0414 08:00:40.829692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:00:40.829692 17564 solver.cpp:238]     Train net output #1: loss = 0.00742959 (* 1 = 0.00742959 loss)
I0414 08:00:40.829692 17564 sgd_solver.cpp:105] Iteration 65100, lr = 1e-07
I0414 08:00:55.100692 17564 solver.cpp:219] Iteration 65200 (7.00741 iter/s, 14.2706s/100 iters), loss = 0.00402486
I0414 08:00:55.100692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:00:55.100692 17564 solver.cpp:238]     Train net output #1: loss = 0.00402489 (* 1 = 0.00402489 loss)
I0414 08:00:55.100692 17564 sgd_solver.cpp:105] Iteration 65200, lr = 1e-07
I0414 08:01:09.378691 17564 solver.cpp:219] Iteration 65300 (7.00376 iter/s, 14.278s/100 iters), loss = 0.00398915
I0414 08:01:09.378691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:01:09.379693 17564 solver.cpp:238]     Train net output #1: loss = 0.00398919 (* 1 = 0.00398919 loss)
I0414 08:01:09.379693 17564 sgd_solver.cpp:105] Iteration 65300, lr = 1e-07
I0414 08:01:22.939692 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:01:23.507691 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_65400.caffemodel
I0414 08:01:23.651692 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_65400.solverstate
I0414 08:01:23.718693 17564 solver.cpp:331] Iteration 65400, Testing net (#0)
I0414 08:01:23.719692 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:01:27.641692 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:01:27.803692 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 08:01:27.803692 17564 solver.cpp:398]     Test net output #1: loss = 0.0140456 (* 1 = 0.0140456 loss)
I0414 08:01:27.942692 17564 solver.cpp:219] Iteration 65400 (5.38704 iter/s, 18.5631s/100 iters), loss = 0.00796599
I0414 08:01:27.942692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:01:27.942692 17564 solver.cpp:238]     Train net output #1: loss = 0.00796602 (* 1 = 0.00796602 loss)
I0414 08:01:27.942692 17564 sgd_solver.cpp:105] Iteration 65400, lr = 1e-07
I0414 08:01:42.227691 17564 solver.cpp:219] Iteration 65500 (7.00087 iter/s, 14.2839s/100 iters), loss = 0.00865978
I0414 08:01:42.227691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:01:42.227691 17564 solver.cpp:238]     Train net output #1: loss = 0.00865981 (* 1 = 0.00865981 loss)
I0414 08:01:42.227691 17564 sgd_solver.cpp:105] Iteration 65500, lr = 1e-07
I0414 08:01:56.498692 17564 solver.cpp:219] Iteration 65600 (7.00739 iter/s, 14.2706s/100 iters), loss = 0.00760863
I0414 08:01:56.498692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:01:56.498692 17564 solver.cpp:238]     Train net output #1: loss = 0.00760866 (* 1 = 0.00760866 loss)
I0414 08:01:56.498692 17564 sgd_solver.cpp:105] Iteration 65600, lr = 1e-07
I0414 08:02:10.771692 17564 solver.cpp:219] Iteration 65700 (7.0064 iter/s, 14.2727s/100 iters), loss = 0.0200517
I0414 08:02:10.771692 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 08:02:10.771692 17564 solver.cpp:238]     Train net output #1: loss = 0.0200517 (* 1 = 0.0200517 loss)
I0414 08:02:10.771692 17564 sgd_solver.cpp:105] Iteration 65700, lr = 1e-07
I0414 08:02:25.052691 17564 solver.cpp:219] Iteration 65800 (7.00252 iter/s, 14.2806s/100 iters), loss = 0.00403709
I0414 08:02:25.052691 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:02:25.052691 17564 solver.cpp:238]     Train net output #1: loss = 0.00403712 (* 1 = 0.00403712 loss)
I0414 08:02:25.052691 17564 sgd_solver.cpp:105] Iteration 65800, lr = 1e-07
I0414 08:02:39.314810 17564 solver.cpp:219] Iteration 65900 (7.01181 iter/s, 14.2616s/100 iters), loss = 0.00482538
I0414 08:02:39.314810 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:02:39.314810 17564 solver.cpp:238]     Train net output #1: loss = 0.00482541 (* 1 = 0.00482541 loss)
I0414 08:02:39.314810 17564 sgd_solver.cpp:105] Iteration 65900, lr = 1e-07
I0414 08:02:52.873813 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:02:53.442809 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_66000.caffemodel
I0414 08:02:53.581810 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_66000.solverstate
I0414 08:02:53.648810 17564 solver.cpp:331] Iteration 66000, Testing net (#0)
I0414 08:02:53.648810 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:02:57.568810 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:02:57.729809 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 08:02:57.730810 17564 solver.cpp:398]     Test net output #1: loss = 0.0140696 (* 1 = 0.0140696 loss)
I0414 08:02:57.869809 17564 solver.cpp:219] Iteration 66000 (5.38962 iter/s, 18.5542s/100 iters), loss = 0.004426
I0414 08:02:57.869809 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:02:57.869809 17564 solver.cpp:238]     Train net output #1: loss = 0.00442603 (* 1 = 0.00442603 loss)
I0414 08:02:57.869809 17564 sgd_solver.cpp:105] Iteration 66000, lr = 1e-07
I0414 08:03:12.148811 17564 solver.cpp:219] Iteration 66100 (7.00348 iter/s, 14.2786s/100 iters), loss = 0.0119003
I0414 08:03:12.148811 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:03:12.148811 17564 solver.cpp:238]     Train net output #1: loss = 0.0119003 (* 1 = 0.0119003 loss)
I0414 08:03:12.148811 17564 sgd_solver.cpp:105] Iteration 66100, lr = 1e-07
I0414 08:03:26.424809 17564 solver.cpp:219] Iteration 66200 (7.00513 iter/s, 14.2752s/100 iters), loss = 0.00660785
I0414 08:03:26.424809 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:03:26.424809 17564 solver.cpp:238]     Train net output #1: loss = 0.00660788 (* 1 = 0.00660788 loss)
I0414 08:03:26.424809 17564 sgd_solver.cpp:105] Iteration 66200, lr = 1e-07
I0414 08:03:40.681808 17564 solver.cpp:219] Iteration 66300 (7.01451 iter/s, 14.2562s/100 iters), loss = 0.0227811
I0414 08:03:40.681808 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 08:03:40.681808 17564 solver.cpp:238]     Train net output #1: loss = 0.0227812 (* 1 = 0.0227812 loss)
I0414 08:03:40.681808 17564 sgd_solver.cpp:105] Iteration 66300, lr = 1e-07
I0414 08:03:54.946810 17564 solver.cpp:219] Iteration 66400 (7.01054 iter/s, 14.2642s/100 iters), loss = 0.00392174
I0414 08:03:54.946810 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:03:54.946810 17564 solver.cpp:238]     Train net output #1: loss = 0.00392177 (* 1 = 0.00392177 loss)
I0414 08:03:54.946810 17564 sgd_solver.cpp:105] Iteration 66400, lr = 1e-07
I0414 08:04:09.228809 17564 solver.cpp:219] Iteration 66500 (7.00239 iter/s, 14.2808s/100 iters), loss = 0.00402636
I0414 08:04:09.228809 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:04:09.228809 17564 solver.cpp:238]     Train net output #1: loss = 0.0040264 (* 1 = 0.0040264 loss)
I0414 08:04:09.228809 17564 sgd_solver.cpp:105] Iteration 66500, lr = 1e-07
I0414 08:04:22.780810 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:04:23.348810 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_66600.caffemodel
I0414 08:04:23.489809 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_66600.solverstate
I0414 08:04:23.554811 17564 solver.cpp:331] Iteration 66600, Testing net (#0)
I0414 08:04:23.554811 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:04:27.476810 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:04:27.638809 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 08:04:27.638809 17564 solver.cpp:398]     Test net output #1: loss = 0.0140707 (* 1 = 0.0140707 loss)
I0414 08:04:27.776810 17564 solver.cpp:219] Iteration 66600 (5.39137 iter/s, 18.5482s/100 iters), loss = 0.00433467
I0414 08:04:27.776810 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:04:27.776810 17564 solver.cpp:238]     Train net output #1: loss = 0.00433471 (* 1 = 0.00433471 loss)
I0414 08:04:27.776810 17564 sgd_solver.cpp:105] Iteration 66600, lr = 1e-07
I0414 08:04:42.041810 17564 solver.cpp:219] Iteration 66700 (7.01079 iter/s, 14.2637s/100 iters), loss = 0.0159926
I0414 08:04:42.041810 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 08:04:42.041810 17564 solver.cpp:238]     Train net output #1: loss = 0.0159926 (* 1 = 0.0159926 loss)
I0414 08:04:42.041810 17564 sgd_solver.cpp:105] Iteration 66700, lr = 1e-07
I0414 08:04:56.305809 17564 solver.cpp:219] Iteration 66800 (7.01096 iter/s, 14.2634s/100 iters), loss = 0.0133497
I0414 08:04:56.305809 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:04:56.305809 17564 solver.cpp:238]     Train net output #1: loss = 0.0133498 (* 1 = 0.0133498 loss)
I0414 08:04:56.305809 17564 sgd_solver.cpp:105] Iteration 66800, lr = 1e-07
I0414 08:05:10.577810 17564 solver.cpp:219] Iteration 66900 (7.00677 iter/s, 14.2719s/100 iters), loss = 0.0141073
I0414 08:05:10.577810 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 08:05:10.577810 17564 solver.cpp:238]     Train net output #1: loss = 0.0141074 (* 1 = 0.0141074 loss)
I0414 08:05:10.577810 17564 sgd_solver.cpp:105] Iteration 66900, lr = 1e-07
I0414 08:05:24.852808 17564 solver.cpp:219] Iteration 67000 (7.00557 iter/s, 14.2744s/100 iters), loss = 0.0030968
I0414 08:05:24.852808 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:05:24.852808 17564 solver.cpp:238]     Train net output #1: loss = 0.00309685 (* 1 = 0.00309685 loss)
I0414 08:05:24.852808 17564 sgd_solver.cpp:105] Iteration 67000, lr = 1e-07
I0414 08:05:39.118808 17564 solver.cpp:219] Iteration 67100 (7.01005 iter/s, 14.2652s/100 iters), loss = 0.00611473
I0414 08:05:39.118808 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:05:39.118808 17564 solver.cpp:238]     Train net output #1: loss = 0.00611478 (* 1 = 0.00611478 loss)
I0414 08:05:39.118808 17564 sgd_solver.cpp:105] Iteration 67100, lr = 1e-07
I0414 08:05:52.683886 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:05:53.252885 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_67200.caffemodel
I0414 08:05:53.394886 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_67200.solverstate
I0414 08:05:53.459893 17564 solver.cpp:331] Iteration 67200, Testing net (#0)
I0414 08:05:53.459893 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:05:57.381886 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:05:57.544885 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 08:05:57.544885 17564 solver.cpp:398]     Test net output #1: loss = 0.0140587 (* 1 = 0.0140587 loss)
I0414 08:05:57.683884 17564 solver.cpp:219] Iteration 67200 (5.38655 iter/s, 18.5648s/100 iters), loss = 0.0115447
I0414 08:05:57.683884 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:05:57.683884 17564 solver.cpp:238]     Train net output #1: loss = 0.0115447 (* 1 = 0.0115447 loss)
I0414 08:05:57.683884 17564 sgd_solver.cpp:105] Iteration 67200, lr = 1e-07
I0414 08:06:11.953886 17564 solver.cpp:219] Iteration 67300 (7.00812 iter/s, 14.2692s/100 iters), loss = 0.0107576
I0414 08:06:11.953886 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:06:11.953886 17564 solver.cpp:238]     Train net output #1: loss = 0.0107576 (* 1 = 0.0107576 loss)
I0414 08:06:11.953886 17564 sgd_solver.cpp:105] Iteration 67300, lr = 1e-07
I0414 08:06:26.529757 17564 solver.cpp:219] Iteration 67400 (6.86095 iter/s, 14.5752s/100 iters), loss = 0.0133137
I0414 08:06:26.529757 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:06:26.529757 17564 solver.cpp:238]     Train net output #1: loss = 0.0133137 (* 1 = 0.0133137 loss)
I0414 08:06:26.529757 17564 sgd_solver.cpp:105] Iteration 67400, lr = 1e-07
I0414 08:06:40.862757 17564 solver.cpp:219] Iteration 67500 (6.97701 iter/s, 14.3328s/100 iters), loss = 0.00778388
I0414 08:06:40.862757 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:06:40.862757 17564 solver.cpp:238]     Train net output #1: loss = 0.00778392 (* 1 = 0.00778392 loss)
I0414 08:06:40.862757 17564 sgd_solver.cpp:105] Iteration 67500, lr = 1e-07
I0414 08:06:55.248381 17564 solver.cpp:219] Iteration 67600 (6.95186 iter/s, 14.3846s/100 iters), loss = 0.00385349
I0414 08:06:55.248381 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:06:55.248381 17564 solver.cpp:238]     Train net output #1: loss = 0.00385352 (* 1 = 0.00385352 loss)
I0414 08:06:55.248381 17564 sgd_solver.cpp:105] Iteration 67600, lr = 1e-07
I0414 08:07:09.622589 17564 solver.cpp:219] Iteration 67700 (6.95683 iter/s, 14.3744s/100 iters), loss = 0.00655979
I0414 08:07:09.622589 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:07:09.622589 17564 solver.cpp:238]     Train net output #1: loss = 0.00655983 (* 1 = 0.00655983 loss)
I0414 08:07:09.622589 17564 sgd_solver.cpp:105] Iteration 67700, lr = 1e-07
I0414 08:07:23.224591 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:07:23.795590 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_67800.caffemodel
I0414 08:07:23.939594 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_67800.solverstate
I0414 08:07:24.006594 17564 solver.cpp:331] Iteration 67800, Testing net (#0)
I0414 08:07:24.006594 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:07:27.980319 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:07:28.142318 17564 solver.cpp:398]     Test net output #0: accuracy = 0.997
I0414 08:07:28.142318 17564 solver.cpp:398]     Test net output #1: loss = 0.0140549 (* 1 = 0.0140549 loss)
I0414 08:07:28.281317 17564 solver.cpp:219] Iteration 67800 (5.35964 iter/s, 18.658s/100 iters), loss = 0.00731546
I0414 08:07:28.281317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:07:28.281317 17564 solver.cpp:238]     Train net output #1: loss = 0.00731551 (* 1 = 0.00731551 loss)
I0414 08:07:28.281317 17564 sgd_solver.cpp:105] Iteration 67800, lr = 1e-07
I0414 08:07:42.583317 17564 solver.cpp:219] Iteration 67900 (6.99257 iter/s, 14.3009s/100 iters), loss = 0.0117289
I0414 08:07:42.583317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:07:42.583317 17564 solver.cpp:238]     Train net output #1: loss = 0.0117289 (* 1 = 0.0117289 loss)
I0414 08:07:42.583317 17564 sgd_solver.cpp:105] Iteration 67900, lr = 1e-07
I0414 08:07:56.871317 17564 solver.cpp:219] Iteration 68000 (6.99885 iter/s, 14.2881s/100 iters), loss = 0.0114941
I0414 08:07:56.871317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:07:56.871317 17564 solver.cpp:238]     Train net output #1: loss = 0.0114941 (* 1 = 0.0114941 loss)
I0414 08:07:56.871317 17564 sgd_solver.cpp:105] Iteration 68000, lr = 1e-07
I0414 08:08:11.162317 17564 solver.cpp:219] Iteration 68100 (6.9977 iter/s, 14.2904s/100 iters), loss = 0.00938691
I0414 08:08:11.162317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:08:11.162317 17564 solver.cpp:238]     Train net output #1: loss = 0.00938696 (* 1 = 0.00938696 loss)
I0414 08:08:11.162317 17564 sgd_solver.cpp:105] Iteration 68100, lr = 1e-07
I0414 08:08:25.458317 17564 solver.cpp:219] Iteration 68200 (6.99516 iter/s, 14.2956s/100 iters), loss = 0.00473545
I0414 08:08:25.459318 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:08:25.459318 17564 solver.cpp:238]     Train net output #1: loss = 0.0047355 (* 1 = 0.0047355 loss)
I0414 08:08:25.459318 17564 sgd_solver.cpp:105] Iteration 68200, lr = 1e-07
I0414 08:08:39.755321 17564 solver.cpp:219] Iteration 68300 (6.99476 iter/s, 14.2964s/100 iters), loss = 0.00623258
I0414 08:08:39.756319 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:08:39.756319 17564 solver.cpp:238]     Train net output #1: loss = 0.00623264 (* 1 = 0.00623264 loss)
I0414 08:08:39.756319 17564 sgd_solver.cpp:105] Iteration 68300, lr = 1e-07
I0414 08:08:53.335327 15984 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:08:53.903319 17564 solver.cpp:448] Snapshotting to binary proto file examples/mnist/snaps/lenet_iter_68400.caffemodel
I0414 08:08:54.044324 17564 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/snaps/lenet_iter_68400.solverstate
I0414 08:08:54.108321 17564 solver.cpp:331] Iteration 68400, Testing net (#0)
I0414 08:08:54.108321 17564 net.cpp:676] Ignoring source layer accuracy_training
I0414 08:08:58.041318 17584 data_layer.cpp:73] Restarting data prefetching from start.
I0414 08:08:58.202317 17564 solver.cpp:398]     Test net output #0: accuracy = 0.9971
I0414 08:08:58.203320 17564 solver.cpp:398]     Test net output #1: loss = 0.0140619 (* 1 = 0.0140619 loss)
I0414 08:08:58.342317 17564 solver.cpp:219] Iteration 68400 (5.3805 iter/s, 18.5856s/100 iters), loss = 0.0105508
I0414 08:08:58.342317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:08:58.342317 17564 solver.cpp:238]     Train net output #1: loss = 0.0105509 (* 1 = 0.0105509 loss)
I0414 08:08:58.342317 17564 sgd_solver.cpp:105] Iteration 68400, lr = 1e-07
I0414 08:09:12.652318 17564 solver.cpp:219] Iteration 68500 (6.98832 iter/s, 14.3096s/100 iters), loss = 0.00756563
I0414 08:09:12.652318 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:09:12.652318 17564 solver.cpp:238]     Train net output #1: loss = 0.00756568 (* 1 = 0.00756568 loss)
I0414 08:09:12.652318 17564 sgd_solver.cpp:105] Iteration 68500, lr = 1e-07
I0414 08:09:26.950318 17564 solver.cpp:219] Iteration 68600 (6.99442 iter/s, 14.2971s/100 iters), loss = 0.00789555
I0414 08:09:26.950318 17564 solver.cpp:238]     Train net output #0: accuracy_training = 1
I0414 08:09:26.950318 17564 solver.cpp:238]     Train net output #1: loss = 0.0078956 (* 1 = 0.0078956 loss)
I0414 08:09:26.950318 17564 sgd_solver.cpp:105] Iteration 68600, lr = 1e-07
I0414 08:09:41.249317 17564 solver.cpp:219] Iteration 68700 (6.99339 iter/s, 14.2992s/100 iters), loss = 0.0186558
I0414 08:09:41.249317 17564 solver.cpp:238]     Train net output #0: accuracy_training = 0.99
I0414 08:09:41.249317 17564 solver.cpp:238]     Train net output #1: loss = 0.0186558 (* 1 = 