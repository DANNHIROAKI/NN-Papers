
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt 
I0401 01:06:02.508669 11876 caffe.cpp:218] Using GPUs 0
I0401 01:06:02.737191 11876 caffe.cpp:223] GPU 0: GeForce GTX 980
I0401 01:06:03.190752 11876 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.190752 11876 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.01
display: 100
max_iter: 234000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0052
snapshot: 10000
snapshot_prefix: "examples/cifar10/slimnet_310"
solver_mode: GPU
device_id: 0
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: true
stepvalue: 32000
stepvalue: 48000
stepvalue: 54000
stepvalue: 74000
type: "Nesterov"
I0401 01:06:03.191251 11876 solver.cpp:91] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0401 01:06:03.192250 11876 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0401 01:06:03.192250 11876 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0401 01:06:03.192250 11876 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0401 01:06:03.192250 11876 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_train_leveldb_padding"
    batch_size: 100
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0401 01:06:03.198271 11876 layer_factory.cpp:58] Creating layer cifar
I0401 01:06:03.198271 11876 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.199256 11876 net.cpp:100] Creating Layer cifar
I0401 01:06:03.199256 11876 net.cpp:408] cifar -> data
I0401 01:06:03.199256 11876 net.cpp:408] cifar -> label
I0401 01:06:03.201259  8832 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.205253  8832 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_train_leveldb_padding
I0401 01:06:03.248256 11876 data_layer.cpp:41] output data size: 100,3,32,32
I0401 01:06:03.260257 11876 net.cpp:150] Setting up cifar
I0401 01:06:03.260257 11876 net.cpp:157] Top shape: 100 3 32 32 (307200)
I0401 01:06:03.260257 11876 net.cpp:157] Top shape: 100 (100)
I0401 01:06:03.260257 11876 net.cpp:165] Memory required for data: 1229200
I0401 01:06:03.260257 11876 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0401 01:06:03.260257 11876 net.cpp:100] Creating Layer label_cifar_1_split
I0401 01:06:03.260257 11876 net.cpp:434] label_cifar_1_split <- label
I0401 01:06:03.260257 11876 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0401 01:06:03.260257 11876 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0401 01:06:03.261257 11876 net.cpp:150] Setting up label_cifar_1_split
I0401 01:06:03.261257 11876 net.cpp:157] Top shape: 100 (100)
I0401 01:06:03.261257 11876 net.cpp:157] Top shape: 100 (100)
I0401 01:06:03.261257 11876 net.cpp:165] Memory required for data: 1230000
I0401 01:06:03.261257 11876 layer_factory.cpp:58] Creating layer conv1
I0401 01:06:03.261257 11876 net.cpp:100] Creating Layer conv1
I0401 01:06:03.261257 11876 net.cpp:434] conv1 <- data
I0401 01:06:03.261257 11876 net.cpp:408] conv1 -> conv1
I0401 01:06:03.261257  3648 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.673316 11876 net.cpp:150] Setting up conv1
I0401 01:06:03.673316 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.673316 11876 net.cpp:165] Memory required for data: 14337200
I0401 01:06:03.673316 11876 layer_factory.cpp:58] Creating layer bn1
I0401 01:06:03.673316 11876 net.cpp:100] Creating Layer bn1
I0401 01:06:03.673316 11876 net.cpp:434] bn1 <- conv1
I0401 01:06:03.673316 11876 net.cpp:408] bn1 -> bn1
I0401 01:06:03.673316 11876 net.cpp:150] Setting up bn1
I0401 01:06:03.673316 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.673316 11876 net.cpp:165] Memory required for data: 27444400
I0401 01:06:03.673316 11876 layer_factory.cpp:58] Creating layer scale1
I0401 01:06:03.673316 11876 net.cpp:100] Creating Layer scale1
I0401 01:06:03.673316 11876 net.cpp:434] scale1 <- bn1
I0401 01:06:03.673316 11876 net.cpp:408] scale1 -> scale1
I0401 01:06:03.673316 11876 layer_factory.cpp:58] Creating layer scale1
I0401 01:06:03.673316 11876 net.cpp:150] Setting up scale1
I0401 01:06:03.673316 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.673316 11876 net.cpp:165] Memory required for data: 40551600
I0401 01:06:03.673316 11876 layer_factory.cpp:58] Creating layer relu1
I0401 01:06:03.673316 11876 net.cpp:100] Creating Layer relu1
I0401 01:06:03.673316 11876 net.cpp:434] relu1 <- scale1
I0401 01:06:03.673316 11876 net.cpp:408] relu1 -> relu1
I0401 01:06:03.674317 11876 net.cpp:150] Setting up relu1
I0401 01:06:03.674317 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.674317 11876 net.cpp:165] Memory required for data: 53658800
I0401 01:06:03.674317 11876 layer_factory.cpp:58] Creating layer conv1_0
I0401 01:06:03.674317 11876 net.cpp:100] Creating Layer conv1_0
I0401 01:06:03.674317 11876 net.cpp:434] conv1_0 <- relu1
I0401 01:06:03.674317 11876 net.cpp:408] conv1_0 -> conv1_0
I0401 01:06:03.678829 11876 net.cpp:150] Setting up conv1_0
I0401 01:06:03.679332 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.679332 11876 net.cpp:165] Memory required for data: 66766000
I0401 01:06:03.679332 11876 layer_factory.cpp:58] Creating layer bn1_0
I0401 01:06:03.679332 11876 net.cpp:100] Creating Layer bn1_0
I0401 01:06:03.679332 11876 net.cpp:434] bn1_0 <- conv1_0
I0401 01:06:03.679332 11876 net.cpp:408] bn1_0 -> bn1_0
I0401 01:06:03.679332 11876 net.cpp:150] Setting up bn1_0
I0401 01:06:03.679332 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.679332 11876 net.cpp:165] Memory required for data: 79873200
I0401 01:06:03.679332 11876 layer_factory.cpp:58] Creating layer scale1_0
I0401 01:06:03.679332 11876 net.cpp:100] Creating Layer scale1_0
I0401 01:06:03.679332 11876 net.cpp:434] scale1_0 <- bn1_0
I0401 01:06:03.679332 11876 net.cpp:408] scale1_0 -> scale1_0
I0401 01:06:03.679832 11876 layer_factory.cpp:58] Creating layer scale1_0
I0401 01:06:03.679832 11876 net.cpp:150] Setting up scale1_0
I0401 01:06:03.679832 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.679832 11876 net.cpp:165] Memory required for data: 92980400
I0401 01:06:03.679832 11876 layer_factory.cpp:58] Creating layer relu1_0
I0401 01:06:03.679832 11876 net.cpp:100] Creating Layer relu1_0
I0401 01:06:03.679832 11876 net.cpp:434] relu1_0 <- scale1_0
I0401 01:06:03.679832 11876 net.cpp:408] relu1_0 -> relu1_0
I0401 01:06:03.680831 11876 net.cpp:150] Setting up relu1_0
I0401 01:06:03.680831 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.680831 11876 net.cpp:165] Memory required for data: 106087600
I0401 01:06:03.680831 11876 layer_factory.cpp:58] Creating layer conv2
I0401 01:06:03.680831 11876 net.cpp:100] Creating Layer conv2
I0401 01:06:03.680831 11876 net.cpp:434] conv2 <- relu1_0
I0401 01:06:03.680831 11876 net.cpp:408] conv2 -> conv2
I0401 01:06:03.682831 11876 net.cpp:150] Setting up conv2
I0401 01:06:03.682831 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.682831 11876 net.cpp:165] Memory required for data: 119194800
I0401 01:06:03.682831 11876 layer_factory.cpp:58] Creating layer bn2
I0401 01:06:03.683343 11876 net.cpp:100] Creating Layer bn2
I0401 01:06:03.683343 11876 net.cpp:434] bn2 <- conv2
I0401 01:06:03.683343 11876 net.cpp:408] bn2 -> bn2
I0401 01:06:03.683343 11876 net.cpp:150] Setting up bn2
I0401 01:06:03.683343 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.683343 11876 net.cpp:165] Memory required for data: 132302000
I0401 01:06:03.683343 11876 layer_factory.cpp:58] Creating layer scale2
I0401 01:06:03.683343 11876 net.cpp:100] Creating Layer scale2
I0401 01:06:03.683343 11876 net.cpp:434] scale2 <- bn2
I0401 01:06:03.683343 11876 net.cpp:408] scale2 -> scale2
I0401 01:06:03.683843 11876 layer_factory.cpp:58] Creating layer scale2
I0401 01:06:03.683843 11876 net.cpp:150] Setting up scale2
I0401 01:06:03.683843 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.683843 11876 net.cpp:165] Memory required for data: 145409200
I0401 01:06:03.683843 11876 layer_factory.cpp:58] Creating layer relu2
I0401 01:06:03.683843 11876 net.cpp:100] Creating Layer relu2
I0401 01:06:03.683843 11876 net.cpp:434] relu2 <- scale2
I0401 01:06:03.683843 11876 net.cpp:408] relu2 -> relu2
I0401 01:06:03.691828 11876 net.cpp:150] Setting up relu2
I0401 01:06:03.691828 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.691828 11876 net.cpp:165] Memory required for data: 158516400
I0401 01:06:03.691828 11876 layer_factory.cpp:58] Creating layer conv2_1
I0401 01:06:03.691828 11876 net.cpp:100] Creating Layer conv2_1
I0401 01:06:03.691828 11876 net.cpp:434] conv2_1 <- relu2
I0401 01:06:03.691828 11876 net.cpp:408] conv2_1 -> conv2_1
I0401 01:06:03.693358 11876 net.cpp:150] Setting up conv2_1
I0401 01:06:03.693358 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.693358 11876 net.cpp:165] Memory required for data: 171623600
I0401 01:06:03.693358 11876 layer_factory.cpp:58] Creating layer bn2_1
I0401 01:06:03.693358 11876 net.cpp:100] Creating Layer bn2_1
I0401 01:06:03.693358 11876 net.cpp:434] bn2_1 <- conv2_1
I0401 01:06:03.693358 11876 net.cpp:408] bn2_1 -> bn2_1
I0401 01:06:03.693358 11876 net.cpp:150] Setting up bn2_1
I0401 01:06:03.693358 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.693358 11876 net.cpp:165] Memory required for data: 184730800
I0401 01:06:03.693358 11876 layer_factory.cpp:58] Creating layer scale2_1
I0401 01:06:03.693358 11876 net.cpp:100] Creating Layer scale2_1
I0401 01:06:03.693358 11876 net.cpp:434] scale2_1 <- bn2_1
I0401 01:06:03.693358 11876 net.cpp:408] scale2_1 -> scale2_1
I0401 01:06:03.693358 11876 layer_factory.cpp:58] Creating layer scale2_1
I0401 01:06:03.694344 11876 net.cpp:150] Setting up scale2_1
I0401 01:06:03.694344 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.694344 11876 net.cpp:165] Memory required for data: 197838000
I0401 01:06:03.694344 11876 layer_factory.cpp:58] Creating layer relu2_1
I0401 01:06:03.694344 11876 net.cpp:100] Creating Layer relu2_1
I0401 01:06:03.694344 11876 net.cpp:434] relu2_1 <- scale2_1
I0401 01:06:03.694344 11876 net.cpp:408] relu2_1 -> relu2_1
I0401 01:06:03.694344 11876 net.cpp:150] Setting up relu2_1
I0401 01:06:03.694344 11876 net.cpp:157] Top shape: 100 32 32 32 (3276800)
I0401 01:06:03.694344 11876 net.cpp:165] Memory required for data: 210945200
I0401 01:06:03.694344 11876 layer_factory.cpp:58] Creating layer pool2_1
I0401 01:06:03.694344 11876 net.cpp:100] Creating Layer pool2_1
I0401 01:06:03.694344 11876 net.cpp:434] pool2_1 <- relu2_1
I0401 01:06:03.694344 11876 net.cpp:408] pool2_1 -> pool2_1
I0401 01:06:03.694344 11876 net.cpp:150] Setting up pool2_1
I0401 01:06:03.694344 11876 net.cpp:157] Top shape: 100 32 16 16 (819200)
I0401 01:06:03.694344 11876 net.cpp:165] Memory required for data: 214222000
I0401 01:06:03.694344 11876 layer_factory.cpp:58] Creating layer conv2_2
I0401 01:06:03.694344 11876 net.cpp:100] Creating Layer conv2_2
I0401 01:06:03.694344 11876 net.cpp:434] conv2_2 <- pool2_1
I0401 01:06:03.694344 11876 net.cpp:408] conv2_2 -> conv2_2
I0401 01:06:03.696358 11876 net.cpp:150] Setting up conv2_2
I0401 01:06:03.696358 11876 net.cpp:157] Top shape: 100 50 16 16 (1280000)
I0401 01:06:03.696358 11876 net.cpp:165] Memory required for data: 219342000
I0401 01:06:03.696358 11876 layer_factory.cpp:58] Creating layer bn2_2
I0401 01:06:03.696358 11876 net.cpp:100] Creating Layer bn2_2
I0401 01:06:03.696358 11876 net.cpp:434] bn2_2 <- conv2_2
I0401 01:06:03.696358 11876 net.cpp:408] bn2_2 -> bn2_2
I0401 01:06:03.697358 11876 net.cpp:150] Setting up bn2_2
I0401 01:06:03.697358 11876 net.cpp:157] Top shape: 100 50 16 16 (1280000)
I0401 01:06:03.697358 11876 net.cpp:165] Memory required for data: 224462000
I0401 01:06:03.697358 11876 layer_factory.cpp:58] Creating layer scale2_2
I0401 01:06:03.697358 11876 net.cpp:100] Creating Layer scale2_2
I0401 01:06:03.697358 11876 net.cpp:434] scale2_2 <- bn2_2
I0401 01:06:03.697358 11876 net.cpp:408] scale2_2 -> scale2_2
I0401 01:06:03.697358 11876 layer_factory.cpp:58] Creating layer scale2_2
I0401 01:06:03.697358 11876 net.cpp:150] Setting up scale2_2
I0401 01:06:03.697358 11876 net.cpp:157] Top shape: 100 50 16 16 (1280000)
I0401 01:06:03.697358 11876 net.cpp:165] Memory required for data: 229582000
I0401 01:06:03.697358 11876 layer_factory.cpp:58] Creating layer relu2_2
I0401 01:06:03.697358 11876 net.cpp:100] Creating Layer relu2_2
I0401 01:06:03.697358 11876 net.cpp:434] relu2_2 <- scale2_2
I0401 01:06:03.697358 11876 net.cpp:408] relu2_2 -> relu2_2
I0401 01:06:03.697358 11876 net.cpp:150] Setting up relu2_2
I0401 01:06:03.697358 11876 net.cpp:157] Top shape: 100 50 16 16 (1280000)
I0401 01:06:03.697358 11876 net.cpp:165] Memory required for data: 234702000
I0401 01:06:03.697358 11876 layer_factory.cpp:58] Creating layer conv3
I0401 01:06:03.697358 11876 net.cpp:100] Creating Layer conv3
I0401 01:06:03.697358 11876 net.cpp:434] conv3 <- relu2_2
I0401 01:06:03.697358 11876 net.cpp:408] conv3 -> conv3
I0401 01:06:03.700345 11876 net.cpp:150] Setting up conv3
I0401 01:06:03.700345 11876 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0401 01:06:03.700345 11876 net.cpp:165] Memory required for data: 241255600
I0401 01:06:03.700345 11876 layer_factory.cpp:58] Creating layer bn3
I0401 01:06:03.700345 11876 net.cpp:100] Creating Layer bn3
I0401 01:06:03.700345 11876 net.cpp:434] bn3 <- conv3
I0401 01:06:03.700345 11876 net.cpp:408] bn3 -> bn3
I0401 01:06:03.700345 11876 net.cpp:150] Setting up bn3
I0401 01:06:03.700345 11876 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0401 01:06:03.700345 11876 net.cpp:165] Memory required for data: 247809200
I0401 01:06:03.700345 11876 layer_factory.cpp:58] Creating layer scale3
I0401 01:06:03.700345 11876 net.cpp:100] Creating Layer scale3
I0401 01:06:03.700345 11876 net.cpp:434] scale3 <- bn3
I0401 01:06:03.700345 11876 net.cpp:408] scale3 -> scale3
I0401 01:06:03.700345 11876 layer_factory.cpp:58] Creating layer scale3
I0401 01:06:03.700345 11876 net.cpp:150] Setting up scale3
I0401 01:06:03.700345 11876 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0401 01:06:03.700345 11876 net.cpp:165] Memory required for data: 254362800
I0401 01:06:03.700345 11876 layer_factory.cpp:58] Creating layer relu3
I0401 01:06:03.700345 11876 net.cpp:100] Creating Layer relu3
I0401 01:06:03.700345 11876 net.cpp:434] relu3 <- scale3
I0401 01:06:03.700345 11876 net.cpp:408] relu3 -> relu3
I0401 01:06:03.701344 11876 net.cpp:150] Setting up relu3
I0401 01:06:03.701344 11876 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0401 01:06:03.701344 11876 net.cpp:165] Memory required for data: 260916400
I0401 01:06:03.701344 11876 layer_factory.cpp:58] Creating layer conv4
I0401 01:06:03.701344 11876 net.cpp:100] Creating Layer conv4
I0401 01:06:03.701344 11876 net.cpp:434] conv4 <- relu3
I0401 01:06:03.701344 11876 net.cpp:408] conv4 -> conv4
I0401 01:06:03.703344 11876 net.cpp:150] Setting up conv4
I0401 01:06:03.703344 11876 net.cpp:157] Top shape: 100 64 16 16 (1638400)
I0401 01:06:03.703344 11876 net.cpp:165] Memory required for data: 267470000
I0401 01:06:03.703344 11876 layer_factory.cpp:58] Creating layer pool4
I0401 01:06:03.703344 11876 net.cpp:100] Creating Layer pool4
I0401 01:06:03.703344 11876 net.cpp:434] pool4 <- conv4
I0401 01:06:03.703344 11876 net.cpp:408] pool4 -> pool4
I0401 01:06:03.703344 11876 net.cpp:150] Setting up pool4
I0401 01:06:03.703344 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.703344 11876 net.cpp:165] Memory required for data: 269108400
I0401 01:06:03.703344 11876 layer_factory.cpp:58] Creating layer bn4
I0401 01:06:03.703344 11876 net.cpp:100] Creating Layer bn4
I0401 01:06:03.703344 11876 net.cpp:434] bn4 <- pool4
I0401 01:06:03.703344 11876 net.cpp:408] bn4 -> bn4
I0401 01:06:03.704346 11876 net.cpp:150] Setting up bn4
I0401 01:06:03.704346 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.704346 11876 net.cpp:165] Memory required for data: 270746800
I0401 01:06:03.704346 11876 layer_factory.cpp:58] Creating layer scale4
I0401 01:06:03.704346 11876 net.cpp:100] Creating Layer scale4
I0401 01:06:03.704346 11876 net.cpp:434] scale4 <- bn4
I0401 01:06:03.704346 11876 net.cpp:408] scale4 -> scale4
I0401 01:06:03.704346 11876 layer_factory.cpp:58] Creating layer scale4
I0401 01:06:03.704346 11876 net.cpp:150] Setting up scale4
I0401 01:06:03.704346 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.704346 11876 net.cpp:165] Memory required for data: 272385200
I0401 01:06:03.704346 11876 layer_factory.cpp:58] Creating layer relu4
I0401 01:06:03.704346 11876 net.cpp:100] Creating Layer relu4
I0401 01:06:03.704346 11876 net.cpp:434] relu4 <- scale4
I0401 01:06:03.704346 11876 net.cpp:408] relu4 -> relu4
I0401 01:06:03.707358 11876 net.cpp:150] Setting up relu4
I0401 01:06:03.707358 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.707358 11876 net.cpp:165] Memory required for data: 274023600
I0401 01:06:03.707358 11876 layer_factory.cpp:58] Creating layer conv4_1
I0401 01:06:03.707358 11876 net.cpp:100] Creating Layer conv4_1
I0401 01:06:03.708351 11876 net.cpp:434] conv4_1 <- relu4
I0401 01:06:03.708351 11876 net.cpp:408] conv4_1 -> conv4_1
I0401 01:06:03.713356 11876 net.cpp:150] Setting up conv4_1
I0401 01:06:03.713356 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.713356 11876 net.cpp:165] Memory required for data: 275662000
I0401 01:06:03.713356 11876 layer_factory.cpp:58] Creating layer bn4_1
I0401 01:06:03.714346 11876 net.cpp:100] Creating Layer bn4_1
I0401 01:06:03.714346 11876 net.cpp:434] bn4_1 <- conv4_1
I0401 01:06:03.714346 11876 net.cpp:408] bn4_1 -> bn4_1
I0401 01:06:03.714346 11876 net.cpp:150] Setting up bn4_1
I0401 01:06:03.714346 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.714346 11876 net.cpp:165] Memory required for data: 277300400
I0401 01:06:03.714346 11876 layer_factory.cpp:58] Creating layer scale4_1
I0401 01:06:03.714346 11876 net.cpp:100] Creating Layer scale4_1
I0401 01:06:03.714346 11876 net.cpp:434] scale4_1 <- bn4_1
I0401 01:06:03.714346 11876 net.cpp:408] scale4_1 -> scale4_1
I0401 01:06:03.714346 11876 layer_factory.cpp:58] Creating layer scale4_1
I0401 01:06:03.714346 11876 net.cpp:150] Setting up scale4_1
I0401 01:06:03.714346 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.714346 11876 net.cpp:165] Memory required for data: 278938800
I0401 01:06:03.714346 11876 layer_factory.cpp:58] Creating layer relu4_1
I0401 01:06:03.714346 11876 net.cpp:100] Creating Layer relu4_1
I0401 01:06:03.714346 11876 net.cpp:434] relu4_1 <- scale4_1
I0401 01:06:03.714346 11876 net.cpp:408] relu4_1 -> relu4_1
I0401 01:06:03.715361 11876 net.cpp:150] Setting up relu4_1
I0401 01:06:03.715361 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.715361 11876 net.cpp:165] Memory required for data: 280577200
I0401 01:06:03.715361 11876 layer_factory.cpp:58] Creating layer conv4_2
I0401 01:06:03.715361 11876 net.cpp:100] Creating Layer conv4_2
I0401 01:06:03.715361 11876 net.cpp:434] conv4_2 <- relu4_1
I0401 01:06:03.715361 11876 net.cpp:408] conv4_2 -> conv4_2
I0401 01:06:03.721349 11876 net.cpp:150] Setting up conv4_2
I0401 01:06:03.721349 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.721349 11876 net.cpp:165] Memory required for data: 282215600
I0401 01:06:03.721349 11876 layer_factory.cpp:58] Creating layer bn4_2
I0401 01:06:03.721349 11876 net.cpp:100] Creating Layer bn4_2
I0401 01:06:03.721349 11876 net.cpp:434] bn4_2 <- conv4_2
I0401 01:06:03.721349 11876 net.cpp:408] bn4_2 -> bn4_2
I0401 01:06:03.721349 11876 net.cpp:150] Setting up bn4_2
I0401 01:06:03.721349 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.721349 11876 net.cpp:165] Memory required for data: 283854000
I0401 01:06:03.721349 11876 layer_factory.cpp:58] Creating layer scale4_2
I0401 01:06:03.721349 11876 net.cpp:100] Creating Layer scale4_2
I0401 01:06:03.721349 11876 net.cpp:434] scale4_2 <- bn4_2
I0401 01:06:03.721349 11876 net.cpp:408] scale4_2 -> scale4_2
I0401 01:06:03.722359 11876 layer_factory.cpp:58] Creating layer scale4_2
I0401 01:06:03.722359 11876 net.cpp:150] Setting up scale4_2
I0401 01:06:03.722359 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.722359 11876 net.cpp:165] Memory required for data: 285492400
I0401 01:06:03.722359 11876 layer_factory.cpp:58] Creating layer relu4_2
I0401 01:06:03.722359 11876 net.cpp:100] Creating Layer relu4_2
I0401 01:06:03.722359 11876 net.cpp:434] relu4_2 <- scale4_2
I0401 01:06:03.722359 11876 net.cpp:408] relu4_2 -> relu4_2
I0401 01:06:03.722359 11876 net.cpp:150] Setting up relu4_2
I0401 01:06:03.722359 11876 net.cpp:157] Top shape: 100 64 8 8 (409600)
I0401 01:06:03.722359 11876 net.cpp:165] Memory required for data: 287130800
I0401 01:06:03.722359 11876 layer_factory.cpp:58] Creating layer pool4_2
I0401 01:06:03.722359 11876 net.cpp:100] Creating Layer pool4_2
I0401 01:06:03.722359 11876 net.cpp:434] pool4_2 <- relu4_2
I0401 01:06:03.722359 11876 net.cpp:408] pool4_2 -> pool4_2
I0401 01:06:03.722359 11876 net.cpp:150] Setting up pool4_2
I0401 01:06:03.722359 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.722359 11876 net.cpp:165] Memory required for data: 287540400
I0401 01:06:03.722359 11876 layer_factory.cpp:58] Creating layer conv4_0
I0401 01:06:03.722359 11876 net.cpp:100] Creating Layer conv4_0
I0401 01:06:03.722359 11876 net.cpp:434] conv4_0 <- pool4_2
I0401 01:06:03.722359 11876 net.cpp:408] conv4_0 -> conv4_0
I0401 01:06:03.724359 11876 net.cpp:150] Setting up conv4_0
I0401 01:06:03.724359 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.724359 11876 net.cpp:165] Memory required for data: 287950000
I0401 01:06:03.724359 11876 layer_factory.cpp:58] Creating layer bn4_0
I0401 01:06:03.724359 11876 net.cpp:100] Creating Layer bn4_0
I0401 01:06:03.724359 11876 net.cpp:434] bn4_0 <- conv4_0
I0401 01:06:03.724359 11876 net.cpp:408] bn4_0 -> bn4_0
I0401 01:06:03.725363 11876 net.cpp:150] Setting up bn4_0
I0401 01:06:03.725363 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.725363 11876 net.cpp:165] Memory required for data: 288359600
I0401 01:06:03.725363 11876 layer_factory.cpp:58] Creating layer scale4_0
I0401 01:06:03.725363 11876 net.cpp:100] Creating Layer scale4_0
I0401 01:06:03.725363 11876 net.cpp:434] scale4_0 <- bn4_0
I0401 01:06:03.725363 11876 net.cpp:408] scale4_0 -> scale4_0
I0401 01:06:03.725363 11876 layer_factory.cpp:58] Creating layer scale4_0
I0401 01:06:03.725363 11876 net.cpp:150] Setting up scale4_0
I0401 01:06:03.725363 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.725363 11876 net.cpp:165] Memory required for data: 288769200
I0401 01:06:03.725363 11876 layer_factory.cpp:58] Creating layer relu4_0
I0401 01:06:03.725363 11876 net.cpp:100] Creating Layer relu4_0
I0401 01:06:03.725363 11876 net.cpp:434] relu4_0 <- scale4_0
I0401 01:06:03.725363 11876 net.cpp:408] relu4_0 -> relu4_0
I0401 01:06:03.726366 11876 net.cpp:150] Setting up relu4_0
I0401 01:06:03.726366 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.726366 11876 net.cpp:165] Memory required for data: 289178800
I0401 01:06:03.726366 11876 layer_factory.cpp:58] Creating layer cccp4
I0401 01:06:03.726366 11876 net.cpp:100] Creating Layer cccp4
I0401 01:06:03.726366 11876 net.cpp:434] cccp4 <- relu4_0
I0401 01:06:03.726366 11876 net.cpp:408] cccp4 -> cccp4
I0401 01:06:03.728358 11876 net.cpp:150] Setting up cccp4
I0401 01:06:03.728358 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.728358 11876 net.cpp:165] Memory required for data: 289588400
I0401 01:06:03.728358 11876 layer_factory.cpp:58] Creating layer relu_cccp4
I0401 01:06:03.728358 11876 net.cpp:100] Creating Layer relu_cccp4
I0401 01:06:03.728358 11876 net.cpp:434] relu_cccp4 <- cccp4
I0401 01:06:03.728358 11876 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0401 01:06:03.728358 11876 net.cpp:150] Setting up relu_cccp4
I0401 01:06:03.728358 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.728358 11876 net.cpp:165] Memory required for data: 289998000
I0401 01:06:03.728358 11876 layer_factory.cpp:58] Creating layer cccp5
I0401 01:06:03.728358 11876 net.cpp:100] Creating Layer cccp5
I0401 01:06:03.728358 11876 net.cpp:434] cccp5 <- cccp4
I0401 01:06:03.728358 11876 net.cpp:408] cccp5 -> cccp5
I0401 01:06:03.730370 11876 net.cpp:150] Setting up cccp5
I0401 01:06:03.731345 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.731345 11876 net.cpp:165] Memory required for data: 290407600
I0401 01:06:03.731345 11876 layer_factory.cpp:58] Creating layer relu_cccp5
I0401 01:06:03.731345 11876 net.cpp:100] Creating Layer relu_cccp5
I0401 01:06:03.731345 11876 net.cpp:434] relu_cccp5 <- cccp5
I0401 01:06:03.731345 11876 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0401 01:06:03.731345 11876 net.cpp:150] Setting up relu_cccp5
I0401 01:06:03.731345 11876 net.cpp:157] Top shape: 100 64 4 4 (102400)
I0401 01:06:03.731345 11876 net.cpp:165] Memory required for data: 290817200
I0401 01:06:03.731345 11876 layer_factory.cpp:58] Creating layer poolcp5
I0401 01:06:03.731345 11876 net.cpp:100] Creating Layer poolcp5
I0401 01:06:03.731345 11876 net.cpp:434] poolcp5 <- cccp5
I0401 01:06:03.731345 11876 net.cpp:408] poolcp5 -> poolcp5
I0401 01:06:03.731345 11876 net.cpp:150] Setting up poolcp5
I0401 01:06:03.731345 11876 net.cpp:157] Top shape: 100 64 2 2 (25600)
I0401 01:06:03.731345 11876 net.cpp:165] Memory required for data: 290919600
I0401 01:06:03.731345 11876 layer_factory.cpp:58] Creating layer cccp6
I0401 01:06:03.731345 11876 net.cpp:100] Creating Layer cccp6
I0401 01:06:03.731345 11876 net.cpp:434] cccp6 <- poolcp5
I0401 01:06:03.731345 11876 net.cpp:408] cccp6 -> cccp6
I0401 01:06:03.733356 11876 net.cpp:150] Setting up cccp6
I0401 01:06:03.733356 11876 net.cpp:157] Top shape: 100 100 2 2 (40000)
I0401 01:06:03.733356 11876 net.cpp:165] Memory required for data: 291079600
I0401 01:06:03.733356 11876 layer_factory.cpp:58] Creating layer relu_cccp6
I0401 01:06:03.733356 11876 net.cpp:100] Creating Layer relu_cccp6
I0401 01:06:03.733356 11876 net.cpp:434] relu_cccp6 <- cccp6
I0401 01:06:03.733356 11876 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0401 01:06:03.734344 11876 net.cpp:150] Setting up relu_cccp6
I0401 01:06:03.734344 11876 net.cpp:157] Top shape: 100 100 2 2 (40000)
I0401 01:06:03.734344 11876 net.cpp:165] Memory required for data: 291239600
I0401 01:06:03.734344 11876 layer_factory.cpp:58] Creating layer poolcp6
I0401 01:06:03.734344 11876 net.cpp:100] Creating Layer poolcp6
I0401 01:06:03.734344 11876 net.cpp:434] poolcp6 <- cccp6
I0401 01:06:03.734344 11876 net.cpp:408] poolcp6 -> poolcp6
I0401 01:06:03.734344 11876 net.cpp:150] Setting up poolcp6
I0401 01:06:03.734344 11876 net.cpp:157] Top shape: 100 100 1 1 (10000)
I0401 01:06:03.734344 11876 net.cpp:165] Memory required for data: 291279600
I0401 01:06:03.734344 11876 layer_factory.cpp:58] Creating layer ip1
I0401 01:06:03.734344 11876 net.cpp:100] Creating Layer ip1
I0401 01:06:03.734344 11876 net.cpp:434] ip1 <- poolcp6
I0401 01:06:03.734344 11876 net.cpp:408] ip1 -> ip1
I0401 01:06:03.735355 11876 net.cpp:150] Setting up ip1
I0401 01:06:03.735355 11876 net.cpp:157] Top shape: 100 10 (1000)
I0401 01:06:03.735355 11876 net.cpp:165] Memory required for data: 291283600
I0401 01:06:03.735355 11876 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0401 01:06:03.735355 11876 net.cpp:100] Creating Layer ip1_ip1_0_split
I0401 01:06:03.735355 11876 net.cpp:434] ip1_ip1_0_split <- ip1
I0401 01:06:03.735355 11876 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0401 01:06:03.735355 11876 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0401 01:06:03.735355 11876 net.cpp:150] Setting up ip1_ip1_0_split
I0401 01:06:03.735355 11876 net.cpp:157] Top shape: 100 10 (1000)
I0401 01:06:03.735355 11876 net.cpp:157] Top shape: 100 10 (1000)
I0401 01:06:03.735355 11876 net.cpp:165] Memory required for data: 291291600
I0401 01:06:03.735355 11876 layer_factory.cpp:58] Creating layer accuracy_training
I0401 01:06:03.735355 11876 net.cpp:100] Creating Layer accuracy_training
I0401 01:06:03.735355 11876 net.cpp:434] accuracy_training <- ip1_ip1_0_split_0
I0401 01:06:03.735355 11876 net.cpp:434] accuracy_training <- label_cifar_1_split_0
I0401 01:06:03.735355 11876 net.cpp:408] accuracy_training -> accuracy_training
I0401 01:06:03.735355 11876 net.cpp:150] Setting up accuracy_training
I0401 01:06:03.735355 11876 net.cpp:157] Top shape: (1)
I0401 01:06:03.735355 11876 net.cpp:165] Memory required for data: 291291604
I0401 01:06:03.735355 11876 layer_factory.cpp:58] Creating layer loss
I0401 01:06:03.735355 11876 net.cpp:100] Creating Layer loss
I0401 01:06:03.735355 11876 net.cpp:434] loss <- ip1_ip1_0_split_1
I0401 01:06:03.735355 11876 net.cpp:434] loss <- label_cifar_1_split_1
I0401 01:06:03.735355 11876 net.cpp:408] loss -> loss
I0401 01:06:03.735355 11876 layer_factory.cpp:58] Creating layer loss
I0401 01:06:03.738343 11876 net.cpp:150] Setting up loss
I0401 01:06:03.738343 11876 net.cpp:157] Top shape: (1)
I0401 01:06:03.738343 11876 net.cpp:160]     with loss weight 1
I0401 01:06:03.738343 11876 net.cpp:165] Memory required for data: 291291608
I0401 01:06:03.738343 11876 net.cpp:226] loss needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:228] accuracy_training does not need backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] ip1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] poolcp6 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu_cccp6 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] cccp6 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] poolcp5 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu_cccp5 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] cccp5 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu_cccp4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] cccp4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu4_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale4_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn4_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv4_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] pool4_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu4_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale4_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn4_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv4_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu4_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale4_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn4_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv4_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] pool4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv4 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu3 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale3 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn3 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv3 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu2_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale2_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn2_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv2_2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] pool2_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu2_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale2_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn2_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv2_1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv2 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu1_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale1_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn1_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv1_0 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] relu1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] scale1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] bn1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:226] conv1 needs backward computation.
I0401 01:06:03.738343 11876 net.cpp:228] label_cifar_1_split does not need backward computation.
I0401 01:06:03.738343 11876 net.cpp:228] cifar does not need backward computation.
I0401 01:06:03.738343 11876 net.cpp:270] This network produces output accuracy_training
I0401 01:06:03.738343 11876 net.cpp:270] This network produces output loss
I0401 01:06:03.738343 11876 net.cpp:283] Network initialization done.
I0401 01:06:03.740367 11876 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0401 01:06:03.740367 11876 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0401 01:06:03.740367 11876 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0401 01:06:03.740367 11876 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0401 01:06:03.741358 11876 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar10/cifar10_test_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 50
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 100
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0401 01:06:03.741358 11876 layer_factory.cpp:58] Creating layer cifar
I0401 01:06:03.742367 11876 net.cpp:100] Creating Layer cifar
I0401 01:06:03.742367 11876 net.cpp:408] cifar -> data
I0401 01:06:03.742367 11876 net.cpp:408] cifar -> label
I0401 01:06:03.744343 11704 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.750344 11704 db_leveldb.cpp:18] Opened leveldb examples/cifar10/cifar10_test_leveldb_padding
I0401 01:06:03.751345 11876 data_layer.cpp:41] output data size: 50,3,32,32
I0401 01:06:03.756345 11876 net.cpp:150] Setting up cifar
I0401 01:06:03.756345 11876 net.cpp:157] Top shape: 50 3 32 32 (153600)
I0401 01:06:03.756345 11876 net.cpp:157] Top shape: 50 (50)
I0401 01:06:03.756345 11876 net.cpp:165] Memory required for data: 614600
I0401 01:06:03.756345 11876 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0401 01:06:03.756345 11876 net.cpp:100] Creating Layer label_cifar_1_split
I0401 01:06:03.756345 11876 net.cpp:434] label_cifar_1_split <- label
I0401 01:06:03.756345 11876 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0401 01:06:03.756345 11876 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0401 01:06:03.756345 11876 net.cpp:150] Setting up label_cifar_1_split
I0401 01:06:03.756345 11876 net.cpp:157] Top shape: 50 (50)
I0401 01:06:03.756345 11876 net.cpp:157] Top shape: 50 (50)
I0401 01:06:03.756345 11876 net.cpp:165] Memory required for data: 615000
I0401 01:06:03.756345 11876 layer_factory.cpp:58] Creating layer conv1
I0401 01:06:03.756345 11876 net.cpp:100] Creating Layer conv1
I0401 01:06:03.756345 11876 net.cpp:434] conv1 <- data
I0401 01:06:03.756345 11876 net.cpp:408] conv1 -> conv1
I0401 01:06:03.757345 11980 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0401 01:06:03.759346 11876 net.cpp:150] Setting up conv1
I0401 01:06:03.759346 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.759346 11876 net.cpp:165] Memory required for data: 7168600
I0401 01:06:03.759346 11876 layer_factory.cpp:58] Creating layer bn1
I0401 01:06:03.759346 11876 net.cpp:100] Creating Layer bn1
I0401 01:06:03.759346 11876 net.cpp:434] bn1 <- conv1
I0401 01:06:03.759346 11876 net.cpp:408] bn1 -> bn1
I0401 01:06:03.760345 11876 net.cpp:150] Setting up bn1
I0401 01:06:03.760345 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.760345 11876 net.cpp:165] Memory required for data: 13722200
I0401 01:06:03.760345 11876 layer_factory.cpp:58] Creating layer scale1
I0401 01:06:03.760345 11876 net.cpp:100] Creating Layer scale1
I0401 01:06:03.760345 11876 net.cpp:434] scale1 <- bn1
I0401 01:06:03.760345 11876 net.cpp:408] scale1 -> scale1
I0401 01:06:03.760345 11876 layer_factory.cpp:58] Creating layer scale1
I0401 01:06:03.760345 11876 net.cpp:150] Setting up scale1
I0401 01:06:03.760345 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.760345 11876 net.cpp:165] Memory required for data: 20275800
I0401 01:06:03.760345 11876 layer_factory.cpp:58] Creating layer relu1
I0401 01:06:03.760345 11876 net.cpp:100] Creating Layer relu1
I0401 01:06:03.760345 11876 net.cpp:434] relu1 <- scale1
I0401 01:06:03.760345 11876 net.cpp:408] relu1 -> relu1
I0401 01:06:03.761345 11876 net.cpp:150] Setting up relu1
I0401 01:06:03.761345 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.761345 11876 net.cpp:165] Memory required for data: 26829400
I0401 01:06:03.761345 11876 layer_factory.cpp:58] Creating layer conv1_0
I0401 01:06:03.761345 11876 net.cpp:100] Creating Layer conv1_0
I0401 01:06:03.761345 11876 net.cpp:434] conv1_0 <- relu1
I0401 01:06:03.761345 11876 net.cpp:408] conv1_0 -> conv1_0
I0401 01:06:03.764348 11876 net.cpp:150] Setting up conv1_0
I0401 01:06:03.765347 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.765347 11876 net.cpp:165] Memory required for data: 33383000
I0401 01:06:03.765347 11876 layer_factory.cpp:58] Creating layer bn1_0
I0401 01:06:03.765347 11876 net.cpp:100] Creating Layer bn1_0
I0401 01:06:03.765347 11876 net.cpp:434] bn1_0 <- conv1_0
I0401 01:06:03.765347 11876 net.cpp:408] bn1_0 -> bn1_0
I0401 01:06:03.765347 11876 net.cpp:150] Setting up bn1_0
I0401 01:06:03.765347 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.765347 11876 net.cpp:165] Memory required for data: 39936600
I0401 01:06:03.765347 11876 layer_factory.cpp:58] Creating layer scale1_0
I0401 01:06:03.765347 11876 net.cpp:100] Creating Layer scale1_0
I0401 01:06:03.765347 11876 net.cpp:434] scale1_0 <- bn1_0
I0401 01:06:03.765347 11876 net.cpp:408] scale1_0 -> scale1_0
I0401 01:06:03.765347 11876 layer_factory.cpp:58] Creating layer scale1_0
I0401 01:06:03.765347 11876 net.cpp:150] Setting up scale1_0
I0401 01:06:03.765347 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.765347 11876 net.cpp:165] Memory required for data: 46490200
I0401 01:06:03.765347 11876 layer_factory.cpp:58] Creating layer relu1_0
I0401 01:06:03.765347 11876 net.cpp:100] Creating Layer relu1_0
I0401 01:06:03.765347 11876 net.cpp:434] relu1_0 <- scale1_0
I0401 01:06:03.765347 11876 net.cpp:408] relu1_0 -> relu1_0
I0401 01:06:03.766366 11876 net.cpp:150] Setting up relu1_0
I0401 01:06:03.766366 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.766366 11876 net.cpp:165] Memory required for data: 53043800
I0401 01:06:03.766366 11876 layer_factory.cpp:58] Creating layer conv2
I0401 01:06:03.766366 11876 net.cpp:100] Creating Layer conv2
I0401 01:06:03.766366 11876 net.cpp:434] conv2 <- relu1_0
I0401 01:06:03.766366 11876 net.cpp:408] conv2 -> conv2
I0401 01:06:03.767366 11876 net.cpp:150] Setting up conv2
I0401 01:06:03.767366 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.767366 11876 net.cpp:165] Memory required for data: 59597400
I0401 01:06:03.767366 11876 layer_factory.cpp:58] Creating layer bn2
I0401 01:06:03.767366 11876 net.cpp:100] Creating Layer bn2
I0401 01:06:03.767366 11876 net.cpp:434] bn2 <- conv2
I0401 01:06:03.767366 11876 net.cpp:408] bn2 -> bn2
I0401 01:06:03.768366 11876 net.cpp:150] Setting up bn2
I0401 01:06:03.768366 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.768366 11876 net.cpp:165] Memory required for data: 66151000
I0401 01:06:03.768366 11876 layer_factory.cpp:58] Creating layer scale2
I0401 01:06:03.768366 11876 net.cpp:100] Creating Layer scale2
I0401 01:06:03.768366 11876 net.cpp:434] scale2 <- bn2
I0401 01:06:03.768366 11876 net.cpp:408] scale2 -> scale2
I0401 01:06:03.768366 11876 layer_factory.cpp:58] Creating layer scale2
I0401 01:06:03.768366 11876 net.cpp:150] Setting up scale2
I0401 01:06:03.768366 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.768366 11876 net.cpp:165] Memory required for data: 72704600
I0401 01:06:03.768366 11876 layer_factory.cpp:58] Creating layer relu2
I0401 01:06:03.768366 11876 net.cpp:100] Creating Layer relu2
I0401 01:06:03.768366 11876 net.cpp:434] relu2 <- scale2
I0401 01:06:03.768366 11876 net.cpp:408] relu2 -> relu2
I0401 01:06:03.768366 11876 net.cpp:150] Setting up relu2
I0401 01:06:03.768366 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.768366 11876 net.cpp:165] Memory required for data: 79258200
I0401 01:06:03.768366 11876 layer_factory.cpp:58] Creating layer conv2_1
I0401 01:06:03.768366 11876 net.cpp:100] Creating Layer conv2_1
I0401 01:06:03.768366 11876 net.cpp:434] conv2_1 <- relu2
I0401 01:06:03.768366 11876 net.cpp:408] conv2_1 -> conv2_1
I0401 01:06:03.770362 11876 net.cpp:150] Setting up conv2_1
I0401 01:06:03.770362 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.770362 11876 net.cpp:165] Memory required for data: 85811800
I0401 01:06:03.770362 11876 layer_factory.cpp:58] Creating layer bn2_1
I0401 01:06:03.770362 11876 net.cpp:100] Creating Layer bn2_1
I0401 01:06:03.770362 11876 net.cpp:434] bn2_1 <- conv2_1
I0401 01:06:03.770362 11876 net.cpp:408] bn2_1 -> bn2_1
I0401 01:06:03.770362 11876 net.cpp:150] Setting up bn2_1
I0401 01:06:03.770362 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.770362 11876 net.cpp:165] Memory required for data: 92365400
I0401 01:06:03.770362 11876 layer_factory.cpp:58] Creating layer scale2_1
I0401 01:06:03.770362 11876 net.cpp:100] Creating Layer scale2_1
I0401 01:06:03.770362 11876 net.cpp:434] scale2_1 <- bn2_1
I0401 01:06:03.770362 11876 net.cpp:408] scale2_1 -> scale2_1
I0401 01:06:03.770362 11876 layer_factory.cpp:58] Creating layer scale2_1
I0401 01:06:03.771355 11876 net.cpp:150] Setting up scale2_1
I0401 01:06:03.771355 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.771355 11876 net.cpp:165] Memory required for data: 98919000
I0401 01:06:03.771355 11876 layer_factory.cpp:58] Creating layer relu2_1
I0401 01:06:03.771355 11876 net.cpp:100] Creating Layer relu2_1
I0401 01:06:03.771355 11876 net.cpp:434] relu2_1 <- scale2_1
I0401 01:06:03.771355 11876 net.cpp:408] relu2_1 -> relu2_1
I0401 01:06:03.771355 11876 net.cpp:150] Setting up relu2_1
I0401 01:06:03.772346 11876 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0401 01:06:03.772346 11876 net.cpp:165] Memory required for data: 105472600
I0401 01:06:03.772346 11876 layer_factory.cpp:58] Creating layer pool2_1
I0401 01:06:03.772346 11876 net.cpp:100] Creating Layer pool2_1
I0401 01:06:03.772346 11876 net.cpp:434] pool2_1 <- relu2_1
I0401 01:06:03.772346 11876 net.cpp:408] pool2_1 -> pool2_1
I0401 01:06:03.772346 11876 net.cpp:150] Setting up pool2_1
I0401 01:06:03.772346 11876 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0401 01:06:03.772346 11876 net.cpp:165] Memory required for data: 107111000
I0401 01:06:03.772346 11876 layer_factory.cpp:58] Creating layer conv2_2
I0401 01:06:03.772346 11876 net.cpp:100] Creating Layer conv2_2
I0401 01:06:03.772346 11876 net.cpp:434] conv2_2 <- pool2_1
I0401 01:06:03.772346 11876 net.cpp:408] conv2_2 -> conv2_2
I0401 01:06:03.776881 11876 net.cpp:150] Setting up conv2_2
I0401 01:06:03.776881 11876 net.cpp:157] Top shape: 50 50 16 16 (640000)
I0401 01:06:03.776881 11876 net.cpp:165] Memory required for data: 109671000
I0401 01:06:03.776881 11876 layer_factory.cpp:58] Creating layer bn2_2
I0401 01:06:03.776881 11876 net.cpp:100] Creating Layer bn2_2
I0401 01:06:03.776881 11876 net.cpp:434] bn2_2 <- conv2_2
I0401 01:06:03.776881 11876 net.cpp:408] bn2_2 -> bn2_2
I0401 01:06:03.777365 11876 net.cpp:150] Setting up bn2_2
I0401 01:06:03.777365 11876 net.cpp:157] Top shape: 50 50 16 16 (640000)
I0401 01:06:03.777365 11876 net.cpp:165] Memory required for data: 112231000
I0401 01:06:03.777365 11876 layer_factory.cpp:58] Creating layer scale2_2
I0401 01:06:03.777365 11876 net.cpp:100] Creating Layer scale2_2
I0401 01:06:03.777365 11876 net.cpp:434] scale2_2 <- bn2_2
I0401 01:06:03.777365 11876 net.cpp:408] scale2_2 -> scale2_2
I0401 01:06:03.777365 11876 layer_factory.cpp:58] Creating layer scale2_2
I0401 01:06:03.777365 11876 net.cpp:150] Setting up scale2_2
I0401 01:06:03.777365 11876 net.cpp:157] Top shape: 50 50 16 16 (640000)
I0401 01:06:03.777365 11876 net.cpp:165] Memory required for data: 114791000
I0401 01:06:03.777365 11876 layer_factory.cpp:58] Creating layer relu2_2
I0401 01:06:03.777365 11876 net.cpp:100] Creating Layer relu2_2
I0401 01:06:03.777365 11876 net.cpp:434] relu2_2 <- scale2_2
I0401 01:06:03.777365 11876 net.cpp:408] relu2_2 -> relu2_2
I0401 01:06:03.778369 11876 net.cpp:150] Setting up relu2_2
I0401 01:06:03.778369 11876 net.cpp:157] Top shape: 50 50 16 16 (640000)
I0401 01:06:03.778369 11876 net.cpp:165] Memory required for data: 117351000
I0401 01:06:03.778369 11876 layer_factory.cpp:58] Creating layer conv3
I0401 01:06:03.778369 11876 net.cpp:100] Creating Layer conv3
I0401 01:06:03.778369 11876 net.cpp:434] conv3 <- relu2_2
I0401 01:06:03.778369 11876 net.cpp:408] conv3 -> conv3
I0401 01:06:03.788365 11876 net.cpp:150] Setting up conv3
I0401 01:06:03.788365 11876 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0401 01:06:03.788365 11876 net.cpp:165] Memory required for data: 120627800
I0401 01:06:03.788866 11876 layer_factory.cpp:58] Creating layer bn3
I0401 01:06:03.788866 11876 net.cpp:100] Creating Layer bn3
I0401 01:06:03.788866 11876 net.cpp:434] bn3 <- conv3
I0401 01:06:03.788866 11876 net.cpp:408] bn3 -> bn3
I0401 01:06:03.788866 11876 net.cpp:150] Setting up bn3
I0401 01:06:03.788866 11876 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0401 01:06:03.788866 11876 net.cpp:165] Memory required for data: 123904600
I0401 01:06:03.788866 11876 layer_factory.cpp:58] Creating layer scale3
I0401 01:06:03.788866 11876 net.cpp:100] Creating Layer scale3
I0401 01:06:03.788866 11876 net.cpp:434] scale3 <- bn3
I0401 01:06:03.788866 11876 net.cpp:408] scale3 -> scale3
I0401 01:06:03.788866 11876 layer_factory.cpp:58] Creating layer scale3
I0401 01:06:03.789366 11876 net.cpp:150] Setting up scale3
I0401 01:06:03.789366 11876 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0401 01:06:03.789366 11876 net.cpp:165] Memory required for data: 127181400
I0401 01:06:03.789366 11876 layer_factory.cpp:58] Creating layer relu3
I0401 01:06:03.789366 11876 net.cpp:100] Creating Layer relu3
I0401 01:06:03.789366 11876 net.cpp:434] relu3 <- scale3
I0401 01:06:03.789366 11876 net.cpp:408] relu3 -> relu3
I0401 01:06:03.789865 11876 net.cpp:150] Setting up relu3
I0401 01:06:03.789865 11876 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0401 01:06:03.789865 11876 net.cpp:165] Memory required for data: 130458200
I0401 01:06:03.789865 11876 layer_factory.cpp:58] Creating layer conv4
I0401 01:06:03.789865 11876 net.cpp:100] Creating Layer conv4
I0401 01:06:03.789865 11876 net.cpp:434] conv4 <- relu3
I0401 01:06:03.789865 11876 net.cpp:408] conv4 -> conv4
I0401 01:06:03.791885 11876 net.cpp:150] Setting up conv4
I0401 01:06:03.791885 11876 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0401 01:06:03.791885 11876 net.cpp:165] Memory required for data: 133735000
I0401 01:06:03.791885 11876 layer_factory.cpp:58] Creating layer pool4
I0401 01:06:03.791885 11876 net.cpp:100] Creating Layer pool4
I0401 01:06:03.791885 11876 net.cpp:434] pool4 <- conv4
I0401 01:06:03.791885 11876 net.cpp:408] pool4 -> pool4
I0401 01:06:03.791885 11876 net.cpp:150] Setting up pool4
I0401 01:06:03.791885 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.791885 11876 net.cpp:165] Memory required for data: 134554200
I0401 01:06:03.791885 11876 layer_factory.cpp:58] Creating layer bn4
I0401 01:06:03.791885 11876 net.cpp:100] Creating Layer bn4
I0401 01:06:03.791885 11876 net.cpp:434] bn4 <- pool4
I0401 01:06:03.791885 11876 net.cpp:408] bn4 -> bn4
I0401 01:06:03.792385 11876 net.cpp:150] Setting up bn4
I0401 01:06:03.792385 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.792385 11876 net.cpp:165] Memory required for data: 135373400
I0401 01:06:03.792385 11876 layer_factory.cpp:58] Creating layer scale4
I0401 01:06:03.792385 11876 net.cpp:100] Creating Layer scale4
I0401 01:06:03.792385 11876 net.cpp:434] scale4 <- bn4
I0401 01:06:03.792385 11876 net.cpp:408] scale4 -> scale4
I0401 01:06:03.792385 11876 layer_factory.cpp:58] Creating layer scale4
I0401 01:06:03.792385 11876 net.cpp:150] Setting up scale4
I0401 01:06:03.792385 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.792385 11876 net.cpp:165] Memory required for data: 136192600
I0401 01:06:03.792385 11876 layer_factory.cpp:58] Creating layer relu4
I0401 01:06:03.792385 11876 net.cpp:100] Creating Layer relu4
I0401 01:06:03.792385 11876 net.cpp:434] relu4 <- scale4
I0401 01:06:03.792385 11876 net.cpp:408] relu4 -> relu4
I0401 01:06:03.792385 11876 net.cpp:150] Setting up relu4
I0401 01:06:03.792385 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.792385 11876 net.cpp:165] Memory required for data: 137011800
I0401 01:06:03.792385 11876 layer_factory.cpp:58] Creating layer conv4_1
I0401 01:06:03.792385 11876 net.cpp:100] Creating Layer conv4_1
I0401 01:06:03.792385 11876 net.cpp:434] conv4_1 <- relu4
I0401 01:06:03.792385 11876 net.cpp:408] conv4_1 -> conv4_1
I0401 01:06:03.794391 11876 net.cpp:150] Setting up conv4_1
I0401 01:06:03.794391 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.794391 11876 net.cpp:165] Memory required for data: 137831000
I0401 01:06:03.794391 11876 layer_factory.cpp:58] Creating layer bn4_1
I0401 01:06:03.794391 11876 net.cpp:100] Creating Layer bn4_1
I0401 01:06:03.794391 11876 net.cpp:434] bn4_1 <- conv4_1
I0401 01:06:03.794391 11876 net.cpp:408] bn4_1 -> bn4_1
I0401 01:06:03.795408 11876 net.cpp:150] Setting up bn4_1
I0401 01:06:03.795408 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.795408 11876 net.cpp:165] Memory required for data: 138650200
I0401 01:06:03.795408 11876 layer_factory.cpp:58] Creating layer scale4_1
I0401 01:06:03.795408 11876 net.cpp:100] Creating Layer scale4_1
I0401 01:06:03.795408 11876 net.cpp:434] scale4_1 <- bn4_1
I0401 01:06:03.795408 11876 net.cpp:408] scale4_1 -> scale4_1
I0401 01:06:03.795408 11876 layer_factory.cpp:58] Creating layer scale4_1
I0401 01:06:03.795408 11876 net.cpp:150] Setting up scale4_1
I0401 01:06:03.795408 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.795408 11876 net.cpp:165] Memory required for data: 139469400
I0401 01:06:03.795408 11876 layer_factory.cpp:58] Creating layer relu4_1
I0401 01:06:03.795408 11876 net.cpp:100] Creating Layer relu4_1
I0401 01:06:03.795408 11876 net.cpp:434] relu4_1 <- scale4_1
I0401 01:06:03.795408 11876 net.cpp:408] relu4_1 -> relu4_1
I0401 01:06:03.796407 11876 net.cpp:150] Setting up relu4_1
I0401 01:06:03.796407 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.796407 11876 net.cpp:165] Memory required for data: 140288600
I0401 01:06:03.796407 11876 layer_factory.cpp:58] Creating layer conv4_2
I0401 01:06:03.796407 11876 net.cpp:100] Creating Layer conv4_2
I0401 01:06:03.796407 11876 net.cpp:434] conv4_2 <- relu4_1
I0401 01:06:03.796407 11876 net.cpp:408] conv4_2 -> conv4_2
I0401 01:06:03.798391 11876 net.cpp:150] Setting up conv4_2
I0401 01:06:03.798391 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.798391 11876 net.cpp:165] Memory required for data: 141107800
I0401 01:06:03.798391 11876 layer_factory.cpp:58] Creating layer bn4_2
I0401 01:06:03.798391 11876 net.cpp:100] Creating Layer bn4_2
I0401 01:06:03.798391 11876 net.cpp:434] bn4_2 <- conv4_2
I0401 01:06:03.798391 11876 net.cpp:408] bn4_2 -> bn4_2
I0401 01:06:03.798391 11876 net.cpp:150] Setting up bn4_2
I0401 01:06:03.798391 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.798391 11876 net.cpp:165] Memory required for data: 141927000
I0401 01:06:03.798391 11876 layer_factory.cpp:58] Creating layer scale4_2
I0401 01:06:03.798391 11876 net.cpp:100] Creating Layer scale4_2
I0401 01:06:03.798391 11876 net.cpp:434] scale4_2 <- bn4_2
I0401 01:06:03.798391 11876 net.cpp:408] scale4_2 -> scale4_2
I0401 01:06:03.798391 11876 layer_factory.cpp:58] Creating layer scale4_2
I0401 01:06:03.798391 11876 net.cpp:150] Setting up scale4_2
I0401 01:06:03.798391 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.798391 11876 net.cpp:165] Memory required for data: 142746200
I0401 01:06:03.798391 11876 layer_factory.cpp:58] Creating layer relu4_2
I0401 01:06:03.798391 11876 net.cpp:100] Creating Layer relu4_2
I0401 01:06:03.798391 11876 net.cpp:434] relu4_2 <- scale4_2
I0401 01:06:03.798391 11876 net.cpp:408] relu4_2 -> relu4_2
I0401 01:06:03.798391 11876 net.cpp:150] Setting up relu4_2
I0401 01:06:03.798391 11876 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0401 01:06:03.798391 11876 net.cpp:165] Memory required for data: 143565400
I0401 01:06:03.798391 11876 layer_factory.cpp:58] Creating layer pool4_2
I0401 01:06:03.798391 11876 net.cpp:100] Creating Layer pool4_2
I0401 01:06:03.798391 11876 net.cpp:434] pool4_2 <- relu4_2
I0401 01:06:03.798391 11876 net.cpp:408] pool4_2 -> pool4_2
I0401 01:06:03.799407 11876 net.cpp:150] Setting up pool4_2
I0401 01:06:03.799407 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.799407 11876 net.cpp:165] Memory required for data: 143770200
I0401 01:06:03.799407 11876 layer_factory.cpp:58] Creating layer conv4_0
I0401 01:06:03.799407 11876 net.cpp:100] Creating Layer conv4_0
I0401 01:06:03.799407 11876 net.cpp:434] conv4_0 <- pool4_2
I0401 01:06:03.799407 11876 net.cpp:408] conv4_0 -> conv4_0
I0401 01:06:03.802392 11876 net.cpp:150] Setting up conv4_0
I0401 01:06:03.802392 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.802392 11876 net.cpp:165] Memory required for data: 143975000
I0401 01:06:03.802392 11876 layer_factory.cpp:58] Creating layer bn4_0
I0401 01:06:03.802392 11876 net.cpp:100] Creating Layer bn4_0
I0401 01:06:03.802392 11876 net.cpp:434] bn4_0 <- conv4_0
I0401 01:06:03.802392 11876 net.cpp:408] bn4_0 -> bn4_0
I0401 01:06:03.802392 11876 net.cpp:150] Setting up bn4_0
I0401 01:06:03.802392 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.802392 11876 net.cpp:165] Memory required for data: 144179800
I0401 01:06:03.802392 11876 layer_factory.cpp:58] Creating layer scale4_0
I0401 01:06:03.802392 11876 net.cpp:100] Creating Layer scale4_0
I0401 01:06:03.802392 11876 net.cpp:434] scale4_0 <- bn4_0
I0401 01:06:03.802392 11876 net.cpp:408] scale4_0 -> scale4_0
I0401 01:06:03.802392 11876 layer_factory.cpp:58] Creating layer scale4_0
I0401 01:06:03.802392 11876 net.cpp:150] Setting up scale4_0
I0401 01:06:03.802392 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.802392 11876 net.cpp:165] Memory required for data: 144384600
I0401 01:06:03.802392 11876 layer_factory.cpp:58] Creating layer relu4_0
I0401 01:06:03.802392 11876 net.cpp:100] Creating Layer relu4_0
I0401 01:06:03.802392 11876 net.cpp:434] relu4_0 <- scale4_0
I0401 01:06:03.802392 11876 net.cpp:408] relu4_0 -> relu4_0
I0401 01:06:03.805392 11876 net.cpp:150] Setting up relu4_0
I0401 01:06:03.805392 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.805392 11876 net.cpp:165] Memory required for data: 144589400
I0401 01:06:03.805392 11876 layer_factory.cpp:58] Creating layer cccp4
I0401 01:06:03.805392 11876 net.cpp:100] Creating Layer cccp4
I0401 01:06:03.805392 11876 net.cpp:434] cccp4 <- relu4_0
I0401 01:06:03.805392 11876 net.cpp:408] cccp4 -> cccp4
I0401 01:06:03.809392 11876 net.cpp:150] Setting up cccp4
I0401 01:06:03.810395 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.810395 11876 net.cpp:165] Memory required for data: 144794200
I0401 01:06:03.810395 11876 layer_factory.cpp:58] Creating layer relu_cccp4
I0401 01:06:03.810395 11876 net.cpp:100] Creating Layer relu_cccp4
I0401 01:06:03.810395 11876 net.cpp:434] relu_cccp4 <- cccp4
I0401 01:06:03.810395 11876 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0401 01:06:03.812391 11876 net.cpp:150] Setting up relu_cccp4
I0401 01:06:03.812391 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.812391 11876 net.cpp:165] Memory required for data: 144999000
I0401 01:06:03.812391 11876 layer_factory.cpp:58] Creating layer cccp5
I0401 01:06:03.812391 11876 net.cpp:100] Creating Layer cccp5
I0401 01:06:03.812391 11876 net.cpp:434] cccp5 <- cccp4
I0401 01:06:03.812391 11876 net.cpp:408] cccp5 -> cccp5
I0401 01:06:03.819394 11876 net.cpp:150] Setting up cccp5
I0401 01:06:03.819394 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.819394 11876 net.cpp:165] Memory required for data: 145203800
I0401 01:06:03.819394 11876 layer_factory.cpp:58] Creating layer relu_cccp5
I0401 01:06:03.819394 11876 net.cpp:100] Creating Layer relu_cccp5
I0401 01:06:03.819394 11876 net.cpp:434] relu_cccp5 <- cccp5
I0401 01:06:03.819394 11876 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0401 01:06:03.819394 11876 net.cpp:150] Setting up relu_cccp5
I0401 01:06:03.819394 11876 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0401 01:06:03.819394 11876 net.cpp:165] Memory required for data: 145408600
I0401 01:06:03.819394 11876 layer_factory.cpp:58] Creating layer poolcp5
I0401 01:06:03.819394 11876 net.cpp:100] Creating Layer poolcp5
I0401 01:06:03.819394 11876 net.cpp:434] poolcp5 <- cccp5
I0401 01:06:03.819394 11876 net.cpp:408] poolcp5 -> poolcp5
I0401 01:06:03.819394 11876 net.cpp:150] Setting up poolcp5
I0401 01:06:03.820394 11876 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0401 01:06:03.820394 11876 net.cpp:165] Memory required for data: 145459800
I0401 01:06:03.820394 11876 layer_factory.cpp:58] Creating layer cccp6
I0401 01:06:03.820394 11876 net.cpp:100] Creating Layer cccp6
I0401 01:06:03.820394 11876 net.cpp:434] cccp6 <- poolcp5
I0401 01:06:03.820394 11876 net.cpp:408] cccp6 -> cccp6
I0401 01:06:03.822394 11876 net.cpp:150] Setting up cccp6
I0401 01:06:03.822394 11876 net.cpp:157] Top shape: 50 100 2 2 (20000)
I0401 01:06:03.822394 11876 net.cpp:165] Memory required for data: 145539800
I0401 01:06:03.822394 11876 layer_factory.cpp:58] Creating layer relu_cccp6
I0401 01:06:03.822394 11876 net.cpp:100] Creating Layer relu_cccp6
I0401 01:06:03.822394 11876 net.cpp:434] relu_cccp6 <- cccp6
I0401 01:06:03.822394 11876 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0401 01:06:03.822394 11876 net.cpp:150] Setting up relu_cccp6
I0401 01:06:03.822394 11876 net.cpp:157] Top shape: 50 100 2 2 (20000)
I0401 01:06:03.822394 11876 net.cpp:165] Memory required for data: 145619800
I0401 01:06:03.822394 11876 layer_factory.cpp:58] Creating layer poolcp6
I0401 01:06:03.822394 11876 net.cpp:100] Creating Layer poolcp6
I0401 01:06:03.822394 11876 net.cpp:434] poolcp6 <- cccp6
I0401 01:06:03.822394 11876 net.cpp:408] poolcp6 -> poolcp6
I0401 01:06:03.823395 11876 net.cpp:150] Setting up poolcp6
I0401 01:06:03.823395 11876 net.cpp:157] Top shape: 50 100 1 1 (5000)
I0401 01:06:03.823395 11876 net.cpp:165] Memory required for data: 145639800
I0401 01:06:03.823395 11876 layer_factory.cpp:58] Creating layer ip1
I0401 01:06:03.823395 11876 net.cpp:100] Creating Layer ip1
I0401 01:06:03.823395 11876 net.cpp:434] ip1 <- poolcp6
I0401 01:06:03.823395 11876 net.cpp:408] ip1 -> ip1
I0401 01:06:03.823395 11876 net.cpp:150] Setting up ip1
I0401 01:06:03.823395 11876 net.cpp:157] Top shape: 50 10 (500)
I0401 01:06:03.823395 11876 net.cpp:165] Memory required for data: 145641800
I0401 01:06:03.823395 11876 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0401 01:06:03.823395 11876 net.cpp:100] Creating Layer ip1_ip1_0_split
I0401 01:06:03.823395 11876 net.cpp:434] ip1_ip1_0_split <- ip1
I0401 01:06:03.823395 11876 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0401 01:06:03.823395 11876 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0401 01:06:03.823395 11876 net.cpp:150] Setting up ip1_ip1_0_split
I0401 01:06:03.823395 11876 net.cpp:157] Top shape: 50 10 (500)
I0401 01:06:03.823395 11876 net.cpp:157] Top shape: 50 10 (500)
I0401 01:06:03.823395 11876 net.cpp:165] Memory required for data: 145645800
I0401 01:06:03.823395 11876 layer_factory.cpp:58] Creating layer accuracy
I0401 01:06:03.823395 11876 net.cpp:100] Creating Layer accuracy
I0401 01:06:03.823395 11876 net.cpp:434] accuracy <- ip1_ip1_0_split_0
I0401 01:06:03.823395 11876 net.cpp:434] accuracy <- label_cifar_1_split_0
I0401 01:06:03.823395 11876 net.cpp:408] accuracy -> accuracy
I0401 01:06:03.823395 11876 net.cpp:150] Setting up accuracy
I0401 01:06:03.823395 11876 net.cpp:157] Top shape: (1)
I0401 01:06:03.823395 11876 net.cpp:165] Memory required for data: 145645804
I0401 01:06:03.823395 11876 layer_factory.cpp:58] Creating layer loss
I0401 01:06:03.823395 11876 net.cpp:100] Creating Layer loss
I0401 01:06:03.823395 11876 net.cpp:434] loss <- ip1_ip1_0_split_1
I0401 01:06:03.823395 11876 net.cpp:434] loss <- label_cifar_1_split_1
I0401 01:06:03.823395 11876 net.cpp:408] loss -> loss
I0401 01:06:03.823395 11876 layer_factory.cpp:58] Creating layer loss
I0401 01:06:03.824394 11876 net.cpp:150] Setting up loss
I0401 01:06:03.824394 11876 net.cpp:157] Top shape: (1)
I0401 01:06:03.824394 11876 net.cpp:160]     with loss weight 1
I0401 01:06:03.824394 11876 net.cpp:165] Memory required for data: 145645808
I0401 01:06:03.824394 11876 net.cpp:226] loss needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:228] accuracy does not need backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] ip1 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] poolcp6 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu_cccp6 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] cccp6 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] poolcp5 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu_cccp5 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] cccp5 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu_cccp4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] cccp4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu4_0 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] scale4_0 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] bn4_0 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] conv4_0 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] pool4_2 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu4_2 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] scale4_2 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] bn4_2 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] conv4_2 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu4_1 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] scale4_1 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] bn4_1 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] conv4_1 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] scale4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] bn4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] pool4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] conv4 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] relu3 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] scale3 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] bn3 needs backward computation.
I0401 01:06:03.824394 11876 net.cpp:226] conv3 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] relu2_2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] scale2_2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] bn2_2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] conv2_2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] pool2_1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] relu2_1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] scale2_1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] bn2_1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] conv2_1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] relu2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] scale2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] bn2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] conv2 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] relu1_0 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] scale1_0 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] bn1_0 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] conv1_0 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] relu1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] scale1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] bn1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:226] conv1 needs backward computation.
I0401 01:06:03.825393 11876 net.cpp:228] label_cifar_1_split does not need backward computation.
I0401 01:06:03.825393 11876 net.cpp:228] cifar does not need backward computation.
I0401 01:06:03.825393 11876 net.cpp:270] This network produces output accuracy
I0401 01:06:03.825393 11876 net.cpp:270] This network produces output loss
I0401 01:06:03.825393 11876 net.cpp:283] Network initialization done.
I0401 01:06:03.825393 11876 solver.cpp:60] Solver scaffolding done.
I0401 01:06:03.829391 11876 caffe.cpp:252] Starting Optimization
I0401 01:06:03.829391 11876 solver.cpp:279] Solving CIFAR10_full
I0401 01:06:03.829391 11876 solver.cpp:280] Learning Rate Policy: multistep
I0401 01:06:03.831392 11876 solver.cpp:337] Iteration 0, Testing net (#0)
I0401 01:06:03.834410 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:06:06.501819 11876 solver.cpp:404]     Test net output #0: accuracy = 0.1014
I0401 01:06:06.501819 11876 solver.cpp:404]     Test net output #1: loss = 78.4806 (* 1 = 78.4806 loss)
I0401 01:06:09.319561 11876 solver.cpp:228] Iteration 0, loss = 2.36348
I0401 01:06:09.319561 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.1
I0401 01:06:09.319561 11876 solver.cpp:244]     Train net output #1: loss = 2.36348 (* 1 = 2.36348 loss)
I0401 01:06:09.319561 11876 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I0401 01:06:22.723220 11876 solver.cpp:228] Iteration 100, loss = 1.58653
I0401 01:06:22.723220 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0401 01:06:22.723220 11876 solver.cpp:244]     Train net output #1: loss = 1.58653 (* 1 = 1.58653 loss)
I0401 01:06:22.723220 11876 sgd_solver.cpp:106] Iteration 100, lr = 0.01
I0401 01:06:28.317052 11876 solver.cpp:228] Iteration 200, loss = 1.59065
I0401 01:06:28.317052 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.42
I0401 01:06:28.317052 11876 solver.cpp:244]     Train net output #1: loss = 1.59065 (* 1 = 1.59065 loss)
I0401 01:06:28.317052 11876 sgd_solver.cpp:106] Iteration 200, lr = 0.01
I0401 01:06:33.844509 11876 solver.cpp:228] Iteration 300, loss = 1.24606
I0401 01:06:33.844509 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.58
I0401 01:06:33.844509 11876 solver.cpp:244]     Train net output #1: loss = 1.24606 (* 1 = 1.24606 loss)
I0401 01:06:33.844509 11876 sgd_solver.cpp:106] Iteration 300, lr = 0.01
I0401 01:06:39.432737 11876 solver.cpp:228] Iteration 400, loss = 1.09338
I0401 01:06:39.433737 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.56
I0401 01:06:39.433737 11876 solver.cpp:244]     Train net output #1: loss = 1.09338 (* 1 = 1.09338 loss)
I0401 01:06:39.433737 11876 sgd_solver.cpp:106] Iteration 400, lr = 0.01
I0401 01:06:44.991363 11876 solver.cpp:228] Iteration 500, loss = 1.09605
I0401 01:06:44.991863 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.6
I0401 01:06:44.991863 11876 solver.cpp:244]     Train net output #1: loss = 1.09605 (* 1 = 1.09605 loss)
I0401 01:06:44.991863 11876 sgd_solver.cpp:106] Iteration 500, lr = 0.01
I0401 01:06:50.566810 11876 solver.cpp:228] Iteration 600, loss = 0.982531
I0401 01:06:50.566810 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.65
I0401 01:06:50.566810 11876 solver.cpp:244]     Train net output #1: loss = 0.982531 (* 1 = 0.982531 loss)
I0401 01:06:50.566810 11876 sgd_solver.cpp:106] Iteration 600, lr = 0.01
I0401 01:06:56.132192 11876 solver.cpp:228] Iteration 700, loss = 0.995177
I0401 01:06:56.132192 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.64
I0401 01:06:56.132192 11876 solver.cpp:244]     Train net output #1: loss = 0.995177 (* 1 = 0.995177 loss)
I0401 01:06:56.132192 11876 sgd_solver.cpp:106] Iteration 700, lr = 0.01
I0401 01:07:01.711005 11876 solver.cpp:228] Iteration 800, loss = 0.984588
I0401 01:07:01.711005 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.68
I0401 01:07:01.711005 11876 solver.cpp:244]     Train net output #1: loss = 0.984588 (* 1 = 0.984588 loss)
I0401 01:07:01.711005 11876 sgd_solver.cpp:106] Iteration 800, lr = 0.01
I0401 01:07:07.272761 11876 solver.cpp:228] Iteration 900, loss = 0.923322
I0401 01:07:07.272761 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.66
I0401 01:07:07.272761 11876 solver.cpp:244]     Train net output #1: loss = 0.923322 (* 1 = 0.923322 loss)
I0401 01:07:07.272761 11876 sgd_solver.cpp:106] Iteration 900, lr = 0.01
I0401 01:07:12.854693 11876 solver.cpp:337] Iteration 1000, Testing net (#0)
I0401 01:07:12.854693 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:07:14.494910 11876 solver.cpp:404]     Test net output #0: accuracy = 0.6756
I0401 01:07:14.494910 11876 solver.cpp:404]     Test net output #1: loss = 0.940368 (* 1 = 0.940368 loss)
I0401 01:07:14.517923 11876 solver.cpp:228] Iteration 1000, loss = 0.89967
I0401 01:07:14.517923 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.68
I0401 01:07:14.517923 11876 solver.cpp:244]     Train net output #1: loss = 0.89967 (* 1 = 0.89967 loss)
I0401 01:07:14.517923 11876 sgd_solver.cpp:106] Iteration 1000, lr = 0.01
I0401 01:07:20.069931 11876 solver.cpp:228] Iteration 1100, loss = 0.734424
I0401 01:07:20.069931 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.74
I0401 01:07:20.069931 11876 solver.cpp:244]     Train net output #1: loss = 0.734424 (* 1 = 0.734424 loss)
I0401 01:07:20.069931 11876 sgd_solver.cpp:106] Iteration 1100, lr = 0.01
I0401 01:07:25.623946 11876 solver.cpp:228] Iteration 1200, loss = 0.839975
I0401 01:07:25.624446 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.7
I0401 01:07:25.624446 11876 solver.cpp:244]     Train net output #1: loss = 0.839975 (* 1 = 0.839975 loss)
I0401 01:07:25.624446 11876 sgd_solver.cpp:106] Iteration 1200, lr = 0.01
I0401 01:07:31.133780 11876 solver.cpp:228] Iteration 1300, loss = 0.728598
I0401 01:07:31.134280 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0401 01:07:31.134280 11876 solver.cpp:244]     Train net output #1: loss = 0.728598 (* 1 = 0.728598 loss)
I0401 01:07:31.134280 11876 sgd_solver.cpp:106] Iteration 1300, lr = 0.01
I0401 01:07:36.819490 11876 solver.cpp:228] Iteration 1400, loss = 0.691755
I0401 01:07:36.819490 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.72
I0401 01:07:36.819490 11876 solver.cpp:244]     Train net output #1: loss = 0.691755 (* 1 = 0.691755 loss)
I0401 01:07:36.819490 11876 sgd_solver.cpp:106] Iteration 1400, lr = 0.01
I0401 01:07:42.378994 11876 solver.cpp:228] Iteration 1500, loss = 0.716621
I0401 01:07:42.378994 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.74
I0401 01:07:42.378994 11876 solver.cpp:244]     Train net output #1: loss = 0.716621 (* 1 = 0.716621 loss)
I0401 01:07:42.378994 11876 sgd_solver.cpp:106] Iteration 1500, lr = 0.01
I0401 01:07:47.924944 11876 solver.cpp:228] Iteration 1600, loss = 0.598276
I0401 01:07:47.924944 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:07:47.924944 11876 solver.cpp:244]     Train net output #1: loss = 0.598276 (* 1 = 0.598276 loss)
I0401 01:07:47.924944 11876 sgd_solver.cpp:106] Iteration 1600, lr = 0.01
I0401 01:07:53.483332 11876 solver.cpp:228] Iteration 1700, loss = 0.777101
I0401 01:07:53.483332 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.72
I0401 01:07:53.483332 11876 solver.cpp:244]     Train net output #1: loss = 0.777101 (* 1 = 0.777101 loss)
I0401 01:07:53.483332 11876 sgd_solver.cpp:106] Iteration 1700, lr = 0.01
I0401 01:07:59.051743 11876 solver.cpp:228] Iteration 1800, loss = 0.634712
I0401 01:07:59.051743 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:07:59.051743 11876 solver.cpp:244]     Train net output #1: loss = 0.634712 (* 1 = 0.634712 loss)
I0401 01:07:59.051743 11876 sgd_solver.cpp:106] Iteration 1800, lr = 0.01
I0401 01:08:04.613332 11876 solver.cpp:228] Iteration 1900, loss = 0.617943
I0401 01:08:04.613332 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0401 01:08:04.613332 11876 solver.cpp:244]     Train net output #1: loss = 0.617943 (* 1 = 0.617943 loss)
I0401 01:08:04.613332 11876 sgd_solver.cpp:106] Iteration 1900, lr = 0.01
I0401 01:08:10.144287 11876 solver.cpp:337] Iteration 2000, Testing net (#0)
I0401 01:08:10.144287 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:08:11.769938 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0401 01:08:11.770951 11876 solver.cpp:404]     Test net output #1: loss = 0.756892 (* 1 = 0.756892 loss)
I0401 01:08:11.793934 11876 solver.cpp:228] Iteration 2000, loss = 0.607302
I0401 01:08:11.793934 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:08:11.793934 11876 solver.cpp:244]     Train net output #1: loss = 0.607302 (* 1 = 0.607302 loss)
I0401 01:08:11.793934 11876 sgd_solver.cpp:106] Iteration 2000, lr = 0.01
I0401 01:08:17.340080 11876 solver.cpp:228] Iteration 2100, loss = 0.482999
I0401 01:08:17.340080 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:08:17.340080 11876 solver.cpp:244]     Train net output #1: loss = 0.482999 (* 1 = 0.482999 loss)
I0401 01:08:17.340080 11876 sgd_solver.cpp:106] Iteration 2100, lr = 0.01
I0401 01:08:22.885828 11876 solver.cpp:228] Iteration 2200, loss = 0.753533
I0401 01:08:22.885828 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.71
I0401 01:08:22.885828 11876 solver.cpp:244]     Train net output #1: loss = 0.753533 (* 1 = 0.753533 loss)
I0401 01:08:22.885828 11876 sgd_solver.cpp:106] Iteration 2200, lr = 0.01
I0401 01:08:28.404275 11876 solver.cpp:228] Iteration 2300, loss = 0.670945
I0401 01:08:28.404775 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.73
I0401 01:08:28.404775 11876 solver.cpp:244]     Train net output #1: loss = 0.670945 (* 1 = 0.670945 loss)
I0401 01:08:28.404775 11876 sgd_solver.cpp:106] Iteration 2300, lr = 0.01
I0401 01:08:33.993453 11876 solver.cpp:228] Iteration 2400, loss = 0.572922
I0401 01:08:33.993453 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:08:33.993453 11876 solver.cpp:244]     Train net output #1: loss = 0.572922 (* 1 = 0.572922 loss)
I0401 01:08:33.993453 11876 sgd_solver.cpp:106] Iteration 2400, lr = 0.01
I0401 01:08:39.657001 11876 solver.cpp:228] Iteration 2500, loss = 0.601443
I0401 01:08:39.657001 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:08:39.657001 11876 solver.cpp:244]     Train net output #1: loss = 0.601443 (* 1 = 0.601443 loss)
I0401 01:08:39.657001 11876 sgd_solver.cpp:106] Iteration 2500, lr = 0.01
I0401 01:08:45.252216 11876 solver.cpp:228] Iteration 2600, loss = 0.452256
I0401 01:08:45.252216 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:08:45.252216 11876 solver.cpp:244]     Train net output #1: loss = 0.452256 (* 1 = 0.452256 loss)
I0401 01:08:45.252216 11876 sgd_solver.cpp:106] Iteration 2600, lr = 0.01
I0401 01:08:50.834931 11876 solver.cpp:228] Iteration 2700, loss = 0.713845
I0401 01:08:50.834931 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0401 01:08:50.834931 11876 solver.cpp:244]     Train net output #1: loss = 0.713845 (* 1 = 0.713845 loss)
I0401 01:08:50.834931 11876 sgd_solver.cpp:106] Iteration 2700, lr = 0.01
I0401 01:08:56.411514 11876 solver.cpp:228] Iteration 2800, loss = 0.637637
I0401 01:08:56.411514 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:08:56.411514 11876 solver.cpp:244]     Train net output #1: loss = 0.637637 (* 1 = 0.637637 loss)
I0401 01:08:56.411514 11876 sgd_solver.cpp:106] Iteration 2800, lr = 0.01
I0401 01:09:01.976387 11876 solver.cpp:228] Iteration 2900, loss = 0.625196
I0401 01:09:01.976387 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:09:01.976387 11876 solver.cpp:244]     Train net output #1: loss = 0.625196 (* 1 = 0.625196 loss)
I0401 01:09:01.976387 11876 sgd_solver.cpp:106] Iteration 2900, lr = 0.01
I0401 01:09:07.503707 11876 solver.cpp:337] Iteration 3000, Testing net (#0)
I0401 01:09:07.503707 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:09:09.132297 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7479
I0401 01:09:09.132297 11876 solver.cpp:404]     Test net output #1: loss = 0.718623 (* 1 = 0.718623 loss)
I0401 01:09:09.154295 11876 solver.cpp:228] Iteration 3000, loss = 0.579727
I0401 01:09:09.154295 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:09:09.154295 11876 solver.cpp:244]     Train net output #1: loss = 0.579727 (* 1 = 0.579727 loss)
I0401 01:09:09.154295 11876 sgd_solver.cpp:106] Iteration 3000, lr = 0.01
I0401 01:09:14.770985 11876 solver.cpp:228] Iteration 3100, loss = 0.523649
I0401 01:09:14.770985 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:09:14.770985 11876 solver.cpp:244]     Train net output #1: loss = 0.523649 (* 1 = 0.523649 loss)
I0401 01:09:14.770985 11876 sgd_solver.cpp:106] Iteration 3100, lr = 0.01
I0401 01:09:20.332170 11876 solver.cpp:228] Iteration 3200, loss = 0.630844
I0401 01:09:20.332170 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:09:20.332170 11876 solver.cpp:244]     Train net output #1: loss = 0.630844 (* 1 = 0.630844 loss)
I0401 01:09:20.332170 11876 sgd_solver.cpp:106] Iteration 3200, lr = 0.01
I0401 01:09:25.894268 11876 solver.cpp:228] Iteration 3300, loss = 0.578075
I0401 01:09:25.894268 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:09:25.894268 11876 solver.cpp:244]     Train net output #1: loss = 0.578075 (* 1 = 0.578075 loss)
I0401 01:09:25.894268 11876 sgd_solver.cpp:106] Iteration 3300, lr = 0.01
I0401 01:09:31.482007 11876 solver.cpp:228] Iteration 3400, loss = 0.55483
I0401 01:09:31.482007 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:09:31.482007 11876 solver.cpp:244]     Train net output #1: loss = 0.55483 (* 1 = 0.55483 loss)
I0401 01:09:31.482007 11876 sgd_solver.cpp:106] Iteration 3400, lr = 0.01
I0401 01:09:37.060037 11876 solver.cpp:228] Iteration 3500, loss = 0.574659
I0401 01:09:37.060037 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:09:37.060037 11876 solver.cpp:244]     Train net output #1: loss = 0.574659 (* 1 = 0.574659 loss)
I0401 01:09:37.060037 11876 sgd_solver.cpp:106] Iteration 3500, lr = 0.01
I0401 01:09:42.683030 11876 solver.cpp:228] Iteration 3600, loss = 0.496977
I0401 01:09:42.683030 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:09:42.683030 11876 solver.cpp:244]     Train net output #1: loss = 0.496977 (* 1 = 0.496977 loss)
I0401 01:09:42.683030 11876 sgd_solver.cpp:106] Iteration 3600, lr = 0.01
I0401 01:09:48.306474 11876 solver.cpp:228] Iteration 3700, loss = 0.554389
I0401 01:09:48.306474 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:09:48.306474 11876 solver.cpp:244]     Train net output #1: loss = 0.554389 (* 1 = 0.554389 loss)
I0401 01:09:48.306474 11876 sgd_solver.cpp:106] Iteration 3700, lr = 0.01
I0401 01:09:53.892300 11876 solver.cpp:228] Iteration 3800, loss = 0.556954
I0401 01:09:53.892300 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:09:53.892300 11876 solver.cpp:244]     Train net output #1: loss = 0.556954 (* 1 = 0.556954 loss)
I0401 01:09:53.892300 11876 sgd_solver.cpp:106] Iteration 3800, lr = 0.01
I0401 01:09:59.494267 11876 solver.cpp:228] Iteration 3900, loss = 0.568703
I0401 01:09:59.494767 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:09:59.494767 11876 solver.cpp:244]     Train net output #1: loss = 0.568703 (* 1 = 0.568703 loss)
I0401 01:09:59.494767 11876 sgd_solver.cpp:106] Iteration 3900, lr = 0.01
I0401 01:10:05.121932 11876 solver.cpp:337] Iteration 4000, Testing net (#0)
I0401 01:10:05.121932 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:10:06.754417 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7042
I0401 01:10:06.754417 11876 solver.cpp:404]     Test net output #1: loss = 0.909513 (* 1 = 0.909513 loss)
I0401 01:10:06.775416 11876 solver.cpp:228] Iteration 4000, loss = 0.59984
I0401 01:10:06.775416 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:10:06.775416 11876 solver.cpp:244]     Train net output #1: loss = 0.59984 (* 1 = 0.59984 loss)
I0401 01:10:06.775416 11876 sgd_solver.cpp:106] Iteration 4000, lr = 0.01
I0401 01:10:12.342458 11876 solver.cpp:228] Iteration 4100, loss = 0.427201
I0401 01:10:12.342458 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:10:12.342458 11876 solver.cpp:244]     Train net output #1: loss = 0.427201 (* 1 = 0.427201 loss)
I0401 01:10:12.342458 11876 sgd_solver.cpp:106] Iteration 4100, lr = 0.01
I0401 01:10:17.913038 11876 solver.cpp:228] Iteration 4200, loss = 0.499293
I0401 01:10:17.913038 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:10:17.913038 11876 solver.cpp:244]     Train net output #1: loss = 0.499293 (* 1 = 0.499293 loss)
I0401 01:10:17.913038 11876 sgd_solver.cpp:106] Iteration 4200, lr = 0.01
I0401 01:10:23.471470 11876 solver.cpp:228] Iteration 4300, loss = 0.681182
I0401 01:10:23.471969 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.73
I0401 01:10:23.471969 11876 solver.cpp:244]     Train net output #1: loss = 0.681181 (* 1 = 0.681181 loss)
I0401 01:10:23.471969 11876 sgd_solver.cpp:106] Iteration 4300, lr = 0.01
I0401 01:10:29.024425 11876 solver.cpp:228] Iteration 4400, loss = 0.431485
I0401 01:10:29.024425 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:10:29.024425 11876 solver.cpp:244]     Train net output #1: loss = 0.431485 (* 1 = 0.431485 loss)
I0401 01:10:29.024425 11876 sgd_solver.cpp:106] Iteration 4400, lr = 0.01
I0401 01:10:34.570174 11876 solver.cpp:228] Iteration 4500, loss = 0.602798
I0401 01:10:34.570174 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0401 01:10:34.570174 11876 solver.cpp:244]     Train net output #1: loss = 0.602798 (* 1 = 0.602798 loss)
I0401 01:10:34.570174 11876 sgd_solver.cpp:106] Iteration 4500, lr = 0.01
I0401 01:10:40.108568 11876 solver.cpp:228] Iteration 4600, loss = 0.547181
I0401 01:10:40.108568 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:10:40.108568 11876 solver.cpp:244]     Train net output #1: loss = 0.547181 (* 1 = 0.547181 loss)
I0401 01:10:40.108568 11876 sgd_solver.cpp:106] Iteration 4600, lr = 0.01
I0401 01:10:45.666818 11876 solver.cpp:228] Iteration 4700, loss = 0.547918
I0401 01:10:45.666818 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:10:45.666818 11876 solver.cpp:244]     Train net output #1: loss = 0.547918 (* 1 = 0.547918 loss)
I0401 01:10:45.666818 11876 sgd_solver.cpp:106] Iteration 4700, lr = 0.01
I0401 01:10:51.223413 11876 solver.cpp:228] Iteration 4800, loss = 0.591933
I0401 01:10:51.223413 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:10:51.223413 11876 solver.cpp:244]     Train net output #1: loss = 0.591933 (* 1 = 0.591933 loss)
I0401 01:10:51.223413 11876 sgd_solver.cpp:106] Iteration 4800, lr = 0.01
I0401 01:10:56.782009 11876 solver.cpp:228] Iteration 4900, loss = 0.550368
I0401 01:10:56.782009 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:10:56.782009 11876 solver.cpp:244]     Train net output #1: loss = 0.550368 (* 1 = 0.550368 loss)
I0401 01:10:56.782009 11876 sgd_solver.cpp:106] Iteration 4900, lr = 0.01
I0401 01:11:02.314491 11876 solver.cpp:337] Iteration 5000, Testing net (#0)
I0401 01:11:02.314491 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:11:03.935889 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7299
I0401 01:11:03.935889 11876 solver.cpp:404]     Test net output #1: loss = 0.814371 (* 1 = 0.814371 loss)
I0401 01:11:03.955895 11876 solver.cpp:228] Iteration 5000, loss = 0.462611
I0401 01:11:03.956895 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:11:03.956895 11876 solver.cpp:244]     Train net output #1: loss = 0.462611 (* 1 = 0.462611 loss)
I0401 01:11:03.956895 11876 sgd_solver.cpp:106] Iteration 5000, lr = 0.01
I0401 01:11:09.504130 11876 solver.cpp:228] Iteration 5100, loss = 0.408381
I0401 01:11:09.504130 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:11:09.504130 11876 solver.cpp:244]     Train net output #1: loss = 0.408381 (* 1 = 0.408381 loss)
I0401 01:11:09.504130 11876 sgd_solver.cpp:106] Iteration 5100, lr = 0.01
I0401 01:11:15.059406 11876 solver.cpp:228] Iteration 5200, loss = 0.524149
I0401 01:11:15.059907 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:11:15.059907 11876 solver.cpp:244]     Train net output #1: loss = 0.524149 (* 1 = 0.524149 loss)
I0401 01:11:15.059907 11876 sgd_solver.cpp:106] Iteration 5200, lr = 0.01
I0401 01:11:20.607924 11876 solver.cpp:228] Iteration 5300, loss = 0.525642
I0401 01:11:20.608924 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:11:20.608924 11876 solver.cpp:244]     Train net output #1: loss = 0.525642 (* 1 = 0.525642 loss)
I0401 01:11:20.608924 11876 sgd_solver.cpp:106] Iteration 5300, lr = 0.01
I0401 01:11:26.168210 11876 solver.cpp:228] Iteration 5400, loss = 0.589177
I0401 01:11:26.168210 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:11:26.168210 11876 solver.cpp:244]     Train net output #1: loss = 0.589177 (* 1 = 0.589177 loss)
I0401 01:11:26.168210 11876 sgd_solver.cpp:106] Iteration 5400, lr = 0.01
I0401 01:11:31.754683 11876 solver.cpp:228] Iteration 5500, loss = 0.423642
I0401 01:11:31.754683 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:11:31.754683 11876 solver.cpp:244]     Train net output #1: loss = 0.423642 (* 1 = 0.423642 loss)
I0401 01:11:31.754683 11876 sgd_solver.cpp:106] Iteration 5500, lr = 0.01
I0401 01:11:37.332485 11876 solver.cpp:228] Iteration 5600, loss = 0.422619
I0401 01:11:37.332485 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:11:37.332485 11876 solver.cpp:244]     Train net output #1: loss = 0.422619 (* 1 = 0.422619 loss)
I0401 01:11:37.332485 11876 sgd_solver.cpp:106] Iteration 5600, lr = 0.01
I0401 01:11:42.907003 11876 solver.cpp:228] Iteration 5700, loss = 0.548487
I0401 01:11:42.907003 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:11:42.907003 11876 solver.cpp:244]     Train net output #1: loss = 0.548487 (* 1 = 0.548487 loss)
I0401 01:11:42.907003 11876 sgd_solver.cpp:106] Iteration 5700, lr = 0.01
I0401 01:11:48.454279 11876 solver.cpp:228] Iteration 5800, loss = 0.483638
I0401 01:11:48.454279 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:11:48.454279 11876 solver.cpp:244]     Train net output #1: loss = 0.483638 (* 1 = 0.483638 loss)
I0401 01:11:48.454279 11876 sgd_solver.cpp:106] Iteration 5800, lr = 0.01
I0401 01:11:54.009685 11876 solver.cpp:228] Iteration 5900, loss = 0.475029
I0401 01:11:54.009685 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:11:54.009685 11876 solver.cpp:244]     Train net output #1: loss = 0.475028 (* 1 = 0.475028 loss)
I0401 01:11:54.009685 11876 sgd_solver.cpp:106] Iteration 5900, lr = 0.01
I0401 01:11:59.536865 11876 solver.cpp:337] Iteration 6000, Testing net (#0)
I0401 01:11:59.536865 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:12:01.158536 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7958
I0401 01:12:01.158536 11876 solver.cpp:404]     Test net output #1: loss = 0.604645 (* 1 = 0.604645 loss)
I0401 01:12:01.180032 11876 solver.cpp:228] Iteration 6000, loss = 0.512393
I0401 01:12:01.180032 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:12:01.180032 11876 solver.cpp:244]     Train net output #1: loss = 0.512393 (* 1 = 0.512393 loss)
I0401 01:12:01.180032 11876 sgd_solver.cpp:106] Iteration 6000, lr = 0.01
I0401 01:12:06.731493 11876 solver.cpp:228] Iteration 6100, loss = 0.448605
I0401 01:12:06.731493 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:12:06.731493 11876 solver.cpp:244]     Train net output #1: loss = 0.448605 (* 1 = 0.448605 loss)
I0401 01:12:06.731493 11876 sgd_solver.cpp:106] Iteration 6100, lr = 0.01
I0401 01:12:12.291450 11876 solver.cpp:228] Iteration 6200, loss = 0.599367
I0401 01:12:12.291450 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:12:12.291450 11876 solver.cpp:244]     Train net output #1: loss = 0.599367 (* 1 = 0.599367 loss)
I0401 01:12:12.291450 11876 sgd_solver.cpp:106] Iteration 6200, lr = 0.01
I0401 01:12:17.867149 11876 solver.cpp:228] Iteration 6300, loss = 0.430801
I0401 01:12:17.867149 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:12:17.867149 11876 solver.cpp:244]     Train net output #1: loss = 0.430801 (* 1 = 0.430801 loss)
I0401 01:12:17.867149 11876 sgd_solver.cpp:106] Iteration 6300, lr = 0.01
I0401 01:12:23.395262 11876 solver.cpp:228] Iteration 6400, loss = 0.439168
I0401 01:12:23.395262 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:12:23.395262 11876 solver.cpp:244]     Train net output #1: loss = 0.439168 (* 1 = 0.439168 loss)
I0401 01:12:23.395262 11876 sgd_solver.cpp:106] Iteration 6400, lr = 0.01
I0401 01:12:28.967932 11876 solver.cpp:228] Iteration 6500, loss = 0.664
I0401 01:12:28.967932 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.77
I0401 01:12:28.967932 11876 solver.cpp:244]     Train net output #1: loss = 0.664 (* 1 = 0.664 loss)
I0401 01:12:28.967932 11876 sgd_solver.cpp:106] Iteration 6500, lr = 0.01
I0401 01:12:34.538266 11876 solver.cpp:228] Iteration 6600, loss = 0.470844
I0401 01:12:34.538266 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:12:34.539266 11876 solver.cpp:244]     Train net output #1: loss = 0.470844 (* 1 = 0.470844 loss)
I0401 01:12:34.539266 11876 sgd_solver.cpp:106] Iteration 6600, lr = 0.01
I0401 01:12:40.113881 11876 solver.cpp:228] Iteration 6700, loss = 0.491294
I0401 01:12:40.113881 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:12:40.113881 11876 solver.cpp:244]     Train net output #1: loss = 0.491294 (* 1 = 0.491294 loss)
I0401 01:12:40.113881 11876 sgd_solver.cpp:106] Iteration 6700, lr = 0.01
I0401 01:12:45.682234 11876 solver.cpp:228] Iteration 6800, loss = 0.439514
I0401 01:12:45.682234 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:12:45.682234 11876 solver.cpp:244]     Train net output #1: loss = 0.439514 (* 1 = 0.439514 loss)
I0401 01:12:45.682234 11876 sgd_solver.cpp:106] Iteration 6800, lr = 0.01
I0401 01:12:51.233714 11876 solver.cpp:228] Iteration 6900, loss = 0.424912
I0401 01:12:51.233714 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:12:51.233714 11876 solver.cpp:244]     Train net output #1: loss = 0.424911 (* 1 = 0.424911 loss)
I0401 01:12:51.233714 11876 sgd_solver.cpp:106] Iteration 6900, lr = 0.01
I0401 01:12:56.827816 11876 solver.cpp:337] Iteration 7000, Testing net (#0)
I0401 01:12:56.828316 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:12:58.449337 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7379
I0401 01:12:58.449337 11876 solver.cpp:404]     Test net output #1: loss = 0.780175 (* 1 = 0.780175 loss)
I0401 01:12:58.470844 11876 solver.cpp:228] Iteration 7000, loss = 0.552705
I0401 01:12:58.470844 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:12:58.470844 11876 solver.cpp:244]     Train net output #1: loss = 0.552705 (* 1 = 0.552705 loss)
I0401 01:12:58.470844 11876 sgd_solver.cpp:106] Iteration 7000, lr = 0.01
I0401 01:13:04.007345 11876 solver.cpp:228] Iteration 7100, loss = 0.403844
I0401 01:13:04.007345 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:13:04.007345 11876 solver.cpp:244]     Train net output #1: loss = 0.403844 (* 1 = 0.403844 loss)
I0401 01:13:04.007345 11876 sgd_solver.cpp:106] Iteration 7100, lr = 0.01
I0401 01:13:09.594087 11876 solver.cpp:228] Iteration 7200, loss = 0.482959
I0401 01:13:09.594087 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:13:09.594087 11876 solver.cpp:244]     Train net output #1: loss = 0.482959 (* 1 = 0.482959 loss)
I0401 01:13:09.594087 11876 sgd_solver.cpp:106] Iteration 7200, lr = 0.01
I0401 01:13:15.219074 11876 solver.cpp:228] Iteration 7300, loss = 0.525019
I0401 01:13:15.219074 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:13:15.219074 11876 solver.cpp:244]     Train net output #1: loss = 0.525019 (* 1 = 0.525019 loss)
I0401 01:13:15.219074 11876 sgd_solver.cpp:106] Iteration 7300, lr = 0.01
I0401 01:13:20.804622 11876 solver.cpp:228] Iteration 7400, loss = 0.516904
I0401 01:13:20.804622 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:13:20.804622 11876 solver.cpp:244]     Train net output #1: loss = 0.516904 (* 1 = 0.516904 loss)
I0401 01:13:20.804622 11876 sgd_solver.cpp:106] Iteration 7400, lr = 0.01
I0401 01:13:26.427109 11876 solver.cpp:228] Iteration 7500, loss = 0.575643
I0401 01:13:26.427109 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:13:26.427109 11876 solver.cpp:244]     Train net output #1: loss = 0.575643 (* 1 = 0.575643 loss)
I0401 01:13:26.427109 11876 sgd_solver.cpp:106] Iteration 7500, lr = 0.01
I0401 01:13:32.035962 11876 solver.cpp:228] Iteration 7600, loss = 0.46502
I0401 01:13:32.035962 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:13:32.035962 11876 solver.cpp:244]     Train net output #1: loss = 0.46502 (* 1 = 0.46502 loss)
I0401 01:13:32.035962 11876 sgd_solver.cpp:106] Iteration 7600, lr = 0.01
I0401 01:13:37.584002 11876 solver.cpp:228] Iteration 7700, loss = 0.539981
I0401 01:13:37.584002 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:13:37.584002 11876 solver.cpp:244]     Train net output #1: loss = 0.539981 (* 1 = 0.539981 loss)
I0401 01:13:37.584002 11876 sgd_solver.cpp:106] Iteration 7700, lr = 0.01
I0401 01:13:43.148187 11876 solver.cpp:228] Iteration 7800, loss = 0.427038
I0401 01:13:43.148187 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:13:43.148187 11876 solver.cpp:244]     Train net output #1: loss = 0.427038 (* 1 = 0.427038 loss)
I0401 01:13:43.148187 11876 sgd_solver.cpp:106] Iteration 7800, lr = 0.01
I0401 01:13:48.739305 11876 solver.cpp:228] Iteration 7900, loss = 0.449805
I0401 01:13:48.739305 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:13:48.739305 11876 solver.cpp:244]     Train net output #1: loss = 0.449805 (* 1 = 0.449805 loss)
I0401 01:13:48.739305 11876 sgd_solver.cpp:106] Iteration 7900, lr = 0.01
I0401 01:13:54.312896 11876 solver.cpp:337] Iteration 8000, Testing net (#0)
I0401 01:13:54.312896 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:13:55.936050 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7884
I0401 01:13:55.936050 11876 solver.cpp:404]     Test net output #1: loss = 0.620421 (* 1 = 0.620421 loss)
I0401 01:13:55.958056 11876 solver.cpp:228] Iteration 8000, loss = 0.5422
I0401 01:13:55.958056 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:13:55.958056 11876 solver.cpp:244]     Train net output #1: loss = 0.5422 (* 1 = 0.5422 loss)
I0401 01:13:55.958056 11876 sgd_solver.cpp:106] Iteration 8000, lr = 0.01
I0401 01:14:01.567322 11876 solver.cpp:228] Iteration 8100, loss = 0.515928
I0401 01:14:01.567831 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:14:01.567831 11876 solver.cpp:244]     Train net output #1: loss = 0.515928 (* 1 = 0.515928 loss)
I0401 01:14:01.567831 11876 sgd_solver.cpp:106] Iteration 8100, lr = 0.01
I0401 01:14:07.134099 11876 solver.cpp:228] Iteration 8200, loss = 0.544893
I0401 01:14:07.134099 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:14:07.134099 11876 solver.cpp:244]     Train net output #1: loss = 0.544893 (* 1 = 0.544893 loss)
I0401 01:14:07.134099 11876 sgd_solver.cpp:106] Iteration 8200, lr = 0.01
I0401 01:14:12.701738 11876 solver.cpp:228] Iteration 8300, loss = 0.492301
I0401 01:14:12.701738 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:14:12.701738 11876 solver.cpp:244]     Train net output #1: loss = 0.492301 (* 1 = 0.492301 loss)
I0401 01:14:12.701738 11876 sgd_solver.cpp:106] Iteration 8300, lr = 0.01
I0401 01:14:18.267395 11876 solver.cpp:228] Iteration 8400, loss = 0.345792
I0401 01:14:18.267395 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:14:18.267395 11876 solver.cpp:244]     Train net output #1: loss = 0.345792 (* 1 = 0.345792 loss)
I0401 01:14:18.267395 11876 sgd_solver.cpp:106] Iteration 8400, lr = 0.01
I0401 01:14:23.823601 11876 solver.cpp:228] Iteration 8500, loss = 0.481406
I0401 01:14:23.823601 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:14:23.823601 11876 solver.cpp:244]     Train net output #1: loss = 0.481406 (* 1 = 0.481406 loss)
I0401 01:14:23.823601 11876 sgd_solver.cpp:106] Iteration 8500, lr = 0.01
I0401 01:14:29.382460 11876 solver.cpp:228] Iteration 8600, loss = 0.4067
I0401 01:14:29.382961 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:14:29.382961 11876 solver.cpp:244]     Train net output #1: loss = 0.4067 (* 1 = 0.4067 loss)
I0401 01:14:29.382961 11876 sgd_solver.cpp:106] Iteration 8600, lr = 0.01
I0401 01:14:34.934603 11876 solver.cpp:228] Iteration 8700, loss = 0.565971
I0401 01:14:34.934603 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:14:34.934603 11876 solver.cpp:244]     Train net output #1: loss = 0.565971 (* 1 = 0.565971 loss)
I0401 01:14:34.934603 11876 sgd_solver.cpp:106] Iteration 8700, lr = 0.01
I0401 01:14:40.493597 11876 solver.cpp:228] Iteration 8800, loss = 0.48705
I0401 01:14:40.493597 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:14:40.493597 11876 solver.cpp:244]     Train net output #1: loss = 0.48705 (* 1 = 0.48705 loss)
I0401 01:14:40.494097 11876 sgd_solver.cpp:106] Iteration 8800, lr = 0.01
I0401 01:14:46.037417 11876 solver.cpp:228] Iteration 8900, loss = 0.534251
I0401 01:14:46.037417 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:14:46.037919 11876 solver.cpp:244]     Train net output #1: loss = 0.534251 (* 1 = 0.534251 loss)
I0401 01:14:46.037919 11876 sgd_solver.cpp:106] Iteration 8900, lr = 0.01
I0401 01:14:51.576225 11876 solver.cpp:337] Iteration 9000, Testing net (#0)
I0401 01:14:51.576725 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:14:53.194500 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7721
I0401 01:14:53.194500 11876 solver.cpp:404]     Test net output #1: loss = 0.669782 (* 1 = 0.669782 loss)
I0401 01:14:53.215503 11876 solver.cpp:228] Iteration 9000, loss = 0.499777
I0401 01:14:53.215503 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:14:53.215503 11876 solver.cpp:244]     Train net output #1: loss = 0.499777 (* 1 = 0.499777 loss)
I0401 01:14:53.215503 11876 sgd_solver.cpp:106] Iteration 9000, lr = 0.01
I0401 01:14:58.768383 11876 solver.cpp:228] Iteration 9100, loss = 0.415354
I0401 01:14:58.768383 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:14:58.768383 11876 solver.cpp:244]     Train net output #1: loss = 0.415354 (* 1 = 0.415354 loss)
I0401 01:14:58.768383 11876 sgd_solver.cpp:106] Iteration 9100, lr = 0.01
I0401 01:15:04.332407 11876 solver.cpp:228] Iteration 9200, loss = 0.471332
I0401 01:15:04.332407 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:15:04.332407 11876 solver.cpp:244]     Train net output #1: loss = 0.471332 (* 1 = 0.471332 loss)
I0401 01:15:04.332407 11876 sgd_solver.cpp:106] Iteration 9200, lr = 0.01
I0401 01:15:09.879690 11876 solver.cpp:228] Iteration 9300, loss = 0.431579
I0401 01:15:09.879690 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:15:09.879690 11876 solver.cpp:244]     Train net output #1: loss = 0.431579 (* 1 = 0.431579 loss)
I0401 01:15:09.879690 11876 sgd_solver.cpp:106] Iteration 9300, lr = 0.01
I0401 01:15:15.433961 11876 solver.cpp:228] Iteration 9400, loss = 0.444324
I0401 01:15:15.433961 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:15:15.433961 11876 solver.cpp:244]     Train net output #1: loss = 0.444324 (* 1 = 0.444324 loss)
I0401 01:15:15.433961 11876 sgd_solver.cpp:106] Iteration 9400, lr = 0.01
I0401 01:15:20.986798 11876 solver.cpp:228] Iteration 9500, loss = 0.504524
I0401 01:15:20.986798 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:15:20.986798 11876 solver.cpp:244]     Train net output #1: loss = 0.504524 (* 1 = 0.504524 loss)
I0401 01:15:20.986798 11876 sgd_solver.cpp:106] Iteration 9500, lr = 0.01
I0401 01:15:26.569954 11876 solver.cpp:228] Iteration 9600, loss = 0.43597
I0401 01:15:26.570454 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:15:26.570454 11876 solver.cpp:244]     Train net output #1: loss = 0.43597 (* 1 = 0.43597 loss)
I0401 01:15:26.570454 11876 sgd_solver.cpp:106] Iteration 9600, lr = 0.01
I0401 01:15:32.136374 11876 solver.cpp:228] Iteration 9700, loss = 0.494083
I0401 01:15:32.136374 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:15:32.136374 11876 solver.cpp:244]     Train net output #1: loss = 0.494083 (* 1 = 0.494083 loss)
I0401 01:15:32.136374 11876 sgd_solver.cpp:106] Iteration 9700, lr = 0.01
I0401 01:15:37.690280 11876 solver.cpp:228] Iteration 9800, loss = 0.446636
I0401 01:15:37.690280 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:15:37.690280 11876 solver.cpp:244]     Train net output #1: loss = 0.446636 (* 1 = 0.446636 loss)
I0401 01:15:37.690280 11876 sgd_solver.cpp:106] Iteration 9800, lr = 0.01
I0401 01:15:43.232908 11876 solver.cpp:228] Iteration 9900, loss = 0.401065
I0401 01:15:43.233407 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:15:43.233407 11876 solver.cpp:244]     Train net output #1: loss = 0.401065 (* 1 = 0.401065 loss)
I0401 01:15:43.233407 11876 sgd_solver.cpp:106] Iteration 9900, lr = 0.01
I0401 01:15:48.764235 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_10000.caffemodel
I0401 01:15:49.526247 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_10000.solverstate
I0401 01:15:49.531754 11876 solver.cpp:337] Iteration 10000, Testing net (#0)
I0401 01:15:49.531754 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:15:51.146953 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7877
I0401 01:15:51.146953 11876 solver.cpp:404]     Test net output #1: loss = 0.633231 (* 1 = 0.633231 loss)
I0401 01:15:51.167456 11876 solver.cpp:228] Iteration 10000, loss = 0.57684
I0401 01:15:51.167456 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:15:51.167456 11876 solver.cpp:244]     Train net output #1: loss = 0.57684 (* 1 = 0.57684 loss)
I0401 01:15:51.167456 11876 sgd_solver.cpp:106] Iteration 10000, lr = 0.01
I0401 01:15:56.721107 11876 solver.cpp:228] Iteration 10100, loss = 0.437829
I0401 01:15:56.721107 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:15:56.721107 11876 solver.cpp:244]     Train net output #1: loss = 0.437829 (* 1 = 0.437829 loss)
I0401 01:15:56.721107 11876 sgd_solver.cpp:106] Iteration 10100, lr = 0.01
I0401 01:16:02.285563 11876 solver.cpp:228] Iteration 10200, loss = 0.392116
I0401 01:16:02.285563 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:16:02.285563 11876 solver.cpp:244]     Train net output #1: loss = 0.392116 (* 1 = 0.392116 loss)
I0401 01:16:02.285563 11876 sgd_solver.cpp:106] Iteration 10200, lr = 0.01
I0401 01:16:07.876087 11876 solver.cpp:228] Iteration 10300, loss = 0.548061
I0401 01:16:07.876087 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:16:07.876087 11876 solver.cpp:244]     Train net output #1: loss = 0.548061 (* 1 = 0.548061 loss)
I0401 01:16:07.876087 11876 sgd_solver.cpp:106] Iteration 10300, lr = 0.01
I0401 01:16:13.442776 11876 solver.cpp:228] Iteration 10400, loss = 0.384119
I0401 01:16:13.442776 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:16:13.442776 11876 solver.cpp:244]     Train net output #1: loss = 0.384119 (* 1 = 0.384119 loss)
I0401 01:16:13.442776 11876 sgd_solver.cpp:106] Iteration 10400, lr = 0.01
I0401 01:16:19.012967 11876 solver.cpp:228] Iteration 10500, loss = 0.44731
I0401 01:16:19.012967 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:16:19.012967 11876 solver.cpp:244]     Train net output #1: loss = 0.44731 (* 1 = 0.44731 loss)
I0401 01:16:19.012967 11876 sgd_solver.cpp:106] Iteration 10500, lr = 0.01
I0401 01:16:24.577121 11876 solver.cpp:228] Iteration 10600, loss = 0.286318
I0401 01:16:24.577121 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:16:24.577121 11876 solver.cpp:244]     Train net output #1: loss = 0.286318 (* 1 = 0.286318 loss)
I0401 01:16:24.577121 11876 sgd_solver.cpp:106] Iteration 10600, lr = 0.01
I0401 01:16:30.145735 11876 solver.cpp:228] Iteration 10700, loss = 0.583141
I0401 01:16:30.145735 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:16:30.145735 11876 solver.cpp:244]     Train net output #1: loss = 0.583141 (* 1 = 0.583141 loss)
I0401 01:16:30.145735 11876 sgd_solver.cpp:106] Iteration 10700, lr = 0.01
I0401 01:16:35.722652 11876 solver.cpp:228] Iteration 10800, loss = 0.471019
I0401 01:16:35.722652 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:16:35.722652 11876 solver.cpp:244]     Train net output #1: loss = 0.471019 (* 1 = 0.471019 loss)
I0401 01:16:35.722652 11876 sgd_solver.cpp:106] Iteration 10800, lr = 0.01
I0401 01:16:41.295790 11876 solver.cpp:228] Iteration 10900, loss = 0.403027
I0401 01:16:41.295790 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:16:41.295790 11876 solver.cpp:244]     Train net output #1: loss = 0.403027 (* 1 = 0.403027 loss)
I0401 01:16:41.295790 11876 sgd_solver.cpp:106] Iteration 10900, lr = 0.01
I0401 01:16:46.844575 11876 solver.cpp:337] Iteration 11000, Testing net (#0)
I0401 01:16:46.844575 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:16:48.473999 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7683
I0401 01:16:48.473999 11876 solver.cpp:404]     Test net output #1: loss = 0.690105 (* 1 = 0.690105 loss)
I0401 01:16:48.495998 11876 solver.cpp:228] Iteration 11000, loss = 0.438553
I0401 01:16:48.495998 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:16:48.495998 11876 solver.cpp:244]     Train net output #1: loss = 0.438553 (* 1 = 0.438553 loss)
I0401 01:16:48.495998 11876 sgd_solver.cpp:106] Iteration 11000, lr = 0.01
I0401 01:16:54.062068 11876 solver.cpp:228] Iteration 11100, loss = 0.45447
I0401 01:16:54.062567 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:16:54.062567 11876 solver.cpp:244]     Train net output #1: loss = 0.45447 (* 1 = 0.45447 loss)
I0401 01:16:54.062567 11876 sgd_solver.cpp:106] Iteration 11100, lr = 0.01
I0401 01:16:59.639148 11876 solver.cpp:228] Iteration 11200, loss = 0.511195
I0401 01:16:59.639148 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:16:59.639148 11876 solver.cpp:244]     Train net output #1: loss = 0.511195 (* 1 = 0.511195 loss)
I0401 01:16:59.639148 11876 sgd_solver.cpp:106] Iteration 11200, lr = 0.01
I0401 01:17:05.226582 11876 solver.cpp:228] Iteration 11300, loss = 0.465358
I0401 01:17:05.226582 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:17:05.226582 11876 solver.cpp:244]     Train net output #1: loss = 0.465358 (* 1 = 0.465358 loss)
I0401 01:17:05.226582 11876 sgd_solver.cpp:106] Iteration 11300, lr = 0.01
I0401 01:17:10.800148 11876 solver.cpp:228] Iteration 11400, loss = 0.417312
I0401 01:17:10.800148 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:17:10.800148 11876 solver.cpp:244]     Train net output #1: loss = 0.417311 (* 1 = 0.417311 loss)
I0401 01:17:10.800148 11876 sgd_solver.cpp:106] Iteration 11400, lr = 0.01
I0401 01:17:16.385429 11876 solver.cpp:228] Iteration 11500, loss = 0.444097
I0401 01:17:16.385429 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:17:16.385429 11876 solver.cpp:244]     Train net output #1: loss = 0.444097 (* 1 = 0.444097 loss)
I0401 01:17:16.385429 11876 sgd_solver.cpp:106] Iteration 11500, lr = 0.01
I0401 01:17:21.979346 11876 solver.cpp:228] Iteration 11600, loss = 0.444066
I0401 01:17:21.979346 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:17:21.979346 11876 solver.cpp:244]     Train net output #1: loss = 0.444066 (* 1 = 0.444066 loss)
I0401 01:17:21.979346 11876 sgd_solver.cpp:106] Iteration 11600, lr = 0.01
I0401 01:17:27.569232 11876 solver.cpp:228] Iteration 11700, loss = 0.427551
I0401 01:17:27.569232 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:17:27.569232 11876 solver.cpp:244]     Train net output #1: loss = 0.42755 (* 1 = 0.42755 loss)
I0401 01:17:27.569232 11876 sgd_solver.cpp:106] Iteration 11700, lr = 0.01
I0401 01:17:33.150511 11876 solver.cpp:228] Iteration 11800, loss = 0.503274
I0401 01:17:33.150511 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:17:33.150511 11876 solver.cpp:244]     Train net output #1: loss = 0.503274 (* 1 = 0.503274 loss)
I0401 01:17:33.150511 11876 sgd_solver.cpp:106] Iteration 11800, lr = 0.01
I0401 01:17:38.715864 11876 solver.cpp:228] Iteration 11900, loss = 0.458944
I0401 01:17:38.715864 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:17:38.715864 11876 solver.cpp:244]     Train net output #1: loss = 0.458944 (* 1 = 0.458944 loss)
I0401 01:17:38.715864 11876 sgd_solver.cpp:106] Iteration 11900, lr = 0.01
I0401 01:17:44.255537 11876 solver.cpp:337] Iteration 12000, Testing net (#0)
I0401 01:17:44.255537 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:17:45.870857 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7619
I0401 01:17:45.870857 11876 solver.cpp:404]     Test net output #1: loss = 0.715401 (* 1 = 0.715401 loss)
I0401 01:17:45.891849 11876 solver.cpp:228] Iteration 12000, loss = 0.514146
I0401 01:17:45.891849 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:17:45.891849 11876 solver.cpp:244]     Train net output #1: loss = 0.514146 (* 1 = 0.514146 loss)
I0401 01:17:45.891849 11876 sgd_solver.cpp:106] Iteration 12000, lr = 0.01
I0401 01:17:51.456923 11876 solver.cpp:228] Iteration 12100, loss = 0.457399
I0401 01:17:51.456923 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:17:51.456923 11876 solver.cpp:244]     Train net output #1: loss = 0.457399 (* 1 = 0.457399 loss)
I0401 01:17:51.456923 11876 sgd_solver.cpp:106] Iteration 12100, lr = 0.01
I0401 01:17:57.009769 11876 solver.cpp:228] Iteration 12200, loss = 0.4874
I0401 01:17:57.009769 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:17:57.009769 11876 solver.cpp:244]     Train net output #1: loss = 0.4874 (* 1 = 0.4874 loss)
I0401 01:17:57.009769 11876 sgd_solver.cpp:106] Iteration 12200, lr = 0.01
I0401 01:18:02.565287 11876 solver.cpp:228] Iteration 12300, loss = 0.541662
I0401 01:18:02.565287 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:18:02.565287 11876 solver.cpp:244]     Train net output #1: loss = 0.541662 (* 1 = 0.541662 loss)
I0401 01:18:02.565287 11876 sgd_solver.cpp:106] Iteration 12300, lr = 0.01
I0401 01:18:08.122310 11876 solver.cpp:228] Iteration 12400, loss = 0.381854
I0401 01:18:08.122310 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:18:08.122310 11876 solver.cpp:244]     Train net output #1: loss = 0.381854 (* 1 = 0.381854 loss)
I0401 01:18:08.122310 11876 sgd_solver.cpp:106] Iteration 12400, lr = 0.01
I0401 01:18:13.672255 11876 solver.cpp:228] Iteration 12500, loss = 0.45532
I0401 01:18:13.672255 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:18:13.672255 11876 solver.cpp:244]     Train net output #1: loss = 0.45532 (* 1 = 0.45532 loss)
I0401 01:18:13.672255 11876 sgd_solver.cpp:106] Iteration 12500, lr = 0.01
I0401 01:18:19.237092 11876 solver.cpp:228] Iteration 12600, loss = 0.317166
I0401 01:18:19.237092 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:18:19.237092 11876 solver.cpp:244]     Train net output #1: loss = 0.317166 (* 1 = 0.317166 loss)
I0401 01:18:19.237092 11876 sgd_solver.cpp:106] Iteration 12600, lr = 0.01
I0401 01:18:24.785718 11876 solver.cpp:228] Iteration 12700, loss = 0.594052
I0401 01:18:24.785718 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:18:24.785718 11876 solver.cpp:244]     Train net output #1: loss = 0.594052 (* 1 = 0.594052 loss)
I0401 01:18:24.785718 11876 sgd_solver.cpp:106] Iteration 12700, lr = 0.01
I0401 01:18:30.329537 11876 solver.cpp:228] Iteration 12800, loss = 0.485316
I0401 01:18:30.329537 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:18:30.329537 11876 solver.cpp:244]     Train net output #1: loss = 0.485316 (* 1 = 0.485316 loss)
I0401 01:18:30.329537 11876 sgd_solver.cpp:106] Iteration 12800, lr = 0.01
I0401 01:18:35.896654 11876 solver.cpp:228] Iteration 12900, loss = 0.37724
I0401 01:18:35.896654 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:18:35.896654 11876 solver.cpp:244]     Train net output #1: loss = 0.37724 (* 1 = 0.37724 loss)
I0401 01:18:35.896654 11876 sgd_solver.cpp:106] Iteration 12900, lr = 0.01
I0401 01:18:41.412962 11876 solver.cpp:337] Iteration 13000, Testing net (#0)
I0401 01:18:41.412962 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:18:43.033392 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7582
I0401 01:18:43.033392 11876 solver.cpp:404]     Test net output #1: loss = 0.710121 (* 1 = 0.710121 loss)
I0401 01:18:43.055410 11876 solver.cpp:228] Iteration 13000, loss = 0.503828
I0401 01:18:43.055410 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:18:43.055410 11876 solver.cpp:244]     Train net output #1: loss = 0.503828 (* 1 = 0.503828 loss)
I0401 01:18:43.055410 11876 sgd_solver.cpp:106] Iteration 13000, lr = 0.01
I0401 01:18:48.603615 11876 solver.cpp:228] Iteration 13100, loss = 0.413103
I0401 01:18:48.603615 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:18:48.603615 11876 solver.cpp:244]     Train net output #1: loss = 0.413103 (* 1 = 0.413103 loss)
I0401 01:18:48.603615 11876 sgd_solver.cpp:106] Iteration 13100, lr = 0.01
I0401 01:18:54.147173 11876 solver.cpp:228] Iteration 13200, loss = 0.51751
I0401 01:18:54.147173 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:18:54.147173 11876 solver.cpp:244]     Train net output #1: loss = 0.51751 (* 1 = 0.51751 loss)
I0401 01:18:54.147173 11876 sgd_solver.cpp:106] Iteration 13200, lr = 0.01
I0401 01:18:59.691120 11876 solver.cpp:228] Iteration 13300, loss = 0.536032
I0401 01:18:59.691120 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:18:59.691120 11876 solver.cpp:244]     Train net output #1: loss = 0.536032 (* 1 = 0.536032 loss)
I0401 01:18:59.691120 11876 sgd_solver.cpp:106] Iteration 13300, lr = 0.01
I0401 01:19:05.238199 11876 solver.cpp:228] Iteration 13400, loss = 0.422017
I0401 01:19:05.238199 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:19:05.238199 11876 solver.cpp:244]     Train net output #1: loss = 0.422016 (* 1 = 0.422016 loss)
I0401 01:19:05.238199 11876 sgd_solver.cpp:106] Iteration 13400, lr = 0.01
I0401 01:19:10.778642 11876 solver.cpp:228] Iteration 13500, loss = 0.485875
I0401 01:19:10.778642 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:19:10.778642 11876 solver.cpp:244]     Train net output #1: loss = 0.485875 (* 1 = 0.485875 loss)
I0401 01:19:10.778642 11876 sgd_solver.cpp:106] Iteration 13500, lr = 0.01
I0401 01:19:16.342957 11876 solver.cpp:228] Iteration 13600, loss = 0.425079
I0401 01:19:16.342957 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:19:16.342957 11876 solver.cpp:244]     Train net output #1: loss = 0.425079 (* 1 = 0.425079 loss)
I0401 01:19:16.342957 11876 sgd_solver.cpp:106] Iteration 13600, lr = 0.01
I0401 01:19:21.904980 11876 solver.cpp:228] Iteration 13700, loss = 0.502957
I0401 01:19:21.904980 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:19:21.904980 11876 solver.cpp:244]     Train net output #1: loss = 0.502957 (* 1 = 0.502957 loss)
I0401 01:19:21.904980 11876 sgd_solver.cpp:106] Iteration 13700, lr = 0.01
I0401 01:19:27.468912 11876 solver.cpp:228] Iteration 13800, loss = 0.464303
I0401 01:19:27.468912 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:19:27.468912 11876 solver.cpp:244]     Train net output #1: loss = 0.464302 (* 1 = 0.464302 loss)
I0401 01:19:27.468912 11876 sgd_solver.cpp:106] Iteration 13800, lr = 0.01
I0401 01:19:33.044970 11876 solver.cpp:228] Iteration 13900, loss = 0.372041
I0401 01:19:33.044970 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:19:33.044970 11876 solver.cpp:244]     Train net output #1: loss = 0.372041 (* 1 = 0.372041 loss)
I0401 01:19:33.045467 11876 sgd_solver.cpp:106] Iteration 13900, lr = 0.01
I0401 01:19:38.587260 11876 solver.cpp:337] Iteration 14000, Testing net (#0)
I0401 01:19:38.587260 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:19:40.202913 11876 solver.cpp:404]     Test net output #0: accuracy = 0.779
I0401 01:19:40.202913 11876 solver.cpp:404]     Test net output #1: loss = 0.678442 (* 1 = 0.678442 loss)
I0401 01:19:40.224416 11876 solver.cpp:228] Iteration 14000, loss = 0.530751
I0401 01:19:40.224416 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:19:40.224416 11876 solver.cpp:244]     Train net output #1: loss = 0.530751 (* 1 = 0.530751 loss)
I0401 01:19:40.224416 11876 sgd_solver.cpp:106] Iteration 14000, lr = 0.01
I0401 01:19:45.776829 11876 solver.cpp:228] Iteration 14100, loss = 0.387576
I0401 01:19:45.776829 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:19:45.776829 11876 solver.cpp:244]     Train net output #1: loss = 0.387576 (* 1 = 0.387576 loss)
I0401 01:19:45.776829 11876 sgd_solver.cpp:106] Iteration 14100, lr = 0.01
I0401 01:19:51.336719 11876 solver.cpp:228] Iteration 14200, loss = 0.397023
I0401 01:19:51.336719 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:19:51.336719 11876 solver.cpp:244]     Train net output #1: loss = 0.397023 (* 1 = 0.397023 loss)
I0401 01:19:51.336719 11876 sgd_solver.cpp:106] Iteration 14200, lr = 0.01
I0401 01:19:56.889819 11876 solver.cpp:228] Iteration 14300, loss = 0.505503
I0401 01:19:56.889819 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:19:56.889819 11876 solver.cpp:244]     Train net output #1: loss = 0.505503 (* 1 = 0.505503 loss)
I0401 01:19:56.889819 11876 sgd_solver.cpp:106] Iteration 14300, lr = 0.01
I0401 01:20:02.515270 11876 solver.cpp:228] Iteration 14400, loss = 0.375088
I0401 01:20:02.515270 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:20:02.515270 11876 solver.cpp:244]     Train net output #1: loss = 0.375088 (* 1 = 0.375088 loss)
I0401 01:20:02.515270 11876 sgd_solver.cpp:106] Iteration 14400, lr = 0.01
I0401 01:20:08.050750 11876 solver.cpp:228] Iteration 14500, loss = 0.590799
I0401 01:20:08.050750 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:20:08.050750 11876 solver.cpp:244]     Train net output #1: loss = 0.590799 (* 1 = 0.590799 loss)
I0401 01:20:08.050750 11876 sgd_solver.cpp:106] Iteration 14500, lr = 0.01
I0401 01:20:13.587563 11876 solver.cpp:228] Iteration 14600, loss = 0.399642
I0401 01:20:13.587563 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:20:13.587563 11876 solver.cpp:244]     Train net output #1: loss = 0.399642 (* 1 = 0.399642 loss)
I0401 01:20:13.587563 11876 sgd_solver.cpp:106] Iteration 14600, lr = 0.01
I0401 01:20:19.135082 11876 solver.cpp:228] Iteration 14700, loss = 0.46573
I0401 01:20:19.135082 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:20:19.135082 11876 solver.cpp:244]     Train net output #1: loss = 0.465729 (* 1 = 0.465729 loss)
I0401 01:20:19.135583 11876 sgd_solver.cpp:106] Iteration 14700, lr = 0.01
I0401 01:20:24.662993 11876 solver.cpp:228] Iteration 14800, loss = 0.495301
I0401 01:20:24.662993 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:20:24.662993 11876 solver.cpp:244]     Train net output #1: loss = 0.495301 (* 1 = 0.495301 loss)
I0401 01:20:24.662993 11876 sgd_solver.cpp:106] Iteration 14800, lr = 0.01
I0401 01:20:30.229630 11876 solver.cpp:228] Iteration 14900, loss = 0.430561
I0401 01:20:30.229630 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:20:30.229630 11876 solver.cpp:244]     Train net output #1: loss = 0.430561 (* 1 = 0.430561 loss)
I0401 01:20:30.229630 11876 sgd_solver.cpp:106] Iteration 14900, lr = 0.01
I0401 01:20:35.757489 11876 solver.cpp:337] Iteration 15000, Testing net (#0)
I0401 01:20:35.757975 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:20:37.382452 11876 solver.cpp:404]     Test net output #0: accuracy = 0.6474
I0401 01:20:37.382452 11876 solver.cpp:404]     Test net output #1: loss = 1.06041 (* 1 = 1.06041 loss)
I0401 01:20:37.403764 11876 solver.cpp:228] Iteration 15000, loss = 0.390737
I0401 01:20:37.403764 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:20:37.403764 11876 solver.cpp:244]     Train net output #1: loss = 0.390737 (* 1 = 0.390737 loss)
I0401 01:20:37.403764 11876 sgd_solver.cpp:106] Iteration 15000, lr = 0.01
I0401 01:20:42.923279 11876 solver.cpp:228] Iteration 15100, loss = 0.520955
I0401 01:20:42.923279 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:20:42.923779 11876 solver.cpp:244]     Train net output #1: loss = 0.520955 (* 1 = 0.520955 loss)
I0401 01:20:42.923779 11876 sgd_solver.cpp:106] Iteration 15100, lr = 0.01
I0401 01:20:48.460968 11876 solver.cpp:228] Iteration 15200, loss = 0.449453
I0401 01:20:48.460968 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:20:48.460968 11876 solver.cpp:244]     Train net output #1: loss = 0.449453 (* 1 = 0.449453 loss)
I0401 01:20:48.460968 11876 sgd_solver.cpp:106] Iteration 15200, lr = 0.01
I0401 01:20:54.005875 11876 solver.cpp:228] Iteration 15300, loss = 0.470075
I0401 01:20:54.005875 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:20:54.005875 11876 solver.cpp:244]     Train net output #1: loss = 0.470075 (* 1 = 0.470075 loss)
I0401 01:20:54.005875 11876 sgd_solver.cpp:106] Iteration 15300, lr = 0.01
I0401 01:20:59.554774 11876 solver.cpp:228] Iteration 15400, loss = 0.427204
I0401 01:20:59.554774 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:20:59.554774 11876 solver.cpp:244]     Train net output #1: loss = 0.427204 (* 1 = 0.427204 loss)
I0401 01:20:59.554774 11876 sgd_solver.cpp:106] Iteration 15400, lr = 0.01
I0401 01:21:05.098950 11876 solver.cpp:228] Iteration 15500, loss = 0.49927
I0401 01:21:05.099450 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:21:05.099450 11876 solver.cpp:244]     Train net output #1: loss = 0.499269 (* 1 = 0.499269 loss)
I0401 01:21:05.099450 11876 sgd_solver.cpp:106] Iteration 15500, lr = 0.01
I0401 01:21:10.617691 11876 solver.cpp:228] Iteration 15600, loss = 0.333244
I0401 01:21:10.617691 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:21:10.617691 11876 solver.cpp:244]     Train net output #1: loss = 0.333244 (* 1 = 0.333244 loss)
I0401 01:21:10.617691 11876 sgd_solver.cpp:106] Iteration 15600, lr = 0.01
I0401 01:21:16.142591 11876 solver.cpp:228] Iteration 15700, loss = 0.368271
I0401 01:21:16.142591 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:21:16.142591 11876 solver.cpp:244]     Train net output #1: loss = 0.368271 (* 1 = 0.368271 loss)
I0401 01:21:16.142591 11876 sgd_solver.cpp:106] Iteration 15700, lr = 0.01
I0401 01:21:21.670616 11876 solver.cpp:228] Iteration 15800, loss = 0.465425
I0401 01:21:21.670616 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:21:21.670616 11876 solver.cpp:244]     Train net output #1: loss = 0.465424 (* 1 = 0.465424 loss)
I0401 01:21:21.670616 11876 sgd_solver.cpp:106] Iteration 15800, lr = 0.01
I0401 01:21:27.217555 11876 solver.cpp:228] Iteration 15900, loss = 0.370533
I0401 01:21:27.217555 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:21:27.217555 11876 solver.cpp:244]     Train net output #1: loss = 0.370533 (* 1 = 0.370533 loss)
I0401 01:21:27.217555 11876 sgd_solver.cpp:106] Iteration 15900, lr = 0.01
I0401 01:21:32.727469 11876 solver.cpp:337] Iteration 16000, Testing net (#0)
I0401 01:21:32.727469 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:21:34.347242 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7314
I0401 01:21:34.348242 11876 solver.cpp:404]     Test net output #1: loss = 0.823301 (* 1 = 0.823301 loss)
I0401 01:21:34.369269 11876 solver.cpp:228] Iteration 16000, loss = 0.5511
I0401 01:21:34.369269 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:21:34.369269 11876 solver.cpp:244]     Train net output #1: loss = 0.5511 (* 1 = 0.5511 loss)
I0401 01:21:34.369269 11876 sgd_solver.cpp:106] Iteration 16000, lr = 0.01
I0401 01:21:39.899065 11876 solver.cpp:228] Iteration 16100, loss = 0.393855
I0401 01:21:39.899065 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:21:39.899065 11876 solver.cpp:244]     Train net output #1: loss = 0.393855 (* 1 = 0.393855 loss)
I0401 01:21:39.899065 11876 sgd_solver.cpp:106] Iteration 16100, lr = 0.01
I0401 01:21:45.444461 11876 solver.cpp:228] Iteration 16200, loss = 0.559754
I0401 01:21:45.444461 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:21:45.444461 11876 solver.cpp:244]     Train net output #1: loss = 0.559754 (* 1 = 0.559754 loss)
I0401 01:21:45.444461 11876 sgd_solver.cpp:106] Iteration 16200, lr = 0.01
I0401 01:21:51.004779 11876 solver.cpp:228] Iteration 16300, loss = 0.442638
I0401 01:21:51.004779 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:21:51.004779 11876 solver.cpp:244]     Train net output #1: loss = 0.442638 (* 1 = 0.442638 loss)
I0401 01:21:51.005280 11876 sgd_solver.cpp:106] Iteration 16300, lr = 0.01
I0401 01:21:56.547936 11876 solver.cpp:228] Iteration 16400, loss = 0.3554
I0401 01:21:56.548420 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:21:56.548420 11876 solver.cpp:244]     Train net output #1: loss = 0.3554 (* 1 = 0.3554 loss)
I0401 01:21:56.548420 11876 sgd_solver.cpp:106] Iteration 16400, lr = 0.01
I0401 01:22:02.112701 11876 solver.cpp:228] Iteration 16500, loss = 0.484762
I0401 01:22:02.112701 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:22:02.112701 11876 solver.cpp:244]     Train net output #1: loss = 0.484762 (* 1 = 0.484762 loss)
I0401 01:22:02.112701 11876 sgd_solver.cpp:106] Iteration 16500, lr = 0.01
I0401 01:22:07.642838 11876 solver.cpp:228] Iteration 16600, loss = 0.490437
I0401 01:22:07.642838 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:22:07.642838 11876 solver.cpp:244]     Train net output #1: loss = 0.490437 (* 1 = 0.490437 loss)
I0401 01:22:07.642838 11876 sgd_solver.cpp:106] Iteration 16600, lr = 0.01
I0401 01:22:13.166954 11876 solver.cpp:228] Iteration 16700, loss = 0.452851
I0401 01:22:13.166954 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:22:13.166954 11876 solver.cpp:244]     Train net output #1: loss = 0.45285 (* 1 = 0.45285 loss)
I0401 01:22:13.166954 11876 sgd_solver.cpp:106] Iteration 16700, lr = 0.01
I0401 01:22:18.692770 11876 solver.cpp:228] Iteration 16800, loss = 0.507784
I0401 01:22:18.692770 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:22:18.692770 11876 solver.cpp:244]     Train net output #1: loss = 0.507784 (* 1 = 0.507784 loss)
I0401 01:22:18.692770 11876 sgd_solver.cpp:106] Iteration 16800, lr = 0.01
I0401 01:22:24.229758 11876 solver.cpp:228] Iteration 16900, loss = 0.332135
I0401 01:22:24.229758 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:22:24.229758 11876 solver.cpp:244]     Train net output #1: loss = 0.332135 (* 1 = 0.332135 loss)
I0401 01:22:24.229758 11876 sgd_solver.cpp:106] Iteration 16900, lr = 0.01
I0401 01:22:29.743376 11876 solver.cpp:337] Iteration 17000, Testing net (#0)
I0401 01:22:29.743376 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:22:31.361546 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8108
I0401 01:22:31.361546 11876 solver.cpp:404]     Test net output #1: loss = 0.555632 (* 1 = 0.555632 loss)
I0401 01:22:31.383570 11876 solver.cpp:228] Iteration 17000, loss = 0.366492
I0401 01:22:31.383570 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:22:31.383570 11876 solver.cpp:244]     Train net output #1: loss = 0.366492 (* 1 = 0.366492 loss)
I0401 01:22:31.383570 11876 sgd_solver.cpp:106] Iteration 17000, lr = 0.01
I0401 01:22:36.923758 11876 solver.cpp:228] Iteration 17100, loss = 0.448576
I0401 01:22:36.924258 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:22:36.924258 11876 solver.cpp:244]     Train net output #1: loss = 0.448576 (* 1 = 0.448576 loss)
I0401 01:22:36.924258 11876 sgd_solver.cpp:106] Iteration 17100, lr = 0.01
I0401 01:22:42.472239 11876 solver.cpp:228] Iteration 17200, loss = 0.49023
I0401 01:22:42.472239 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:22:42.472736 11876 solver.cpp:244]     Train net output #1: loss = 0.49023 (* 1 = 0.49023 loss)
I0401 01:22:42.472736 11876 sgd_solver.cpp:106] Iteration 17200, lr = 0.01
I0401 01:22:48.037214 11876 solver.cpp:228] Iteration 17300, loss = 0.434076
I0401 01:22:48.037214 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:22:48.037214 11876 solver.cpp:244]     Train net output #1: loss = 0.434076 (* 1 = 0.434076 loss)
I0401 01:22:48.037214 11876 sgd_solver.cpp:106] Iteration 17300, lr = 0.01
I0401 01:22:53.596756 11876 solver.cpp:228] Iteration 17400, loss = 0.335097
I0401 01:22:53.596756 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:22:53.596756 11876 solver.cpp:244]     Train net output #1: loss = 0.335097 (* 1 = 0.335097 loss)
I0401 01:22:53.596756 11876 sgd_solver.cpp:106] Iteration 17400, lr = 0.01
I0401 01:22:59.141238 11876 solver.cpp:228] Iteration 17500, loss = 0.453913
I0401 01:22:59.141238 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:22:59.141238 11876 solver.cpp:244]     Train net output #1: loss = 0.453913 (* 1 = 0.453913 loss)
I0401 01:22:59.141238 11876 sgd_solver.cpp:106] Iteration 17500, lr = 0.01
I0401 01:23:04.708272 11876 solver.cpp:228] Iteration 17600, loss = 0.407353
I0401 01:23:04.708772 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:23:04.708772 11876 solver.cpp:244]     Train net output #1: loss = 0.407353 (* 1 = 0.407353 loss)
I0401 01:23:04.708772 11876 sgd_solver.cpp:106] Iteration 17600, lr = 0.01
I0401 01:23:10.255437 11876 solver.cpp:228] Iteration 17700, loss = 0.501832
I0401 01:23:10.255437 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:23:10.255437 11876 solver.cpp:244]     Train net output #1: loss = 0.501831 (* 1 = 0.501831 loss)
I0401 01:23:10.255437 11876 sgd_solver.cpp:106] Iteration 17700, lr = 0.01
I0401 01:23:15.811079 11876 solver.cpp:228] Iteration 17800, loss = 0.464464
I0401 01:23:15.811079 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:23:15.811079 11876 solver.cpp:244]     Train net output #1: loss = 0.464464 (* 1 = 0.464464 loss)
I0401 01:23:15.811079 11876 sgd_solver.cpp:106] Iteration 17800, lr = 0.01
I0401 01:23:21.351033 11876 solver.cpp:228] Iteration 17900, loss = 0.442345
I0401 01:23:21.351033 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:23:21.351033 11876 solver.cpp:244]     Train net output #1: loss = 0.442345 (* 1 = 0.442345 loss)
I0401 01:23:21.351033 11876 sgd_solver.cpp:106] Iteration 17900, lr = 0.01
I0401 01:23:26.868899 11876 solver.cpp:337] Iteration 18000, Testing net (#0)
I0401 01:23:26.868899 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:23:28.496325 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7794
I0401 01:23:28.496325 11876 solver.cpp:404]     Test net output #1: loss = 0.6642 (* 1 = 0.6642 loss)
I0401 01:23:28.517336 11876 solver.cpp:228] Iteration 18000, loss = 0.454205
I0401 01:23:28.517336 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:23:28.517336 11876 solver.cpp:244]     Train net output #1: loss = 0.454205 (* 1 = 0.454205 loss)
I0401 01:23:28.517336 11876 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0401 01:23:34.072701 11876 solver.cpp:228] Iteration 18100, loss = 0.464049
I0401 01:23:34.072701 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:23:34.072701 11876 solver.cpp:244]     Train net output #1: loss = 0.464048 (* 1 = 0.464048 loss)
I0401 01:23:34.073210 11876 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0401 01:23:39.618114 11876 solver.cpp:228] Iteration 18200, loss = 0.489813
I0401 01:23:39.618114 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:23:39.618114 11876 solver.cpp:244]     Train net output #1: loss = 0.489813 (* 1 = 0.489813 loss)
I0401 01:23:39.618114 11876 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0401 01:23:45.174047 11876 solver.cpp:228] Iteration 18300, loss = 0.528931
I0401 01:23:45.174047 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:23:45.174047 11876 solver.cpp:244]     Train net output #1: loss = 0.528931 (* 1 = 0.528931 loss)
I0401 01:23:45.174047 11876 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0401 01:23:50.713263 11876 solver.cpp:228] Iteration 18400, loss = 0.362436
I0401 01:23:50.713263 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:23:50.713263 11876 solver.cpp:244]     Train net output #1: loss = 0.362436 (* 1 = 0.362436 loss)
I0401 01:23:50.713263 11876 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0401 01:23:56.265655 11876 solver.cpp:228] Iteration 18500, loss = 0.47785
I0401 01:23:56.265655 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:23:56.265655 11876 solver.cpp:244]     Train net output #1: loss = 0.47785 (* 1 = 0.47785 loss)
I0401 01:23:56.265655 11876 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0401 01:24:01.823591 11876 solver.cpp:228] Iteration 18600, loss = 0.417887
I0401 01:24:01.823591 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:24:01.823591 11876 solver.cpp:244]     Train net output #1: loss = 0.417887 (* 1 = 0.417887 loss)
I0401 01:24:01.823591 11876 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0401 01:24:07.378147 11876 solver.cpp:228] Iteration 18700, loss = 0.522171
I0401 01:24:07.378147 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:24:07.378648 11876 solver.cpp:244]     Train net output #1: loss = 0.522171 (* 1 = 0.522171 loss)
I0401 01:24:07.378648 11876 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0401 01:24:12.918476 11876 solver.cpp:228] Iteration 18800, loss = 0.448719
I0401 01:24:12.918476 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:24:12.918476 11876 solver.cpp:244]     Train net output #1: loss = 0.448719 (* 1 = 0.448719 loss)
I0401 01:24:12.918476 11876 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0401 01:24:18.473814 11876 solver.cpp:228] Iteration 18900, loss = 0.373302
I0401 01:24:18.473814 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:24:18.473814 11876 solver.cpp:244]     Train net output #1: loss = 0.373302 (* 1 = 0.373302 loss)
I0401 01:24:18.473814 11876 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0401 01:24:24.011505 11876 solver.cpp:337] Iteration 19000, Testing net (#0)
I0401 01:24:24.011505 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:24:25.637042 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7739
I0401 01:24:25.637042 11876 solver.cpp:404]     Test net output #1: loss = 0.690905 (* 1 = 0.690905 loss)
I0401 01:24:25.658046 11876 solver.cpp:228] Iteration 19000, loss = 0.528977
I0401 01:24:25.658046 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:24:25.658046 11876 solver.cpp:244]     Train net output #1: loss = 0.528977 (* 1 = 0.528977 loss)
I0401 01:24:25.658046 11876 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0401 01:24:31.231971 11876 solver.cpp:228] Iteration 19100, loss = 0.478438
I0401 01:24:31.231971 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:24:31.231971 11876 solver.cpp:244]     Train net output #1: loss = 0.478438 (* 1 = 0.478438 loss)
I0401 01:24:31.231971 11876 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0401 01:24:36.800523 11876 solver.cpp:228] Iteration 19200, loss = 0.459066
I0401 01:24:36.800523 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:24:36.800523 11876 solver.cpp:244]     Train net output #1: loss = 0.459066 (* 1 = 0.459066 loss)
I0401 01:24:36.800523 11876 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0401 01:24:42.364616 11876 solver.cpp:228] Iteration 19300, loss = 0.504418
I0401 01:24:42.364616 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:24:42.364616 11876 solver.cpp:244]     Train net output #1: loss = 0.504417 (* 1 = 0.504417 loss)
I0401 01:24:42.364616 11876 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0401 01:24:47.919713 11876 solver.cpp:228] Iteration 19400, loss = 0.371761
I0401 01:24:47.919713 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:24:47.919713 11876 solver.cpp:244]     Train net output #1: loss = 0.371761 (* 1 = 0.371761 loss)
I0401 01:24:47.919713 11876 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0401 01:24:53.474305 11876 solver.cpp:228] Iteration 19500, loss = 0.508755
I0401 01:24:53.474305 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:24:53.474305 11876 solver.cpp:244]     Train net output #1: loss = 0.508755 (* 1 = 0.508755 loss)
I0401 01:24:53.474305 11876 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0401 01:24:59.010957 11876 solver.cpp:228] Iteration 19600, loss = 0.420295
I0401 01:24:59.010957 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:24:59.010957 11876 solver.cpp:244]     Train net output #1: loss = 0.420295 (* 1 = 0.420295 loss)
I0401 01:24:59.010957 11876 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0401 01:25:04.542816 11876 solver.cpp:228] Iteration 19700, loss = 0.413104
I0401 01:25:04.542816 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:25:04.542816 11876 solver.cpp:244]     Train net output #1: loss = 0.413104 (* 1 = 0.413104 loss)
I0401 01:25:04.542816 11876 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0401 01:25:10.072149 11876 solver.cpp:228] Iteration 19800, loss = 0.451528
I0401 01:25:10.072149 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:25:10.072149 11876 solver.cpp:244]     Train net output #1: loss = 0.451527 (* 1 = 0.451527 loss)
I0401 01:25:10.072149 11876 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0401 01:25:15.597543 11876 solver.cpp:228] Iteration 19900, loss = 0.361841
I0401 01:25:15.597543 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:25:15.597543 11876 solver.cpp:244]     Train net output #1: loss = 0.36184 (* 1 = 0.36184 loss)
I0401 01:25:15.597543 11876 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0401 01:25:21.119140 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_20000.caffemodel
I0401 01:25:21.128640 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_20000.solverstate
I0401 01:25:21.131641 11876 solver.cpp:337] Iteration 20000, Testing net (#0)
I0401 01:25:21.131641 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:25:22.749936 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7922
I0401 01:25:22.749936 11876 solver.cpp:404]     Test net output #1: loss = 0.625585 (* 1 = 0.625585 loss)
I0401 01:25:22.771448 11876 solver.cpp:228] Iteration 20000, loss = 0.393912
I0401 01:25:22.771448 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:25:22.771448 11876 solver.cpp:244]     Train net output #1: loss = 0.393912 (* 1 = 0.393912 loss)
I0401 01:25:22.771448 11876 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0401 01:25:28.316401 11876 solver.cpp:228] Iteration 20100, loss = 0.458415
I0401 01:25:28.317406 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:25:28.317406 11876 solver.cpp:244]     Train net output #1: loss = 0.458415 (* 1 = 0.458415 loss)
I0401 01:25:28.317406 11876 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0401 01:25:33.894703 11876 solver.cpp:228] Iteration 20200, loss = 0.497538
I0401 01:25:33.894703 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:25:33.894703 11876 solver.cpp:244]     Train net output #1: loss = 0.497538 (* 1 = 0.497538 loss)
I0401 01:25:33.894703 11876 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0401 01:25:39.476074 11876 solver.cpp:228] Iteration 20300, loss = 0.475335
I0401 01:25:39.476574 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:25:39.476574 11876 solver.cpp:244]     Train net output #1: loss = 0.475335 (* 1 = 0.475335 loss)
I0401 01:25:39.476574 11876 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0401 01:25:45.046797 11876 solver.cpp:228] Iteration 20400, loss = 0.357401
I0401 01:25:45.046797 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:25:45.046797 11876 solver.cpp:244]     Train net output #1: loss = 0.357401 (* 1 = 0.357401 loss)
I0401 01:25:45.046797 11876 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0401 01:25:50.579476 11876 solver.cpp:228] Iteration 20500, loss = 0.438833
I0401 01:25:50.579975 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:25:50.579975 11876 solver.cpp:244]     Train net output #1: loss = 0.438832 (* 1 = 0.438832 loss)
I0401 01:25:50.579975 11876 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0401 01:25:56.120465 11876 solver.cpp:228] Iteration 20600, loss = 0.312374
I0401 01:25:56.120465 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:25:56.120465 11876 solver.cpp:244]     Train net output #1: loss = 0.312374 (* 1 = 0.312374 loss)
I0401 01:25:56.120465 11876 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0401 01:26:01.667927 11876 solver.cpp:228] Iteration 20700, loss = 0.465512
I0401 01:26:01.667927 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:26:01.667927 11876 solver.cpp:244]     Train net output #1: loss = 0.465512 (* 1 = 0.465512 loss)
I0401 01:26:01.667927 11876 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0401 01:26:07.230666 11876 solver.cpp:228] Iteration 20800, loss = 0.542837
I0401 01:26:07.230666 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.8
I0401 01:26:07.230666 11876 solver.cpp:244]     Train net output #1: loss = 0.542837 (* 1 = 0.542837 loss)
I0401 01:26:07.230666 11876 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0401 01:26:12.829223 11876 solver.cpp:228] Iteration 20900, loss = 0.472245
I0401 01:26:12.829223 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:26:12.829223 11876 solver.cpp:244]     Train net output #1: loss = 0.472245 (* 1 = 0.472245 loss)
I0401 01:26:12.829223 11876 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0401 01:26:18.382663 11876 solver.cpp:337] Iteration 21000, Testing net (#0)
I0401 01:26:18.382663 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:26:20.011994 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8102
I0401 01:26:20.011994 11876 solver.cpp:404]     Test net output #1: loss = 0.560763 (* 1 = 0.560763 loss)
I0401 01:26:20.033985 11876 solver.cpp:228] Iteration 21000, loss = 0.406013
I0401 01:26:20.033985 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:26:20.033985 11876 solver.cpp:244]     Train net output #1: loss = 0.406013 (* 1 = 0.406013 loss)
I0401 01:26:20.033985 11876 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0401 01:26:25.576478 11876 solver.cpp:228] Iteration 21100, loss = 0.461381
I0401 01:26:25.576478 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:26:25.576478 11876 solver.cpp:244]     Train net output #1: loss = 0.461381 (* 1 = 0.461381 loss)
I0401 01:26:25.576478 11876 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0401 01:26:31.127744 11876 solver.cpp:228] Iteration 21200, loss = 0.448387
I0401 01:26:31.127744 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:26:31.127744 11876 solver.cpp:244]     Train net output #1: loss = 0.448386 (* 1 = 0.448386 loss)
I0401 01:26:31.127744 11876 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0401 01:26:36.672363 11876 solver.cpp:228] Iteration 21300, loss = 0.498575
I0401 01:26:36.672363 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:26:36.672363 11876 solver.cpp:244]     Train net output #1: loss = 0.498575 (* 1 = 0.498575 loss)
I0401 01:26:36.672363 11876 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0401 01:26:42.212733 11876 solver.cpp:228] Iteration 21400, loss = 0.36142
I0401 01:26:42.213232 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:26:42.213232 11876 solver.cpp:244]     Train net output #1: loss = 0.36142 (* 1 = 0.36142 loss)
I0401 01:26:42.213232 11876 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0401 01:26:47.763892 11876 solver.cpp:228] Iteration 21500, loss = 0.464132
I0401 01:26:47.763892 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:26:47.763892 11876 solver.cpp:244]     Train net output #1: loss = 0.464132 (* 1 = 0.464132 loss)
I0401 01:26:47.763892 11876 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0401 01:26:53.313468 11876 solver.cpp:228] Iteration 21600, loss = 0.34374
I0401 01:26:53.313468 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:26:53.313468 11876 solver.cpp:244]     Train net output #1: loss = 0.34374 (* 1 = 0.34374 loss)
I0401 01:26:53.313468 11876 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0401 01:26:58.860719 11876 solver.cpp:228] Iteration 21700, loss = 0.411774
I0401 01:26:58.861719 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:26:58.861719 11876 solver.cpp:244]     Train net output #1: loss = 0.411774 (* 1 = 0.411774 loss)
I0401 01:26:58.861719 11876 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0401 01:27:04.414865 11876 solver.cpp:228] Iteration 21800, loss = 0.51877
I0401 01:27:04.414865 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:27:04.414865 11876 solver.cpp:244]     Train net output #1: loss = 0.518769 (* 1 = 0.518769 loss)
I0401 01:27:04.414865 11876 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0401 01:27:09.958565 11876 solver.cpp:228] Iteration 21900, loss = 0.376793
I0401 01:27:09.958565 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:27:09.958565 11876 solver.cpp:244]     Train net output #1: loss = 0.376793 (* 1 = 0.376793 loss)
I0401 01:27:09.958565 11876 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0401 01:27:15.475888 11876 solver.cpp:337] Iteration 22000, Testing net (#0)
I0401 01:27:15.475888 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:27:17.094661 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7862
I0401 01:27:17.094661 11876 solver.cpp:404]     Test net output #1: loss = 0.625364 (* 1 = 0.625364 loss)
I0401 01:27:17.115164 11876 solver.cpp:228] Iteration 22000, loss = 0.561869
I0401 01:27:17.115164 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.78
I0401 01:27:17.115164 11876 solver.cpp:244]     Train net output #1: loss = 0.561869 (* 1 = 0.561869 loss)
I0401 01:27:17.115164 11876 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0401 01:27:22.672741 11876 solver.cpp:228] Iteration 22100, loss = 0.481958
I0401 01:27:22.672741 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:27:22.672741 11876 solver.cpp:244]     Train net output #1: loss = 0.481958 (* 1 = 0.481958 loss)
I0401 01:27:22.672741 11876 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0401 01:27:28.219095 11876 solver.cpp:228] Iteration 22200, loss = 0.401328
I0401 01:27:28.219095 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:27:28.219095 11876 solver.cpp:244]     Train net output #1: loss = 0.401328 (* 1 = 0.401328 loss)
I0401 01:27:28.219095 11876 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0401 01:27:33.768568 11876 solver.cpp:228] Iteration 22300, loss = 0.478978
I0401 01:27:33.768568 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:27:33.768568 11876 solver.cpp:244]     Train net output #1: loss = 0.478977 (* 1 = 0.478977 loss)
I0401 01:27:33.768568 11876 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0401 01:27:39.382647 11876 solver.cpp:228] Iteration 22400, loss = 0.352922
I0401 01:27:39.382647 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:27:39.382647 11876 solver.cpp:244]     Train net output #1: loss = 0.352922 (* 1 = 0.352922 loss)
I0401 01:27:39.382647 11876 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0401 01:27:44.908120 11876 solver.cpp:228] Iteration 22500, loss = 0.4939
I0401 01:27:44.908120 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:27:44.908120 11876 solver.cpp:244]     Train net output #1: loss = 0.4939 (* 1 = 0.4939 loss)
I0401 01:27:44.908120 11876 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0401 01:27:50.427904 11876 solver.cpp:228] Iteration 22600, loss = 0.434801
I0401 01:27:50.427904 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:27:50.427904 11876 solver.cpp:244]     Train net output #1: loss = 0.434801 (* 1 = 0.434801 loss)
I0401 01:27:50.427904 11876 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0401 01:27:55.946722 11876 solver.cpp:228] Iteration 22700, loss = 0.368228
I0401 01:27:55.946722 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:27:55.946722 11876 solver.cpp:244]     Train net output #1: loss = 0.368228 (* 1 = 0.368228 loss)
I0401 01:27:55.946722 11876 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0401 01:28:01.495126 11876 solver.cpp:228] Iteration 22800, loss = 0.479819
I0401 01:28:01.496135 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:28:01.496135 11876 solver.cpp:244]     Train net output #1: loss = 0.479819 (* 1 = 0.479819 loss)
I0401 01:28:01.496135 11876 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0401 01:28:07.020661 11876 solver.cpp:228] Iteration 22900, loss = 0.46421
I0401 01:28:07.020661 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:28:07.020661 11876 solver.cpp:244]     Train net output #1: loss = 0.46421 (* 1 = 0.46421 loss)
I0401 01:28:07.020661 11876 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0401 01:28:12.513751 11876 solver.cpp:337] Iteration 23000, Testing net (#0)
I0401 01:28:12.514262 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:28:14.126694 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8022
I0401 01:28:14.126694 11876 solver.cpp:404]     Test net output #1: loss = 0.606779 (* 1 = 0.606779 loss)
I0401 01:28:14.147693 11876 solver.cpp:228] Iteration 23000, loss = 0.476001
I0401 01:28:14.147693 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:28:14.147693 11876 solver.cpp:244]     Train net output #1: loss = 0.476001 (* 1 = 0.476001 loss)
I0401 01:28:14.147693 11876 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0401 01:28:19.679474 11876 solver.cpp:228] Iteration 23100, loss = 0.332656
I0401 01:28:19.679474 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:28:19.679474 11876 solver.cpp:244]     Train net output #1: loss = 0.332656 (* 1 = 0.332656 loss)
I0401 01:28:19.679474 11876 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0401 01:28:25.213959 11876 solver.cpp:228] Iteration 23200, loss = 0.430855
I0401 01:28:25.213959 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:28:25.213959 11876 solver.cpp:244]     Train net output #1: loss = 0.430855 (* 1 = 0.430855 loss)
I0401 01:28:25.213959 11876 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0401 01:28:30.735585 11876 solver.cpp:228] Iteration 23300, loss = 0.448524
I0401 01:28:30.735585 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:28:30.735585 11876 solver.cpp:244]     Train net output #1: loss = 0.448524 (* 1 = 0.448524 loss)
I0401 01:28:30.735585 11876 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0401 01:28:36.253144 11876 solver.cpp:228] Iteration 23400, loss = 0.323345
I0401 01:28:36.253144 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:28:36.253144 11876 solver.cpp:244]     Train net output #1: loss = 0.323344 (* 1 = 0.323344 loss)
I0401 01:28:36.253144 11876 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0401 01:28:41.773834 11876 solver.cpp:228] Iteration 23500, loss = 0.500067
I0401 01:28:41.773834 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:28:41.773834 11876 solver.cpp:244]     Train net output #1: loss = 0.500067 (* 1 = 0.500067 loss)
I0401 01:28:41.773834 11876 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0401 01:28:47.309284 11876 solver.cpp:228] Iteration 23600, loss = 0.302393
I0401 01:28:47.309284 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:28:47.309284 11876 solver.cpp:244]     Train net output #1: loss = 0.302393 (* 1 = 0.302393 loss)
I0401 01:28:47.309284 11876 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0401 01:28:52.838567 11876 solver.cpp:228] Iteration 23700, loss = 0.45189
I0401 01:28:52.838567 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:28:52.838567 11876 solver.cpp:244]     Train net output #1: loss = 0.45189 (* 1 = 0.45189 loss)
I0401 01:28:52.838567 11876 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0401 01:28:58.372822 11876 solver.cpp:228] Iteration 23800, loss = 0.488939
I0401 01:28:58.372822 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:28:58.372822 11876 solver.cpp:244]     Train net output #1: loss = 0.488939 (* 1 = 0.488939 loss)
I0401 01:28:58.372822 11876 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0401 01:29:03.910610 11876 solver.cpp:228] Iteration 23900, loss = 0.378705
I0401 01:29:03.910610 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:29:03.910610 11876 solver.cpp:244]     Train net output #1: loss = 0.378704 (* 1 = 0.378704 loss)
I0401 01:29:03.910610 11876 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0401 01:29:09.426594 11876 solver.cpp:337] Iteration 24000, Testing net (#0)
I0401 01:29:09.426594 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:29:11.041169 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7552
I0401 01:29:11.041169 11876 solver.cpp:404]     Test net output #1: loss = 0.739192 (* 1 = 0.739192 loss)
I0401 01:29:11.062156 11876 solver.cpp:228] Iteration 24000, loss = 0.425081
I0401 01:29:11.062156 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:29:11.062156 11876 solver.cpp:244]     Train net output #1: loss = 0.425081 (* 1 = 0.425081 loss)
I0401 01:29:11.062156 11876 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0401 01:29:16.585023 11876 solver.cpp:228] Iteration 24100, loss = 0.379991
I0401 01:29:16.585023 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:29:16.585023 11876 solver.cpp:244]     Train net output #1: loss = 0.379991 (* 1 = 0.379991 loss)
I0401 01:29:16.585023 11876 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0401 01:29:22.108191 11876 solver.cpp:228] Iteration 24200, loss = 0.453538
I0401 01:29:22.108191 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:29:22.108191 11876 solver.cpp:244]     Train net output #1: loss = 0.453538 (* 1 = 0.453538 loss)
I0401 01:29:22.108191 11876 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0401 01:29:27.625969 11876 solver.cpp:228] Iteration 24300, loss = 0.513636
I0401 01:29:27.626466 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:29:27.626466 11876 solver.cpp:244]     Train net output #1: loss = 0.513636 (* 1 = 0.513636 loss)
I0401 01:29:27.626466 11876 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0401 01:29:33.136948 11876 solver.cpp:228] Iteration 24400, loss = 0.436732
I0401 01:29:33.136948 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:29:33.136948 11876 solver.cpp:244]     Train net output #1: loss = 0.436732 (* 1 = 0.436732 loss)
I0401 01:29:33.136948 11876 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0401 01:29:38.659915 11876 solver.cpp:228] Iteration 24500, loss = 0.66226
I0401 01:29:38.659915 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.76
I0401 01:29:38.659915 11876 solver.cpp:244]     Train net output #1: loss = 0.66226 (* 1 = 0.66226 loss)
I0401 01:29:38.659915 11876 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0401 01:29:44.163838 11876 solver.cpp:228] Iteration 24600, loss = 0.392106
I0401 01:29:44.163838 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:29:44.163838 11876 solver.cpp:244]     Train net output #1: loss = 0.392105 (* 1 = 0.392105 loss)
I0401 01:29:44.163838 11876 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0401 01:29:49.679764 11876 solver.cpp:228] Iteration 24700, loss = 0.476447
I0401 01:29:49.679764 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:29:49.679764 11876 solver.cpp:244]     Train net output #1: loss = 0.476446 (* 1 = 0.476446 loss)
I0401 01:29:49.679764 11876 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0401 01:29:55.208183 11876 solver.cpp:228] Iteration 24800, loss = 0.491467
I0401 01:29:55.208183 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:29:55.208183 11876 solver.cpp:244]     Train net output #1: loss = 0.491467 (* 1 = 0.491467 loss)
I0401 01:29:55.208183 11876 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0401 01:30:00.727200 11876 solver.cpp:228] Iteration 24900, loss = 0.377519
I0401 01:30:00.727200 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:30:00.727200 11876 solver.cpp:244]     Train net output #1: loss = 0.377518 (* 1 = 0.377518 loss)
I0401 01:30:00.727200 11876 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0401 01:30:06.225265 11876 solver.cpp:337] Iteration 25000, Testing net (#0)
I0401 01:30:06.225764 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:30:07.842609 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7573
I0401 01:30:07.842609 11876 solver.cpp:404]     Test net output #1: loss = 0.740411 (* 1 = 0.740411 loss)
I0401 01:30:07.863616 11876 solver.cpp:228] Iteration 25000, loss = 0.508118
I0401 01:30:07.863616 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:30:07.863616 11876 solver.cpp:244]     Train net output #1: loss = 0.508117 (* 1 = 0.508117 loss)
I0401 01:30:07.863616 11876 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0401 01:30:13.390537 11876 solver.cpp:228] Iteration 25100, loss = 0.462339
I0401 01:30:13.390537 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:30:13.390537 11876 solver.cpp:244]     Train net output #1: loss = 0.462338 (* 1 = 0.462338 loss)
I0401 01:30:13.390537 11876 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0401 01:30:18.924538 11876 solver.cpp:228] Iteration 25200, loss = 0.450461
I0401 01:30:18.925040 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:30:18.925040 11876 solver.cpp:244]     Train net output #1: loss = 0.450461 (* 1 = 0.450461 loss)
I0401 01:30:18.925040 11876 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0401 01:30:24.448776 11876 solver.cpp:228] Iteration 25300, loss = 0.473267
I0401 01:30:24.448776 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:30:24.448776 11876 solver.cpp:244]     Train net output #1: loss = 0.473267 (* 1 = 0.473267 loss)
I0401 01:30:24.448776 11876 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0401 01:30:29.970510 11876 solver.cpp:228] Iteration 25400, loss = 0.360777
I0401 01:30:29.971516 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:30:29.971516 11876 solver.cpp:244]     Train net output #1: loss = 0.360777 (* 1 = 0.360777 loss)
I0401 01:30:29.971516 11876 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0401 01:30:35.495944 11876 solver.cpp:228] Iteration 25500, loss = 0.487702
I0401 01:30:35.495944 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:30:35.495944 11876 solver.cpp:244]     Train net output #1: loss = 0.487702 (* 1 = 0.487702 loss)
I0401 01:30:35.495944 11876 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0401 01:30:41.025270 11876 solver.cpp:228] Iteration 25600, loss = 0.386406
I0401 01:30:41.025270 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:30:41.025270 11876 solver.cpp:244]     Train net output #1: loss = 0.386406 (* 1 = 0.386406 loss)
I0401 01:30:41.025270 11876 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0401 01:30:46.550632 11876 solver.cpp:228] Iteration 25700, loss = 0.493796
I0401 01:30:46.550632 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:30:46.550632 11876 solver.cpp:244]     Train net output #1: loss = 0.493796 (* 1 = 0.493796 loss)
I0401 01:30:46.550632 11876 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0401 01:30:52.088907 11876 solver.cpp:228] Iteration 25800, loss = 0.469007
I0401 01:30:52.088907 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:30:52.088907 11876 solver.cpp:244]     Train net output #1: loss = 0.469006 (* 1 = 0.469006 loss)
I0401 01:30:52.088907 11876 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0401 01:30:57.624732 11876 solver.cpp:228] Iteration 25900, loss = 0.346894
I0401 01:30:57.624732 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:30:57.624732 11876 solver.cpp:244]     Train net output #1: loss = 0.346894 (* 1 = 0.346894 loss)
I0401 01:30:57.624732 11876 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0401 01:31:03.136968 11876 solver.cpp:337] Iteration 26000, Testing net (#0)
I0401 01:31:03.137468 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:31:04.745601 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7911
I0401 01:31:04.745601 11876 solver.cpp:404]     Test net output #1: loss = 0.630985 (* 1 = 0.630985 loss)
I0401 01:31:04.766605 11876 solver.cpp:228] Iteration 26000, loss = 0.475741
I0401 01:31:04.766605 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:31:04.766605 11876 solver.cpp:244]     Train net output #1: loss = 0.475741 (* 1 = 0.475741 loss)
I0401 01:31:04.766605 11876 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0401 01:31:10.276569 11876 solver.cpp:228] Iteration 26100, loss = 0.448958
I0401 01:31:10.276569 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:31:10.276569 11876 solver.cpp:244]     Train net output #1: loss = 0.448957 (* 1 = 0.448957 loss)
I0401 01:31:10.276569 11876 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0401 01:31:15.791461 11876 solver.cpp:228] Iteration 26200, loss = 0.413101
I0401 01:31:15.791461 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:31:15.791461 11876 solver.cpp:244]     Train net output #1: loss = 0.413101 (* 1 = 0.413101 loss)
I0401 01:31:15.791461 11876 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0401 01:31:21.319020 11876 solver.cpp:228] Iteration 26300, loss = 0.594766
I0401 01:31:21.319020 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:31:21.319020 11876 solver.cpp:244]     Train net output #1: loss = 0.594766 (* 1 = 0.594766 loss)
I0401 01:31:21.319020 11876 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0401 01:31:26.846767 11876 solver.cpp:228] Iteration 26400, loss = 0.360786
I0401 01:31:26.846767 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:31:26.846767 11876 solver.cpp:244]     Train net output #1: loss = 0.360786 (* 1 = 0.360786 loss)
I0401 01:31:26.846767 11876 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0401 01:31:32.369482 11876 solver.cpp:228] Iteration 26500, loss = 0.431514
I0401 01:31:32.369482 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:31:32.369482 11876 solver.cpp:244]     Train net output #1: loss = 0.431514 (* 1 = 0.431514 loss)
I0401 01:31:32.369482 11876 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0401 01:31:37.895331 11876 solver.cpp:228] Iteration 26600, loss = 0.404843
I0401 01:31:37.895331 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:31:37.895331 11876 solver.cpp:244]     Train net output #1: loss = 0.404843 (* 1 = 0.404843 loss)
I0401 01:31:37.895331 11876 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0401 01:31:43.415385 11876 solver.cpp:228] Iteration 26700, loss = 0.481492
I0401 01:31:43.415385 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:31:43.415385 11876 solver.cpp:244]     Train net output #1: loss = 0.481491 (* 1 = 0.481491 loss)
I0401 01:31:43.415385 11876 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0401 01:31:48.938271 11876 solver.cpp:228] Iteration 26800, loss = 0.523373
I0401 01:31:48.938271 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:31:48.938271 11876 solver.cpp:244]     Train net output #1: loss = 0.523373 (* 1 = 0.523373 loss)
I0401 01:31:48.938271 11876 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0401 01:31:54.453964 11876 solver.cpp:228] Iteration 26900, loss = 0.38148
I0401 01:31:54.453964 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:31:54.453964 11876 solver.cpp:244]     Train net output #1: loss = 0.38148 (* 1 = 0.38148 loss)
I0401 01:31:54.454464 11876 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0401 01:31:59.961796 11876 solver.cpp:337] Iteration 27000, Testing net (#0)
I0401 01:31:59.961796 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:32:01.574101 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0401 01:32:01.574101 11876 solver.cpp:404]     Test net output #1: loss = 0.790307 (* 1 = 0.790307 loss)
I0401 01:32:01.596102 11876 solver.cpp:228] Iteration 27000, loss = 0.492252
I0401 01:32:01.596102 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:32:01.596102 11876 solver.cpp:244]     Train net output #1: loss = 0.492252 (* 1 = 0.492252 loss)
I0401 01:32:01.596102 11876 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0401 01:32:07.119052 11876 solver.cpp:228] Iteration 27100, loss = 0.404152
I0401 01:32:07.119052 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:32:07.119052 11876 solver.cpp:244]     Train net output #1: loss = 0.404152 (* 1 = 0.404152 loss)
I0401 01:32:07.119052 11876 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0401 01:32:12.638098 11876 solver.cpp:228] Iteration 27200, loss = 0.490386
I0401 01:32:12.638098 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.84
I0401 01:32:12.638098 11876 solver.cpp:244]     Train net output #1: loss = 0.490386 (* 1 = 0.490386 loss)
I0401 01:32:12.638098 11876 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0401 01:32:18.159468 11876 solver.cpp:228] Iteration 27300, loss = 0.450075
I0401 01:32:18.159468 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:32:18.159468 11876 solver.cpp:244]     Train net output #1: loss = 0.450075 (* 1 = 0.450075 loss)
I0401 01:32:18.159468 11876 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0401 01:32:23.698004 11876 solver.cpp:228] Iteration 27400, loss = 0.383822
I0401 01:32:23.698004 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:32:23.698004 11876 solver.cpp:244]     Train net output #1: loss = 0.383822 (* 1 = 0.383822 loss)
I0401 01:32:23.698004 11876 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0401 01:32:29.230902 11876 solver.cpp:228] Iteration 27500, loss = 0.350773
I0401 01:32:29.230902 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:32:29.230902 11876 solver.cpp:244]     Train net output #1: loss = 0.350773 (* 1 = 0.350773 loss)
I0401 01:32:29.230902 11876 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0401 01:32:34.764428 11876 solver.cpp:228] Iteration 27600, loss = 0.430933
I0401 01:32:34.764428 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:32:34.764428 11876 solver.cpp:244]     Train net output #1: loss = 0.430933 (* 1 = 0.430933 loss)
I0401 01:32:34.764428 11876 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0401 01:32:40.284359 11876 solver.cpp:228] Iteration 27700, loss = 0.551251
I0401 01:32:40.284359 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:32:40.284359 11876 solver.cpp:244]     Train net output #1: loss = 0.551251 (* 1 = 0.551251 loss)
I0401 01:32:40.284359 11876 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0401 01:32:45.809427 11876 solver.cpp:228] Iteration 27800, loss = 0.448066
I0401 01:32:45.809427 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:32:45.809427 11876 solver.cpp:244]     Train net output #1: loss = 0.448065 (* 1 = 0.448065 loss)
I0401 01:32:45.809427 11876 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0401 01:32:51.327685 11876 solver.cpp:228] Iteration 27900, loss = 0.359747
I0401 01:32:51.327685 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:32:51.327685 11876 solver.cpp:244]     Train net output #1: loss = 0.359747 (* 1 = 0.359747 loss)
I0401 01:32:51.327685 11876 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0401 01:32:56.824673 11876 solver.cpp:337] Iteration 28000, Testing net (#0)
I0401 01:32:56.824673 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:32:58.437104 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8036
I0401 01:32:58.437104 11876 solver.cpp:404]     Test net output #1: loss = 0.589301 (* 1 = 0.589301 loss)
I0401 01:32:58.458103 11876 solver.cpp:228] Iteration 28000, loss = 0.40554
I0401 01:32:58.458103 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:32:58.458103 11876 solver.cpp:244]     Train net output #1: loss = 0.40554 (* 1 = 0.40554 loss)
I0401 01:32:58.458103 11876 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0401 01:33:03.991380 11876 solver.cpp:228] Iteration 28100, loss = 0.501054
I0401 01:33:03.991380 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:33:03.991380 11876 solver.cpp:244]     Train net output #1: loss = 0.501054 (* 1 = 0.501054 loss)
I0401 01:33:03.991380 11876 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0401 01:33:09.535581 11876 solver.cpp:228] Iteration 28200, loss = 0.410589
I0401 01:33:09.535581 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:33:09.535581 11876 solver.cpp:244]     Train net output #1: loss = 0.410589 (* 1 = 0.410589 loss)
I0401 01:33:09.535581 11876 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0401 01:33:15.083127 11876 solver.cpp:228] Iteration 28300, loss = 0.467359
I0401 01:33:15.083127 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:33:15.083127 11876 solver.cpp:244]     Train net output #1: loss = 0.467359 (* 1 = 0.467359 loss)
I0401 01:33:15.083127 11876 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0401 01:33:20.616518 11876 solver.cpp:228] Iteration 28400, loss = 0.348523
I0401 01:33:20.616518 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.87
I0401 01:33:20.616518 11876 solver.cpp:244]     Train net output #1: loss = 0.348523 (* 1 = 0.348523 loss)
I0401 01:33:20.616518 11876 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0401 01:33:26.169970 11876 solver.cpp:228] Iteration 28500, loss = 0.455877
I0401 01:33:26.170471 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:33:26.170471 11876 solver.cpp:244]     Train net output #1: loss = 0.455876 (* 1 = 0.455876 loss)
I0401 01:33:26.170471 11876 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0401 01:33:31.697799 11876 solver.cpp:228] Iteration 28600, loss = 0.61999
I0401 01:33:31.698299 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:33:31.698299 11876 solver.cpp:244]     Train net output #1: loss = 0.619989 (* 1 = 0.619989 loss)
I0401 01:33:31.698299 11876 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0401 01:33:37.244943 11876 solver.cpp:228] Iteration 28700, loss = 0.481081
I0401 01:33:37.244943 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:33:37.244943 11876 solver.cpp:244]     Train net output #1: loss = 0.481081 (* 1 = 0.481081 loss)
I0401 01:33:37.244943 11876 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0401 01:33:42.818799 11876 solver.cpp:228] Iteration 28800, loss = 0.507505
I0401 01:33:42.818799 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:33:42.818799 11876 solver.cpp:244]     Train net output #1: loss = 0.507505 (* 1 = 0.507505 loss)
I0401 01:33:42.818799 11876 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0401 01:33:48.365334 11876 solver.cpp:228] Iteration 28900, loss = 0.305258
I0401 01:33:48.365334 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:33:48.365334 11876 solver.cpp:244]     Train net output #1: loss = 0.305258 (* 1 = 0.305258 loss)
I0401 01:33:48.365334 11876 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0401 01:33:53.873929 11876 solver.cpp:337] Iteration 29000, Testing net (#0)
I0401 01:33:53.873929 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:33:55.481242 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7746
I0401 01:33:55.481242 11876 solver.cpp:404]     Test net output #1: loss = 0.666651 (* 1 = 0.666651 loss)
I0401 01:33:55.503257 11876 solver.cpp:228] Iteration 29000, loss = 0.377682
I0401 01:33:55.503257 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:33:55.503257 11876 solver.cpp:244]     Train net output #1: loss = 0.377682 (* 1 = 0.377682 loss)
I0401 01:33:55.503257 11876 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0401 01:34:01.042660 11876 solver.cpp:228] Iteration 29100, loss = 0.507049
I0401 01:34:01.042660 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:34:01.042660 11876 solver.cpp:244]     Train net output #1: loss = 0.507048 (* 1 = 0.507048 loss)
I0401 01:34:01.042660 11876 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0401 01:34:06.614796 11876 solver.cpp:228] Iteration 29200, loss = 0.445024
I0401 01:34:06.615298 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:34:06.615298 11876 solver.cpp:244]     Train net output #1: loss = 0.445024 (* 1 = 0.445024 loss)
I0401 01:34:06.615298 11876 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0401 01:34:12.174217 11876 solver.cpp:228] Iteration 29300, loss = 0.505834
I0401 01:34:12.174217 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:34:12.174217 11876 solver.cpp:244]     Train net output #1: loss = 0.505834 (* 1 = 0.505834 loss)
I0401 01:34:12.174217 11876 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0401 01:34:17.700673 11876 solver.cpp:228] Iteration 29400, loss = 0.382504
I0401 01:34:17.700673 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:34:17.700673 11876 solver.cpp:244]     Train net output #1: loss = 0.382503 (* 1 = 0.382503 loss)
I0401 01:34:17.700673 11876 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0401 01:34:23.238777 11876 solver.cpp:228] Iteration 29500, loss = 0.497246
I0401 01:34:23.238777 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:34:23.238777 11876 solver.cpp:244]     Train net output #1: loss = 0.497246 (* 1 = 0.497246 loss)
I0401 01:34:23.238777 11876 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0401 01:34:28.765250 11876 solver.cpp:228] Iteration 29600, loss = 0.346921
I0401 01:34:28.765769 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:34:28.765769 11876 solver.cpp:244]     Train net output #1: loss = 0.346921 (* 1 = 0.346921 loss)
I0401 01:34:28.765769 11876 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0401 01:34:34.323905 11876 solver.cpp:228] Iteration 29700, loss = 0.449277
I0401 01:34:34.323905 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:34:34.323905 11876 solver.cpp:244]     Train net output #1: loss = 0.449277 (* 1 = 0.449277 loss)
I0401 01:34:34.323905 11876 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0401 01:34:39.889590 11876 solver.cpp:228] Iteration 29800, loss = 0.584211
I0401 01:34:39.889590 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:34:39.889590 11876 solver.cpp:244]     Train net output #1: loss = 0.584211 (* 1 = 0.584211 loss)
I0401 01:34:39.889590 11876 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0401 01:34:45.417270 11876 solver.cpp:228] Iteration 29900, loss = 0.345821
I0401 01:34:45.417270 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:34:45.417270 11876 solver.cpp:244]     Train net output #1: loss = 0.345821 (* 1 = 0.345821 loss)
I0401 01:34:45.417270 11876 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0401 01:34:50.945811 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_30000.caffemodel
I0401 01:34:50.961813 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_30000.solverstate
I0401 01:34:50.963811 11876 solver.cpp:337] Iteration 30000, Testing net (#0)
I0401 01:34:50.963811 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:34:52.590052 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8022
I0401 01:34:52.590052 11876 solver.cpp:404]     Test net output #1: loss = 0.599989 (* 1 = 0.599989 loss)
I0401 01:34:52.611059 11876 solver.cpp:228] Iteration 30000, loss = 0.556808
I0401 01:34:52.611059 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:34:52.611059 11876 solver.cpp:244]     Train net output #1: loss = 0.556807 (* 1 = 0.556807 loss)
I0401 01:34:52.611059 11876 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0401 01:34:58.170856 11876 solver.cpp:228] Iteration 30100, loss = 0.334007
I0401 01:34:58.170856 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:34:58.170856 11876 solver.cpp:244]     Train net output #1: loss = 0.334006 (* 1 = 0.334006 loss)
I0401 01:34:58.170856 11876 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0401 01:35:03.718818 11876 solver.cpp:228] Iteration 30200, loss = 0.480786
I0401 01:35:03.718818 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:35:03.718818 11876 solver.cpp:244]     Train net output #1: loss = 0.480786 (* 1 = 0.480786 loss)
I0401 01:35:03.718818 11876 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0401 01:35:09.277407 11876 solver.cpp:228] Iteration 30300, loss = 0.516767
I0401 01:35:09.277407 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.82
I0401 01:35:09.277407 11876 solver.cpp:244]     Train net output #1: loss = 0.516767 (* 1 = 0.516767 loss)
I0401 01:35:09.277407 11876 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0401 01:35:14.820924 11876 solver.cpp:228] Iteration 30400, loss = 0.393938
I0401 01:35:14.821925 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:35:14.821925 11876 solver.cpp:244]     Train net output #1: loss = 0.393938 (* 1 = 0.393938 loss)
I0401 01:35:14.821925 11876 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0401 01:35:20.398432 11876 solver.cpp:228] Iteration 30500, loss = 0.512357
I0401 01:35:20.398932 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.81
I0401 01:35:20.398932 11876 solver.cpp:244]     Train net output #1: loss = 0.512356 (* 1 = 0.512356 loss)
I0401 01:35:20.398932 11876 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0401 01:35:25.925068 11876 solver.cpp:228] Iteration 30600, loss = 0.40229
I0401 01:35:25.925068 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:35:25.925068 11876 solver.cpp:244]     Train net output #1: loss = 0.40229 (* 1 = 0.40229 loss)
I0401 01:35:25.925068 11876 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0401 01:35:31.479233 11876 solver.cpp:228] Iteration 30700, loss = 0.65607
I0401 01:35:31.479233 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.79
I0401 01:35:31.479233 11876 solver.cpp:244]     Train net output #1: loss = 0.65607 (* 1 = 0.65607 loss)
I0401 01:35:31.479233 11876 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0401 01:35:37.045395 11876 solver.cpp:228] Iteration 30800, loss = 0.448844
I0401 01:35:37.045395 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:35:37.045395 11876 solver.cpp:244]     Train net output #1: loss = 0.448844 (* 1 = 0.448844 loss)
I0401 01:35:37.045395 11876 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0401 01:35:42.578896 11876 solver.cpp:228] Iteration 30900, loss = 0.358933
I0401 01:35:42.578896 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:35:42.578896 11876 solver.cpp:244]     Train net output #1: loss = 0.358933 (* 1 = 0.358933 loss)
I0401 01:35:42.578896 11876 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0401 01:35:48.084764 11876 solver.cpp:337] Iteration 31000, Testing net (#0)
I0401 01:35:48.084764 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:35:49.701055 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7858
I0401 01:35:49.701055 11876 solver.cpp:404]     Test net output #1: loss = 0.665482 (* 1 = 0.665482 loss)
I0401 01:35:49.723062 11876 solver.cpp:228] Iteration 31000, loss = 0.512357
I0401 01:35:49.723062 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:35:49.723062 11876 solver.cpp:244]     Train net output #1: loss = 0.512357 (* 1 = 0.512357 loss)
I0401 01:35:49.723062 11876 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0401 01:35:55.269474 11876 solver.cpp:228] Iteration 31100, loss = 0.422471
I0401 01:35:55.269474 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:35:55.269474 11876 solver.cpp:244]     Train net output #1: loss = 0.422471 (* 1 = 0.422471 loss)
I0401 01:35:55.269474 11876 sgd_solver.cpp:106] Iteration 31100, lr = 0.01
I0401 01:36:00.813186 11876 solver.cpp:228] Iteration 31200, loss = 0.416994
I0401 01:36:00.813186 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:36:00.813186 11876 solver.cpp:244]     Train net output #1: loss = 0.416993 (* 1 = 0.416993 loss)
I0401 01:36:00.813186 11876 sgd_solver.cpp:106] Iteration 31200, lr = 0.01
I0401 01:36:06.342434 11876 solver.cpp:228] Iteration 31300, loss = 0.546434
I0401 01:36:06.342434 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:36:06.342434 11876 solver.cpp:244]     Train net output #1: loss = 0.546434 (* 1 = 0.546434 loss)
I0401 01:36:06.342434 11876 sgd_solver.cpp:106] Iteration 31300, lr = 0.01
I0401 01:36:11.887524 11876 solver.cpp:228] Iteration 31400, loss = 0.349808
I0401 01:36:11.887524 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:36:11.887524 11876 solver.cpp:244]     Train net output #1: loss = 0.349808 (* 1 = 0.349808 loss)
I0401 01:36:11.888525 11876 sgd_solver.cpp:106] Iteration 31400, lr = 0.01
I0401 01:36:17.424263 11876 solver.cpp:228] Iteration 31500, loss = 0.301192
I0401 01:36:17.424263 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:36:17.424263 11876 solver.cpp:244]     Train net output #1: loss = 0.301192 (* 1 = 0.301192 loss)
I0401 01:36:17.424263 11876 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0401 01:36:22.986444 11876 solver.cpp:228] Iteration 31600, loss = 0.453595
I0401 01:36:22.986444 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:36:22.986444 11876 solver.cpp:244]     Train net output #1: loss = 0.453595 (* 1 = 0.453595 loss)
I0401 01:36:22.986444 11876 sgd_solver.cpp:106] Iteration 31600, lr = 0.01
I0401 01:36:28.537135 11876 solver.cpp:228] Iteration 31700, loss = 0.460612
I0401 01:36:28.537135 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.85
I0401 01:36:28.537135 11876 solver.cpp:244]     Train net output #1: loss = 0.460612 (* 1 = 0.460612 loss)
I0401 01:36:28.537135 11876 sgd_solver.cpp:106] Iteration 31700, lr = 0.01
I0401 01:36:34.095324 11876 solver.cpp:228] Iteration 31800, loss = 0.488389
I0401 01:36:34.095324 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.83
I0401 01:36:34.095324 11876 solver.cpp:244]     Train net output #1: loss = 0.488389 (* 1 = 0.488389 loss)
I0401 01:36:34.095324 11876 sgd_solver.cpp:106] Iteration 31800, lr = 0.01
I0401 01:36:39.640930 11876 solver.cpp:228] Iteration 31900, loss = 0.413931
I0401 01:36:39.641420 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:36:39.641420 11876 solver.cpp:244]     Train net output #1: loss = 0.413931 (* 1 = 0.413931 loss)
I0401 01:36:39.641420 11876 sgd_solver.cpp:106] Iteration 31900, lr = 0.01
I0401 01:36:45.147053 11876 solver.cpp:337] Iteration 32000, Testing net (#0)
I0401 01:36:45.147053 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:36:46.764588 11876 solver.cpp:404]     Test net output #0: accuracy = 0.7165
I0401 01:36:46.764588 11876 solver.cpp:404]     Test net output #1: loss = 0.895603 (* 1 = 0.895603 loss)
I0401 01:36:46.784588 11876 solver.cpp:228] Iteration 32000, loss = 0.458576
I0401 01:36:46.784588 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.86
I0401 01:36:46.784588 11876 solver.cpp:244]     Train net output #1: loss = 0.458575 (* 1 = 0.458575 loss)
I0401 01:36:46.784588 11876 sgd_solver.cpp:46] MultiStep Status: Iteration 32000, step = 1
I0401 01:36:46.784588 11876 sgd_solver.cpp:106] Iteration 32000, lr = 0.001
I0401 01:36:52.324307 11876 solver.cpp:228] Iteration 32100, loss = 0.31863
I0401 01:36:52.324307 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:36:52.324307 11876 solver.cpp:244]     Train net output #1: loss = 0.318629 (* 1 = 0.318629 loss)
I0401 01:36:52.324307 11876 sgd_solver.cpp:106] Iteration 32100, lr = 0.001
I0401 01:36:57.870920 11876 solver.cpp:228] Iteration 32200, loss = 0.361815
I0401 01:36:57.870920 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:36:57.870920 11876 solver.cpp:244]     Train net output #1: loss = 0.361815 (* 1 = 0.361815 loss)
I0401 01:36:57.870920 11876 sgd_solver.cpp:106] Iteration 32200, lr = 0.001
I0401 01:37:03.461664 11876 solver.cpp:228] Iteration 32300, loss = 0.289628
I0401 01:37:03.461664 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:37:03.461664 11876 solver.cpp:244]     Train net output #1: loss = 0.289628 (* 1 = 0.289628 loss)
I0401 01:37:03.461664 11876 sgd_solver.cpp:106] Iteration 32300, lr = 0.001
I0401 01:37:09.051513 11876 solver.cpp:228] Iteration 32400, loss = 0.221827
I0401 01:37:09.051513 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:37:09.051513 11876 solver.cpp:244]     Train net output #1: loss = 0.221826 (* 1 = 0.221826 loss)
I0401 01:37:09.051513 11876 sgd_solver.cpp:106] Iteration 32400, lr = 0.001
I0401 01:37:14.609930 11876 solver.cpp:228] Iteration 32500, loss = 0.242122
I0401 01:37:14.609930 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:37:14.609930 11876 solver.cpp:244]     Train net output #1: loss = 0.242122 (* 1 = 0.242122 loss)
I0401 01:37:14.609930 11876 sgd_solver.cpp:106] Iteration 32500, lr = 0.001
I0401 01:37:20.146765 11876 solver.cpp:228] Iteration 32600, loss = 0.231501
I0401 01:37:20.146765 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:37:20.147264 11876 solver.cpp:244]     Train net output #1: loss = 0.231501 (* 1 = 0.231501 loss)
I0401 01:37:20.147264 11876 sgd_solver.cpp:106] Iteration 32600, lr = 0.001
I0401 01:37:25.699350 11876 solver.cpp:228] Iteration 32700, loss = 0.314479
I0401 01:37:25.699350 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:37:25.699350 11876 solver.cpp:244]     Train net output #1: loss = 0.314478 (* 1 = 0.314478 loss)
I0401 01:37:25.699350 11876 sgd_solver.cpp:106] Iteration 32700, lr = 0.001
I0401 01:37:31.244427 11876 solver.cpp:228] Iteration 32800, loss = 0.341307
I0401 01:37:31.244427 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:37:31.244427 11876 solver.cpp:244]     Train net output #1: loss = 0.341307 (* 1 = 0.341307 loss)
I0401 01:37:31.244427 11876 sgd_solver.cpp:106] Iteration 32800, lr = 0.001
I0401 01:37:36.785967 11876 solver.cpp:228] Iteration 32900, loss = 0.185897
I0401 01:37:36.785967 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:37:36.785967 11876 solver.cpp:244]     Train net output #1: loss = 0.185896 (* 1 = 0.185896 loss)
I0401 01:37:36.785967 11876 sgd_solver.cpp:106] Iteration 32900, lr = 0.001
I0401 01:37:42.300436 11876 solver.cpp:337] Iteration 33000, Testing net (#0)
I0401 01:37:42.300436 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:37:43.912173 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8955
I0401 01:37:43.912173 11876 solver.cpp:404]     Test net output #1: loss = 0.312503 (* 1 = 0.312503 loss)
I0401 01:37:43.933188 11876 solver.cpp:228] Iteration 33000, loss = 0.255014
I0401 01:37:43.933188 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:37:43.933188 11876 solver.cpp:244]     Train net output #1: loss = 0.255013 (* 1 = 0.255013 loss)
I0401 01:37:43.933188 11876 sgd_solver.cpp:106] Iteration 33000, lr = 0.001
I0401 01:37:49.456480 11876 solver.cpp:228] Iteration 33100, loss = 0.246305
I0401 01:37:49.456480 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:37:49.456480 11876 solver.cpp:244]     Train net output #1: loss = 0.246305 (* 1 = 0.246305 loss)
I0401 01:37:49.456480 11876 sgd_solver.cpp:106] Iteration 33100, lr = 0.001
I0401 01:37:54.983969 11876 solver.cpp:228] Iteration 33200, loss = 0.253242
I0401 01:37:54.983969 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:37:54.983969 11876 solver.cpp:244]     Train net output #1: loss = 0.253242 (* 1 = 0.253242 loss)
I0401 01:37:54.983969 11876 sgd_solver.cpp:106] Iteration 33200, lr = 0.001
I0401 01:38:00.525161 11876 solver.cpp:228] Iteration 33300, loss = 0.255376
I0401 01:38:00.525161 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:38:00.525161 11876 solver.cpp:244]     Train net output #1: loss = 0.255376 (* 1 = 0.255376 loss)
I0401 01:38:00.525161 11876 sgd_solver.cpp:106] Iteration 33300, lr = 0.001
I0401 01:38:06.074712 11876 solver.cpp:228] Iteration 33400, loss = 0.226302
I0401 01:38:06.074712 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:38:06.074712 11876 solver.cpp:244]     Train net output #1: loss = 0.226302 (* 1 = 0.226302 loss)
I0401 01:38:06.074712 11876 sgd_solver.cpp:106] Iteration 33400, lr = 0.001
I0401 01:38:11.599107 11876 solver.cpp:228] Iteration 33500, loss = 0.248442
I0401 01:38:11.599607 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:38:11.599607 11876 solver.cpp:244]     Train net output #1: loss = 0.248441 (* 1 = 0.248441 loss)
I0401 01:38:11.599607 11876 sgd_solver.cpp:106] Iteration 33500, lr = 0.001
I0401 01:38:17.116752 11876 solver.cpp:228] Iteration 33600, loss = 0.260807
I0401 01:38:17.116752 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:38:17.116752 11876 solver.cpp:244]     Train net output #1: loss = 0.260807 (* 1 = 0.260807 loss)
I0401 01:38:17.116752 11876 sgd_solver.cpp:106] Iteration 33600, lr = 0.001
I0401 01:38:22.645102 11876 solver.cpp:228] Iteration 33700, loss = 0.201548
I0401 01:38:22.645102 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:38:22.645102 11876 solver.cpp:244]     Train net output #1: loss = 0.201548 (* 1 = 0.201548 loss)
I0401 01:38:22.645102 11876 sgd_solver.cpp:106] Iteration 33700, lr = 0.001
I0401 01:38:28.169455 11876 solver.cpp:228] Iteration 33800, loss = 0.237946
I0401 01:38:28.169455 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:38:28.169455 11876 solver.cpp:244]     Train net output #1: loss = 0.237946 (* 1 = 0.237946 loss)
I0401 01:38:28.169455 11876 sgd_solver.cpp:106] Iteration 33800, lr = 0.001
I0401 01:38:33.698210 11876 solver.cpp:228] Iteration 33900, loss = 0.192828
I0401 01:38:33.698210 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:38:33.698210 11876 solver.cpp:244]     Train net output #1: loss = 0.192827 (* 1 = 0.192827 loss)
I0401 01:38:33.698210 11876 sgd_solver.cpp:106] Iteration 33900, lr = 0.001
I0401 01:38:39.195834 11876 solver.cpp:337] Iteration 34000, Testing net (#0)
I0401 01:38:39.195834 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:38:40.813583 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8958
I0401 01:38:40.813583 11876 solver.cpp:404]     Test net output #1: loss = 0.31505 (* 1 = 0.31505 loss)
I0401 01:38:40.834581 11876 solver.cpp:228] Iteration 34000, loss = 0.228318
I0401 01:38:40.834581 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:38:40.834581 11876 solver.cpp:244]     Train net output #1: loss = 0.228318 (* 1 = 0.228318 loss)
I0401 01:38:40.834581 11876 sgd_solver.cpp:106] Iteration 34000, lr = 0.001
I0401 01:38:46.359215 11876 solver.cpp:228] Iteration 34100, loss = 0.246785
I0401 01:38:46.359215 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:38:46.359215 11876 solver.cpp:244]     Train net output #1: loss = 0.246785 (* 1 = 0.246785 loss)
I0401 01:38:46.359215 11876 sgd_solver.cpp:106] Iteration 34100, lr = 0.001
I0401 01:38:51.902896 11876 solver.cpp:228] Iteration 34200, loss = 0.232594
I0401 01:38:51.902896 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:38:51.902896 11876 solver.cpp:244]     Train net output #1: loss = 0.232594 (* 1 = 0.232594 loss)
I0401 01:38:51.902896 11876 sgd_solver.cpp:106] Iteration 34200, lr = 0.001
I0401 01:38:57.450094 11876 solver.cpp:228] Iteration 34300, loss = 0.236934
I0401 01:38:57.450094 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:38:57.450094 11876 solver.cpp:244]     Train net output #1: loss = 0.236934 (* 1 = 0.236934 loss)
I0401 01:38:57.450094 11876 sgd_solver.cpp:106] Iteration 34300, lr = 0.001
I0401 01:39:03.030280 11876 solver.cpp:228] Iteration 34400, loss = 0.144375
I0401 01:39:03.030781 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:39:03.030781 11876 solver.cpp:244]     Train net output #1: loss = 0.144375 (* 1 = 0.144375 loss)
I0401 01:39:03.030781 11876 sgd_solver.cpp:106] Iteration 34400, lr = 0.001
I0401 01:39:08.626320 11876 solver.cpp:228] Iteration 34500, loss = 0.225526
I0401 01:39:08.626821 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:39:08.626821 11876 solver.cpp:244]     Train net output #1: loss = 0.225525 (* 1 = 0.225525 loss)
I0401 01:39:08.626821 11876 sgd_solver.cpp:106] Iteration 34500, lr = 0.001
I0401 01:39:14.217664 11876 solver.cpp:228] Iteration 34600, loss = 0.198198
I0401 01:39:14.217664 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:39:14.217664 11876 solver.cpp:244]     Train net output #1: loss = 0.198198 (* 1 = 0.198198 loss)
I0401 01:39:14.217664 11876 sgd_solver.cpp:106] Iteration 34600, lr = 0.001
I0401 01:39:19.799396 11876 solver.cpp:228] Iteration 34700, loss = 0.206519
I0401 01:39:19.799396 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:39:19.800395 11876 solver.cpp:244]     Train net output #1: loss = 0.206518 (* 1 = 0.206518 loss)
I0401 01:39:19.800395 11876 sgd_solver.cpp:106] Iteration 34700, lr = 0.001
I0401 01:39:25.360221 11876 solver.cpp:228] Iteration 34800, loss = 0.20479
I0401 01:39:25.360221 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:39:25.360221 11876 solver.cpp:244]     Train net output #1: loss = 0.20479 (* 1 = 0.20479 loss)
I0401 01:39:25.360221 11876 sgd_solver.cpp:106] Iteration 34800, lr = 0.001
I0401 01:39:30.912597 11876 solver.cpp:228] Iteration 34900, loss = 0.15189
I0401 01:39:30.912597 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:39:30.912597 11876 solver.cpp:244]     Train net output #1: loss = 0.15189 (* 1 = 0.15189 loss)
I0401 01:39:30.912597 11876 sgd_solver.cpp:106] Iteration 34900, lr = 0.001
I0401 01:39:36.455128 11876 solver.cpp:337] Iteration 35000, Testing net (#0)
I0401 01:39:36.455128 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:39:38.093725 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9023
I0401 01:39:38.093725 11876 solver.cpp:404]     Test net output #1: loss = 0.299366 (* 1 = 0.299366 loss)
I0401 01:39:38.115713 11876 solver.cpp:228] Iteration 35000, loss = 0.265132
I0401 01:39:38.115713 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:39:38.115713 11876 solver.cpp:244]     Train net output #1: loss = 0.265131 (* 1 = 0.265131 loss)
I0401 01:39:38.115713 11876 sgd_solver.cpp:106] Iteration 35000, lr = 0.001
I0401 01:39:43.689846 11876 solver.cpp:228] Iteration 35100, loss = 0.227743
I0401 01:39:43.689846 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:39:43.689846 11876 solver.cpp:244]     Train net output #1: loss = 0.227742 (* 1 = 0.227742 loss)
I0401 01:39:43.689846 11876 sgd_solver.cpp:106] Iteration 35100, lr = 0.001
I0401 01:39:49.265187 11876 solver.cpp:228] Iteration 35200, loss = 0.170795
I0401 01:39:49.265187 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:39:49.265187 11876 solver.cpp:244]     Train net output #1: loss = 0.170795 (* 1 = 0.170795 loss)
I0401 01:39:49.265187 11876 sgd_solver.cpp:106] Iteration 35200, lr = 0.001
I0401 01:39:54.851850 11876 solver.cpp:228] Iteration 35300, loss = 0.238963
I0401 01:39:54.851850 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:39:54.851850 11876 solver.cpp:244]     Train net output #1: loss = 0.238963 (* 1 = 0.238963 loss)
I0401 01:39:54.851850 11876 sgd_solver.cpp:106] Iteration 35300, lr = 0.001
I0401 01:40:00.434545 11876 solver.cpp:228] Iteration 35400, loss = 0.167851
I0401 01:40:00.434545 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:40:00.434545 11876 solver.cpp:244]     Train net output #1: loss = 0.16785 (* 1 = 0.16785 loss)
I0401 01:40:00.434545 11876 sgd_solver.cpp:106] Iteration 35400, lr = 0.001
I0401 01:40:06.014415 11876 solver.cpp:228] Iteration 35500, loss = 0.173765
I0401 01:40:06.014415 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:40:06.014415 11876 solver.cpp:244]     Train net output #1: loss = 0.173764 (* 1 = 0.173764 loss)
I0401 01:40:06.014415 11876 sgd_solver.cpp:106] Iteration 35500, lr = 0.001
I0401 01:40:11.570183 11876 solver.cpp:228] Iteration 35600, loss = 0.120243
I0401 01:40:11.570683 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:40:11.570683 11876 solver.cpp:244]     Train net output #1: loss = 0.120242 (* 1 = 0.120242 loss)
I0401 01:40:11.570683 11876 sgd_solver.cpp:106] Iteration 35600, lr = 0.001
I0401 01:40:17.152218 11876 solver.cpp:228] Iteration 35700, loss = 0.223612
I0401 01:40:17.152218 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.89
I0401 01:40:17.152218 11876 solver.cpp:244]     Train net output #1: loss = 0.223612 (* 1 = 0.223612 loss)
I0401 01:40:17.152218 11876 sgd_solver.cpp:106] Iteration 35700, lr = 0.001
I0401 01:40:22.729899 11876 solver.cpp:228] Iteration 35800, loss = 0.198584
I0401 01:40:22.729899 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:40:22.729899 11876 solver.cpp:244]     Train net output #1: loss = 0.198584 (* 1 = 0.198584 loss)
I0401 01:40:22.729899 11876 sgd_solver.cpp:106] Iteration 35800, lr = 0.001
I0401 01:40:28.332568 11876 solver.cpp:228] Iteration 35900, loss = 0.123151
I0401 01:40:28.332568 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:40:28.333569 11876 solver.cpp:244]     Train net output #1: loss = 0.123151 (* 1 = 0.123151 loss)
I0401 01:40:28.333569 11876 sgd_solver.cpp:106] Iteration 35900, lr = 0.001
I0401 01:40:33.934557 11876 solver.cpp:337] Iteration 36000, Testing net (#0)
I0401 01:40:33.934557 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:40:35.568774 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8987
I0401 01:40:35.568774 11876 solver.cpp:404]     Test net output #1: loss = 0.303672 (* 1 = 0.303672 loss)
I0401 01:40:35.590782 11876 solver.cpp:228] Iteration 36000, loss = 0.230624
I0401 01:40:35.590782 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:40:35.590782 11876 solver.cpp:244]     Train net output #1: loss = 0.230623 (* 1 = 0.230623 loss)
I0401 01:40:35.590782 11876 sgd_solver.cpp:106] Iteration 36000, lr = 0.001
I0401 01:40:41.156627 11876 solver.cpp:228] Iteration 36100, loss = 0.195932
I0401 01:40:41.157127 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:40:41.157127 11876 solver.cpp:244]     Train net output #1: loss = 0.195932 (* 1 = 0.195932 loss)
I0401 01:40:41.157127 11876 sgd_solver.cpp:106] Iteration 36100, lr = 0.001
I0401 01:40:46.769834 11876 solver.cpp:228] Iteration 36200, loss = 0.239321
I0401 01:40:46.769834 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:40:46.769834 11876 solver.cpp:244]     Train net output #1: loss = 0.239321 (* 1 = 0.239321 loss)
I0401 01:40:46.769834 11876 sgd_solver.cpp:106] Iteration 36200, lr = 0.001
I0401 01:40:52.319674 11876 solver.cpp:228] Iteration 36300, loss = 0.184019
I0401 01:40:52.319674 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:40:52.320173 11876 solver.cpp:244]     Train net output #1: loss = 0.184019 (* 1 = 0.184019 loss)
I0401 01:40:52.320173 11876 sgd_solver.cpp:106] Iteration 36300, lr = 0.001
I0401 01:40:57.880134 11876 solver.cpp:228] Iteration 36400, loss = 0.1401
I0401 01:40:57.880134 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:40:57.880134 11876 solver.cpp:244]     Train net output #1: loss = 0.1401 (* 1 = 0.1401 loss)
I0401 01:40:57.880134 11876 sgd_solver.cpp:106] Iteration 36400, lr = 0.001
I0401 01:41:03.420856 11876 solver.cpp:228] Iteration 36500, loss = 0.207749
I0401 01:41:03.420856 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:41:03.420856 11876 solver.cpp:244]     Train net output #1: loss = 0.207749 (* 1 = 0.207749 loss)
I0401 01:41:03.420856 11876 sgd_solver.cpp:106] Iteration 36500, lr = 0.001
I0401 01:41:09.056897 11876 solver.cpp:228] Iteration 36600, loss = 0.19995
I0401 01:41:09.056897 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:41:09.056897 11876 solver.cpp:244]     Train net output #1: loss = 0.19995 (* 1 = 0.19995 loss)
I0401 01:41:09.056897 11876 sgd_solver.cpp:106] Iteration 36600, lr = 0.001
I0401 01:41:14.628856 11876 solver.cpp:228] Iteration 36700, loss = 0.196126
I0401 01:41:14.628856 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:41:14.628856 11876 solver.cpp:244]     Train net output #1: loss = 0.196125 (* 1 = 0.196125 loss)
I0401 01:41:14.628856 11876 sgd_solver.cpp:106] Iteration 36700, lr = 0.001
I0401 01:41:20.182209 11876 solver.cpp:228] Iteration 36800, loss = 0.186741
I0401 01:41:20.182209 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:41:20.182209 11876 solver.cpp:244]     Train net output #1: loss = 0.18674 (* 1 = 0.18674 loss)
I0401 01:41:20.182209 11876 sgd_solver.cpp:106] Iteration 36800, lr = 0.001
I0401 01:41:25.725051 11876 solver.cpp:228] Iteration 36900, loss = 0.109783
I0401 01:41:25.725051 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:41:25.725051 11876 solver.cpp:244]     Train net output #1: loss = 0.109783 (* 1 = 0.109783 loss)
I0401 01:41:25.725051 11876 sgd_solver.cpp:106] Iteration 36900, lr = 0.001
I0401 01:41:31.257838 11876 solver.cpp:337] Iteration 37000, Testing net (#0)
I0401 01:41:31.257838 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:41:32.884223 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9063
I0401 01:41:32.884223 11876 solver.cpp:404]     Test net output #1: loss = 0.293341 (* 1 = 0.293341 loss)
I0401 01:41:32.905225 11876 solver.cpp:228] Iteration 37000, loss = 0.188005
I0401 01:41:32.905225 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:41:32.905225 11876 solver.cpp:244]     Train net output #1: loss = 0.188004 (* 1 = 0.188004 loss)
I0401 01:41:32.905225 11876 sgd_solver.cpp:106] Iteration 37000, lr = 0.001
I0401 01:41:38.453456 11876 solver.cpp:228] Iteration 37100, loss = 0.131394
I0401 01:41:38.453456 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:41:38.453456 11876 solver.cpp:244]     Train net output #1: loss = 0.131394 (* 1 = 0.131394 loss)
I0401 01:41:38.453456 11876 sgd_solver.cpp:106] Iteration 37100, lr = 0.001
I0401 01:41:44.001718 11876 solver.cpp:228] Iteration 37200, loss = 0.145899
I0401 01:41:44.001718 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:41:44.001718 11876 solver.cpp:244]     Train net output #1: loss = 0.145899 (* 1 = 0.145899 loss)
I0401 01:41:44.001718 11876 sgd_solver.cpp:106] Iteration 37200, lr = 0.001
I0401 01:41:49.537591 11876 solver.cpp:228] Iteration 37300, loss = 0.192359
I0401 01:41:49.537591 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:41:49.537591 11876 solver.cpp:244]     Train net output #1: loss = 0.192359 (* 1 = 0.192359 loss)
I0401 01:41:49.537591 11876 sgd_solver.cpp:106] Iteration 37300, lr = 0.001
I0401 01:41:55.118814 11876 solver.cpp:228] Iteration 37400, loss = 0.113923
I0401 01:41:55.118814 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:41:55.118814 11876 solver.cpp:244]     Train net output #1: loss = 0.113922 (* 1 = 0.113922 loss)
I0401 01:41:55.118814 11876 sgd_solver.cpp:106] Iteration 37400, lr = 0.001
I0401 01:42:00.673426 11876 solver.cpp:228] Iteration 37500, loss = 0.185755
I0401 01:42:00.673426 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:42:00.673426 11876 solver.cpp:244]     Train net output #1: loss = 0.185755 (* 1 = 0.185755 loss)
I0401 01:42:00.673426 11876 sgd_solver.cpp:106] Iteration 37500, lr = 0.001
I0401 01:42:06.237040 11876 solver.cpp:228] Iteration 37600, loss = 0.151448
I0401 01:42:06.237040 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:42:06.237040 11876 solver.cpp:244]     Train net output #1: loss = 0.151448 (* 1 = 0.151448 loss)
I0401 01:42:06.237040 11876 sgd_solver.cpp:106] Iteration 37600, lr = 0.001
I0401 01:42:11.784754 11876 solver.cpp:228] Iteration 37700, loss = 0.177949
I0401 01:42:11.784754 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:42:11.784754 11876 solver.cpp:244]     Train net output #1: loss = 0.177949 (* 1 = 0.177949 loss)
I0401 01:42:11.784754 11876 sgd_solver.cpp:106] Iteration 37700, lr = 0.001
I0401 01:42:17.340612 11876 solver.cpp:228] Iteration 37800, loss = 0.245238
I0401 01:42:17.340612 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:42:17.340612 11876 solver.cpp:244]     Train net output #1: loss = 0.245238 (* 1 = 0.245238 loss)
I0401 01:42:17.340612 11876 sgd_solver.cpp:106] Iteration 37800, lr = 0.001
I0401 01:42:22.899483 11876 solver.cpp:228] Iteration 37900, loss = 0.192966
I0401 01:42:22.899483 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:42:22.899483 11876 solver.cpp:244]     Train net output #1: loss = 0.192966 (* 1 = 0.192966 loss)
I0401 01:42:22.899483 11876 sgd_solver.cpp:106] Iteration 37900, lr = 0.001
I0401 01:42:28.431665 11876 solver.cpp:337] Iteration 38000, Testing net (#0)
I0401 01:42:28.431665 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:42:30.055665 11876 solver.cpp:404]     Test net output #0: accuracy = 0.899
I0401 01:42:30.055665 11876 solver.cpp:404]     Test net output #1: loss = 0.315882 (* 1 = 0.315882 loss)
I0401 01:42:30.076169 11876 solver.cpp:228] Iteration 38000, loss = 0.172224
I0401 01:42:30.077170 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:42:30.077170 11876 solver.cpp:244]     Train net output #1: loss = 0.172224 (* 1 = 0.172224 loss)
I0401 01:42:30.077170 11876 sgd_solver.cpp:106] Iteration 38000, lr = 0.001
I0401 01:42:35.614650 11876 solver.cpp:228] Iteration 38100, loss = 0.0938392
I0401 01:42:35.614650 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:42:35.614650 11876 solver.cpp:244]     Train net output #1: loss = 0.0938388 (* 1 = 0.0938388 loss)
I0401 01:42:35.614650 11876 sgd_solver.cpp:106] Iteration 38100, lr = 0.001
I0401 01:42:41.165567 11876 solver.cpp:228] Iteration 38200, loss = 0.162732
I0401 01:42:41.166067 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:42:41.166067 11876 solver.cpp:244]     Train net output #1: loss = 0.162732 (* 1 = 0.162732 loss)
I0401 01:42:41.166067 11876 sgd_solver.cpp:106] Iteration 38200, lr = 0.001
I0401 01:42:46.711818 11876 solver.cpp:228] Iteration 38300, loss = 0.189038
I0401 01:42:46.711818 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:42:46.711818 11876 solver.cpp:244]     Train net output #1: loss = 0.189037 (* 1 = 0.189037 loss)
I0401 01:42:46.711818 11876 sgd_solver.cpp:106] Iteration 38300, lr = 0.001
I0401 01:42:52.252060 11876 solver.cpp:228] Iteration 38400, loss = 0.125529
I0401 01:42:52.252060 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:42:52.252060 11876 solver.cpp:244]     Train net output #1: loss = 0.125528 (* 1 = 0.125528 loss)
I0401 01:42:52.252060 11876 sgd_solver.cpp:106] Iteration 38400, lr = 0.001
I0401 01:42:57.792191 11876 solver.cpp:228] Iteration 38500, loss = 0.177984
I0401 01:42:57.792191 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:42:57.792191 11876 solver.cpp:244]     Train net output #1: loss = 0.177984 (* 1 = 0.177984 loss)
I0401 01:42:57.792191 11876 sgd_solver.cpp:106] Iteration 38500, lr = 0.001
I0401 01:43:03.377280 11876 solver.cpp:228] Iteration 38600, loss = 0.20539
I0401 01:43:03.377280 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:43:03.377280 11876 solver.cpp:244]     Train net output #1: loss = 0.20539 (* 1 = 0.20539 loss)
I0401 01:43:03.377280 11876 sgd_solver.cpp:106] Iteration 38600, lr = 0.001
I0401 01:43:08.938311 11876 solver.cpp:228] Iteration 38700, loss = 0.160895
I0401 01:43:08.938311 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:43:08.938311 11876 solver.cpp:244]     Train net output #1: loss = 0.160894 (* 1 = 0.160894 loss)
I0401 01:43:08.938311 11876 sgd_solver.cpp:106] Iteration 38700, lr = 0.001
I0401 01:43:14.486613 11876 solver.cpp:228] Iteration 38800, loss = 0.214867
I0401 01:43:14.486613 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:43:14.486613 11876 solver.cpp:244]     Train net output #1: loss = 0.214867 (* 1 = 0.214867 loss)
I0401 01:43:14.486613 11876 sgd_solver.cpp:106] Iteration 38800, lr = 0.001
I0401 01:43:20.039911 11876 solver.cpp:228] Iteration 38900, loss = 0.13239
I0401 01:43:20.039911 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:43:20.039911 11876 solver.cpp:244]     Train net output #1: loss = 0.132389 (* 1 = 0.132389 loss)
I0401 01:43:20.039911 11876 sgd_solver.cpp:106] Iteration 38900, lr = 0.001
I0401 01:43:25.589005 11876 solver.cpp:337] Iteration 39000, Testing net (#0)
I0401 01:43:25.589005 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:43:27.216279 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8968
I0401 01:43:27.216279 11876 solver.cpp:404]     Test net output #1: loss = 0.311049 (* 1 = 0.311049 loss)
I0401 01:43:27.237283 11876 solver.cpp:228] Iteration 39000, loss = 0.180478
I0401 01:43:27.237283 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:43:27.237283 11876 solver.cpp:244]     Train net output #1: loss = 0.180477 (* 1 = 0.180477 loss)
I0401 01:43:27.237283 11876 sgd_solver.cpp:106] Iteration 39000, lr = 0.001
I0401 01:43:32.799476 11876 solver.cpp:228] Iteration 39100, loss = 0.0977524
I0401 01:43:32.799476 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:43:32.799476 11876 solver.cpp:244]     Train net output #1: loss = 0.097752 (* 1 = 0.097752 loss)
I0401 01:43:32.799476 11876 sgd_solver.cpp:106] Iteration 39100, lr = 0.001
I0401 01:43:38.363025 11876 solver.cpp:228] Iteration 39200, loss = 0.236269
I0401 01:43:38.363025 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:43:38.363025 11876 solver.cpp:244]     Train net output #1: loss = 0.236269 (* 1 = 0.236269 loss)
I0401 01:43:38.363025 11876 sgd_solver.cpp:106] Iteration 39200, lr = 0.001
I0401 01:43:43.918367 11876 solver.cpp:228] Iteration 39300, loss = 0.167751
I0401 01:43:43.918367 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:43:43.918367 11876 solver.cpp:244]     Train net output #1: loss = 0.167751 (* 1 = 0.167751 loss)
I0401 01:43:43.918367 11876 sgd_solver.cpp:106] Iteration 39300, lr = 0.001
I0401 01:43:49.454728 11876 solver.cpp:228] Iteration 39400, loss = 0.136452
I0401 01:43:49.454728 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:43:49.454728 11876 solver.cpp:244]     Train net output #1: loss = 0.136452 (* 1 = 0.136452 loss)
I0401 01:43:49.454728 11876 sgd_solver.cpp:106] Iteration 39400, lr = 0.001
I0401 01:43:55.013906 11876 solver.cpp:228] Iteration 39500, loss = 0.154763
I0401 01:43:55.013906 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:43:55.013906 11876 solver.cpp:244]     Train net output #1: loss = 0.154763 (* 1 = 0.154763 loss)
I0401 01:43:55.014906 11876 sgd_solver.cpp:106] Iteration 39500, lr = 0.001
I0401 01:44:00.550971 11876 solver.cpp:228] Iteration 39600, loss = 0.215302
I0401 01:44:00.550971 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:44:00.550971 11876 solver.cpp:244]     Train net output #1: loss = 0.215301 (* 1 = 0.215301 loss)
I0401 01:44:00.550971 11876 sgd_solver.cpp:106] Iteration 39600, lr = 0.001
I0401 01:44:06.086141 11876 solver.cpp:228] Iteration 39700, loss = 0.229887
I0401 01:44:06.086141 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:44:06.086141 11876 solver.cpp:244]     Train net output #1: loss = 0.229886 (* 1 = 0.229886 loss)
I0401 01:44:06.086141 11876 sgd_solver.cpp:106] Iteration 39700, lr = 0.001
I0401 01:44:11.636077 11876 solver.cpp:228] Iteration 39800, loss = 0.184813
I0401 01:44:11.636077 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:44:11.636077 11876 solver.cpp:244]     Train net output #1: loss = 0.184813 (* 1 = 0.184813 loss)
I0401 01:44:11.636077 11876 sgd_solver.cpp:106] Iteration 39800, lr = 0.001
I0401 01:44:17.179955 11876 solver.cpp:228] Iteration 39900, loss = 0.16809
I0401 01:44:17.179955 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:44:17.179955 11876 solver.cpp:244]     Train net output #1: loss = 0.168089 (* 1 = 0.168089 loss)
I0401 01:44:17.179955 11876 sgd_solver.cpp:106] Iteration 39900, lr = 0.001
I0401 01:44:22.696509 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_40000.caffemodel
I0401 01:44:22.709509 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_40000.solverstate
I0401 01:44:22.712522 11876 solver.cpp:337] Iteration 40000, Testing net (#0)
I0401 01:44:22.713507 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:44:24.326252 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8936
I0401 01:44:24.326252 11876 solver.cpp:404]     Test net output #1: loss = 0.329524 (* 1 = 0.329524 loss)
I0401 01:44:24.348026 11876 solver.cpp:228] Iteration 40000, loss = 0.166478
I0401 01:44:24.348026 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:44:24.348026 11876 solver.cpp:244]     Train net output #1: loss = 0.166478 (* 1 = 0.166478 loss)
I0401 01:44:24.348026 11876 sgd_solver.cpp:106] Iteration 40000, lr = 0.001
I0401 01:44:29.887562 11876 solver.cpp:228] Iteration 40100, loss = 0.165858
I0401 01:44:29.887562 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:44:29.887562 11876 solver.cpp:244]     Train net output #1: loss = 0.165858 (* 1 = 0.165858 loss)
I0401 01:44:29.887562 11876 sgd_solver.cpp:106] Iteration 40100, lr = 0.001
I0401 01:44:35.432348 11876 solver.cpp:228] Iteration 40200, loss = 0.166752
I0401 01:44:35.432848 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:44:35.432848 11876 solver.cpp:244]     Train net output #1: loss = 0.166752 (* 1 = 0.166752 loss)
I0401 01:44:35.432848 11876 sgd_solver.cpp:106] Iteration 40200, lr = 0.001
I0401 01:44:40.981914 11876 solver.cpp:228] Iteration 40300, loss = 0.155949
I0401 01:44:40.981914 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:44:40.981914 11876 solver.cpp:244]     Train net output #1: loss = 0.155949 (* 1 = 0.155949 loss)
I0401 01:44:40.981914 11876 sgd_solver.cpp:106] Iteration 40300, lr = 0.001
I0401 01:44:46.525661 11876 solver.cpp:228] Iteration 40400, loss = 0.0964435
I0401 01:44:46.526161 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:44:46.526161 11876 solver.cpp:244]     Train net output #1: loss = 0.0964431 (* 1 = 0.0964431 loss)
I0401 01:44:46.526161 11876 sgd_solver.cpp:106] Iteration 40400, lr = 0.001
I0401 01:44:52.074540 11876 solver.cpp:228] Iteration 40500, loss = 0.176739
I0401 01:44:52.074540 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:44:52.074540 11876 solver.cpp:244]     Train net output #1: loss = 0.176738 (* 1 = 0.176738 loss)
I0401 01:44:52.074540 11876 sgd_solver.cpp:106] Iteration 40500, lr = 0.001
I0401 01:44:57.616034 11876 solver.cpp:228] Iteration 40600, loss = 0.199429
I0401 01:44:57.616034 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:44:57.616034 11876 solver.cpp:244]     Train net output #1: loss = 0.199429 (* 1 = 0.199429 loss)
I0401 01:44:57.616034 11876 sgd_solver.cpp:106] Iteration 40600, lr = 0.001
I0401 01:45:03.168826 11876 solver.cpp:228] Iteration 40700, loss = 0.186387
I0401 01:45:03.168826 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:45:03.168826 11876 solver.cpp:244]     Train net output #1: loss = 0.186386 (* 1 = 0.186386 loss)
I0401 01:45:03.168826 11876 sgd_solver.cpp:106] Iteration 40700, lr = 0.001
I0401 01:45:08.722565 11876 solver.cpp:228] Iteration 40800, loss = 0.157908
I0401 01:45:08.722565 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:45:08.722565 11876 solver.cpp:244]     Train net output #1: loss = 0.157907 (* 1 = 0.157907 loss)
I0401 01:45:08.723565 11876 sgd_solver.cpp:106] Iteration 40800, lr = 0.001
I0401 01:45:14.275900 11876 solver.cpp:228] Iteration 40900, loss = 0.115744
I0401 01:45:14.275900 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:45:14.275900 11876 solver.cpp:244]     Train net output #1: loss = 0.115744 (* 1 = 0.115744 loss)
I0401 01:45:14.275900 11876 sgd_solver.cpp:106] Iteration 40900, lr = 0.001
I0401 01:45:19.791759 11876 solver.cpp:337] Iteration 41000, Testing net (#0)
I0401 01:45:19.792760 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:45:21.422119 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8894
I0401 01:45:21.422119 11876 solver.cpp:404]     Test net output #1: loss = 0.348822 (* 1 = 0.348822 loss)
I0401 01:45:21.443085 11876 solver.cpp:228] Iteration 41000, loss = 0.211472
I0401 01:45:21.443085 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:45:21.443085 11876 solver.cpp:244]     Train net output #1: loss = 0.211471 (* 1 = 0.211471 loss)
I0401 01:45:21.443085 11876 sgd_solver.cpp:106] Iteration 41000, lr = 0.001
I0401 01:45:26.974736 11876 solver.cpp:228] Iteration 41100, loss = 0.156267
I0401 01:45:26.974736 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:45:26.974736 11876 solver.cpp:244]     Train net output #1: loss = 0.156267 (* 1 = 0.156267 loss)
I0401 01:45:26.974736 11876 sgd_solver.cpp:106] Iteration 41100, lr = 0.001
I0401 01:45:32.511229 11876 solver.cpp:228] Iteration 41200, loss = 0.211722
I0401 01:45:32.511728 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:45:32.511728 11876 solver.cpp:244]     Train net output #1: loss = 0.211721 (* 1 = 0.211721 loss)
I0401 01:45:32.511728 11876 sgd_solver.cpp:106] Iteration 41200, lr = 0.001
I0401 01:45:38.081612 11876 solver.cpp:228] Iteration 41300, loss = 0.180111
I0401 01:45:38.081612 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:45:38.081612 11876 solver.cpp:244]     Train net output #1: loss = 0.18011 (* 1 = 0.18011 loss)
I0401 01:45:38.081612 11876 sgd_solver.cpp:106] Iteration 41300, lr = 0.001
I0401 01:45:43.649163 11876 solver.cpp:228] Iteration 41400, loss = 0.1293
I0401 01:45:43.649163 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:45:43.649163 11876 solver.cpp:244]     Train net output #1: loss = 0.1293 (* 1 = 0.1293 loss)
I0401 01:45:43.649163 11876 sgd_solver.cpp:106] Iteration 41400, lr = 0.001
I0401 01:45:49.181685 11876 solver.cpp:228] Iteration 41500, loss = 0.216886
I0401 01:45:49.181685 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:45:49.181685 11876 solver.cpp:244]     Train net output #1: loss = 0.216886 (* 1 = 0.216886 loss)
I0401 01:45:49.181685 11876 sgd_solver.cpp:106] Iteration 41500, lr = 0.001
I0401 01:45:54.744127 11876 solver.cpp:228] Iteration 41600, loss = 0.168687
I0401 01:45:54.744627 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:45:54.744627 11876 solver.cpp:244]     Train net output #1: loss = 0.168686 (* 1 = 0.168686 loss)
I0401 01:45:54.744627 11876 sgd_solver.cpp:106] Iteration 41600, lr = 0.001
I0401 01:46:00.268005 11876 solver.cpp:228] Iteration 41700, loss = 0.150857
I0401 01:46:00.268506 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:46:00.268506 11876 solver.cpp:244]     Train net output #1: loss = 0.150856 (* 1 = 0.150856 loss)
I0401 01:46:00.268506 11876 sgd_solver.cpp:106] Iteration 41700, lr = 0.001
I0401 01:46:05.825901 11876 solver.cpp:228] Iteration 41800, loss = 0.169887
I0401 01:46:05.826405 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:46:05.826405 11876 solver.cpp:244]     Train net output #1: loss = 0.169886 (* 1 = 0.169886 loss)
I0401 01:46:05.826405 11876 sgd_solver.cpp:106] Iteration 41800, lr = 0.001
I0401 01:46:11.378172 11876 solver.cpp:228] Iteration 41900, loss = 0.153863
I0401 01:46:11.378172 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:46:11.378172 11876 solver.cpp:244]     Train net output #1: loss = 0.153863 (* 1 = 0.153863 loss)
I0401 01:46:11.378672 11876 sgd_solver.cpp:106] Iteration 41900, lr = 0.001
I0401 01:46:16.890455 11876 solver.cpp:337] Iteration 42000, Testing net (#0)
I0401 01:46:16.891460 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:46:18.511905 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8805
I0401 01:46:18.511905 11876 solver.cpp:404]     Test net output #1: loss = 0.386204 (* 1 = 0.386204 loss)
I0401 01:46:18.534904 11876 solver.cpp:228] Iteration 42000, loss = 0.163631
I0401 01:46:18.534904 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:46:18.534904 11876 solver.cpp:244]     Train net output #1: loss = 0.16363 (* 1 = 0.16363 loss)
I0401 01:46:18.534904 11876 sgd_solver.cpp:106] Iteration 42000, lr = 0.001
I0401 01:46:24.079252 11876 solver.cpp:228] Iteration 42100, loss = 0.144568
I0401 01:46:24.079252 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:46:24.079252 11876 solver.cpp:244]     Train net output #1: loss = 0.144568 (* 1 = 0.144568 loss)
I0401 01:46:24.079252 11876 sgd_solver.cpp:106] Iteration 42100, lr = 0.001
I0401 01:46:29.622632 11876 solver.cpp:228] Iteration 42200, loss = 0.213602
I0401 01:46:29.622632 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:46:29.622632 11876 solver.cpp:244]     Train net output #1: loss = 0.213601 (* 1 = 0.213601 loss)
I0401 01:46:29.622632 11876 sgd_solver.cpp:106] Iteration 42200, lr = 0.001
I0401 01:46:35.220074 11876 solver.cpp:228] Iteration 42300, loss = 0.161569
I0401 01:46:35.220074 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:46:35.220074 11876 solver.cpp:244]     Train net output #1: loss = 0.161569 (* 1 = 0.161569 loss)
I0401 01:46:35.220074 11876 sgd_solver.cpp:106] Iteration 42300, lr = 0.001
I0401 01:46:40.760027 11876 solver.cpp:228] Iteration 42400, loss = 0.121185
I0401 01:46:40.760027 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:46:40.760027 11876 solver.cpp:244]     Train net output #1: loss = 0.121184 (* 1 = 0.121184 loss)
I0401 01:46:40.760027 11876 sgd_solver.cpp:106] Iteration 42400, lr = 0.001
I0401 01:46:46.323935 11876 solver.cpp:228] Iteration 42500, loss = 0.19534
I0401 01:46:46.323935 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:46:46.323935 11876 solver.cpp:244]     Train net output #1: loss = 0.195339 (* 1 = 0.195339 loss)
I0401 01:46:46.323935 11876 sgd_solver.cpp:106] Iteration 42500, lr = 0.001
I0401 01:46:51.876624 11876 solver.cpp:228] Iteration 42600, loss = 0.14253
I0401 01:46:51.876624 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:46:51.876624 11876 solver.cpp:244]     Train net output #1: loss = 0.14253 (* 1 = 0.14253 loss)
I0401 01:46:51.876624 11876 sgd_solver.cpp:106] Iteration 42600, lr = 0.001
I0401 01:46:57.427062 11876 solver.cpp:228] Iteration 42700, loss = 0.106615
I0401 01:46:57.427062 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:46:57.427062 11876 solver.cpp:244]     Train net output #1: loss = 0.106615 (* 1 = 0.106615 loss)
I0401 01:46:57.427062 11876 sgd_solver.cpp:106] Iteration 42700, lr = 0.001
I0401 01:47:02.970321 11876 solver.cpp:228] Iteration 42800, loss = 0.209116
I0401 01:47:02.970321 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:47:02.970321 11876 solver.cpp:244]     Train net output #1: loss = 0.209115 (* 1 = 0.209115 loss)
I0401 01:47:02.970321 11876 sgd_solver.cpp:106] Iteration 42800, lr = 0.001
I0401 01:47:08.532796 11876 solver.cpp:228] Iteration 42900, loss = 0.189334
I0401 01:47:08.532796 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:47:08.532796 11876 solver.cpp:244]     Train net output #1: loss = 0.189334 (* 1 = 0.189334 loss)
I0401 01:47:08.532796 11876 sgd_solver.cpp:106] Iteration 42900, lr = 0.001
I0401 01:47:14.054718 11876 solver.cpp:337] Iteration 43000, Testing net (#0)
I0401 01:47:14.054718 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:47:15.665055 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8986
I0401 01:47:15.666055 11876 solver.cpp:404]     Test net output #1: loss = 0.327387 (* 1 = 0.327387 loss)
I0401 01:47:15.687055 11876 solver.cpp:228] Iteration 43000, loss = 0.152265
I0401 01:47:15.687055 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:47:15.687055 11876 solver.cpp:244]     Train net output #1: loss = 0.152264 (* 1 = 0.152264 loss)
I0401 01:47:15.687055 11876 sgd_solver.cpp:106] Iteration 43000, lr = 0.001
I0401 01:47:21.214831 11876 solver.cpp:228] Iteration 43100, loss = 0.175402
I0401 01:47:21.214831 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:47:21.214831 11876 solver.cpp:244]     Train net output #1: loss = 0.175401 (* 1 = 0.175401 loss)
I0401 01:47:21.214831 11876 sgd_solver.cpp:106] Iteration 43100, lr = 0.001
I0401 01:47:26.754551 11876 solver.cpp:228] Iteration 43200, loss = 0.209719
I0401 01:47:26.754551 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:47:26.754551 11876 solver.cpp:244]     Train net output #1: loss = 0.209719 (* 1 = 0.209719 loss)
I0401 01:47:26.754551 11876 sgd_solver.cpp:106] Iteration 43200, lr = 0.001
I0401 01:47:32.306502 11876 solver.cpp:228] Iteration 43300, loss = 0.236461
I0401 01:47:32.306502 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:47:32.306502 11876 solver.cpp:244]     Train net output #1: loss = 0.236461 (* 1 = 0.236461 loss)
I0401 01:47:32.306502 11876 sgd_solver.cpp:106] Iteration 43300, lr = 0.001
I0401 01:47:37.852443 11876 solver.cpp:228] Iteration 43400, loss = 0.124287
I0401 01:47:37.852443 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:47:37.852443 11876 solver.cpp:244]     Train net output #1: loss = 0.124287 (* 1 = 0.124287 loss)
I0401 01:47:37.852443 11876 sgd_solver.cpp:106] Iteration 43400, lr = 0.001
I0401 01:47:43.405129 11876 solver.cpp:228] Iteration 43500, loss = 0.179844
I0401 01:47:43.405129 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:47:43.405129 11876 solver.cpp:244]     Train net output #1: loss = 0.179844 (* 1 = 0.179844 loss)
I0401 01:47:43.405129 11876 sgd_solver.cpp:106] Iteration 43500, lr = 0.001
I0401 01:47:48.967695 11876 solver.cpp:228] Iteration 43600, loss = 0.159676
I0401 01:47:48.967695 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:47:48.967695 11876 solver.cpp:244]     Train net output #1: loss = 0.159676 (* 1 = 0.159676 loss)
I0401 01:47:48.967695 11876 sgd_solver.cpp:106] Iteration 43600, lr = 0.001
I0401 01:47:54.523156 11876 solver.cpp:228] Iteration 43700, loss = 0.163876
I0401 01:47:54.523156 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:47:54.523156 11876 solver.cpp:244]     Train net output #1: loss = 0.163876 (* 1 = 0.163876 loss)
I0401 01:47:54.523156 11876 sgd_solver.cpp:106] Iteration 43700, lr = 0.001
I0401 01:48:00.071502 11876 solver.cpp:228] Iteration 43800, loss = 0.168141
I0401 01:48:00.071502 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:48:00.071502 11876 solver.cpp:244]     Train net output #1: loss = 0.168141 (* 1 = 0.168141 loss)
I0401 01:48:00.071502 11876 sgd_solver.cpp:106] Iteration 43800, lr = 0.001
I0401 01:48:05.598595 11876 solver.cpp:228] Iteration 43900, loss = 0.133806
I0401 01:48:05.599083 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:48:05.599083 11876 solver.cpp:244]     Train net output #1: loss = 0.133806 (* 1 = 0.133806 loss)
I0401 01:48:05.599083 11876 sgd_solver.cpp:106] Iteration 43900, lr = 0.001
I0401 01:48:11.096843 11876 solver.cpp:337] Iteration 44000, Testing net (#0)
I0401 01:48:11.096843 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:48:12.709517 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8879
I0401 01:48:12.709517 11876 solver.cpp:404]     Test net output #1: loss = 0.366767 (* 1 = 0.366767 loss)
I0401 01:48:12.730517 11876 solver.cpp:228] Iteration 44000, loss = 0.207615
I0401 01:48:12.730517 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.88
I0401 01:48:12.730517 11876 solver.cpp:244]     Train net output #1: loss = 0.207615 (* 1 = 0.207615 loss)
I0401 01:48:12.730517 11876 sgd_solver.cpp:106] Iteration 44000, lr = 0.001
I0401 01:48:18.259512 11876 solver.cpp:228] Iteration 44100, loss = 0.161527
I0401 01:48:18.259512 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:48:18.259512 11876 solver.cpp:244]     Train net output #1: loss = 0.161527 (* 1 = 0.161527 loss)
I0401 01:48:18.259512 11876 sgd_solver.cpp:106] Iteration 44100, lr = 0.001
I0401 01:48:23.804942 11876 solver.cpp:228] Iteration 44200, loss = 0.220657
I0401 01:48:23.804942 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:48:23.804942 11876 solver.cpp:244]     Train net output #1: loss = 0.220657 (* 1 = 0.220657 loss)
I0401 01:48:23.804942 11876 sgd_solver.cpp:106] Iteration 44200, lr = 0.001
I0401 01:48:29.345576 11876 solver.cpp:228] Iteration 44300, loss = 0.153577
I0401 01:48:29.345576 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:48:29.345576 11876 solver.cpp:244]     Train net output #1: loss = 0.153577 (* 1 = 0.153577 loss)
I0401 01:48:29.345576 11876 sgd_solver.cpp:106] Iteration 44300, lr = 0.001
I0401 01:48:34.877364 11876 solver.cpp:228] Iteration 44400, loss = 0.136498
I0401 01:48:34.877364 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:48:34.877364 11876 solver.cpp:244]     Train net output #1: loss = 0.136498 (* 1 = 0.136498 loss)
I0401 01:48:34.877364 11876 sgd_solver.cpp:106] Iteration 44400, lr = 0.001
I0401 01:48:40.394711 11876 solver.cpp:228] Iteration 44500, loss = 0.178944
I0401 01:48:40.394711 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:48:40.394711 11876 solver.cpp:244]     Train net output #1: loss = 0.178944 (* 1 = 0.178944 loss)
I0401 01:48:40.394711 11876 sgd_solver.cpp:106] Iteration 44500, lr = 0.001
I0401 01:48:45.937944 11876 solver.cpp:228] Iteration 44600, loss = 0.210784
I0401 01:48:45.937944 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:48:45.937944 11876 solver.cpp:244]     Train net output #1: loss = 0.210784 (* 1 = 0.210784 loss)
I0401 01:48:45.937944 11876 sgd_solver.cpp:106] Iteration 44600, lr = 0.001
I0401 01:48:51.470767 11876 solver.cpp:228] Iteration 44700, loss = 0.179229
I0401 01:48:51.470767 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:48:51.470767 11876 solver.cpp:244]     Train net output #1: loss = 0.179228 (* 1 = 0.179228 loss)
I0401 01:48:51.470767 11876 sgd_solver.cpp:106] Iteration 44700, lr = 0.001
I0401 01:48:57.023437 11876 solver.cpp:228] Iteration 44800, loss = 0.247914
I0401 01:48:57.023437 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:48:57.023437 11876 solver.cpp:244]     Train net output #1: loss = 0.247914 (* 1 = 0.247914 loss)
I0401 01:48:57.023437 11876 sgd_solver.cpp:106] Iteration 44800, lr = 0.001
I0401 01:49:02.583885 11876 solver.cpp:228] Iteration 44900, loss = 0.180834
I0401 01:49:02.583885 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:49:02.583885 11876 solver.cpp:244]     Train net output #1: loss = 0.180834 (* 1 = 0.180834 loss)
I0401 01:49:02.583885 11876 sgd_solver.cpp:106] Iteration 44900, lr = 0.001
I0401 01:49:08.128706 11876 solver.cpp:337] Iteration 45000, Testing net (#0)
I0401 01:49:08.128706 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:49:09.752037 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8889
I0401 01:49:09.752037 11876 solver.cpp:404]     Test net output #1: loss = 0.355942 (* 1 = 0.355942 loss)
I0401 01:49:09.774019 11876 solver.cpp:228] Iteration 45000, loss = 0.128889
I0401 01:49:09.774019 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:49:09.774019 11876 solver.cpp:244]     Train net output #1: loss = 0.128888 (* 1 = 0.128888 loss)
I0401 01:49:09.774019 11876 sgd_solver.cpp:106] Iteration 45000, lr = 0.001
I0401 01:49:15.314961 11876 solver.cpp:228] Iteration 45100, loss = 0.195858
I0401 01:49:15.314961 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:49:15.314961 11876 solver.cpp:244]     Train net output #1: loss = 0.195858 (* 1 = 0.195858 loss)
I0401 01:49:15.314961 11876 sgd_solver.cpp:106] Iteration 45100, lr = 0.001
I0401 01:49:20.849987 11876 solver.cpp:228] Iteration 45200, loss = 0.241252
I0401 01:49:20.849987 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.91
I0401 01:49:20.849987 11876 solver.cpp:244]     Train net output #1: loss = 0.241251 (* 1 = 0.241251 loss)
I0401 01:49:20.849987 11876 sgd_solver.cpp:106] Iteration 45200, lr = 0.001
I0401 01:49:26.385011 11876 solver.cpp:228] Iteration 45300, loss = 0.188372
I0401 01:49:26.385011 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:49:26.385011 11876 solver.cpp:244]     Train net output #1: loss = 0.188372 (* 1 = 0.188372 loss)
I0401 01:49:26.385011 11876 sgd_solver.cpp:106] Iteration 45300, lr = 0.001
I0401 01:49:31.929381 11876 solver.cpp:228] Iteration 45400, loss = 0.130015
I0401 01:49:31.929381 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:49:31.929381 11876 solver.cpp:244]     Train net output #1: loss = 0.130015 (* 1 = 0.130015 loss)
I0401 01:49:31.929381 11876 sgd_solver.cpp:106] Iteration 45400, lr = 0.001
I0401 01:49:37.460110 11876 solver.cpp:228] Iteration 45500, loss = 0.143472
I0401 01:49:37.460110 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:49:37.460110 11876 solver.cpp:244]     Train net output #1: loss = 0.143472 (* 1 = 0.143472 loss)
I0401 01:49:37.460610 11876 sgd_solver.cpp:106] Iteration 45500, lr = 0.001
I0401 01:49:42.991632 11876 solver.cpp:228] Iteration 45600, loss = 0.133946
I0401 01:49:42.991632 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:49:42.991632 11876 solver.cpp:244]     Train net output #1: loss = 0.133945 (* 1 = 0.133945 loss)
I0401 01:49:42.991632 11876 sgd_solver.cpp:106] Iteration 45600, lr = 0.001
I0401 01:49:48.523356 11876 solver.cpp:228] Iteration 45700, loss = 0.143006
I0401 01:49:48.523356 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:49:48.523356 11876 solver.cpp:244]     Train net output #1: loss = 0.143006 (* 1 = 0.143006 loss)
I0401 01:49:48.523356 11876 sgd_solver.cpp:106] Iteration 45700, lr = 0.001
I0401 01:49:54.070389 11876 solver.cpp:228] Iteration 45800, loss = 0.203694
I0401 01:49:54.070389 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:49:54.070389 11876 solver.cpp:244]     Train net output #1: loss = 0.203694 (* 1 = 0.203694 loss)
I0401 01:49:54.070389 11876 sgd_solver.cpp:106] Iteration 45800, lr = 0.001
I0401 01:49:59.603884 11876 solver.cpp:228] Iteration 45900, loss = 0.0854922
I0401 01:49:59.603884 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:49:59.603884 11876 solver.cpp:244]     Train net output #1: loss = 0.085492 (* 1 = 0.085492 loss)
I0401 01:49:59.603884 11876 sgd_solver.cpp:106] Iteration 45900, lr = 0.001
I0401 01:50:05.114431 11876 solver.cpp:337] Iteration 46000, Testing net (#0)
I0401 01:50:05.114431 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:50:06.724156 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8896
I0401 01:50:06.724156 11876 solver.cpp:404]     Test net output #1: loss = 0.347589 (* 1 = 0.347589 loss)
I0401 01:50:06.747156 11876 solver.cpp:228] Iteration 46000, loss = 0.123661
I0401 01:50:06.747156 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:50:06.747156 11876 solver.cpp:244]     Train net output #1: loss = 0.123661 (* 1 = 0.123661 loss)
I0401 01:50:06.747156 11876 sgd_solver.cpp:106] Iteration 46000, lr = 0.001
I0401 01:50:12.282923 11876 solver.cpp:228] Iteration 46100, loss = 0.187431
I0401 01:50:12.283416 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:50:12.283416 11876 solver.cpp:244]     Train net output #1: loss = 0.187431 (* 1 = 0.187431 loss)
I0401 01:50:12.283416 11876 sgd_solver.cpp:106] Iteration 46100, lr = 0.001
I0401 01:50:17.836802 11876 solver.cpp:228] Iteration 46200, loss = 0.121424
I0401 01:50:17.836802 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:50:17.836802 11876 solver.cpp:244]     Train net output #1: loss = 0.121423 (* 1 = 0.121423 loss)
I0401 01:50:17.836802 11876 sgd_solver.cpp:106] Iteration 46200, lr = 0.001
I0401 01:50:23.376137 11876 solver.cpp:228] Iteration 46300, loss = 0.0949366
I0401 01:50:23.376137 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:50:23.376137 11876 solver.cpp:244]     Train net output #1: loss = 0.0949363 (* 1 = 0.0949363 loss)
I0401 01:50:23.376137 11876 sgd_solver.cpp:106] Iteration 46300, lr = 0.001
I0401 01:50:28.913010 11876 solver.cpp:228] Iteration 46400, loss = 0.157991
I0401 01:50:28.913511 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:50:28.913511 11876 solver.cpp:244]     Train net output #1: loss = 0.157991 (* 1 = 0.157991 loss)
I0401 01:50:28.913511 11876 sgd_solver.cpp:106] Iteration 46400, lr = 0.001
I0401 01:50:34.451683 11876 solver.cpp:228] Iteration 46500, loss = 0.107324
I0401 01:50:34.451683 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:50:34.451683 11876 solver.cpp:244]     Train net output #1: loss = 0.107324 (* 1 = 0.107324 loss)
I0401 01:50:34.451683 11876 sgd_solver.cpp:106] Iteration 46500, lr = 0.001
I0401 01:50:40.003659 11876 solver.cpp:228] Iteration 46600, loss = 0.243239
I0401 01:50:40.003659 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:50:40.003659 11876 solver.cpp:244]     Train net output #1: loss = 0.243239 (* 1 = 0.243239 loss)
I0401 01:50:40.003659 11876 sgd_solver.cpp:106] Iteration 46600, lr = 0.001
I0401 01:50:45.533648 11876 solver.cpp:228] Iteration 46700, loss = 0.158011
I0401 01:50:45.533648 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:50:45.533648 11876 solver.cpp:244]     Train net output #1: loss = 0.158011 (* 1 = 0.158011 loss)
I0401 01:50:45.533648 11876 sgd_solver.cpp:106] Iteration 46700, lr = 0.001
I0401 01:50:51.058688 11876 solver.cpp:228] Iteration 46800, loss = 0.208297
I0401 01:50:51.058688 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:50:51.058688 11876 solver.cpp:244]     Train net output #1: loss = 0.208297 (* 1 = 0.208297 loss)
I0401 01:50:51.058688 11876 sgd_solver.cpp:106] Iteration 46800, lr = 0.001
I0401 01:50:56.596544 11876 solver.cpp:228] Iteration 46900, loss = 0.121399
I0401 01:50:56.596544 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:50:56.596544 11876 solver.cpp:244]     Train net output #1: loss = 0.121398 (* 1 = 0.121398 loss)
I0401 01:50:56.596544 11876 sgd_solver.cpp:106] Iteration 46900, lr = 0.001
I0401 01:51:02.101920 11876 solver.cpp:337] Iteration 47000, Testing net (#0)
I0401 01:51:02.101920 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:51:03.717423 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8955
I0401 01:51:03.717923 11876 solver.cpp:404]     Test net output #1: loss = 0.340933 (* 1 = 0.340933 loss)
I0401 01:51:03.738744 11876 solver.cpp:228] Iteration 47000, loss = 0.162048
I0401 01:51:03.738744 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:51:03.738744 11876 solver.cpp:244]     Train net output #1: loss = 0.162048 (* 1 = 0.162048 loss)
I0401 01:51:03.738744 11876 sgd_solver.cpp:106] Iteration 47000, lr = 0.001
I0401 01:51:09.283160 11876 solver.cpp:228] Iteration 47100, loss = 0.110692
I0401 01:51:09.283676 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:51:09.283676 11876 solver.cpp:244]     Train net output #1: loss = 0.110691 (* 1 = 0.110691 loss)
I0401 01:51:09.283676 11876 sgd_solver.cpp:106] Iteration 47100, lr = 0.001
I0401 01:51:14.810387 11876 solver.cpp:228] Iteration 47200, loss = 0.124567
I0401 01:51:14.810387 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:51:14.810387 11876 solver.cpp:244]     Train net output #1: loss = 0.124567 (* 1 = 0.124567 loss)
I0401 01:51:14.810387 11876 sgd_solver.cpp:106] Iteration 47200, lr = 0.001
I0401 01:51:20.342380 11876 solver.cpp:228] Iteration 47300, loss = 0.17259
I0401 01:51:20.342380 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:51:20.342380 11876 solver.cpp:244]     Train net output #1: loss = 0.17259 (* 1 = 0.17259 loss)
I0401 01:51:20.342380 11876 sgd_solver.cpp:106] Iteration 47300, lr = 0.001
I0401 01:51:25.873931 11876 solver.cpp:228] Iteration 47400, loss = 0.108545
I0401 01:51:25.873931 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:51:25.873931 11876 solver.cpp:244]     Train net output #1: loss = 0.108545 (* 1 = 0.108545 loss)
I0401 01:51:25.873931 11876 sgd_solver.cpp:106] Iteration 47400, lr = 0.001
I0401 01:51:31.414412 11876 solver.cpp:228] Iteration 47500, loss = 0.165031
I0401 01:51:31.414412 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:51:31.415415 11876 solver.cpp:244]     Train net output #1: loss = 0.165031 (* 1 = 0.165031 loss)
I0401 01:51:31.415415 11876 sgd_solver.cpp:106] Iteration 47500, lr = 0.001
I0401 01:51:36.952392 11876 solver.cpp:228] Iteration 47600, loss = 0.237882
I0401 01:51:36.952392 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.9
I0401 01:51:36.952392 11876 solver.cpp:244]     Train net output #1: loss = 0.237882 (* 1 = 0.237882 loss)
I0401 01:51:36.952392 11876 sgd_solver.cpp:106] Iteration 47600, lr = 0.001
I0401 01:51:42.502913 11876 solver.cpp:228] Iteration 47700, loss = 0.189728
I0401 01:51:42.503414 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:51:42.503414 11876 solver.cpp:244]     Train net output #1: loss = 0.189728 (* 1 = 0.189728 loss)
I0401 01:51:42.503414 11876 sgd_solver.cpp:106] Iteration 47700, lr = 0.001
I0401 01:51:48.048178 11876 solver.cpp:228] Iteration 47800, loss = 0.156341
I0401 01:51:48.048178 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:51:48.048178 11876 solver.cpp:244]     Train net output #1: loss = 0.156341 (* 1 = 0.156341 loss)
I0401 01:51:48.048178 11876 sgd_solver.cpp:106] Iteration 47800, lr = 0.001
I0401 01:51:53.591883 11876 solver.cpp:228] Iteration 47900, loss = 0.155131
I0401 01:51:53.591883 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:51:53.591883 11876 solver.cpp:244]     Train net output #1: loss = 0.15513 (* 1 = 0.15513 loss)
I0401 01:51:53.591883 11876 sgd_solver.cpp:106] Iteration 47900, lr = 0.001
I0401 01:51:59.106345 11876 solver.cpp:337] Iteration 48000, Testing net (#0)
I0401 01:51:59.107336 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:52:00.726167 11876 solver.cpp:404]     Test net output #0: accuracy = 0.8934
I0401 01:52:00.726167 11876 solver.cpp:404]     Test net output #1: loss = 0.341019 (* 1 = 0.341019 loss)
I0401 01:52:00.746673 11876 solver.cpp:228] Iteration 48000, loss = 0.175824
I0401 01:52:00.746673 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:52:00.746673 11876 solver.cpp:244]     Train net output #1: loss = 0.175824 (* 1 = 0.175824 loss)
I0401 01:52:00.746673 11876 sgd_solver.cpp:46] MultiStep Status: Iteration 48000, step = 2
I0401 01:52:00.746673 11876 sgd_solver.cpp:106] Iteration 48000, lr = 0.0001
I0401 01:52:06.282163 11876 solver.cpp:228] Iteration 48100, loss = 0.109941
I0401 01:52:06.282163 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:52:06.282163 11876 solver.cpp:244]     Train net output #1: loss = 0.10994 (* 1 = 0.10994 loss)
I0401 01:52:06.282163 11876 sgd_solver.cpp:106] Iteration 48100, lr = 0.0001
I0401 01:52:11.811799 11876 solver.cpp:228] Iteration 48200, loss = 0.227922
I0401 01:52:11.811799 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.92
I0401 01:52:11.811799 11876 solver.cpp:244]     Train net output #1: loss = 0.227921 (* 1 = 0.227921 loss)
I0401 01:52:11.811799 11876 sgd_solver.cpp:106] Iteration 48200, lr = 0.0001
I0401 01:52:17.296241 11876 solver.cpp:228] Iteration 48300, loss = 0.111372
I0401 01:52:17.296241 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:52:17.296241 11876 solver.cpp:244]     Train net output #1: loss = 0.111372 (* 1 = 0.111372 loss)
I0401 01:52:17.296241 11876 sgd_solver.cpp:106] Iteration 48300, lr = 0.0001
I0401 01:52:22.803966 11876 solver.cpp:228] Iteration 48400, loss = 0.0678378
I0401 01:52:22.803966 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:52:22.803966 11876 solver.cpp:244]     Train net output #1: loss = 0.0678375 (* 1 = 0.0678375 loss)
I0401 01:52:22.803966 11876 sgd_solver.cpp:106] Iteration 48400, lr = 0.0001
I0401 01:52:28.340804 11876 solver.cpp:228] Iteration 48500, loss = 0.155533
I0401 01:52:28.340804 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.93
I0401 01:52:28.340804 11876 solver.cpp:244]     Train net output #1: loss = 0.155533 (* 1 = 0.155533 loss)
I0401 01:52:28.340804 11876 sgd_solver.cpp:106] Iteration 48500, lr = 0.0001
I0401 01:52:33.871093 11876 solver.cpp:228] Iteration 48600, loss = 0.12386
I0401 01:52:33.871093 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:52:33.871093 11876 solver.cpp:244]     Train net output #1: loss = 0.12386 (* 1 = 0.12386 loss)
I0401 01:52:33.871093 11876 sgd_solver.cpp:106] Iteration 48600, lr = 0.0001
I0401 01:52:39.413971 11876 solver.cpp:228] Iteration 48700, loss = 0.133498
I0401 01:52:39.413971 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:52:39.413971 11876 solver.cpp:244]     Train net output #1: loss = 0.133497 (* 1 = 0.133497 loss)
I0401 01:52:39.413971 11876 sgd_solver.cpp:106] Iteration 48700, lr = 0.0001
I0401 01:52:44.959077 11876 solver.cpp:228] Iteration 48800, loss = 0.0957301
I0401 01:52:44.959077 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:52:44.959077 11876 solver.cpp:244]     Train net output #1: loss = 0.0957299 (* 1 = 0.0957299 loss)
I0401 01:52:44.959077 11876 sgd_solver.cpp:106] Iteration 48800, lr = 0.0001
I0401 01:52:50.528237 11876 solver.cpp:228] Iteration 48900, loss = 0.110279
I0401 01:52:50.528237 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:52:50.528237 11876 solver.cpp:244]     Train net output #1: loss = 0.110279 (* 1 = 0.110279 loss)
I0401 01:52:50.528237 11876 sgd_solver.cpp:106] Iteration 48900, lr = 0.0001
I0401 01:52:56.069219 11876 solver.cpp:337] Iteration 49000, Testing net (#0)
I0401 01:52:56.069219 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:52:57.684213 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9131
I0401 01:52:57.684213 11876 solver.cpp:404]     Test net output #1: loss = 0.273284 (* 1 = 0.273284 loss)
I0401 01:52:57.706213 11876 solver.cpp:228] Iteration 49000, loss = 0.120467
I0401 01:52:57.706213 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:52:57.706213 11876 solver.cpp:244]     Train net output #1: loss = 0.120467 (* 1 = 0.120467 loss)
I0401 01:52:57.706213 11876 sgd_solver.cpp:106] Iteration 49000, lr = 0.0001
I0401 01:53:03.265377 11876 solver.cpp:228] Iteration 49100, loss = 0.0898327
I0401 01:53:03.265377 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:53:03.265377 11876 solver.cpp:244]     Train net output #1: loss = 0.0898325 (* 1 = 0.0898325 loss)
I0401 01:53:03.265377 11876 sgd_solver.cpp:106] Iteration 49100, lr = 0.0001
I0401 01:53:08.838878 11876 solver.cpp:228] Iteration 49200, loss = 0.11404
I0401 01:53:08.838878 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:53:08.838878 11876 solver.cpp:244]     Train net output #1: loss = 0.11404 (* 1 = 0.11404 loss)
I0401 01:53:08.838878 11876 sgd_solver.cpp:106] Iteration 49200, lr = 0.0001
I0401 01:53:14.403627 11876 solver.cpp:228] Iteration 49300, loss = 0.0839337
I0401 01:53:14.403627 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:53:14.403627 11876 solver.cpp:244]     Train net output #1: loss = 0.0839335 (* 1 = 0.0839335 loss)
I0401 01:53:14.403627 11876 sgd_solver.cpp:106] Iteration 49300, lr = 0.0001
I0401 01:53:19.956382 11876 solver.cpp:228] Iteration 49400, loss = 0.0308165
I0401 01:53:19.956382 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:53:19.956382 11876 solver.cpp:244]     Train net output #1: loss = 0.0308164 (* 1 = 0.0308164 loss)
I0401 01:53:19.956382 11876 sgd_solver.cpp:106] Iteration 49400, lr = 0.0001
I0401 01:53:25.520051 11876 solver.cpp:228] Iteration 49500, loss = 0.113494
I0401 01:53:25.520051 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:53:25.520051 11876 solver.cpp:244]     Train net output #1: loss = 0.113494 (* 1 = 0.113494 loss)
I0401 01:53:25.520051 11876 sgd_solver.cpp:106] Iteration 49500, lr = 0.0001
I0401 01:53:31.087946 11876 solver.cpp:228] Iteration 49600, loss = 0.110179
I0401 01:53:31.087946 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:53:31.087946 11876 solver.cpp:244]     Train net output #1: loss = 0.110179 (* 1 = 0.110179 loss)
I0401 01:53:31.087946 11876 sgd_solver.cpp:106] Iteration 49600, lr = 0.0001
I0401 01:53:36.664201 11876 solver.cpp:228] Iteration 49700, loss = 0.116058
I0401 01:53:36.664201 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:53:36.664201 11876 solver.cpp:244]     Train net output #1: loss = 0.116058 (* 1 = 0.116058 loss)
I0401 01:53:36.664201 11876 sgd_solver.cpp:106] Iteration 49700, lr = 0.0001
I0401 01:53:42.210235 11876 solver.cpp:228] Iteration 49800, loss = 0.0934088
I0401 01:53:42.210235 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:53:42.210235 11876 solver.cpp:244]     Train net output #1: loss = 0.0934087 (* 1 = 0.0934087 loss)
I0401 01:53:42.210235 11876 sgd_solver.cpp:106] Iteration 49800, lr = 0.0001
I0401 01:53:47.739274 11876 solver.cpp:228] Iteration 49900, loss = 0.0385562
I0401 01:53:47.739274 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:53:47.739274 11876 solver.cpp:244]     Train net output #1: loss = 0.0385562 (* 1 = 0.0385562 loss)
I0401 01:53:47.739274 11876 sgd_solver.cpp:106] Iteration 49900, lr = 0.0001
I0401 01:53:53.260339 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_50000.caffemodel
I0401 01:53:53.272351 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_50000.solverstate
I0401 01:53:53.275352 11876 solver.cpp:337] Iteration 50000, Testing net (#0)
I0401 01:53:53.275352 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:53:54.915506 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9146
I0401 01:53:54.915506 11876 solver.cpp:404]     Test net output #1: loss = 0.269963 (* 1 = 0.269963 loss)
I0401 01:53:54.936504 11876 solver.cpp:228] Iteration 50000, loss = 0.175205
I0401 01:53:54.936504 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:53:54.936504 11876 solver.cpp:244]     Train net output #1: loss = 0.175205 (* 1 = 0.175205 loss)
I0401 01:53:54.936504 11876 sgd_solver.cpp:106] Iteration 50000, lr = 0.0001
I0401 01:54:00.479472 11876 solver.cpp:228] Iteration 50100, loss = 0.103441
I0401 01:54:00.479472 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:54:00.479472 11876 solver.cpp:244]     Train net output #1: loss = 0.10344 (* 1 = 0.10344 loss)
I0401 01:54:00.479472 11876 sgd_solver.cpp:106] Iteration 50100, lr = 0.0001
I0401 01:54:06.014096 11876 solver.cpp:228] Iteration 50200, loss = 0.102134
I0401 01:54:06.015100 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:54:06.015100 11876 solver.cpp:244]     Train net output #1: loss = 0.102134 (* 1 = 0.102134 loss)
I0401 01:54:06.015100 11876 sgd_solver.cpp:106] Iteration 50200, lr = 0.0001
I0401 01:54:11.569278 11876 solver.cpp:228] Iteration 50300, loss = 0.0587291
I0401 01:54:11.569278 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:54:11.569278 11876 solver.cpp:244]     Train net output #1: loss = 0.058729 (* 1 = 0.058729 loss)
I0401 01:54:11.569278 11876 sgd_solver.cpp:106] Iteration 50300, lr = 0.0001
I0401 01:54:17.140135 11876 solver.cpp:228] Iteration 50400, loss = 0.0666041
I0401 01:54:17.140135 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:54:17.140135 11876 solver.cpp:244]     Train net output #1: loss = 0.066604 (* 1 = 0.066604 loss)
I0401 01:54:17.140135 11876 sgd_solver.cpp:106] Iteration 50400, lr = 0.0001
I0401 01:54:22.708768 11876 solver.cpp:228] Iteration 50500, loss = 0.0957966
I0401 01:54:22.708768 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:54:22.708768 11876 solver.cpp:244]     Train net output #1: loss = 0.0957965 (* 1 = 0.0957965 loss)
I0401 01:54:22.708768 11876 sgd_solver.cpp:106] Iteration 50500, lr = 0.0001
I0401 01:54:28.266038 11876 solver.cpp:228] Iteration 50600, loss = 0.109289
I0401 01:54:28.266038 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:54:28.266038 11876 solver.cpp:244]     Train net output #1: loss = 0.109289 (* 1 = 0.109289 loss)
I0401 01:54:28.266038 11876 sgd_solver.cpp:106] Iteration 50600, lr = 0.0001
I0401 01:54:33.792194 11876 solver.cpp:228] Iteration 50700, loss = 0.114065
I0401 01:54:33.792194 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:54:33.792194 11876 solver.cpp:244]     Train net output #1: loss = 0.114065 (* 1 = 0.114065 loss)
I0401 01:54:33.792194 11876 sgd_solver.cpp:106] Iteration 50700, lr = 0.0001
I0401 01:54:39.312855 11876 solver.cpp:228] Iteration 50800, loss = 0.0837881
I0401 01:54:39.312855 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:54:39.312855 11876 solver.cpp:244]     Train net output #1: loss = 0.083788 (* 1 = 0.083788 loss)
I0401 01:54:39.312855 11876 sgd_solver.cpp:106] Iteration 50800, lr = 0.0001
I0401 01:54:44.843883 11876 solver.cpp:228] Iteration 50900, loss = 0.038711
I0401 01:54:44.843883 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:54:44.843883 11876 solver.cpp:244]     Train net output #1: loss = 0.0387109 (* 1 = 0.0387109 loss)
I0401 01:54:44.843883 11876 sgd_solver.cpp:106] Iteration 50900, lr = 0.0001
I0401 01:54:50.344112 11876 solver.cpp:337] Iteration 51000, Testing net (#0)
I0401 01:54:50.344112 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:54:51.951242 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9168
I0401 01:54:51.951242 11876 solver.cpp:404]     Test net output #1: loss = 0.270214 (* 1 = 0.270214 loss)
I0401 01:54:51.971758 11876 solver.cpp:228] Iteration 51000, loss = 0.1391
I0401 01:54:51.971758 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:54:51.971758 11876 solver.cpp:244]     Train net output #1: loss = 0.1391 (* 1 = 0.1391 loss)
I0401 01:54:51.971758 11876 sgd_solver.cpp:106] Iteration 51000, lr = 0.0001
I0401 01:54:57.482661 11876 solver.cpp:228] Iteration 51100, loss = 0.0909413
I0401 01:54:57.482661 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:54:57.482661 11876 solver.cpp:244]     Train net output #1: loss = 0.0909412 (* 1 = 0.0909412 loss)
I0401 01:54:57.482661 11876 sgd_solver.cpp:106] Iteration 51100, lr = 0.0001
I0401 01:55:03.011693 11876 solver.cpp:228] Iteration 51200, loss = 0.0711362
I0401 01:55:03.011693 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:55:03.011693 11876 solver.cpp:244]     Train net output #1: loss = 0.0711362 (* 1 = 0.0711362 loss)
I0401 01:55:03.011693 11876 sgd_solver.cpp:106] Iteration 51200, lr = 0.0001
I0401 01:55:08.532244 11876 solver.cpp:228] Iteration 51300, loss = 0.0884727
I0401 01:55:08.532244 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:55:08.532244 11876 solver.cpp:244]     Train net output #1: loss = 0.0884727 (* 1 = 0.0884727 loss)
I0401 01:55:08.532244 11876 sgd_solver.cpp:106] Iteration 51300, lr = 0.0001
I0401 01:55:14.057608 11876 solver.cpp:228] Iteration 51400, loss = 0.0481104
I0401 01:55:14.057608 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:55:14.057608 11876 solver.cpp:244]     Train net output #1: loss = 0.0481104 (* 1 = 0.0481104 loss)
I0401 01:55:14.057608 11876 sgd_solver.cpp:106] Iteration 51400, lr = 0.0001
I0401 01:55:19.587843 11876 solver.cpp:228] Iteration 51500, loss = 0.0902878
I0401 01:55:19.587843 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:55:19.587843 11876 solver.cpp:244]     Train net output #1: loss = 0.0902878 (* 1 = 0.0902878 loss)
I0401 01:55:19.587843 11876 sgd_solver.cpp:106] Iteration 51500, lr = 0.0001
I0401 01:55:25.143388 11876 solver.cpp:228] Iteration 51600, loss = 0.0907404
I0401 01:55:25.143388 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:55:25.143388 11876 solver.cpp:244]     Train net output #1: loss = 0.0907403 (* 1 = 0.0907403 loss)
I0401 01:55:25.143388 11876 sgd_solver.cpp:106] Iteration 51600, lr = 0.0001
I0401 01:55:30.670681 11876 solver.cpp:228] Iteration 51700, loss = 0.0950993
I0401 01:55:30.670681 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:55:30.670681 11876 solver.cpp:244]     Train net output #1: loss = 0.0950992 (* 1 = 0.0950992 loss)
I0401 01:55:30.670681 11876 sgd_solver.cpp:106] Iteration 51700, lr = 0.0001
I0401 01:55:36.219470 11876 solver.cpp:228] Iteration 51800, loss = 0.0765895
I0401 01:55:36.219470 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:55:36.219470 11876 solver.cpp:244]     Train net output #1: loss = 0.0765894 (* 1 = 0.0765894 loss)
I0401 01:55:36.219470 11876 sgd_solver.cpp:106] Iteration 51800, lr = 0.0001
I0401 01:55:41.762187 11876 solver.cpp:228] Iteration 51900, loss = 0.0678784
I0401 01:55:41.762187 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:55:41.762187 11876 solver.cpp:244]     Train net output #1: loss = 0.0678783 (* 1 = 0.0678783 loss)
I0401 01:55:41.762187 11876 sgd_solver.cpp:106] Iteration 51900, lr = 0.0001
I0401 01:55:47.287850 11876 solver.cpp:337] Iteration 52000, Testing net (#0)
I0401 01:55:47.287850 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:55:48.902521 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9186
I0401 01:55:48.903527 11876 solver.cpp:404]     Test net output #1: loss = 0.272197 (* 1 = 0.272197 loss)
I0401 01:55:48.924530 11876 solver.cpp:228] Iteration 52000, loss = 0.120121
I0401 01:55:48.924530 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:55:48.924530 11876 solver.cpp:244]     Train net output #1: loss = 0.120121 (* 1 = 0.120121 loss)
I0401 01:55:48.924530 11876 sgd_solver.cpp:106] Iteration 52000, lr = 0.0001
I0401 01:55:54.468441 11876 solver.cpp:228] Iteration 52100, loss = 0.126238
I0401 01:55:54.468441 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:55:54.468441 11876 solver.cpp:244]     Train net output #1: loss = 0.126238 (* 1 = 0.126238 loss)
I0401 01:55:54.468441 11876 sgd_solver.cpp:106] Iteration 52100, lr = 0.0001
I0401 01:56:00.005997 11876 solver.cpp:228] Iteration 52200, loss = 0.063346
I0401 01:56:00.005997 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:56:00.005997 11876 solver.cpp:244]     Train net output #1: loss = 0.0633459 (* 1 = 0.0633459 loss)
I0401 01:56:00.005997 11876 sgd_solver.cpp:106] Iteration 52200, lr = 0.0001
I0401 01:56:05.549773 11876 solver.cpp:228] Iteration 52300, loss = 0.0464365
I0401 01:56:05.549773 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:56:05.549773 11876 solver.cpp:244]     Train net output #1: loss = 0.0464364 (* 1 = 0.0464364 loss)
I0401 01:56:05.549773 11876 sgd_solver.cpp:106] Iteration 52300, lr = 0.0001
I0401 01:56:11.087208 11876 solver.cpp:228] Iteration 52400, loss = 0.0400492
I0401 01:56:11.087208 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:56:11.087208 11876 solver.cpp:244]     Train net output #1: loss = 0.0400491 (* 1 = 0.0400491 loss)
I0401 01:56:11.087208 11876 sgd_solver.cpp:106] Iteration 52400, lr = 0.0001
I0401 01:56:16.619664 11876 solver.cpp:228] Iteration 52500, loss = 0.101457
I0401 01:56:16.619664 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:56:16.619664 11876 solver.cpp:244]     Train net output #1: loss = 0.101457 (* 1 = 0.101457 loss)
I0401 01:56:16.619664 11876 sgd_solver.cpp:106] Iteration 52500, lr = 0.0001
I0401 01:56:22.160060 11876 solver.cpp:228] Iteration 52600, loss = 0.0781188
I0401 01:56:22.160060 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:56:22.160560 11876 solver.cpp:244]     Train net output #1: loss = 0.0781187 (* 1 = 0.0781187 loss)
I0401 01:56:22.160560 11876 sgd_solver.cpp:106] Iteration 52600, lr = 0.0001
I0401 01:56:27.698573 11876 solver.cpp:228] Iteration 52700, loss = 0.124692
I0401 01:56:27.698573 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:56:27.698573 11876 solver.cpp:244]     Train net output #1: loss = 0.124692 (* 1 = 0.124692 loss)
I0401 01:56:27.698573 11876 sgd_solver.cpp:106] Iteration 52700, lr = 0.0001
I0401 01:56:33.212321 11876 solver.cpp:228] Iteration 52800, loss = 0.0598145
I0401 01:56:33.212321 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:56:33.212321 11876 solver.cpp:244]     Train net output #1: loss = 0.0598145 (* 1 = 0.0598145 loss)
I0401 01:56:33.212321 11876 sgd_solver.cpp:106] Iteration 52800, lr = 0.0001
I0401 01:56:38.764124 11876 solver.cpp:228] Iteration 52900, loss = 0.0420274
I0401 01:56:38.764124 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:56:38.764124 11876 solver.cpp:244]     Train net output #1: loss = 0.0420273 (* 1 = 0.0420273 loss)
I0401 01:56:38.764124 11876 sgd_solver.cpp:106] Iteration 52900, lr = 0.0001
I0401 01:56:44.284237 11876 solver.cpp:337] Iteration 53000, Testing net (#0)
I0401 01:56:44.284237 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:56:45.911453 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9172
I0401 01:56:45.911453 11876 solver.cpp:404]     Test net output #1: loss = 0.273744 (* 1 = 0.273744 loss)
I0401 01:56:45.932481 11876 solver.cpp:228] Iteration 53000, loss = 0.129321
I0401 01:56:45.932481 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:56:45.932481 11876 solver.cpp:244]     Train net output #1: loss = 0.129321 (* 1 = 0.129321 loss)
I0401 01:56:45.932481 11876 sgd_solver.cpp:106] Iteration 53000, lr = 0.0001
I0401 01:56:51.485416 11876 solver.cpp:228] Iteration 53100, loss = 0.119588
I0401 01:56:51.485416 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:56:51.485416 11876 solver.cpp:244]     Train net output #1: loss = 0.119587 (* 1 = 0.119587 loss)
I0401 01:56:51.485416 11876 sgd_solver.cpp:106] Iteration 53100, lr = 0.0001
I0401 01:56:57.022603 11876 solver.cpp:228] Iteration 53200, loss = 0.125729
I0401 01:56:57.022603 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:56:57.022603 11876 solver.cpp:244]     Train net output #1: loss = 0.125729 (* 1 = 0.125729 loss)
I0401 01:56:57.022603 11876 sgd_solver.cpp:106] Iteration 53200, lr = 0.0001
I0401 01:57:02.572840 11876 solver.cpp:228] Iteration 53300, loss = 0.0761369
I0401 01:57:02.572840 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:57:02.572840 11876 solver.cpp:244]     Train net output #1: loss = 0.0761368 (* 1 = 0.0761368 loss)
I0401 01:57:02.572840 11876 sgd_solver.cpp:106] Iteration 53300, lr = 0.0001
I0401 01:57:08.098642 11876 solver.cpp:228] Iteration 53400, loss = 0.0570901
I0401 01:57:08.098642 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:57:08.098642 11876 solver.cpp:244]     Train net output #1: loss = 0.05709 (* 1 = 0.05709 loss)
I0401 01:57:08.098642 11876 sgd_solver.cpp:106] Iteration 53400, lr = 0.0001
I0401 01:57:13.658320 11876 solver.cpp:228] Iteration 53500, loss = 0.0736743
I0401 01:57:13.658320 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:57:13.658320 11876 solver.cpp:244]     Train net output #1: loss = 0.0736742 (* 1 = 0.0736742 loss)
I0401 01:57:13.658320 11876 sgd_solver.cpp:106] Iteration 53500, lr = 0.0001
I0401 01:57:19.214606 11876 solver.cpp:228] Iteration 53600, loss = 0.0747111
I0401 01:57:19.214606 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:57:19.214606 11876 solver.cpp:244]     Train net output #1: loss = 0.074711 (* 1 = 0.074711 loss)
I0401 01:57:19.214606 11876 sgd_solver.cpp:106] Iteration 53600, lr = 0.0001
I0401 01:57:24.818735 11876 solver.cpp:228] Iteration 53700, loss = 0.114681
I0401 01:57:24.818735 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 01:57:24.818735 11876 solver.cpp:244]     Train net output #1: loss = 0.114681 (* 1 = 0.114681 loss)
I0401 01:57:24.818735 11876 sgd_solver.cpp:106] Iteration 53700, lr = 0.0001
I0401 01:57:30.404831 11876 solver.cpp:228] Iteration 53800, loss = 0.096308
I0401 01:57:30.405838 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:57:30.405838 11876 solver.cpp:244]     Train net output #1: loss = 0.096308 (* 1 = 0.096308 loss)
I0401 01:57:30.405838 11876 sgd_solver.cpp:106] Iteration 53800, lr = 0.0001
I0401 01:57:35.971015 11876 solver.cpp:228] Iteration 53900, loss = 0.0415964
I0401 01:57:35.971015 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:57:35.971015 11876 solver.cpp:244]     Train net output #1: loss = 0.0415964 (* 1 = 0.0415964 loss)
I0401 01:57:35.971015 11876 sgd_solver.cpp:106] Iteration 53900, lr = 0.0001
I0401 01:57:41.481547 11876 solver.cpp:337] Iteration 54000, Testing net (#0)
I0401 01:57:41.481547 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:57:43.103014 11876 solver.cpp:404]     Test net output #0: accuracy = 0.918
I0401 01:57:43.103014 11876 solver.cpp:404]     Test net output #1: loss = 0.27418 (* 1 = 0.27418 loss)
I0401 01:57:43.123992 11876 solver.cpp:228] Iteration 54000, loss = 0.0561757
I0401 01:57:43.123992 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:57:43.123992 11876 solver.cpp:244]     Train net output #1: loss = 0.0561757 (* 1 = 0.0561757 loss)
I0401 01:57:43.123992 11876 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 3
I0401 01:57:43.123992 11876 sgd_solver.cpp:106] Iteration 54000, lr = 1e-005
I0401 01:57:48.645710 11876 solver.cpp:228] Iteration 54100, loss = 0.091903
I0401 01:57:48.645710 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:57:48.645710 11876 solver.cpp:244]     Train net output #1: loss = 0.091903 (* 1 = 0.091903 loss)
I0401 01:57:48.645710 11876 sgd_solver.cpp:106] Iteration 54100, lr = 1e-005
I0401 01:57:54.180879 11876 solver.cpp:228] Iteration 54200, loss = 0.0982884
I0401 01:57:54.180879 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:57:54.180879 11876 solver.cpp:244]     Train net output #1: loss = 0.0982884 (* 1 = 0.0982884 loss)
I0401 01:57:54.180879 11876 sgd_solver.cpp:106] Iteration 54200, lr = 1e-005
I0401 01:57:59.728184 11876 solver.cpp:228] Iteration 54300, loss = 0.0368336
I0401 01:57:59.728688 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:57:59.728688 11876 solver.cpp:244]     Train net output #1: loss = 0.0368336 (* 1 = 0.0368336 loss)
I0401 01:57:59.728688 11876 sgd_solver.cpp:106] Iteration 54300, lr = 1e-005
I0401 01:58:05.269321 11876 solver.cpp:228] Iteration 54400, loss = 0.0494449
I0401 01:58:05.269321 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:58:05.269321 11876 solver.cpp:244]     Train net output #1: loss = 0.0494449 (* 1 = 0.0494449 loss)
I0401 01:58:05.269321 11876 sgd_solver.cpp:106] Iteration 54400, lr = 1e-005
I0401 01:58:10.798475 11876 solver.cpp:228] Iteration 54500, loss = 0.086124
I0401 01:58:10.798475 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:58:10.798475 11876 solver.cpp:244]     Train net output #1: loss = 0.0861239 (* 1 = 0.0861239 loss)
I0401 01:58:10.798475 11876 sgd_solver.cpp:106] Iteration 54500, lr = 1e-005
I0401 01:58:16.335187 11876 solver.cpp:228] Iteration 54600, loss = 0.0776454
I0401 01:58:16.335187 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:58:16.335187 11876 solver.cpp:244]     Train net output #1: loss = 0.0776454 (* 1 = 0.0776454 loss)
I0401 01:58:16.335187 11876 sgd_solver.cpp:106] Iteration 54600, lr = 1e-005
I0401 01:58:21.880724 11876 solver.cpp:228] Iteration 54700, loss = 0.0719365
I0401 01:58:21.880724 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:58:21.880724 11876 solver.cpp:244]     Train net output #1: loss = 0.0719365 (* 1 = 0.0719365 loss)
I0401 01:58:21.880724 11876 sgd_solver.cpp:106] Iteration 54700, lr = 1e-005
I0401 01:58:27.435447 11876 solver.cpp:228] Iteration 54800, loss = 0.0506721
I0401 01:58:27.435447 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:58:27.435447 11876 solver.cpp:244]     Train net output #1: loss = 0.0506721 (* 1 = 0.0506721 loss)
I0401 01:58:27.435447 11876 sgd_solver.cpp:106] Iteration 54800, lr = 1e-005
I0401 01:58:32.986929 11876 solver.cpp:228] Iteration 54900, loss = 0.0224313
I0401 01:58:32.986929 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:58:32.986929 11876 solver.cpp:244]     Train net output #1: loss = 0.0224313 (* 1 = 0.0224313 loss)
I0401 01:58:32.986929 11876 sgd_solver.cpp:106] Iteration 54900, lr = 1e-005
I0401 01:58:38.513079 11876 solver.cpp:337] Iteration 55000, Testing net (#0)
I0401 01:58:38.513079 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:58:40.134974 11876 solver.cpp:404]     Test net output #0: accuracy = 0.918
I0401 01:58:40.134974 11876 solver.cpp:404]     Test net output #1: loss = 0.272126 (* 1 = 0.272126 loss)
I0401 01:58:40.157012 11876 solver.cpp:228] Iteration 55000, loss = 0.101473
I0401 01:58:40.157012 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 01:58:40.157012 11876 solver.cpp:244]     Train net output #1: loss = 0.101473 (* 1 = 0.101473 loss)
I0401 01:58:40.157012 11876 sgd_solver.cpp:106] Iteration 55000, lr = 1e-005
I0401 01:58:45.707545 11876 solver.cpp:228] Iteration 55100, loss = 0.0767074
I0401 01:58:45.707545 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:58:45.707545 11876 solver.cpp:244]     Train net output #1: loss = 0.0767074 (* 1 = 0.0767074 loss)
I0401 01:58:45.707545 11876 sgd_solver.cpp:106] Iteration 55100, lr = 1e-005
I0401 01:58:51.265666 11876 solver.cpp:228] Iteration 55200, loss = 0.10757
I0401 01:58:51.265666 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 01:58:51.265666 11876 solver.cpp:244]     Train net output #1: loss = 0.10757 (* 1 = 0.10757 loss)
I0401 01:58:51.265666 11876 sgd_solver.cpp:106] Iteration 55200, lr = 1e-005
I0401 01:58:56.808596 11876 solver.cpp:228] Iteration 55300, loss = 0.0439324
I0401 01:58:56.808596 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:58:56.808596 11876 solver.cpp:244]     Train net output #1: loss = 0.0439324 (* 1 = 0.0439324 loss)
I0401 01:58:56.808596 11876 sgd_solver.cpp:106] Iteration 55300, lr = 1e-005
I0401 01:59:02.349488 11876 solver.cpp:228] Iteration 55400, loss = 0.101109
I0401 01:59:02.349488 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:59:02.349488 11876 solver.cpp:244]     Train net output #1: loss = 0.101109 (* 1 = 0.101109 loss)
I0401 01:59:02.349488 11876 sgd_solver.cpp:106] Iteration 55400, lr = 1e-005
I0401 01:59:07.926980 11876 solver.cpp:228] Iteration 55500, loss = 0.0874871
I0401 01:59:07.926980 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:59:07.926980 11876 solver.cpp:244]     Train net output #1: loss = 0.0874871 (* 1 = 0.0874871 loss)
I0401 01:59:07.926980 11876 sgd_solver.cpp:106] Iteration 55500, lr = 1e-005
I0401 01:59:13.495239 11876 solver.cpp:228] Iteration 55600, loss = 0.0565804
I0401 01:59:13.495239 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:59:13.495239 11876 solver.cpp:244]     Train net output #1: loss = 0.0565804 (* 1 = 0.0565804 loss)
I0401 01:59:13.495239 11876 sgd_solver.cpp:106] Iteration 55600, lr = 1e-005
I0401 01:59:19.052984 11876 solver.cpp:228] Iteration 55700, loss = 0.105759
I0401 01:59:19.052984 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:59:19.052984 11876 solver.cpp:244]     Train net output #1: loss = 0.105759 (* 1 = 0.105759 loss)
I0401 01:59:19.052984 11876 sgd_solver.cpp:106] Iteration 55700, lr = 1e-005
I0401 01:59:24.606322 11876 solver.cpp:228] Iteration 55800, loss = 0.0422138
I0401 01:59:24.606322 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:59:24.606322 11876 solver.cpp:244]     Train net output #1: loss = 0.0422138 (* 1 = 0.0422138 loss)
I0401 01:59:24.606322 11876 sgd_solver.cpp:106] Iteration 55800, lr = 1e-005
I0401 01:59:30.138314 11876 solver.cpp:228] Iteration 55900, loss = 0.0270763
I0401 01:59:30.138314 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:59:30.138314 11876 solver.cpp:244]     Train net output #1: loss = 0.0270763 (* 1 = 0.0270763 loss)
I0401 01:59:30.138314 11876 sgd_solver.cpp:106] Iteration 55900, lr = 1e-005
I0401 01:59:35.688129 11876 solver.cpp:337] Iteration 56000, Testing net (#0)
I0401 01:59:35.689128 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 01:59:37.300269 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9183
I0401 01:59:37.301281 11876 solver.cpp:404]     Test net output #1: loss = 0.272279 (* 1 = 0.272279 loss)
I0401 01:59:37.321784 11876 solver.cpp:228] Iteration 56000, loss = 0.0826413
I0401 01:59:37.321784 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 01:59:37.321784 11876 solver.cpp:244]     Train net output #1: loss = 0.0826414 (* 1 = 0.0826414 loss)
I0401 01:59:37.321784 11876 sgd_solver.cpp:106] Iteration 56000, lr = 1e-005
I0401 01:59:42.902567 11876 solver.cpp:228] Iteration 56100, loss = 0.0775826
I0401 01:59:42.902567 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:59:42.902567 11876 solver.cpp:244]     Train net output #1: loss = 0.0775827 (* 1 = 0.0775827 loss)
I0401 01:59:42.902567 11876 sgd_solver.cpp:106] Iteration 56100, lr = 1e-005
I0401 01:59:48.490165 11876 solver.cpp:228] Iteration 56200, loss = 0.0653099
I0401 01:59:48.490165 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 01:59:48.490165 11876 solver.cpp:244]     Train net output #1: loss = 0.0653099 (* 1 = 0.0653099 loss)
I0401 01:59:48.490165 11876 sgd_solver.cpp:106] Iteration 56200, lr = 1e-005
I0401 01:59:54.040189 11876 solver.cpp:228] Iteration 56300, loss = 0.0743043
I0401 01:59:54.040688 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 01:59:54.040688 11876 solver.cpp:244]     Train net output #1: loss = 0.0743044 (* 1 = 0.0743044 loss)
I0401 01:59:54.040688 11876 sgd_solver.cpp:106] Iteration 56300, lr = 1e-005
I0401 01:59:59.596667 11876 solver.cpp:228] Iteration 56400, loss = 0.0209658
I0401 01:59:59.596667 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 01:59:59.596667 11876 solver.cpp:244]     Train net output #1: loss = 0.0209659 (* 1 = 0.0209659 loss)
I0401 01:59:59.596667 11876 sgd_solver.cpp:106] Iteration 56400, lr = 1e-005
I0401 02:00:05.142940 11876 solver.cpp:228] Iteration 56500, loss = 0.103415
I0401 02:00:05.142940 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:00:05.142940 11876 solver.cpp:244]     Train net output #1: loss = 0.103415 (* 1 = 0.103415 loss)
I0401 02:00:05.142940 11876 sgd_solver.cpp:106] Iteration 56500, lr = 1e-005
I0401 02:00:10.695806 11876 solver.cpp:228] Iteration 56600, loss = 0.0750922
I0401 02:00:10.695806 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:00:10.695806 11876 solver.cpp:244]     Train net output #1: loss = 0.0750922 (* 1 = 0.0750922 loss)
I0401 02:00:10.695806 11876 sgd_solver.cpp:106] Iteration 56600, lr = 1e-005
I0401 02:00:16.255298 11876 solver.cpp:228] Iteration 56700, loss = 0.0797703
I0401 02:00:16.255298 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:00:16.255298 11876 solver.cpp:244]     Train net output #1: loss = 0.0797704 (* 1 = 0.0797704 loss)
I0401 02:00:16.255298 11876 sgd_solver.cpp:106] Iteration 56700, lr = 1e-005
I0401 02:00:21.809260 11876 solver.cpp:228] Iteration 56800, loss = 0.0537453
I0401 02:00:21.809260 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:00:21.809762 11876 solver.cpp:244]     Train net output #1: loss = 0.0537454 (* 1 = 0.0537454 loss)
I0401 02:00:21.809762 11876 sgd_solver.cpp:106] Iteration 56800, lr = 1e-005
I0401 02:00:27.374377 11876 solver.cpp:228] Iteration 56900, loss = 0.0305501
I0401 02:00:27.374377 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:00:27.374377 11876 solver.cpp:244]     Train net output #1: loss = 0.0305502 (* 1 = 0.0305502 loss)
I0401 02:00:27.374377 11876 sgd_solver.cpp:106] Iteration 56900, lr = 1e-005
I0401 02:00:32.901362 11876 solver.cpp:337] Iteration 57000, Testing net (#0)
I0401 02:00:32.901362 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:00:34.525296 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9189
I0401 02:00:34.525296 11876 solver.cpp:404]     Test net output #1: loss = 0.27216 (* 1 = 0.27216 loss)
I0401 02:00:34.546298 11876 solver.cpp:228] Iteration 57000, loss = 0.137102
I0401 02:00:34.546298 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 02:00:34.546298 11876 solver.cpp:244]     Train net output #1: loss = 0.137102 (* 1 = 0.137102 loss)
I0401 02:00:34.546298 11876 sgd_solver.cpp:106] Iteration 57000, lr = 1e-005
I0401 02:00:40.097849 11876 solver.cpp:228] Iteration 57100, loss = 0.0936948
I0401 02:00:40.097849 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:00:40.097849 11876 solver.cpp:244]     Train net output #1: loss = 0.0936949 (* 1 = 0.0936949 loss)
I0401 02:00:40.097849 11876 sgd_solver.cpp:106] Iteration 57100, lr = 1e-005
I0401 02:00:45.655714 11876 solver.cpp:228] Iteration 57200, loss = 0.0518335
I0401 02:00:45.655714 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:00:45.655714 11876 solver.cpp:244]     Train net output #1: loss = 0.0518336 (* 1 = 0.0518336 loss)
I0401 02:00:45.655714 11876 sgd_solver.cpp:106] Iteration 57200, lr = 1e-005
I0401 02:00:51.215523 11876 solver.cpp:228] Iteration 57300, loss = 0.057331
I0401 02:00:51.215523 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:00:51.215523 11876 solver.cpp:244]     Train net output #1: loss = 0.0573311 (* 1 = 0.0573311 loss)
I0401 02:00:51.215523 11876 sgd_solver.cpp:106] Iteration 57300, lr = 1e-005
I0401 02:00:56.781450 11876 solver.cpp:228] Iteration 57400, loss = 0.0380773
I0401 02:00:56.781450 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:00:56.781450 11876 solver.cpp:244]     Train net output #1: loss = 0.0380774 (* 1 = 0.0380774 loss)
I0401 02:00:56.781450 11876 sgd_solver.cpp:106] Iteration 57400, lr = 1e-005
I0401 02:01:02.329648 11876 solver.cpp:228] Iteration 57500, loss = 0.0387241
I0401 02:01:02.329648 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:01:02.329648 11876 solver.cpp:244]     Train net output #1: loss = 0.0387241 (* 1 = 0.0387241 loss)
I0401 02:01:02.329648 11876 sgd_solver.cpp:106] Iteration 57500, lr = 1e-005
I0401 02:01:07.884683 11876 solver.cpp:228] Iteration 57600, loss = 0.0932274
I0401 02:01:07.884683 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:01:07.884683 11876 solver.cpp:244]     Train net output #1: loss = 0.0932274 (* 1 = 0.0932274 loss)
I0401 02:01:07.884683 11876 sgd_solver.cpp:106] Iteration 57600, lr = 1e-005
I0401 02:01:13.431133 11876 solver.cpp:228] Iteration 57700, loss = 0.0841099
I0401 02:01:13.431632 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:01:13.431632 11876 solver.cpp:244]     Train net output #1: loss = 0.0841099 (* 1 = 0.0841099 loss)
I0401 02:01:13.431632 11876 sgd_solver.cpp:106] Iteration 57700, lr = 1e-005
I0401 02:01:18.986964 11876 solver.cpp:228] Iteration 57800, loss = 0.0366173
I0401 02:01:18.987964 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:01:18.987964 11876 solver.cpp:244]     Train net output #1: loss = 0.0366173 (* 1 = 0.0366173 loss)
I0401 02:01:18.987964 11876 sgd_solver.cpp:106] Iteration 57800, lr = 1e-005
I0401 02:01:24.544927 11876 solver.cpp:228] Iteration 57900, loss = 0.0379504
I0401 02:01:24.544927 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:01:24.544927 11876 solver.cpp:244]     Train net output #1: loss = 0.0379504 (* 1 = 0.0379504 loss)
I0401 02:01:24.544927 11876 sgd_solver.cpp:106] Iteration 57900, lr = 1e-005
I0401 02:01:30.072249 11876 solver.cpp:337] Iteration 58000, Testing net (#0)
I0401 02:01:30.072249 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:01:31.685626 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9195
I0401 02:01:31.685626 11876 solver.cpp:404]     Test net output #1: loss = 0.271792 (* 1 = 0.271792 loss)
I0401 02:01:31.706615 11876 solver.cpp:228] Iteration 58000, loss = 0.0584326
I0401 02:01:31.706615 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:01:31.706615 11876 solver.cpp:244]     Train net output #1: loss = 0.0584326 (* 1 = 0.0584326 loss)
I0401 02:01:31.706615 11876 sgd_solver.cpp:106] Iteration 58000, lr = 1e-005
I0401 02:01:37.240730 11876 solver.cpp:228] Iteration 58100, loss = 0.0995318
I0401 02:01:37.240730 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:01:37.240730 11876 solver.cpp:244]     Train net output #1: loss = 0.0995319 (* 1 = 0.0995319 loss)
I0401 02:01:37.240730 11876 sgd_solver.cpp:106] Iteration 58100, lr = 1e-005
I0401 02:01:42.782790 11876 solver.cpp:228] Iteration 58200, loss = 0.122474
I0401 02:01:42.783299 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:01:42.783299 11876 solver.cpp:244]     Train net output #1: loss = 0.122474 (* 1 = 0.122474 loss)
I0401 02:01:42.783299 11876 sgd_solver.cpp:106] Iteration 58200, lr = 1e-005
I0401 02:01:48.381718 11876 solver.cpp:228] Iteration 58300, loss = 0.0535747
I0401 02:01:48.381718 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:01:48.381718 11876 solver.cpp:244]     Train net output #1: loss = 0.0535748 (* 1 = 0.0535748 loss)
I0401 02:01:48.381718 11876 sgd_solver.cpp:106] Iteration 58300, lr = 1e-005
I0401 02:01:54.020660 11876 solver.cpp:228] Iteration 58400, loss = 0.0362297
I0401 02:01:54.020660 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:01:54.020660 11876 solver.cpp:244]     Train net output #1: loss = 0.0362297 (* 1 = 0.0362297 loss)
I0401 02:01:54.020660 11876 sgd_solver.cpp:106] Iteration 58400, lr = 1e-005
I0401 02:01:59.599838 11876 solver.cpp:228] Iteration 58500, loss = 0.0505635
I0401 02:01:59.599838 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:01:59.599838 11876 solver.cpp:244]     Train net output #1: loss = 0.0505636 (* 1 = 0.0505636 loss)
I0401 02:01:59.599838 11876 sgd_solver.cpp:106] Iteration 58500, lr = 1e-005
I0401 02:02:05.216944 11876 solver.cpp:228] Iteration 58600, loss = 0.075973
I0401 02:02:05.216944 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:02:05.216944 11876 solver.cpp:244]     Train net output #1: loss = 0.075973 (* 1 = 0.075973 loss)
I0401 02:02:05.216944 11876 sgd_solver.cpp:106] Iteration 58600, lr = 1e-005
I0401 02:02:10.813230 11876 solver.cpp:228] Iteration 58700, loss = 0.0639091
I0401 02:02:10.813230 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:02:10.813230 11876 solver.cpp:244]     Train net output #1: loss = 0.0639091 (* 1 = 0.0639091 loss)
I0401 02:02:10.813230 11876 sgd_solver.cpp:106] Iteration 58700, lr = 1e-005
I0401 02:02:16.369246 11876 solver.cpp:228] Iteration 58800, loss = 0.048137
I0401 02:02:16.369246 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:02:16.369246 11876 solver.cpp:244]     Train net output #1: loss = 0.0481371 (* 1 = 0.0481371 loss)
I0401 02:02:16.369246 11876 sgd_solver.cpp:106] Iteration 58800, lr = 1e-005
I0401 02:02:21.932729 11876 solver.cpp:228] Iteration 58900, loss = 0.0446043
I0401 02:02:21.933728 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:02:21.933728 11876 solver.cpp:244]     Train net output #1: loss = 0.0446044 (* 1 = 0.0446044 loss)
I0401 02:02:21.933728 11876 sgd_solver.cpp:106] Iteration 58900, lr = 1e-005
I0401 02:02:27.451885 11876 solver.cpp:337] Iteration 59000, Testing net (#0)
I0401 02:02:27.451885 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:02:29.079221 11876 solver.cpp:404]     Test net output #0: accuracy = 0.919
I0401 02:02:29.079221 11876 solver.cpp:404]     Test net output #1: loss = 0.271825 (* 1 = 0.271825 loss)
I0401 02:02:29.101727 11876 solver.cpp:228] Iteration 59000, loss = 0.0850036
I0401 02:02:29.101727 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:02:29.101727 11876 solver.cpp:244]     Train net output #1: loss = 0.0850037 (* 1 = 0.0850037 loss)
I0401 02:02:29.101727 11876 sgd_solver.cpp:106] Iteration 59000, lr = 1e-005
I0401 02:02:34.711746 11876 solver.cpp:228] Iteration 59100, loss = 0.0565865
I0401 02:02:34.711746 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:02:34.711746 11876 solver.cpp:244]     Train net output #1: loss = 0.0565866 (* 1 = 0.0565866 loss)
I0401 02:02:34.711746 11876 sgd_solver.cpp:106] Iteration 59100, lr = 1e-005
I0401 02:02:40.290027 11876 solver.cpp:228] Iteration 59200, loss = 0.0710054
I0401 02:02:40.290027 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:02:40.290027 11876 solver.cpp:244]     Train net output #1: loss = 0.0710055 (* 1 = 0.0710055 loss)
I0401 02:02:40.290027 11876 sgd_solver.cpp:106] Iteration 59200, lr = 1e-005
I0401 02:02:45.886711 11876 solver.cpp:228] Iteration 59300, loss = 0.0682945
I0401 02:02:45.886711 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:02:45.886711 11876 solver.cpp:244]     Train net output #1: loss = 0.0682946 (* 1 = 0.0682946 loss)
I0401 02:02:45.886711 11876 sgd_solver.cpp:106] Iteration 59300, lr = 1e-005
I0401 02:02:51.546203 11876 solver.cpp:228] Iteration 59400, loss = 0.0433519
I0401 02:02:51.546203 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:02:51.546203 11876 solver.cpp:244]     Train net output #1: loss = 0.043352 (* 1 = 0.043352 loss)
I0401 02:02:51.546203 11876 sgd_solver.cpp:106] Iteration 59400, lr = 1e-005
I0401 02:02:57.078773 11876 solver.cpp:228] Iteration 59500, loss = 0.0730008
I0401 02:02:57.079285 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:02:57.079285 11876 solver.cpp:244]     Train net output #1: loss = 0.0730008 (* 1 = 0.0730008 loss)
I0401 02:02:57.079285 11876 sgd_solver.cpp:106] Iteration 59500, lr = 1e-005
I0401 02:03:02.621343 11876 solver.cpp:228] Iteration 59600, loss = 0.0768547
I0401 02:03:02.621343 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:03:02.621343 11876 solver.cpp:244]     Train net output #1: loss = 0.0768548 (* 1 = 0.0768548 loss)
I0401 02:03:02.622341 11876 sgd_solver.cpp:106] Iteration 59600, lr = 1e-005
I0401 02:03:08.167492 11876 solver.cpp:228] Iteration 59700, loss = 0.129073
I0401 02:03:08.167492 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:03:08.167492 11876 solver.cpp:244]     Train net output #1: loss = 0.129073 (* 1 = 0.129073 loss)
I0401 02:03:08.167492 11876 sgd_solver.cpp:106] Iteration 59700, lr = 1e-005
I0401 02:03:13.715751 11876 solver.cpp:228] Iteration 59800, loss = 0.0671554
I0401 02:03:13.715751 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:03:13.715751 11876 solver.cpp:244]     Train net output #1: loss = 0.0671555 (* 1 = 0.0671555 loss)
I0401 02:03:13.715751 11876 sgd_solver.cpp:106] Iteration 59800, lr = 1e-005
I0401 02:03:19.246325 11876 solver.cpp:228] Iteration 59900, loss = 0.0305951
I0401 02:03:19.246325 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:03:19.246325 11876 solver.cpp:244]     Train net output #1: loss = 0.0305952 (* 1 = 0.0305952 loss)
I0401 02:03:19.246325 11876 sgd_solver.cpp:106] Iteration 59900, lr = 1e-005
I0401 02:03:24.762513 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_60000.caffemodel
I0401 02:03:24.772013 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_60000.solverstate
I0401 02:03:24.775013 11876 solver.cpp:337] Iteration 60000, Testing net (#0)
I0401 02:03:24.775013 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:03:26.390307 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9186
I0401 02:03:26.390807 11876 solver.cpp:404]     Test net output #1: loss = 0.272667 (* 1 = 0.272667 loss)
I0401 02:03:26.411809 11876 solver.cpp:228] Iteration 60000, loss = 0.0995214
I0401 02:03:26.411809 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:03:26.411809 11876 solver.cpp:244]     Train net output #1: loss = 0.0995215 (* 1 = 0.0995215 loss)
I0401 02:03:26.411809 11876 sgd_solver.cpp:106] Iteration 60000, lr = 1e-005
I0401 02:03:31.924142 11876 solver.cpp:228] Iteration 60100, loss = 0.0880928
I0401 02:03:31.924142 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:03:31.924643 11876 solver.cpp:244]     Train net output #1: loss = 0.0880929 (* 1 = 0.0880929 loss)
I0401 02:03:31.924643 11876 sgd_solver.cpp:106] Iteration 60100, lr = 1e-005
I0401 02:03:37.461583 11876 solver.cpp:228] Iteration 60200, loss = 0.062589
I0401 02:03:37.462585 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:03:37.462585 11876 solver.cpp:244]     Train net output #1: loss = 0.0625891 (* 1 = 0.0625891 loss)
I0401 02:03:37.462585 11876 sgd_solver.cpp:106] Iteration 60200, lr = 1e-005
I0401 02:03:43.011747 11876 solver.cpp:228] Iteration 60300, loss = 0.089664
I0401 02:03:43.011747 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:03:43.011747 11876 solver.cpp:244]     Train net output #1: loss = 0.0896641 (* 1 = 0.0896641 loss)
I0401 02:03:43.011747 11876 sgd_solver.cpp:106] Iteration 60300, lr = 1e-005
I0401 02:03:48.583324 11876 solver.cpp:228] Iteration 60400, loss = 0.0748138
I0401 02:03:48.583324 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:03:48.583324 11876 solver.cpp:244]     Train net output #1: loss = 0.0748139 (* 1 = 0.0748139 loss)
I0401 02:03:48.583324 11876 sgd_solver.cpp:106] Iteration 60400, lr = 1e-005
I0401 02:03:54.166868 11876 solver.cpp:228] Iteration 60500, loss = 0.0914147
I0401 02:03:54.166868 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:03:54.166868 11876 solver.cpp:244]     Train net output #1: loss = 0.0914148 (* 1 = 0.0914148 loss)
I0401 02:03:54.166868 11876 sgd_solver.cpp:106] Iteration 60500, lr = 1e-005
I0401 02:03:59.706336 11876 solver.cpp:228] Iteration 60600, loss = 0.0818215
I0401 02:03:59.706336 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:03:59.706336 11876 solver.cpp:244]     Train net output #1: loss = 0.0818216 (* 1 = 0.0818216 loss)
I0401 02:03:59.706336 11876 sgd_solver.cpp:106] Iteration 60600, lr = 1e-005
I0401 02:04:05.254317 11876 solver.cpp:228] Iteration 60700, loss = 0.0914038
I0401 02:04:05.254317 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:04:05.254317 11876 solver.cpp:244]     Train net output #1: loss = 0.0914039 (* 1 = 0.0914039 loss)
I0401 02:04:05.254317 11876 sgd_solver.cpp:106] Iteration 60700, lr = 1e-005
I0401 02:04:10.805249 11876 solver.cpp:228] Iteration 60800, loss = 0.0622226
I0401 02:04:10.805249 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:04:10.805249 11876 solver.cpp:244]     Train net output #1: loss = 0.0622227 (* 1 = 0.0622227 loss)
I0401 02:04:10.805249 11876 sgd_solver.cpp:106] Iteration 60800, lr = 1e-005
I0401 02:04:16.347010 11876 solver.cpp:228] Iteration 60900, loss = 0.0529793
I0401 02:04:16.347010 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:04:16.347010 11876 solver.cpp:244]     Train net output #1: loss = 0.0529795 (* 1 = 0.0529795 loss)
I0401 02:04:16.347010 11876 sgd_solver.cpp:106] Iteration 60900, lr = 1e-005
I0401 02:04:21.865581 11876 solver.cpp:337] Iteration 61000, Testing net (#0)
I0401 02:04:21.865581 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:04:23.485363 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9188
I0401 02:04:23.485363 11876 solver.cpp:404]     Test net output #1: loss = 0.272915 (* 1 = 0.272915 loss)
I0401 02:04:23.507369 11876 solver.cpp:228] Iteration 61000, loss = 0.117919
I0401 02:04:23.507369 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:04:23.507369 11876 solver.cpp:244]     Train net output #1: loss = 0.117919 (* 1 = 0.117919 loss)
I0401 02:04:23.507369 11876 sgd_solver.cpp:106] Iteration 61000, lr = 1e-005
I0401 02:04:29.081637 11876 solver.cpp:228] Iteration 61100, loss = 0.0707744
I0401 02:04:29.081637 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:04:29.081637 11876 solver.cpp:244]     Train net output #1: loss = 0.0707746 (* 1 = 0.0707746 loss)
I0401 02:04:29.081637 11876 sgd_solver.cpp:106] Iteration 61100, lr = 1e-005
I0401 02:04:34.654417 11876 solver.cpp:228] Iteration 61200, loss = 0.106745
I0401 02:04:34.654417 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:04:34.654417 11876 solver.cpp:244]     Train net output #1: loss = 0.106745 (* 1 = 0.106745 loss)
I0401 02:04:34.654417 11876 sgd_solver.cpp:106] Iteration 61200, lr = 1e-005
I0401 02:04:40.214637 11876 solver.cpp:228] Iteration 61300, loss = 0.0684848
I0401 02:04:40.214637 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:04:40.214637 11876 solver.cpp:244]     Train net output #1: loss = 0.0684849 (* 1 = 0.0684849 loss)
I0401 02:04:40.214637 11876 sgd_solver.cpp:106] Iteration 61300, lr = 1e-005
I0401 02:04:45.793836 11876 solver.cpp:228] Iteration 61400, loss = 0.0586352
I0401 02:04:45.793836 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:04:45.793836 11876 solver.cpp:244]     Train net output #1: loss = 0.0586354 (* 1 = 0.0586354 loss)
I0401 02:04:45.793836 11876 sgd_solver.cpp:106] Iteration 61400, lr = 1e-005
I0401 02:04:51.377879 11876 solver.cpp:228] Iteration 61500, loss = 0.106432
I0401 02:04:51.377879 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:04:51.377879 11876 solver.cpp:244]     Train net output #1: loss = 0.106432 (* 1 = 0.106432 loss)
I0401 02:04:51.377879 11876 sgd_solver.cpp:106] Iteration 61500, lr = 1e-005
I0401 02:04:56.924584 11876 solver.cpp:228] Iteration 61600, loss = 0.0697116
I0401 02:04:56.925084 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:04:56.925084 11876 solver.cpp:244]     Train net output #1: loss = 0.0697117 (* 1 = 0.0697117 loss)
I0401 02:04:56.925084 11876 sgd_solver.cpp:106] Iteration 61600, lr = 1e-005
I0401 02:05:02.514081 11876 solver.cpp:228] Iteration 61700, loss = 0.0815336
I0401 02:05:02.514081 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:05:02.514081 11876 solver.cpp:244]     Train net output #1: loss = 0.0815337 (* 1 = 0.0815337 loss)
I0401 02:05:02.514081 11876 sgd_solver.cpp:106] Iteration 61700, lr = 1e-005
I0401 02:05:08.202857 11876 solver.cpp:228] Iteration 61800, loss = 0.0303688
I0401 02:05:08.202857 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:05:08.202857 11876 solver.cpp:244]     Train net output #1: loss = 0.030369 (* 1 = 0.030369 loss)
I0401 02:05:08.202857 11876 sgd_solver.cpp:106] Iteration 61800, lr = 1e-005
I0401 02:05:13.849892 11876 solver.cpp:228] Iteration 61900, loss = 0.0545898
I0401 02:05:13.849892 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:05:13.849892 11876 solver.cpp:244]     Train net output #1: loss = 0.05459 (* 1 = 0.05459 loss)
I0401 02:05:13.849892 11876 sgd_solver.cpp:106] Iteration 61900, lr = 1e-005
I0401 02:05:19.446583 11876 solver.cpp:337] Iteration 62000, Testing net (#0)
I0401 02:05:19.446583 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:05:21.071879 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9188
I0401 02:05:21.071879 11876 solver.cpp:404]     Test net output #1: loss = 0.272695 (* 1 = 0.272695 loss)
I0401 02:05:21.093883 11876 solver.cpp:228] Iteration 62000, loss = 0.0732411
I0401 02:05:21.093883 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:05:21.093883 11876 solver.cpp:244]     Train net output #1: loss = 0.0732412 (* 1 = 0.0732412 loss)
I0401 02:05:21.093883 11876 sgd_solver.cpp:106] Iteration 62000, lr = 1e-005
I0401 02:05:26.665827 11876 solver.cpp:228] Iteration 62100, loss = 0.0642942
I0401 02:05:26.665827 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:05:26.665827 11876 solver.cpp:244]     Train net output #1: loss = 0.0642944 (* 1 = 0.0642944 loss)
I0401 02:05:26.665827 11876 sgd_solver.cpp:106] Iteration 62100, lr = 1e-005
I0401 02:05:32.290259 11876 solver.cpp:228] Iteration 62200, loss = 0.108152
I0401 02:05:32.290259 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:05:32.290259 11876 solver.cpp:244]     Train net output #1: loss = 0.108153 (* 1 = 0.108153 loss)
I0401 02:05:32.290259 11876 sgd_solver.cpp:106] Iteration 62200, lr = 1e-005
I0401 02:05:37.829566 11876 solver.cpp:228] Iteration 62300, loss = 0.0427986
I0401 02:05:37.829566 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:05:37.829566 11876 solver.cpp:244]     Train net output #1: loss = 0.0427987 (* 1 = 0.0427987 loss)
I0401 02:05:37.829566 11876 sgd_solver.cpp:106] Iteration 62300, lr = 1e-005
I0401 02:05:43.397517 11876 solver.cpp:228] Iteration 62400, loss = 0.0341288
I0401 02:05:43.397517 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:05:43.397517 11876 solver.cpp:244]     Train net output #1: loss = 0.0341289 (* 1 = 0.0341289 loss)
I0401 02:05:43.397517 11876 sgd_solver.cpp:106] Iteration 62400, lr = 1e-005
I0401 02:05:48.965889 11876 solver.cpp:228] Iteration 62500, loss = 0.104004
I0401 02:05:48.965889 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:05:48.965889 11876 solver.cpp:244]     Train net output #1: loss = 0.104004 (* 1 = 0.104004 loss)
I0401 02:05:48.965889 11876 sgd_solver.cpp:106] Iteration 62500, lr = 1e-005
I0401 02:05:54.544708 11876 solver.cpp:228] Iteration 62600, loss = 0.0655254
I0401 02:05:54.544708 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:05:54.544708 11876 solver.cpp:244]     Train net output #1: loss = 0.0655255 (* 1 = 0.0655255 loss)
I0401 02:05:54.544708 11876 sgd_solver.cpp:106] Iteration 62600, lr = 1e-005
I0401 02:06:00.107913 11876 solver.cpp:228] Iteration 62700, loss = 0.120219
I0401 02:06:00.108912 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:06:00.108912 11876 solver.cpp:244]     Train net output #1: loss = 0.120219 (* 1 = 0.120219 loss)
I0401 02:06:00.108912 11876 sgd_solver.cpp:106] Iteration 62700, lr = 1e-005
I0401 02:06:05.667590 11876 solver.cpp:228] Iteration 62800, loss = 0.0460656
I0401 02:06:05.667590 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:06:05.667590 11876 solver.cpp:244]     Train net output #1: loss = 0.0460657 (* 1 = 0.0460657 loss)
I0401 02:06:05.667590 11876 sgd_solver.cpp:106] Iteration 62800, lr = 1e-005
I0401 02:06:11.226222 11876 solver.cpp:228] Iteration 62900, loss = 0.0212157
I0401 02:06:11.226222 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:06:11.226222 11876 solver.cpp:244]     Train net output #1: loss = 0.0212158 (* 1 = 0.0212158 loss)
I0401 02:06:11.226222 11876 sgd_solver.cpp:106] Iteration 62900, lr = 1e-005
I0401 02:06:16.753247 11876 solver.cpp:337] Iteration 63000, Testing net (#0)
I0401 02:06:16.753247 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:06:18.362248 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9189
I0401 02:06:18.362248 11876 solver.cpp:404]     Test net output #1: loss = 0.273011 (* 1 = 0.273011 loss)
I0401 02:06:18.383752 11876 solver.cpp:228] Iteration 63000, loss = 0.0796639
I0401 02:06:18.383752 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:06:18.383752 11876 solver.cpp:244]     Train net output #1: loss = 0.079664 (* 1 = 0.079664 loss)
I0401 02:06:18.383752 11876 sgd_solver.cpp:106] Iteration 63000, lr = 1e-005
I0401 02:06:23.938940 11876 solver.cpp:228] Iteration 63100, loss = 0.0571881
I0401 02:06:23.938940 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:06:23.938940 11876 solver.cpp:244]     Train net output #1: loss = 0.0571882 (* 1 = 0.0571882 loss)
I0401 02:06:23.938940 11876 sgd_solver.cpp:106] Iteration 63100, lr = 1e-005
I0401 02:06:29.488340 11876 solver.cpp:228] Iteration 63200, loss = 0.0507527
I0401 02:06:29.488340 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:06:29.488340 11876 solver.cpp:244]     Train net output #1: loss = 0.0507528 (* 1 = 0.0507528 loss)
I0401 02:06:29.488340 11876 sgd_solver.cpp:106] Iteration 63200, lr = 1e-005
I0401 02:06:35.037482 11876 solver.cpp:228] Iteration 63300, loss = 0.0593614
I0401 02:06:35.037482 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:06:35.037482 11876 solver.cpp:244]     Train net output #1: loss = 0.0593615 (* 1 = 0.0593615 loss)
I0401 02:06:35.037482 11876 sgd_solver.cpp:106] Iteration 63300, lr = 1e-005
I0401 02:06:40.588749 11876 solver.cpp:228] Iteration 63400, loss = 0.0437497
I0401 02:06:40.588749 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:06:40.588749 11876 solver.cpp:244]     Train net output #1: loss = 0.0437498 (* 1 = 0.0437498 loss)
I0401 02:06:40.588749 11876 sgd_solver.cpp:106] Iteration 63400, lr = 1e-005
I0401 02:06:46.141815 11876 solver.cpp:228] Iteration 63500, loss = 0.0744995
I0401 02:06:46.141815 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:06:46.141815 11876 solver.cpp:244]     Train net output #1: loss = 0.0744997 (* 1 = 0.0744997 loss)
I0401 02:06:46.141815 11876 sgd_solver.cpp:106] Iteration 63500, lr = 1e-005
I0401 02:06:51.682314 11876 solver.cpp:228] Iteration 63600, loss = 0.06957
I0401 02:06:51.682314 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:06:51.682314 11876 solver.cpp:244]     Train net output #1: loss = 0.0695702 (* 1 = 0.0695702 loss)
I0401 02:06:51.682314 11876 sgd_solver.cpp:106] Iteration 63600, lr = 1e-005
I0401 02:06:57.218968 11876 solver.cpp:228] Iteration 63700, loss = 0.107291
I0401 02:06:57.218968 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:06:57.218968 11876 solver.cpp:244]     Train net output #1: loss = 0.107291 (* 1 = 0.107291 loss)
I0401 02:06:57.218968 11876 sgd_solver.cpp:106] Iteration 63700, lr = 1e-005
I0401 02:07:02.785444 11876 solver.cpp:228] Iteration 63800, loss = 0.0514283
I0401 02:07:02.785444 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:07:02.785444 11876 solver.cpp:244]     Train net output #1: loss = 0.0514284 (* 1 = 0.0514284 loss)
I0401 02:07:02.785444 11876 sgd_solver.cpp:106] Iteration 63800, lr = 1e-005
I0401 02:07:08.354265 11876 solver.cpp:228] Iteration 63900, loss = 0.0317617
I0401 02:07:08.354265 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:07:08.354265 11876 solver.cpp:244]     Train net output #1: loss = 0.0317618 (* 1 = 0.0317618 loss)
I0401 02:07:08.354265 11876 sgd_solver.cpp:106] Iteration 63900, lr = 1e-005
I0401 02:07:13.889245 11876 solver.cpp:337] Iteration 64000, Testing net (#0)
I0401 02:07:13.889245 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:07:15.509127 11876 solver.cpp:404]     Test net output #0: accuracy = 0.919
I0401 02:07:15.509127 11876 solver.cpp:404]     Test net output #1: loss = 0.273155 (* 1 = 0.273155 loss)
I0401 02:07:15.531144 11876 solver.cpp:228] Iteration 64000, loss = 0.0889649
I0401 02:07:15.531144 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:07:15.531144 11876 solver.cpp:244]     Train net output #1: loss = 0.0889651 (* 1 = 0.0889651 loss)
I0401 02:07:15.531144 11876 sgd_solver.cpp:106] Iteration 64000, lr = 1e-005
I0401 02:07:21.108445 11876 solver.cpp:228] Iteration 64100, loss = 0.070631
I0401 02:07:21.108445 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:07:21.108445 11876 solver.cpp:244]     Train net output #1: loss = 0.0706311 (* 1 = 0.0706311 loss)
I0401 02:07:21.108445 11876 sgd_solver.cpp:106] Iteration 64100, lr = 1e-005
I0401 02:07:26.694551 11876 solver.cpp:228] Iteration 64200, loss = 0.0992157
I0401 02:07:26.694551 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:07:26.695052 11876 solver.cpp:244]     Train net output #1: loss = 0.0992158 (* 1 = 0.0992158 loss)
I0401 02:07:26.695052 11876 sgd_solver.cpp:106] Iteration 64200, lr = 1e-005
I0401 02:07:32.268410 11876 solver.cpp:228] Iteration 64300, loss = 0.0427963
I0401 02:07:32.268410 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:07:32.268410 11876 solver.cpp:244]     Train net output #1: loss = 0.0427964 (* 1 = 0.0427964 loss)
I0401 02:07:32.268410 11876 sgd_solver.cpp:106] Iteration 64300, lr = 1e-005
I0401 02:07:37.806514 11876 solver.cpp:228] Iteration 64400, loss = 0.0589464
I0401 02:07:37.806514 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:07:37.806514 11876 solver.cpp:244]     Train net output #1: loss = 0.0589465 (* 1 = 0.0589465 loss)
I0401 02:07:37.806514 11876 sgd_solver.cpp:106] Iteration 64400, lr = 1e-005
I0401 02:07:43.353294 11876 solver.cpp:228] Iteration 64500, loss = 0.0715717
I0401 02:07:43.353294 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:07:43.353294 11876 solver.cpp:244]     Train net output #1: loss = 0.0715718 (* 1 = 0.0715718 loss)
I0401 02:07:43.353294 11876 sgd_solver.cpp:106] Iteration 64500, lr = 1e-005
I0401 02:07:48.909976 11876 solver.cpp:228] Iteration 64600, loss = 0.0514122
I0401 02:07:48.909976 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:07:48.909976 11876 solver.cpp:244]     Train net output #1: loss = 0.0514123 (* 1 = 0.0514123 loss)
I0401 02:07:48.909976 11876 sgd_solver.cpp:106] Iteration 64600, lr = 1e-005
I0401 02:07:54.492643 11876 solver.cpp:228] Iteration 64700, loss = 0.128775
I0401 02:07:54.492643 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 02:07:54.492643 11876 solver.cpp:244]     Train net output #1: loss = 0.128775 (* 1 = 0.128775 loss)
I0401 02:07:54.492643 11876 sgd_solver.cpp:106] Iteration 64700, lr = 1e-005
I0401 02:08:00.117568 11876 solver.cpp:228] Iteration 64800, loss = 0.0627061
I0401 02:08:00.117568 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:08:00.117568 11876 solver.cpp:244]     Train net output #1: loss = 0.0627063 (* 1 = 0.0627063 loss)
I0401 02:08:00.117568 11876 sgd_solver.cpp:106] Iteration 64800, lr = 1e-005
I0401 02:08:05.701282 11876 solver.cpp:228] Iteration 64900, loss = 0.0858561
I0401 02:08:05.701282 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:08:05.701282 11876 solver.cpp:244]     Train net output #1: loss = 0.0858562 (* 1 = 0.0858562 loss)
I0401 02:08:05.701282 11876 sgd_solver.cpp:106] Iteration 64900, lr = 1e-005
I0401 02:08:11.249981 11876 solver.cpp:337] Iteration 65000, Testing net (#0)
I0401 02:08:11.249981 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:08:12.873302 11876 solver.cpp:404]     Test net output #0: accuracy = 0.919
I0401 02:08:12.873302 11876 solver.cpp:404]     Test net output #1: loss = 0.274045 (* 1 = 0.274045 loss)
I0401 02:08:12.894265 11876 solver.cpp:228] Iteration 65000, loss = 0.0754149
I0401 02:08:12.894265 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:08:12.894265 11876 solver.cpp:244]     Train net output #1: loss = 0.0754151 (* 1 = 0.0754151 loss)
I0401 02:08:12.894265 11876 sgd_solver.cpp:106] Iteration 65000, lr = 1e-005
I0401 02:08:18.485788 11876 solver.cpp:228] Iteration 65100, loss = 0.104677
I0401 02:08:18.485788 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:08:18.485788 11876 solver.cpp:244]     Train net output #1: loss = 0.104677 (* 1 = 0.104677 loss)
I0401 02:08:18.485788 11876 sgd_solver.cpp:106] Iteration 65100, lr = 1e-005
I0401 02:08:24.059226 11876 solver.cpp:228] Iteration 65200, loss = 0.10949
I0401 02:08:24.059226 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:08:24.059226 11876 solver.cpp:244]     Train net output #1: loss = 0.10949 (* 1 = 0.10949 loss)
I0401 02:08:24.059226 11876 sgd_solver.cpp:106] Iteration 65200, lr = 1e-005
I0401 02:08:29.612031 11876 solver.cpp:228] Iteration 65300, loss = 0.0754752
I0401 02:08:29.612031 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:08:29.612031 11876 solver.cpp:244]     Train net output #1: loss = 0.0754754 (* 1 = 0.0754754 loss)
I0401 02:08:29.612031 11876 sgd_solver.cpp:106] Iteration 65300, lr = 1e-005
I0401 02:08:35.197823 11876 solver.cpp:228] Iteration 65400, loss = 0.0456495
I0401 02:08:35.197823 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:08:35.197823 11876 solver.cpp:244]     Train net output #1: loss = 0.0456496 (* 1 = 0.0456496 loss)
I0401 02:08:35.197823 11876 sgd_solver.cpp:106] Iteration 65400, lr = 1e-005
I0401 02:08:40.792007 11876 solver.cpp:228] Iteration 65500, loss = 0.115239
I0401 02:08:40.792007 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.94
I0401 02:08:40.792007 11876 solver.cpp:244]     Train net output #1: loss = 0.115239 (* 1 = 0.115239 loss)
I0401 02:08:40.792007 11876 sgd_solver.cpp:106] Iteration 65500, lr = 1e-005
I0401 02:08:46.405138 11876 solver.cpp:228] Iteration 65600, loss = 0.102248
I0401 02:08:46.405138 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:08:46.405138 11876 solver.cpp:244]     Train net output #1: loss = 0.102248 (* 1 = 0.102248 loss)
I0401 02:08:46.405138 11876 sgd_solver.cpp:106] Iteration 65600, lr = 1e-005
I0401 02:08:51.998303 11876 solver.cpp:228] Iteration 65700, loss = 0.107759
I0401 02:08:51.998303 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:08:51.998303 11876 solver.cpp:244]     Train net output #1: loss = 0.107759 (* 1 = 0.107759 loss)
I0401 02:08:51.998303 11876 sgd_solver.cpp:106] Iteration 65700, lr = 1e-005
I0401 02:08:57.596590 11876 solver.cpp:228] Iteration 65800, loss = 0.0360832
I0401 02:08:57.596590 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:08:57.596590 11876 solver.cpp:244]     Train net output #1: loss = 0.0360833 (* 1 = 0.0360833 loss)
I0401 02:08:57.596590 11876 sgd_solver.cpp:106] Iteration 65800, lr = 1e-005
I0401 02:09:03.189234 11876 solver.cpp:228] Iteration 65900, loss = 0.0974043
I0401 02:09:03.189234 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:09:03.189234 11876 solver.cpp:244]     Train net output #1: loss = 0.0974044 (* 1 = 0.0974044 loss)
I0401 02:09:03.189234 11876 sgd_solver.cpp:106] Iteration 65900, lr = 1e-005
I0401 02:09:08.759968 11876 solver.cpp:337] Iteration 66000, Testing net (#0)
I0401 02:09:08.759968 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:09:10.385927 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9193
I0401 02:09:10.385927 11876 solver.cpp:404]     Test net output #1: loss = 0.273624 (* 1 = 0.273624 loss)
I0401 02:09:10.409431 11876 solver.cpp:228] Iteration 66000, loss = 0.0703928
I0401 02:09:10.409431 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:09:10.409431 11876 solver.cpp:244]     Train net output #1: loss = 0.0703929 (* 1 = 0.0703929 loss)
I0401 02:09:10.409431 11876 sgd_solver.cpp:106] Iteration 66000, lr = 1e-005
I0401 02:09:16.051829 11876 solver.cpp:228] Iteration 66100, loss = 0.0640037
I0401 02:09:16.051829 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:09:16.051829 11876 solver.cpp:244]     Train net output #1: loss = 0.0640039 (* 1 = 0.0640039 loss)
I0401 02:09:16.051829 11876 sgd_solver.cpp:106] Iteration 66100, lr = 1e-005
I0401 02:09:21.687083 11876 solver.cpp:228] Iteration 66200, loss = 0.112641
I0401 02:09:21.688083 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:09:21.688083 11876 solver.cpp:244]     Train net output #1: loss = 0.112641 (* 1 = 0.112641 loss)
I0401 02:09:21.688083 11876 sgd_solver.cpp:106] Iteration 66200, lr = 1e-005
I0401 02:09:27.294524 11876 solver.cpp:228] Iteration 66300, loss = 0.0290074
I0401 02:09:27.294524 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:09:27.294524 11876 solver.cpp:244]     Train net output #1: loss = 0.0290075 (* 1 = 0.0290075 loss)
I0401 02:09:27.294524 11876 sgd_solver.cpp:106] Iteration 66300, lr = 1e-005
I0401 02:09:32.875254 11876 solver.cpp:228] Iteration 66400, loss = 0.0167262
I0401 02:09:32.875254 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:09:32.875254 11876 solver.cpp:244]     Train net output #1: loss = 0.0167264 (* 1 = 0.0167264 loss)
I0401 02:09:32.875254 11876 sgd_solver.cpp:106] Iteration 66400, lr = 1e-005
I0401 02:09:38.483393 11876 solver.cpp:228] Iteration 66500, loss = 0.0898294
I0401 02:09:38.483393 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:09:38.483393 11876 solver.cpp:244]     Train net output #1: loss = 0.0898296 (* 1 = 0.0898296 loss)
I0401 02:09:38.483393 11876 sgd_solver.cpp:106] Iteration 66500, lr = 1e-005
I0401 02:09:44.088053 11876 solver.cpp:228] Iteration 66600, loss = 0.0580213
I0401 02:09:44.088053 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:09:44.088053 11876 solver.cpp:244]     Train net output #1: loss = 0.0580215 (* 1 = 0.0580215 loss)
I0401 02:09:44.088053 11876 sgd_solver.cpp:106] Iteration 66600, lr = 1e-005
I0401 02:09:49.659384 11876 solver.cpp:228] Iteration 66700, loss = 0.0760502
I0401 02:09:49.659885 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:09:49.659885 11876 solver.cpp:244]     Train net output #1: loss = 0.0760503 (* 1 = 0.0760503 loss)
I0401 02:09:49.659885 11876 sgd_solver.cpp:106] Iteration 66700, lr = 1e-005
I0401 02:09:55.183063 11876 solver.cpp:228] Iteration 66800, loss = 0.0385945
I0401 02:09:55.183063 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:09:55.183063 11876 solver.cpp:244]     Train net output #1: loss = 0.0385946 (* 1 = 0.0385946 loss)
I0401 02:09:55.183063 11876 sgd_solver.cpp:106] Iteration 66800, lr = 1e-005
I0401 02:10:00.704879 11876 solver.cpp:228] Iteration 66900, loss = 0.0427193
I0401 02:10:00.704879 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:10:00.704879 11876 solver.cpp:244]     Train net output #1: loss = 0.0427195 (* 1 = 0.0427195 loss)
I0401 02:10:00.704879 11876 sgd_solver.cpp:106] Iteration 66900, lr = 1e-005
I0401 02:10:06.240665 11876 solver.cpp:337] Iteration 67000, Testing net (#0)
I0401 02:10:06.240665 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:10:07.858386 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9186
I0401 02:10:07.858386 11876 solver.cpp:404]     Test net output #1: loss = 0.274832 (* 1 = 0.274832 loss)
I0401 02:10:07.879389 11876 solver.cpp:228] Iteration 67000, loss = 0.0923852
I0401 02:10:07.879389 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:10:07.879389 11876 solver.cpp:244]     Train net output #1: loss = 0.0923854 (* 1 = 0.0923854 loss)
I0401 02:10:07.879389 11876 sgd_solver.cpp:106] Iteration 67000, lr = 1e-005
I0401 02:10:13.422014 11876 solver.cpp:228] Iteration 67100, loss = 0.0555779
I0401 02:10:13.422014 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:10:13.422014 11876 solver.cpp:244]     Train net output #1: loss = 0.055578 (* 1 = 0.055578 loss)
I0401 02:10:13.422014 11876 sgd_solver.cpp:106] Iteration 67100, lr = 1e-005
I0401 02:10:18.956393 11876 solver.cpp:228] Iteration 67200, loss = 0.0828352
I0401 02:10:18.956393 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:10:18.956393 11876 solver.cpp:244]     Train net output #1: loss = 0.0828354 (* 1 = 0.0828354 loss)
I0401 02:10:18.956393 11876 sgd_solver.cpp:106] Iteration 67200, lr = 1e-005
I0401 02:10:24.465138 11876 solver.cpp:228] Iteration 67300, loss = 0.0467153
I0401 02:10:24.465138 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:10:24.465138 11876 solver.cpp:244]     Train net output #1: loss = 0.0467155 (* 1 = 0.0467155 loss)
I0401 02:10:24.465138 11876 sgd_solver.cpp:106] Iteration 67300, lr = 1e-005
I0401 02:10:29.973325 11876 solver.cpp:228] Iteration 67400, loss = 0.0453748
I0401 02:10:29.973325 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:10:29.973325 11876 solver.cpp:244]     Train net output #1: loss = 0.045375 (* 1 = 0.045375 loss)
I0401 02:10:29.973325 11876 sgd_solver.cpp:106] Iteration 67400, lr = 1e-005
I0401 02:10:35.494446 11876 solver.cpp:228] Iteration 67500, loss = 0.0743564
I0401 02:10:35.494446 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:10:35.494446 11876 solver.cpp:244]     Train net output #1: loss = 0.0743565 (* 1 = 0.0743565 loss)
I0401 02:10:35.494446 11876 sgd_solver.cpp:106] Iteration 67500, lr = 1e-005
I0401 02:10:41.025884 11876 solver.cpp:228] Iteration 67600, loss = 0.0525569
I0401 02:10:41.025884 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:10:41.025884 11876 solver.cpp:244]     Train net output #1: loss = 0.0525571 (* 1 = 0.0525571 loss)
I0401 02:10:41.025884 11876 sgd_solver.cpp:106] Iteration 67600, lr = 1e-005
I0401 02:10:46.546679 11876 solver.cpp:228] Iteration 67700, loss = 0.111604
I0401 02:10:46.546679 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:10:46.546679 11876 solver.cpp:244]     Train net output #1: loss = 0.111604 (* 1 = 0.111604 loss)
I0401 02:10:46.546679 11876 sgd_solver.cpp:106] Iteration 67700, lr = 1e-005
I0401 02:10:52.056008 11876 solver.cpp:228] Iteration 67800, loss = 0.0671705
I0401 02:10:52.056008 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:10:52.056008 11876 solver.cpp:244]     Train net output #1: loss = 0.0671706 (* 1 = 0.0671706 loss)
I0401 02:10:52.056008 11876 sgd_solver.cpp:106] Iteration 67800, lr = 1e-005
I0401 02:10:57.581769 11876 solver.cpp:228] Iteration 67900, loss = 0.0483041
I0401 02:10:57.581769 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:10:57.581769 11876 solver.cpp:244]     Train net output #1: loss = 0.0483042 (* 1 = 0.0483042 loss)
I0401 02:10:57.581769 11876 sgd_solver.cpp:106] Iteration 67900, lr = 1e-005
I0401 02:11:03.085760 11876 solver.cpp:337] Iteration 68000, Testing net (#0)
I0401 02:11:03.086261 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:11:04.693804 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9195
I0401 02:11:04.693804 11876 solver.cpp:404]     Test net output #1: loss = 0.274296 (* 1 = 0.274296 loss)
I0401 02:11:04.715320 11876 solver.cpp:228] Iteration 68000, loss = 0.115208
I0401 02:11:04.715320 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:11:04.715320 11876 solver.cpp:244]     Train net output #1: loss = 0.115208 (* 1 = 0.115208 loss)
I0401 02:11:04.715320 11876 sgd_solver.cpp:106] Iteration 68000, lr = 1e-005
I0401 02:11:10.232244 11876 solver.cpp:228] Iteration 68100, loss = 0.129037
I0401 02:11:10.232244 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:11:10.232739 11876 solver.cpp:244]     Train net output #1: loss = 0.129037 (* 1 = 0.129037 loss)
I0401 02:11:10.232739 11876 sgd_solver.cpp:106] Iteration 68100, lr = 1e-005
I0401 02:11:15.754904 11876 solver.cpp:228] Iteration 68200, loss = 0.0700969
I0401 02:11:15.754904 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:11:15.754904 11876 solver.cpp:244]     Train net output #1: loss = 0.070097 (* 1 = 0.070097 loss)
I0401 02:11:15.754904 11876 sgd_solver.cpp:106] Iteration 68200, lr = 1e-005
I0401 02:11:21.267058 11876 solver.cpp:228] Iteration 68300, loss = 0.0643523
I0401 02:11:21.267058 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:11:21.267058 11876 solver.cpp:244]     Train net output #1: loss = 0.0643524 (* 1 = 0.0643524 loss)
I0401 02:11:21.267058 11876 sgd_solver.cpp:106] Iteration 68300, lr = 1e-005
I0401 02:11:26.781756 11876 solver.cpp:228] Iteration 68400, loss = 0.0374804
I0401 02:11:26.781756 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:11:26.781756 11876 solver.cpp:244]     Train net output #1: loss = 0.0374805 (* 1 = 0.0374805 loss)
I0401 02:11:26.781756 11876 sgd_solver.cpp:106] Iteration 68400, lr = 1e-005
I0401 02:11:32.342067 11876 solver.cpp:228] Iteration 68500, loss = 0.0662736
I0401 02:11:32.342067 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:11:32.342067 11876 solver.cpp:244]     Train net output #1: loss = 0.0662738 (* 1 = 0.0662738 loss)
I0401 02:11:32.342067 11876 sgd_solver.cpp:106] Iteration 68500, lr = 1e-005
I0401 02:11:37.879931 11876 solver.cpp:228] Iteration 68600, loss = 0.0738975
I0401 02:11:37.879931 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:11:37.879931 11876 solver.cpp:244]     Train net output #1: loss = 0.0738976 (* 1 = 0.0738976 loss)
I0401 02:11:37.879931 11876 sgd_solver.cpp:106] Iteration 68600, lr = 1e-005
I0401 02:11:43.410511 11876 solver.cpp:228] Iteration 68700, loss = 0.0554514
I0401 02:11:43.411010 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:11:43.411010 11876 solver.cpp:244]     Train net output #1: loss = 0.0554515 (* 1 = 0.0554515 loss)
I0401 02:11:43.411010 11876 sgd_solver.cpp:106] Iteration 68700, lr = 1e-005
I0401 02:11:48.955312 11876 solver.cpp:228] Iteration 68800, loss = 0.0551541
I0401 02:11:48.955312 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:11:48.955312 11876 solver.cpp:244]     Train net output #1: loss = 0.0551542 (* 1 = 0.0551542 loss)
I0401 02:11:48.955312 11876 sgd_solver.cpp:106] Iteration 68800, lr = 1e-005
I0401 02:11:54.507140 11876 solver.cpp:228] Iteration 68900, loss = 0.0663185
I0401 02:11:54.508141 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:11:54.508141 11876 solver.cpp:244]     Train net output #1: loss = 0.0663187 (* 1 = 0.0663187 loss)
I0401 02:11:54.508141 11876 sgd_solver.cpp:106] Iteration 68900, lr = 1e-005
I0401 02:12:00.042342 11876 solver.cpp:337] Iteration 69000, Testing net (#0)
I0401 02:12:00.042342 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:12:01.662606 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9197
I0401 02:12:01.662606 11876 solver.cpp:404]     Test net output #1: loss = 0.274632 (* 1 = 0.274632 loss)
I0401 02:12:01.684590 11876 solver.cpp:228] Iteration 69000, loss = 0.106164
I0401 02:12:01.684590 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:12:01.684590 11876 solver.cpp:244]     Train net output #1: loss = 0.106164 (* 1 = 0.106164 loss)
I0401 02:12:01.684590 11876 sgd_solver.cpp:106] Iteration 69000, lr = 1e-005
I0401 02:12:07.232735 11876 solver.cpp:228] Iteration 69100, loss = 0.073158
I0401 02:12:07.232735 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:12:07.232735 11876 solver.cpp:244]     Train net output #1: loss = 0.0731581 (* 1 = 0.0731581 loss)
I0401 02:12:07.232735 11876 sgd_solver.cpp:106] Iteration 69100, lr = 1e-005
I0401 02:12:12.768270 11876 solver.cpp:228] Iteration 69200, loss = 0.0576744
I0401 02:12:12.768270 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:12:12.768270 11876 solver.cpp:244]     Train net output #1: loss = 0.0576745 (* 1 = 0.0576745 loss)
I0401 02:12:12.768270 11876 sgd_solver.cpp:106] Iteration 69200, lr = 1e-005
I0401 02:12:18.305646 11876 solver.cpp:228] Iteration 69300, loss = 0.0448464
I0401 02:12:18.305646 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:12:18.305646 11876 solver.cpp:244]     Train net output #1: loss = 0.0448465 (* 1 = 0.0448465 loss)
I0401 02:12:18.305646 11876 sgd_solver.cpp:106] Iteration 69300, lr = 1e-005
I0401 02:12:23.879370 11876 solver.cpp:228] Iteration 69400, loss = 0.0568652
I0401 02:12:23.879370 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:12:23.879370 11876 solver.cpp:244]     Train net output #1: loss = 0.0568653 (* 1 = 0.0568653 loss)
I0401 02:12:23.879370 11876 sgd_solver.cpp:106] Iteration 69400, lr = 1e-005
I0401 02:12:29.436822 11876 solver.cpp:228] Iteration 69500, loss = 0.0786793
I0401 02:12:29.437820 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:12:29.437820 11876 solver.cpp:244]     Train net output #1: loss = 0.0786794 (* 1 = 0.0786794 loss)
I0401 02:12:29.437820 11876 sgd_solver.cpp:106] Iteration 69500, lr = 1e-005
I0401 02:12:34.981722 11876 solver.cpp:228] Iteration 69600, loss = 0.0837236
I0401 02:12:34.981722 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:12:34.981722 11876 solver.cpp:244]     Train net output #1: loss = 0.0837237 (* 1 = 0.0837237 loss)
I0401 02:12:34.981722 11876 sgd_solver.cpp:106] Iteration 69600, lr = 1e-005
I0401 02:12:40.522639 11876 solver.cpp:228] Iteration 69700, loss = 0.0860982
I0401 02:12:40.522639 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:12:40.522639 11876 solver.cpp:244]     Train net output #1: loss = 0.0860983 (* 1 = 0.0860983 loss)
I0401 02:12:40.522639 11876 sgd_solver.cpp:106] Iteration 69700, lr = 1e-005
I0401 02:12:46.068518 11876 solver.cpp:228] Iteration 69800, loss = 0.0751282
I0401 02:12:46.068518 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:12:46.068518 11876 solver.cpp:244]     Train net output #1: loss = 0.0751283 (* 1 = 0.0751283 loss)
I0401 02:12:46.068518 11876 sgd_solver.cpp:106] Iteration 69800, lr = 1e-005
I0401 02:12:51.588867 11876 solver.cpp:228] Iteration 69900, loss = 0.0362872
I0401 02:12:51.588867 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:12:51.588867 11876 solver.cpp:244]     Train net output #1: loss = 0.0362872 (* 1 = 0.0362872 loss)
I0401 02:12:51.588867 11876 sgd_solver.cpp:106] Iteration 69900, lr = 1e-005
I0401 02:12:57.084743 11876 solver.cpp:454] Snapshotting to binary proto file examples/cifar10/slimnet_310_iter_70000.caffemodel
I0401 02:12:57.120767 11876 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10/slimnet_310_iter_70000.solverstate
I0401 02:12:57.135785 11876 solver.cpp:337] Iteration 70000, Testing net (#0)
I0401 02:12:57.135785 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:12:58.757202 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9196
I0401 02:12:58.757202 11876 solver.cpp:404]     Test net output #1: loss = 0.275346 (* 1 = 0.275346 loss)
I0401 02:12:58.778198 11876 solver.cpp:228] Iteration 70000, loss = 0.0592748
I0401 02:12:58.778198 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:12:58.778198 11876 solver.cpp:244]     Train net output #1: loss = 0.0592748 (* 1 = 0.0592748 loss)
I0401 02:12:58.778198 11876 sgd_solver.cpp:106] Iteration 70000, lr = 1e-005
I0401 02:13:04.291023 11876 solver.cpp:228] Iteration 70100, loss = 0.127538
I0401 02:13:04.291023 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:13:04.291023 11876 solver.cpp:244]     Train net output #1: loss = 0.127538 (* 1 = 0.127538 loss)
I0401 02:13:04.291023 11876 sgd_solver.cpp:106] Iteration 70100, lr = 1e-005
I0401 02:13:09.806718 11876 solver.cpp:228] Iteration 70200, loss = 0.0583898
I0401 02:13:09.806718 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:13:09.806718 11876 solver.cpp:244]     Train net output #1: loss = 0.0583899 (* 1 = 0.0583899 loss)
I0401 02:13:09.806718 11876 sgd_solver.cpp:106] Iteration 70200, lr = 1e-005
I0401 02:13:15.329177 11876 solver.cpp:228] Iteration 70300, loss = 0.0400915
I0401 02:13:15.329177 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:13:15.329177 11876 solver.cpp:244]     Train net output #1: loss = 0.0400915 (* 1 = 0.0400915 loss)
I0401 02:13:15.329177 11876 sgd_solver.cpp:106] Iteration 70300, lr = 1e-005
I0401 02:13:20.865238 11876 solver.cpp:228] Iteration 70400, loss = 0.0459911
I0401 02:13:20.865238 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:13:20.865238 11876 solver.cpp:244]     Train net output #1: loss = 0.0459912 (* 1 = 0.0459912 loss)
I0401 02:13:20.865238 11876 sgd_solver.cpp:106] Iteration 70400, lr = 1e-005
I0401 02:13:26.384613 11876 solver.cpp:228] Iteration 70500, loss = 0.0740196
I0401 02:13:26.384613 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:13:26.384613 11876 solver.cpp:244]     Train net output #1: loss = 0.0740197 (* 1 = 0.0740197 loss)
I0401 02:13:26.384613 11876 sgd_solver.cpp:106] Iteration 70500, lr = 1e-005
I0401 02:13:31.897367 11876 solver.cpp:228] Iteration 70600, loss = 0.0548702
I0401 02:13:31.897367 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:13:31.897367 11876 solver.cpp:244]     Train net output #1: loss = 0.0548703 (* 1 = 0.0548703 loss)
I0401 02:13:31.897367 11876 sgd_solver.cpp:106] Iteration 70600, lr = 1e-005
I0401 02:13:37.404055 11876 solver.cpp:228] Iteration 70700, loss = 0.127462
I0401 02:13:37.404055 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.96
I0401 02:13:37.404556 11876 solver.cpp:244]     Train net output #1: loss = 0.127462 (* 1 = 0.127462 loss)
I0401 02:13:37.404556 11876 sgd_solver.cpp:106] Iteration 70700, lr = 1e-005
I0401 02:13:42.962848 11876 solver.cpp:228] Iteration 70800, loss = 0.0327158
I0401 02:13:42.962848 11876 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0401 02:13:42.962848 11876 solver.cpp:244]     Train net output #1: loss = 0.0327159 (* 1 = 0.0327159 loss)
I0401 02:13:42.962848 11876 sgd_solver.cpp:106] Iteration 70800, lr = 1e-005
I0401 02:13:48.488127 11876 solver.cpp:228] Iteration 70900, loss = 0.0724642
I0401 02:13:48.488127 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:13:48.488127 11876 solver.cpp:244]     Train net output #1: loss = 0.0724642 (* 1 = 0.0724642 loss)
I0401 02:13:48.489122 11876 sgd_solver.cpp:106] Iteration 70900, lr = 1e-005
I0401 02:13:53.999028 11876 solver.cpp:337] Iteration 71000, Testing net (#0)
I0401 02:13:53.999028 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:13:55.609092 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9193
I0401 02:13:55.610106 11876 solver.cpp:404]     Test net output #1: loss = 0.274869 (* 1 = 0.274869 loss)
I0401 02:13:55.631127 11876 solver.cpp:228] Iteration 71000, loss = 0.0614028
I0401 02:13:55.631127 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:13:55.631127 11876 solver.cpp:244]     Train net output #1: loss = 0.0614029 (* 1 = 0.0614029 loss)
I0401 02:13:55.631127 11876 sgd_solver.cpp:106] Iteration 71000, lr = 1e-005
I0401 02:14:01.142454 11876 solver.cpp:228] Iteration 71100, loss = 0.0925771
I0401 02:14:01.142454 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:14:01.142454 11876 solver.cpp:244]     Train net output #1: loss = 0.0925772 (* 1 = 0.0925772 loss)
I0401 02:14:01.142454 11876 sgd_solver.cpp:106] Iteration 71100, lr = 1e-005
I0401 02:14:06.659441 11876 solver.cpp:228] Iteration 71200, loss = 0.115576
I0401 02:14:06.659441 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:14:06.659441 11876 solver.cpp:244]     Train net output #1: loss = 0.115576 (* 1 = 0.115576 loss)
I0401 02:14:06.659441 11876 sgd_solver.cpp:106] Iteration 71200, lr = 1e-005
I0401 02:14:12.183559 11876 solver.cpp:228] Iteration 71300, loss = 0.0314208
I0401 02:14:12.183559 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:14:12.183559 11876 solver.cpp:244]     Train net output #1: loss = 0.0314209 (* 1 = 0.0314209 loss)
I0401 02:14:12.183559 11876 sgd_solver.cpp:106] Iteration 71300, lr = 1e-005
I0401 02:14:17.689805 11876 solver.cpp:228] Iteration 71400, loss = 0.0656555
I0401 02:14:17.689805 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:14:17.689805 11876 solver.cpp:244]     Train net output #1: loss = 0.0656555 (* 1 = 0.0656555 loss)
I0401 02:14:17.689805 11876 sgd_solver.cpp:106] Iteration 71400, lr = 1e-005
I0401 02:14:23.200603 11876 solver.cpp:228] Iteration 71500, loss = 0.0635046
I0401 02:14:23.200603 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:14:23.200603 11876 solver.cpp:244]     Train net output #1: loss = 0.0635047 (* 1 = 0.0635047 loss)
I0401 02:14:23.200603 11876 sgd_solver.cpp:106] Iteration 71500, lr = 1e-005
I0401 02:14:28.708506 11876 solver.cpp:228] Iteration 71600, loss = 0.0859192
I0401 02:14:28.708989 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0401 02:14:28.708989 11876 solver.cpp:244]     Train net output #1: loss = 0.0859193 (* 1 = 0.0859193 loss)
I0401 02:14:28.708989 11876 sgd_solver.cpp:106] Iteration 71600, lr = 1e-005
I0401 02:14:34.219096 11876 solver.cpp:228] Iteration 71700, loss = 0.0988535
I0401 02:14:34.219096 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.95
I0401 02:14:34.219096 11876 solver.cpp:244]     Train net output #1: loss = 0.0988535 (* 1 = 0.0988535 loss)
I0401 02:14:34.219096 11876 sgd_solver.cpp:106] Iteration 71700, lr = 1e-005
I0401 02:14:39.738878 11876 solver.cpp:228] Iteration 71800, loss = 0.0695134
I0401 02:14:39.738878 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.97
I0401 02:14:39.738878 11876 solver.cpp:244]     Train net output #1: loss = 0.0695135 (* 1 = 0.0695135 loss)
I0401 02:14:39.738878 11876 sgd_solver.cpp:106] Iteration 71800, lr = 1e-005
I0401 02:14:45.254974 11876 solver.cpp:228] Iteration 71900, loss = 0.0438067
I0401 02:14:45.255468 11876 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0401 02:14:45.255468 11876 solver.cpp:244]     Train net output #1: loss = 0.0438068 (* 1 = 0.0438068 loss)
I0401 02:14:45.255468 11876 sgd_solver.cpp:106] Iteration 71900, lr = 1e-005
I0401 02:14:50.741833 11876 solver.cpp:337] Iteration 72000, Testing net (#0)
I0401 02:14:50.742333 11876 net.cpp:693] Ignoring source layer accuracy_training
I0401 02:14:52.630790 11876 solver.cpp:404]     Test net output #0: accuracy = 0.9198
I0401 02:14:52.630790 11876 solver.cpp:404]     Test net output #1: loss = 0.276046 (* 1 = 0.276046 loss)