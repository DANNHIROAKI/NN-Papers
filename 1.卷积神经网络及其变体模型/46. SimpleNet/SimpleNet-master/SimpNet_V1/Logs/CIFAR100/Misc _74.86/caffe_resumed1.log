
N:\Caffe\examples\cifar100>REM go to the caffe root 

N:\Caffe\examples\cifar100>cd ../../ 

N:\Caffe>set BIN=build/x64/Release 

N:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt --snapshot=examples/cifar10_full_relu_bn_iter_126000.solverstate 
I0930 04:42:43.276495 15120 caffe.cpp:186] Using GPUs 0
I0930 04:42:43.660341 15120 caffe.cpp:191] GPU 0: GeForce GTX 980
I0930 04:42:43.911645 15120 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0930 04:42:43.912647 15120 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.002
snapshot: 1000
snapshot_prefix: "examples/cifar10_full_relu_bn"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
delta: 0.001
stepvalue: 18000
stepvalue: 23000
stepvalue: 220000
stepvalue: 295000
stepvalue: 320000
stepvalue: 270000
type: "AdaDelta"
I0930 04:42:43.912647 15120 solver.cpp:91] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0930 04:42:43.913648 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0930 04:42:43.914649 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0930 04:42:43.914649 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0930 04:42:43.914649 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0930 04:42:43.914649 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0930 04:42:43.914649 15120 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0930 04:42:43.914649 15120 net.cpp:49] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label_fine"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "bn_cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp4"
  type: "Scale"
  bottom: "bn_cccp4"
  top: "scale_ccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "scale_ccp4"
  top: "scale_ccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "scale_ccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "bn_cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp5"
  type: "Scale"
  bottom: "bn_cccp5"
  top: "scale_ccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "scale_ccp5"
  top: "scale_ccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "scale_ccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "bn_cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp6"
  type: "Scale"
  bottom: "bn_cccp6"
  top: "scale_ccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "scale_ccp6"
  top: "scale_ccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "scale_ccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc_conv"
  type: "Convolution"
  bottom: "poolcp6"
  top: "fc_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    pad: 1
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ipf0"
  type: "InnerProduct"
  bottom: "fc_conv"
  top: "ipf0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "loss"
}
I0930 04:42:43.914649 15120 layer_factory.hpp:77] Creating layer cifar
I0930 04:42:43.915648 15120 net.cpp:91] Creating Layer cifar
I0930 04:42:43.916649 15120 net.cpp:399] cifar -> data
I0930 04:42:43.916649 15120 net.cpp:399] cifar -> label_fine
I0930 04:42:43.916649 10036 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0930 04:42:43.924654 10036 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I0930 04:42:43.948665 15120 data_layer.cpp:41] output data size: 50,3,32,32
I0930 04:42:43.951843 15120 net.cpp:141] Setting up cifar
I0930 04:42:43.951843 15120 net.cpp:148] Top shape: 50 3 32 32 (153600)
I0930 04:42:43.951843 15120 net.cpp:148] Top shape: 50 (50)
I0930 04:42:43.951843 15120 net.cpp:156] Memory required for data: 614600
I0930 04:42:43.951843 15120 layer_factory.hpp:77] Creating layer conv1
I0930 04:42:43.951843 15120 net.cpp:91] Creating Layer conv1
I0930 04:42:43.952343 15120 net.cpp:425] conv1 <- data
I0930 04:42:43.952343 15120 net.cpp:399] conv1 -> conv1
I0930 04:42:43.952843 14652 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0930 04:42:44.224957 15120 net.cpp:141] Setting up conv1
I0930 04:42:44.224957 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.224957 15120 net.cpp:156] Memory required for data: 13721800
I0930 04:42:44.224957 15120 layer_factory.hpp:77] Creating layer bn1
I0930 04:42:44.224957 15120 net.cpp:91] Creating Layer bn1
I0930 04:42:44.224957 15120 net.cpp:425] bn1 <- conv1
I0930 04:42:44.224957 15120 net.cpp:399] bn1 -> bn1
I0930 04:42:44.224957 15120 net.cpp:141] Setting up bn1
I0930 04:42:44.224957 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.224957 15120 net.cpp:156] Memory required for data: 26829000
I0930 04:42:44.224957 15120 layer_factory.hpp:77] Creating layer scale1
I0930 04:42:44.224957 15120 net.cpp:91] Creating Layer scale1
I0930 04:42:44.224957 15120 net.cpp:425] scale1 <- bn1
I0930 04:42:44.224957 15120 net.cpp:399] scale1 -> scale1
I0930 04:42:44.224957 15120 layer_factory.hpp:77] Creating layer scale1
I0930 04:42:44.225958 15120 net.cpp:141] Setting up scale1
I0930 04:42:44.225958 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.225958 15120 net.cpp:156] Memory required for data: 39936200
I0930 04:42:44.225958 15120 layer_factory.hpp:77] Creating layer relu1
I0930 04:42:44.225958 15120 net.cpp:91] Creating Layer relu1
I0930 04:42:44.225958 15120 net.cpp:425] relu1 <- scale1
I0930 04:42:44.225958 15120 net.cpp:386] relu1 -> scale1 (in-place)
I0930 04:42:44.225958 15120 net.cpp:141] Setting up relu1
I0930 04:42:44.225958 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.225958 15120 net.cpp:156] Memory required for data: 53043400
I0930 04:42:44.225958 15120 layer_factory.hpp:77] Creating layer conv1_0
I0930 04:42:44.225958 15120 net.cpp:91] Creating Layer conv1_0
I0930 04:42:44.225958 15120 net.cpp:425] conv1_0 <- scale1
I0930 04:42:44.225958 15120 net.cpp:399] conv1_0 -> conv1_0
I0930 04:42:44.227943 15120 net.cpp:141] Setting up conv1_0
I0930 04:42:44.227943 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.227943 15120 net.cpp:156] Memory required for data: 79257800
I0930 04:42:44.227943 15120 layer_factory.hpp:77] Creating layer bn1_0
I0930 04:42:44.227943 15120 net.cpp:91] Creating Layer bn1_0
I0930 04:42:44.227943 15120 net.cpp:425] bn1_0 <- conv1_0
I0930 04:42:44.227943 15120 net.cpp:399] bn1_0 -> bn1_0
I0930 04:42:44.227943 15120 net.cpp:141] Setting up bn1_0
I0930 04:42:44.227943 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.227943 15120 net.cpp:156] Memory required for data: 105472200
I0930 04:42:44.227943 15120 layer_factory.hpp:77] Creating layer scale1_0
I0930 04:42:44.227943 15120 net.cpp:91] Creating Layer scale1_0
I0930 04:42:44.227943 15120 net.cpp:425] scale1_0 <- bn1_0
I0930 04:42:44.227943 15120 net.cpp:399] scale1_0 -> scale1_0
I0930 04:42:44.227943 15120 layer_factory.hpp:77] Creating layer scale1_0
I0930 04:42:44.228945 15120 net.cpp:141] Setting up scale1_0
I0930 04:42:44.228945 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.228945 15120 net.cpp:156] Memory required for data: 131686600
I0930 04:42:44.228945 15120 layer_factory.hpp:77] Creating layer relu1_0
I0930 04:42:44.228945 15120 net.cpp:91] Creating Layer relu1_0
I0930 04:42:44.228945 15120 net.cpp:425] relu1_0 <- scale1_0
I0930 04:42:44.228945 15120 net.cpp:386] relu1_0 -> scale1_0 (in-place)
I0930 04:42:44.228945 15120 net.cpp:141] Setting up relu1_0
I0930 04:42:44.228945 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.228945 15120 net.cpp:156] Memory required for data: 157901000
I0930 04:42:44.228945 15120 layer_factory.hpp:77] Creating layer conv2
I0930 04:42:44.228945 15120 net.cpp:91] Creating Layer conv2
I0930 04:42:44.228945 15120 net.cpp:425] conv2 <- scale1_0
I0930 04:42:44.228945 15120 net.cpp:399] conv2 -> conv2
I0930 04:42:44.232947 15120 net.cpp:141] Setting up conv2
I0930 04:42:44.232947 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.232947 15120 net.cpp:156] Memory required for data: 184115400
I0930 04:42:44.232947 15120 layer_factory.hpp:77] Creating layer bn2
I0930 04:42:44.232947 15120 net.cpp:91] Creating Layer bn2
I0930 04:42:44.232947 15120 net.cpp:425] bn2 <- conv2
I0930 04:42:44.232947 15120 net.cpp:399] bn2 -> bn2
I0930 04:42:44.232947 15120 net.cpp:141] Setting up bn2
I0930 04:42:44.232947 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.232947 15120 net.cpp:156] Memory required for data: 210329800
I0930 04:42:44.232947 15120 layer_factory.hpp:77] Creating layer scale2
I0930 04:42:44.232947 15120 net.cpp:91] Creating Layer scale2
I0930 04:42:44.232947 15120 net.cpp:425] scale2 <- bn2
I0930 04:42:44.232947 15120 net.cpp:399] scale2 -> scale2
I0930 04:42:44.232947 15120 layer_factory.hpp:77] Creating layer scale2
I0930 04:42:44.232947 15120 net.cpp:141] Setting up scale2
I0930 04:42:44.232947 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.232947 15120 net.cpp:156] Memory required for data: 236544200
I0930 04:42:44.232947 15120 layer_factory.hpp:77] Creating layer relu2
I0930 04:42:44.232947 15120 net.cpp:91] Creating Layer relu2
I0930 04:42:44.232947 15120 net.cpp:425] relu2 <- scale2
I0930 04:42:44.232947 15120 net.cpp:386] relu2 -> scale2 (in-place)
I0930 04:42:44.233948 15120 net.cpp:141] Setting up relu2
I0930 04:42:44.233948 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.233948 15120 net.cpp:156] Memory required for data: 262758600
I0930 04:42:44.233948 15120 layer_factory.hpp:77] Creating layer conv2_1
I0930 04:42:44.233948 15120 net.cpp:91] Creating Layer conv2_1
I0930 04:42:44.233948 15120 net.cpp:425] conv2_1 <- scale2
I0930 04:42:44.233948 15120 net.cpp:399] conv2_1 -> conv2_1
I0930 04:42:44.236950 15120 net.cpp:141] Setting up conv2_1
I0930 04:42:44.236950 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.236950 15120 net.cpp:156] Memory required for data: 288973000
I0930 04:42:44.236950 15120 layer_factory.hpp:77] Creating layer bn2_1
I0930 04:42:44.236950 15120 net.cpp:91] Creating Layer bn2_1
I0930 04:42:44.236950 15120 net.cpp:425] bn2_1 <- conv2_1
I0930 04:42:44.236950 15120 net.cpp:399] bn2_1 -> bn2_1
I0930 04:42:44.237951 15120 net.cpp:141] Setting up bn2_1
I0930 04:42:44.237951 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.237951 15120 net.cpp:156] Memory required for data: 315187400
I0930 04:42:44.237951 15120 layer_factory.hpp:77] Creating layer scale2_1
I0930 04:42:44.237951 15120 net.cpp:91] Creating Layer scale2_1
I0930 04:42:44.237951 15120 net.cpp:425] scale2_1 <- bn2_1
I0930 04:42:44.237951 15120 net.cpp:399] scale2_1 -> scale2_1
I0930 04:42:44.237951 15120 layer_factory.hpp:77] Creating layer scale2_1
I0930 04:42:44.237951 15120 net.cpp:141] Setting up scale2_1
I0930 04:42:44.237951 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.237951 15120 net.cpp:156] Memory required for data: 341401800
I0930 04:42:44.237951 15120 layer_factory.hpp:77] Creating layer relu2_1
I0930 04:42:44.237951 15120 net.cpp:91] Creating Layer relu2_1
I0930 04:42:44.237951 15120 net.cpp:425] relu2_1 <- scale2_1
I0930 04:42:44.237951 15120 net.cpp:386] relu2_1 -> scale2_1 (in-place)
I0930 04:42:44.237951 15120 net.cpp:141] Setting up relu2_1
I0930 04:42:44.237951 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.237951 15120 net.cpp:156] Memory required for data: 367616200
I0930 04:42:44.237951 15120 layer_factory.hpp:77] Creating layer pool2_1
I0930 04:42:44.237951 15120 net.cpp:91] Creating Layer pool2_1
I0930 04:42:44.237951 15120 net.cpp:425] pool2_1 <- scale2_1
I0930 04:42:44.237951 15120 net.cpp:399] pool2_1 -> pool2_1
I0930 04:42:44.237951 15120 net.cpp:141] Setting up pool2_1
I0930 04:42:44.237951 15120 net.cpp:148] Top shape: 50 128 16 16 (1638400)
I0930 04:42:44.237951 15120 net.cpp:156] Memory required for data: 374169800
I0930 04:42:44.237951 15120 layer_factory.hpp:77] Creating layer conv2_2
I0930 04:42:44.237951 15120 net.cpp:91] Creating Layer conv2_2
I0930 04:42:44.237951 15120 net.cpp:425] conv2_2 <- pool2_1
I0930 04:42:44.237951 15120 net.cpp:399] conv2_2 -> conv2_2
I0930 04:42:44.244504 15120 net.cpp:141] Setting up conv2_2
I0930 04:42:44.244504 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.244504 15120 net.cpp:156] Memory required for data: 387277000
I0930 04:42:44.244504 15120 layer_factory.hpp:77] Creating layer bn2_2
I0930 04:42:44.244504 15120 net.cpp:91] Creating Layer bn2_2
I0930 04:42:44.244504 15120 net.cpp:425] bn2_2 <- conv2_2
I0930 04:42:44.244504 15120 net.cpp:399] bn2_2 -> bn2_2
I0930 04:42:44.244504 15120 net.cpp:141] Setting up bn2_2
I0930 04:42:44.244504 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.244504 15120 net.cpp:156] Memory required for data: 400384200
I0930 04:42:44.244504 15120 layer_factory.hpp:77] Creating layer scale2_2
I0930 04:42:44.244504 15120 net.cpp:91] Creating Layer scale2_2
I0930 04:42:44.244504 15120 net.cpp:425] scale2_2 <- bn2_2
I0930 04:42:44.244504 15120 net.cpp:399] scale2_2 -> scale2_2
I0930 04:42:44.244504 15120 layer_factory.hpp:77] Creating layer scale2_2
I0930 04:42:44.244504 15120 net.cpp:141] Setting up scale2_2
I0930 04:42:44.244504 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.244504 15120 net.cpp:156] Memory required for data: 413491400
I0930 04:42:44.244504 15120 layer_factory.hpp:77] Creating layer relu2_2
I0930 04:42:44.244504 15120 net.cpp:91] Creating Layer relu2_2
I0930 04:42:44.244504 15120 net.cpp:425] relu2_2 <- scale2_2
I0930 04:42:44.244504 15120 net.cpp:386] relu2_2 -> scale2_2 (in-place)
I0930 04:42:44.245416 15120 net.cpp:141] Setting up relu2_2
I0930 04:42:44.245416 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.245416 15120 net.cpp:156] Memory required for data: 426598600
I0930 04:42:44.245416 15120 layer_factory.hpp:77] Creating layer conv3
I0930 04:42:44.245416 15120 net.cpp:91] Creating Layer conv3
I0930 04:42:44.245416 15120 net.cpp:425] conv3 <- scale2_2
I0930 04:42:44.245416 15120 net.cpp:399] conv3 -> conv3
I0930 04:42:44.251572 15120 net.cpp:141] Setting up conv3
I0930 04:42:44.251572 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.251572 15120 net.cpp:156] Memory required for data: 439705800
I0930 04:42:44.251572 15120 layer_factory.hpp:77] Creating layer bn3
I0930 04:42:44.251572 15120 net.cpp:91] Creating Layer bn3
I0930 04:42:44.251572 15120 net.cpp:425] bn3 <- conv3
I0930 04:42:44.251572 15120 net.cpp:399] bn3 -> bn3
I0930 04:42:44.251572 15120 net.cpp:141] Setting up bn3
I0930 04:42:44.251572 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.251572 15120 net.cpp:156] Memory required for data: 452813000
I0930 04:42:44.251572 15120 layer_factory.hpp:77] Creating layer scale3
I0930 04:42:44.251572 15120 net.cpp:91] Creating Layer scale3
I0930 04:42:44.251572 15120 net.cpp:425] scale3 <- bn3
I0930 04:42:44.251572 15120 net.cpp:399] scale3 -> scale3
I0930 04:42:44.251572 15120 layer_factory.hpp:77] Creating layer scale3
I0930 04:42:44.252574 15120 net.cpp:141] Setting up scale3
I0930 04:42:44.252574 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.252574 15120 net.cpp:156] Memory required for data: 465920200
I0930 04:42:44.252574 15120 layer_factory.hpp:77] Creating layer relu3
I0930 04:42:44.252574 15120 net.cpp:91] Creating Layer relu3
I0930 04:42:44.252574 15120 net.cpp:425] relu3 <- scale3
I0930 04:42:44.252574 15120 net.cpp:386] relu3 -> scale3 (in-place)
I0930 04:42:44.252905 15120 net.cpp:141] Setting up relu3
I0930 04:42:44.252905 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.252905 15120 net.cpp:156] Memory required for data: 479027400
I0930 04:42:44.252905 15120 layer_factory.hpp:77] Creating layer conv4
I0930 04:42:44.252905 15120 net.cpp:91] Creating Layer conv4
I0930 04:42:44.252905 15120 net.cpp:425] conv4 <- scale3
I0930 04:42:44.252905 15120 net.cpp:399] conv4 -> conv4
I0930 04:42:44.261914 15120 net.cpp:141] Setting up conv4
I0930 04:42:44.261914 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.261914 15120 net.cpp:156] Memory required for data: 492134600
I0930 04:42:44.261914 15120 layer_factory.hpp:77] Creating layer pool4
I0930 04:42:44.261914 15120 net.cpp:91] Creating Layer pool4
I0930 04:42:44.261914 15120 net.cpp:425] pool4 <- conv4
I0930 04:42:44.261914 15120 net.cpp:399] pool4 -> pool4
I0930 04:42:44.261914 15120 net.cpp:141] Setting up pool4
I0930 04:42:44.261914 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.261914 15120 net.cpp:156] Memory required for data: 495411400
I0930 04:42:44.261914 15120 layer_factory.hpp:77] Creating layer bn4
I0930 04:42:44.262914 15120 net.cpp:91] Creating Layer bn4
I0930 04:42:44.262914 15120 net.cpp:425] bn4 <- pool4
I0930 04:42:44.262914 15120 net.cpp:399] bn4 -> bn4
I0930 04:42:44.262914 15120 net.cpp:141] Setting up bn4
I0930 04:42:44.262914 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.262914 15120 net.cpp:156] Memory required for data: 498688200
I0930 04:42:44.262914 15120 layer_factory.hpp:77] Creating layer scale4
I0930 04:42:44.262914 15120 net.cpp:91] Creating Layer scale4
I0930 04:42:44.262914 15120 net.cpp:425] scale4 <- bn4
I0930 04:42:44.262914 15120 net.cpp:399] scale4 -> scale4
I0930 04:42:44.262914 15120 layer_factory.hpp:77] Creating layer scale4
I0930 04:42:44.262914 15120 net.cpp:141] Setting up scale4
I0930 04:42:44.262914 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.262914 15120 net.cpp:156] Memory required for data: 501965000
I0930 04:42:44.262914 15120 layer_factory.hpp:77] Creating layer relu4
I0930 04:42:44.262914 15120 net.cpp:91] Creating Layer relu4
I0930 04:42:44.262914 15120 net.cpp:425] relu4 <- scale4
I0930 04:42:44.262914 15120 net.cpp:386] relu4 -> scale4 (in-place)
I0930 04:42:44.263916 15120 net.cpp:141] Setting up relu4
I0930 04:42:44.263916 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.263916 15120 net.cpp:156] Memory required for data: 505241800
I0930 04:42:44.263916 15120 layer_factory.hpp:77] Creating layer conv4_1
I0930 04:42:44.263916 15120 net.cpp:91] Creating Layer conv4_1
I0930 04:42:44.263916 15120 net.cpp:425] conv4_1 <- scale4
I0930 04:42:44.263916 15120 net.cpp:399] conv4_1 -> conv4_1
I0930 04:42:44.269919 15120 net.cpp:141] Setting up conv4_1
I0930 04:42:44.269919 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.269919 15120 net.cpp:156] Memory required for data: 508518600
I0930 04:42:44.269919 15120 layer_factory.hpp:77] Creating layer bn4_1
I0930 04:42:44.269919 15120 net.cpp:91] Creating Layer bn4_1
I0930 04:42:44.269919 15120 net.cpp:425] bn4_1 <- conv4_1
I0930 04:42:44.269919 15120 net.cpp:399] bn4_1 -> bn4_1
I0930 04:42:44.270920 15120 net.cpp:141] Setting up bn4_1
I0930 04:42:44.270920 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.270920 15120 net.cpp:156] Memory required for data: 511795400
I0930 04:42:44.270920 15120 layer_factory.hpp:77] Creating layer scale4_1
I0930 04:42:44.270920 15120 net.cpp:91] Creating Layer scale4_1
I0930 04:42:44.270920 15120 net.cpp:425] scale4_1 <- bn4_1
I0930 04:42:44.270920 15120 net.cpp:399] scale4_1 -> scale4_1
I0930 04:42:44.270920 15120 layer_factory.hpp:77] Creating layer scale4_1
I0930 04:42:44.270920 15120 net.cpp:141] Setting up scale4_1
I0930 04:42:44.270920 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.270920 15120 net.cpp:156] Memory required for data: 515072200
I0930 04:42:44.270920 15120 layer_factory.hpp:77] Creating layer relu4_1
I0930 04:42:44.270920 15120 net.cpp:91] Creating Layer relu4_1
I0930 04:42:44.270920 15120 net.cpp:425] relu4_1 <- scale4_1
I0930 04:42:44.270920 15120 net.cpp:386] relu4_1 -> scale4_1 (in-place)
I0930 04:42:44.272037 15120 net.cpp:141] Setting up relu4_1
I0930 04:42:44.272037 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.272037 15120 net.cpp:156] Memory required for data: 518349000
I0930 04:42:44.272037 15120 layer_factory.hpp:77] Creating layer conv4_2
I0930 04:42:44.272037 15120 net.cpp:91] Creating Layer conv4_2
I0930 04:42:44.272037 15120 net.cpp:425] conv4_2 <- scale4_1
I0930 04:42:44.272037 15120 net.cpp:399] conv4_2 -> conv4_2
I0930 04:42:44.279043 15120 net.cpp:141] Setting up conv4_2
I0930 04:42:44.279043 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.279043 15120 net.cpp:156] Memory required for data: 521625800
I0930 04:42:44.279043 15120 layer_factory.hpp:77] Creating layer bn4_2
I0930 04:42:44.279043 15120 net.cpp:91] Creating Layer bn4_2
I0930 04:42:44.279043 15120 net.cpp:425] bn4_2 <- conv4_2
I0930 04:42:44.279043 15120 net.cpp:399] bn4_2 -> bn4_2
I0930 04:42:44.280045 15120 net.cpp:141] Setting up bn4_2
I0930 04:42:44.280045 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.280045 15120 net.cpp:156] Memory required for data: 524902600
I0930 04:42:44.280045 15120 layer_factory.hpp:77] Creating layer scale4_2
I0930 04:42:44.280045 15120 net.cpp:91] Creating Layer scale4_2
I0930 04:42:44.280045 15120 net.cpp:425] scale4_2 <- bn4_2
I0930 04:42:44.280045 15120 net.cpp:399] scale4_2 -> scale4_2
I0930 04:42:44.280045 15120 layer_factory.hpp:77] Creating layer scale4_2
I0930 04:42:44.280045 15120 net.cpp:141] Setting up scale4_2
I0930 04:42:44.280045 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.280045 15120 net.cpp:156] Memory required for data: 528179400
I0930 04:42:44.280045 15120 layer_factory.hpp:77] Creating layer relu4_2
I0930 04:42:44.280045 15120 net.cpp:91] Creating Layer relu4_2
I0930 04:42:44.280045 15120 net.cpp:425] relu4_2 <- scale4_2
I0930 04:42:44.280045 15120 net.cpp:386] relu4_2 -> scale4_2 (in-place)
I0930 04:42:44.281045 15120 net.cpp:141] Setting up relu4_2
I0930 04:42:44.281045 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.281045 15120 net.cpp:156] Memory required for data: 531456200
I0930 04:42:44.281045 15120 layer_factory.hpp:77] Creating layer pool4_2
I0930 04:42:44.281045 15120 net.cpp:91] Creating Layer pool4_2
I0930 04:42:44.281045 15120 net.cpp:425] pool4_2 <- scale4_2
I0930 04:42:44.281045 15120 net.cpp:399] pool4_2 -> pool4_2
I0930 04:42:44.281045 15120 net.cpp:141] Setting up pool4_2
I0930 04:42:44.281045 15120 net.cpp:148] Top shape: 50 256 4 4 (204800)
I0930 04:42:44.281045 15120 net.cpp:156] Memory required for data: 532275400
I0930 04:42:44.281045 15120 layer_factory.hpp:77] Creating layer conv4_0
I0930 04:42:44.281045 15120 net.cpp:91] Creating Layer conv4_0
I0930 04:42:44.281045 15120 net.cpp:425] conv4_0 <- pool4_2
I0930 04:42:44.281045 15120 net.cpp:399] conv4_0 -> conv4_0
I0930 04:42:44.292673 15120 net.cpp:141] Setting up conv4_0
I0930 04:42:44.292673 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.292673 15120 net.cpp:156] Memory required for data: 533913800
I0930 04:42:44.292673 15120 layer_factory.hpp:77] Creating layer bn4_0
I0930 04:42:44.292673 15120 net.cpp:91] Creating Layer bn4_0
I0930 04:42:44.292673 15120 net.cpp:425] bn4_0 <- conv4_0
I0930 04:42:44.292673 15120 net.cpp:399] bn4_0 -> bn4_0
I0930 04:42:44.292673 15120 net.cpp:141] Setting up bn4_0
I0930 04:42:44.292673 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.292673 15120 net.cpp:156] Memory required for data: 535552200
I0930 04:42:44.292673 15120 layer_factory.hpp:77] Creating layer scale4_0
I0930 04:42:44.292673 15120 net.cpp:91] Creating Layer scale4_0
I0930 04:42:44.292673 15120 net.cpp:425] scale4_0 <- bn4_0
I0930 04:42:44.292673 15120 net.cpp:399] scale4_0 -> scale4_0
I0930 04:42:44.292673 15120 layer_factory.hpp:77] Creating layer scale4_0
I0930 04:42:44.292673 15120 net.cpp:141] Setting up scale4_0
I0930 04:42:44.292673 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.292673 15120 net.cpp:156] Memory required for data: 537190600
I0930 04:42:44.292673 15120 layer_factory.hpp:77] Creating layer relu4_0
I0930 04:42:44.292673 15120 net.cpp:91] Creating Layer relu4_0
I0930 04:42:44.292673 15120 net.cpp:425] relu4_0 <- scale4_0
I0930 04:42:44.292673 15120 net.cpp:386] relu4_0 -> scale4_0 (in-place)
I0930 04:42:44.293674 15120 net.cpp:141] Setting up relu4_0
I0930 04:42:44.293674 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.293674 15120 net.cpp:156] Memory required for data: 538829000
I0930 04:42:44.293674 15120 layer_factory.hpp:77] Creating layer cccp4
I0930 04:42:44.293674 15120 net.cpp:91] Creating Layer cccp4
I0930 04:42:44.293674 15120 net.cpp:425] cccp4 <- scale4_0
I0930 04:42:44.293674 15120 net.cpp:399] cccp4 -> cccp4
I0930 04:42:44.304302 15120 net.cpp:141] Setting up cccp4
I0930 04:42:44.304302 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.304302 15120 net.cpp:156] Memory required for data: 545382600
I0930 04:42:44.304302 15120 layer_factory.hpp:77] Creating layer bn_cccp4
I0930 04:42:44.304302 15120 net.cpp:91] Creating Layer bn_cccp4
I0930 04:42:44.304302 15120 net.cpp:425] bn_cccp4 <- cccp4
I0930 04:42:44.304302 15120 net.cpp:399] bn_cccp4 -> bn_cccp4
I0930 04:42:44.304302 15120 net.cpp:141] Setting up bn_cccp4
I0930 04:42:44.304302 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.304302 15120 net.cpp:156] Memory required for data: 551936200
I0930 04:42:44.304302 15120 layer_factory.hpp:77] Creating layer scale_ccp4
I0930 04:42:44.304302 15120 net.cpp:91] Creating Layer scale_ccp4
I0930 04:42:44.304302 15120 net.cpp:425] scale_ccp4 <- bn_cccp4
I0930 04:42:44.304302 15120 net.cpp:399] scale_ccp4 -> scale_ccp4
I0930 04:42:44.305304 15120 layer_factory.hpp:77] Creating layer scale_ccp4
I0930 04:42:44.305304 15120 net.cpp:141] Setting up scale_ccp4
I0930 04:42:44.305304 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.305304 15120 net.cpp:156] Memory required for data: 558489800
I0930 04:42:44.305304 15120 layer_factory.hpp:77] Creating layer relu_cccp4
I0930 04:42:44.305304 15120 net.cpp:91] Creating Layer relu_cccp4
I0930 04:42:44.305304 15120 net.cpp:425] relu_cccp4 <- scale_ccp4
I0930 04:42:44.305304 15120 net.cpp:386] relu_cccp4 -> scale_ccp4 (in-place)
I0930 04:42:44.305304 15120 net.cpp:141] Setting up relu_cccp4
I0930 04:42:44.305304 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.305304 15120 net.cpp:156] Memory required for data: 565043400
I0930 04:42:44.305304 15120 layer_factory.hpp:77] Creating layer cccp5
I0930 04:42:44.305304 15120 net.cpp:91] Creating Layer cccp5
I0930 04:42:44.305304 15120 net.cpp:425] cccp5 <- scale_ccp4
I0930 04:42:44.305304 15120 net.cpp:399] cccp5 -> cccp5
I0930 04:42:44.384358 15120 net.cpp:141] Setting up cccp5
I0930 04:42:44.384358 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.384358 15120 net.cpp:156] Memory required for data: 565453000
I0930 04:42:44.384358 15120 layer_factory.hpp:77] Creating layer bn_cccp5
I0930 04:42:44.385360 15120 net.cpp:91] Creating Layer bn_cccp5
I0930 04:42:44.385360 15120 net.cpp:425] bn_cccp5 <- cccp5
I0930 04:42:44.385360 15120 net.cpp:399] bn_cccp5 -> bn_cccp5
I0930 04:42:44.385360 15120 net.cpp:141] Setting up bn_cccp5
I0930 04:42:44.385360 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.385360 15120 net.cpp:156] Memory required for data: 565862600
I0930 04:42:44.385360 15120 layer_factory.hpp:77] Creating layer scale_ccp5
I0930 04:42:44.385360 15120 net.cpp:91] Creating Layer scale_ccp5
I0930 04:42:44.385360 15120 net.cpp:425] scale_ccp5 <- bn_cccp5
I0930 04:42:44.385360 15120 net.cpp:399] scale_ccp5 -> scale_ccp5
I0930 04:42:44.385360 15120 layer_factory.hpp:77] Creating layer scale_ccp5
I0930 04:42:44.385360 15120 net.cpp:141] Setting up scale_ccp5
I0930 04:42:44.385360 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.385360 15120 net.cpp:156] Memory required for data: 566272200
I0930 04:42:44.385360 15120 layer_factory.hpp:77] Creating layer relu_cccp5
I0930 04:42:44.385360 15120 net.cpp:91] Creating Layer relu_cccp5
I0930 04:42:44.385360 15120 net.cpp:425] relu_cccp5 <- scale_ccp5
I0930 04:42:44.385360 15120 net.cpp:386] relu_cccp5 -> scale_ccp5 (in-place)
I0930 04:42:44.386360 15120 net.cpp:141] Setting up relu_cccp5
I0930 04:42:44.386360 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.386360 15120 net.cpp:156] Memory required for data: 566681800
I0930 04:42:44.386360 15120 layer_factory.hpp:77] Creating layer poolcp5
I0930 04:42:44.386360 15120 net.cpp:91] Creating Layer poolcp5
I0930 04:42:44.386360 15120 net.cpp:425] poolcp5 <- scale_ccp5
I0930 04:42:44.386360 15120 net.cpp:399] poolcp5 -> poolcp5
I0930 04:42:44.386360 15120 net.cpp:141] Setting up poolcp5
I0930 04:42:44.386360 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.386360 15120 net.cpp:156] Memory required for data: 566784200
I0930 04:42:44.386360 15120 layer_factory.hpp:77] Creating layer cccp6
I0930 04:42:44.386360 15120 net.cpp:91] Creating Layer cccp6
I0930 04:42:44.386360 15120 net.cpp:425] cccp6 <- poolcp5
I0930 04:42:44.386360 15120 net.cpp:399] cccp6 -> cccp6
I0930 04:42:44.408136 15120 net.cpp:141] Setting up cccp6
I0930 04:42:44.408136 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.408136 15120 net.cpp:156] Memory required for data: 566886600
I0930 04:42:44.408136 15120 layer_factory.hpp:77] Creating layer bn_cccp6
I0930 04:42:44.408136 15120 net.cpp:91] Creating Layer bn_cccp6
I0930 04:42:44.408136 15120 net.cpp:425] bn_cccp6 <- cccp6
I0930 04:42:44.408136 15120 net.cpp:399] bn_cccp6 -> bn_cccp6
I0930 04:42:44.408136 15120 net.cpp:141] Setting up bn_cccp6
I0930 04:42:44.408136 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.408136 15120 net.cpp:156] Memory required for data: 566989000
I0930 04:42:44.408136 15120 layer_factory.hpp:77] Creating layer scale_ccp6
I0930 04:42:44.408136 15120 net.cpp:91] Creating Layer scale_ccp6
I0930 04:42:44.408136 15120 net.cpp:425] scale_ccp6 <- bn_cccp6
I0930 04:42:44.408136 15120 net.cpp:399] scale_ccp6 -> scale_ccp6
I0930 04:42:44.408136 15120 layer_factory.hpp:77] Creating layer scale_ccp6
I0930 04:42:44.409138 15120 net.cpp:141] Setting up scale_ccp6
I0930 04:42:44.409138 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.409138 15120 net.cpp:156] Memory required for data: 567091400
I0930 04:42:44.409138 15120 layer_factory.hpp:77] Creating layer relu_cccp6
I0930 04:42:44.409138 15120 net.cpp:91] Creating Layer relu_cccp6
I0930 04:42:44.409138 15120 net.cpp:425] relu_cccp6 <- scale_ccp6
I0930 04:42:44.409138 15120 net.cpp:386] relu_cccp6 -> scale_ccp6 (in-place)
I0930 04:42:44.409138 15120 net.cpp:141] Setting up relu_cccp6
I0930 04:42:44.409138 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.409138 15120 net.cpp:156] Memory required for data: 567193800
I0930 04:42:44.409138 15120 layer_factory.hpp:77] Creating layer poolcp6
I0930 04:42:44.409138 15120 net.cpp:91] Creating Layer poolcp6
I0930 04:42:44.409138 15120 net.cpp:425] poolcp6 <- scale_ccp6
I0930 04:42:44.409138 15120 net.cpp:399] poolcp6 -> poolcp6
I0930 04:42:44.409138 15120 net.cpp:141] Setting up poolcp6
I0930 04:42:44.409138 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.409138 15120 net.cpp:156] Memory required for data: 567296200
I0930 04:42:44.409138 15120 layer_factory.hpp:77] Creating layer fc_conv
I0930 04:42:44.409138 15120 net.cpp:91] Creating Layer fc_conv
I0930 04:42:44.409138 15120 net.cpp:425] fc_conv <- poolcp6
I0930 04:42:44.409138 15120 net.cpp:399] fc_conv -> fc_conv
I0930 04:42:44.420017 15120 net.cpp:141] Setting up fc_conv
I0930 04:42:44.420017 15120 net.cpp:148] Top shape: 50 2048 3 3 (921600)
I0930 04:42:44.420017 15120 net.cpp:156] Memory required for data: 570982600
I0930 04:42:44.420017 15120 layer_factory.hpp:77] Creating layer ipf0
I0930 04:42:44.420017 15120 net.cpp:91] Creating Layer ipf0
I0930 04:42:44.420017 15120 net.cpp:425] ipf0 <- fc_conv
I0930 04:42:44.420017 15120 net.cpp:399] ipf0 -> ipf0
I0930 04:42:44.436357 15120 net.cpp:141] Setting up ipf0
I0930 04:42:44.436357 15120 net.cpp:148] Top shape: 50 100 (5000)
I0930 04:42:44.436357 15120 net.cpp:156] Memory required for data: 571002600
I0930 04:42:44.436357 15120 layer_factory.hpp:77] Creating layer loss
I0930 04:42:44.436357 15120 net.cpp:91] Creating Layer loss
I0930 04:42:44.436357 15120 net.cpp:425] loss <- ipf0
I0930 04:42:44.436357 15120 net.cpp:425] loss <- label_fine
I0930 04:42:44.436357 15120 net.cpp:399] loss -> loss
I0930 04:42:44.436357 15120 layer_factory.hpp:77] Creating layer loss
I0930 04:42:44.438359 15120 net.cpp:141] Setting up loss
I0930 04:42:44.438359 15120 net.cpp:148] Top shape: (1)
I0930 04:42:44.438359 15120 net.cpp:151]     with loss weight 1
I0930 04:42:44.438359 15120 net.cpp:156] Memory required for data: 571002604
I0930 04:42:44.438359 15120 net.cpp:217] loss needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] ipf0 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] fc_conv needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] poolcp6 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] relu_cccp6 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] scale_ccp6 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] bn_cccp6 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] cccp6 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] poolcp5 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] relu_cccp5 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] scale_ccp5 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] bn_cccp5 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] cccp5 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] relu_cccp4 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] scale_ccp4 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] bn_cccp4 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] cccp4 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] relu4_0 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] scale4_0 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] bn4_0 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] conv4_0 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] pool4_2 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] relu4_2 needs backward computation.
I0930 04:42:44.438359 15120 net.cpp:217] scale4_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn4_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv4_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu4_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale4_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn4_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv4_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu4 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale4 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn4 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] pool4 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv4 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu3 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale3 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn3 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv3 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu2_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale2_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn2_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv2_2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] pool2_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu2_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale2_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn2_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv2_1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv2 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu1_0 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale1_0 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn1_0 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv1_0 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] relu1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] scale1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] bn1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:217] conv1 needs backward computation.
I0930 04:42:44.439358 15120 net.cpp:219] cifar does not need backward computation.
I0930 04:42:44.439358 15120 net.cpp:261] This network produces output loss
I0930 04:42:44.439358 15120 net.cpp:274] Network initialization done.
I0930 04:42:44.440359 15120 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0930 04:42:44.440359 15120 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0930 04:42:44.441360 15120 net.cpp:49] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label_fine"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "bn_cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp4"
  type: "Scale"
  bottom: "bn_cccp4"
  top: "scale_ccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "scale_ccp4"
  top: "scale_ccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "scale_ccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "bn_cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp5"
  type: "Scale"
  bottom: "bn_cccp5"
  top: "scale_ccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "scale_ccp5"
  top: "scale_ccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "scale_ccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "bn_cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp6"
  type: "Scale"
  bottom: "bn_cccp6"
  top: "scale_ccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "scale_ccp6"
  top: "scale_ccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "scale_ccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc_conv"
  type: "Convolution"
  bottom: "poolcp6"
  top: "fc_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    pad: 1
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ipf0"
  type: "InnerProduct"
  bottom: "fc_conv"
  top: "ipf0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "loss"
}
I0930 04:42:44.441360 15120 layer_factory.hpp:77] Creating layer cifar
I0930 04:42:44.442360 15120 net.cpp:91] Creating Layer cifar
I0930 04:42:44.442360 15120 net.cpp:399] cifar -> data
I0930 04:42:44.442360 15120 net.cpp:399] cifar -> label_fine
I0930 04:42:44.443361  6132 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0930 04:42:44.446363  6132 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I0930 04:42:44.447365 15120 data_layer.cpp:41] output data size: 50,3,32,32
I0930 04:42:44.453368 15120 net.cpp:141] Setting up cifar
I0930 04:42:44.453368 15120 net.cpp:148] Top shape: 50 3 32 32 (153600)
I0930 04:42:44.453368 15120 net.cpp:148] Top shape: 50 (50)
I0930 04:42:44.453368 15120 net.cpp:156] Memory required for data: 614600
I0930 04:42:44.453368 15120 layer_factory.hpp:77] Creating layer label_fine_cifar_1_split
I0930 04:42:44.453368 15120 net.cpp:91] Creating Layer label_fine_cifar_1_split
I0930 04:42:44.453368 15120 net.cpp:425] label_fine_cifar_1_split <- label_fine
I0930 04:42:44.453368 15120 net.cpp:399] label_fine_cifar_1_split -> label_fine_cifar_1_split_0
I0930 04:42:44.453368 15120 net.cpp:399] label_fine_cifar_1_split -> label_fine_cifar_1_split_1
I0930 04:42:44.453368 15120 net.cpp:141] Setting up label_fine_cifar_1_split
I0930 04:42:44.453368 15120 net.cpp:148] Top shape: 50 (50)
I0930 04:42:44.453368 15120 net.cpp:148] Top shape: 50 (50)
I0930 04:42:44.453368 15120 net.cpp:156] Memory required for data: 615000
I0930 04:42:44.453368 15120 layer_factory.hpp:77] Creating layer conv1
I0930 04:42:44.453368 15120 net.cpp:91] Creating Layer conv1
I0930 04:42:44.453368 15120 net.cpp:425] conv1 <- data
I0930 04:42:44.453368 15120 net.cpp:399] conv1 -> conv1
I0930 04:42:44.455370 15120 net.cpp:141] Setting up conv1
I0930 04:42:44.455370 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.456370 15120 net.cpp:156] Memory required for data: 13722200
I0930 04:42:44.456370 15120 layer_factory.hpp:77] Creating layer bn1
I0930 04:42:44.456370 15120 net.cpp:91] Creating Layer bn1
I0930 04:42:44.456370 15120 net.cpp:425] bn1 <- conv1
I0930 04:42:44.456370 15120 net.cpp:399] bn1 -> bn1
I0930 04:42:44.456370 12176 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0930 04:42:44.456370 15120 net.cpp:141] Setting up bn1
I0930 04:42:44.456370 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.456370 15120 net.cpp:156] Memory required for data: 26829400
I0930 04:42:44.456370 15120 layer_factory.hpp:77] Creating layer scale1
I0930 04:42:44.456370 15120 net.cpp:91] Creating Layer scale1
I0930 04:42:44.456370 15120 net.cpp:425] scale1 <- bn1
I0930 04:42:44.456370 15120 net.cpp:399] scale1 -> scale1
I0930 04:42:44.456370 15120 layer_factory.hpp:77] Creating layer scale1
I0930 04:42:44.457371 15120 net.cpp:141] Setting up scale1
I0930 04:42:44.457371 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.457371 15120 net.cpp:156] Memory required for data: 39936600
I0930 04:42:44.457371 15120 layer_factory.hpp:77] Creating layer relu1
I0930 04:42:44.457371 15120 net.cpp:91] Creating Layer relu1
I0930 04:42:44.457371 15120 net.cpp:425] relu1 <- scale1
I0930 04:42:44.457371 15120 net.cpp:386] relu1 -> scale1 (in-place)
I0930 04:42:44.457371 15120 net.cpp:141] Setting up relu1
I0930 04:42:44.457371 15120 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0930 04:42:44.457371 15120 net.cpp:156] Memory required for data: 53043800
I0930 04:42:44.457371 15120 layer_factory.hpp:77] Creating layer conv1_0
I0930 04:42:44.457371 15120 net.cpp:91] Creating Layer conv1_0
I0930 04:42:44.457371 15120 net.cpp:425] conv1_0 <- scale1
I0930 04:42:44.457371 15120 net.cpp:399] conv1_0 -> conv1_0
I0930 04:42:44.459959 15120 net.cpp:141] Setting up conv1_0
I0930 04:42:44.459959 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.459959 15120 net.cpp:156] Memory required for data: 79258200
I0930 04:42:44.459959 15120 layer_factory.hpp:77] Creating layer bn1_0
I0930 04:42:44.459959 15120 net.cpp:91] Creating Layer bn1_0
I0930 04:42:44.459959 15120 net.cpp:425] bn1_0 <- conv1_0
I0930 04:42:44.459959 15120 net.cpp:399] bn1_0 -> bn1_0
I0930 04:42:44.459959 15120 net.cpp:141] Setting up bn1_0
I0930 04:42:44.459959 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.459959 15120 net.cpp:156] Memory required for data: 105472600
I0930 04:42:44.459959 15120 layer_factory.hpp:77] Creating layer scale1_0
I0930 04:42:44.459959 15120 net.cpp:91] Creating Layer scale1_0
I0930 04:42:44.459959 15120 net.cpp:425] scale1_0 <- bn1_0
I0930 04:42:44.459959 15120 net.cpp:399] scale1_0 -> scale1_0
I0930 04:42:44.459959 15120 layer_factory.hpp:77] Creating layer scale1_0
I0930 04:42:44.459959 15120 net.cpp:141] Setting up scale1_0
I0930 04:42:44.459959 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.459959 15120 net.cpp:156] Memory required for data: 131687000
I0930 04:42:44.459959 15120 layer_factory.hpp:77] Creating layer relu1_0
I0930 04:42:44.459959 15120 net.cpp:91] Creating Layer relu1_0
I0930 04:42:44.459959 15120 net.cpp:425] relu1_0 <- scale1_0
I0930 04:42:44.459959 15120 net.cpp:386] relu1_0 -> scale1_0 (in-place)
I0930 04:42:44.460961 15120 net.cpp:141] Setting up relu1_0
I0930 04:42:44.460961 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.460961 15120 net.cpp:156] Memory required for data: 157901400
I0930 04:42:44.460961 15120 layer_factory.hpp:77] Creating layer conv2
I0930 04:42:44.460961 15120 net.cpp:91] Creating Layer conv2
I0930 04:42:44.460961 15120 net.cpp:425] conv2 <- scale1_0
I0930 04:42:44.460961 15120 net.cpp:399] conv2 -> conv2
I0930 04:42:44.464354 15120 net.cpp:141] Setting up conv2
I0930 04:42:44.464354 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.464354 15120 net.cpp:156] Memory required for data: 184115800
I0930 04:42:44.464354 15120 layer_factory.hpp:77] Creating layer bn2
I0930 04:42:44.464354 15120 net.cpp:91] Creating Layer bn2
I0930 04:42:44.464354 15120 net.cpp:425] bn2 <- conv2
I0930 04:42:44.464354 15120 net.cpp:399] bn2 -> bn2
I0930 04:42:44.464354 15120 net.cpp:141] Setting up bn2
I0930 04:42:44.464354 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.464354 15120 net.cpp:156] Memory required for data: 210330200
I0930 04:42:44.464354 15120 layer_factory.hpp:77] Creating layer scale2
I0930 04:42:44.464354 15120 net.cpp:91] Creating Layer scale2
I0930 04:42:44.464354 15120 net.cpp:425] scale2 <- bn2
I0930 04:42:44.464354 15120 net.cpp:399] scale2 -> scale2
I0930 04:42:44.464354 15120 layer_factory.hpp:77] Creating layer scale2
I0930 04:42:44.464354 15120 net.cpp:141] Setting up scale2
I0930 04:42:44.464354 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.464354 15120 net.cpp:156] Memory required for data: 236544600
I0930 04:42:44.464354 15120 layer_factory.hpp:77] Creating layer relu2
I0930 04:42:44.464354 15120 net.cpp:91] Creating Layer relu2
I0930 04:42:44.465356 15120 net.cpp:425] relu2 <- scale2
I0930 04:42:44.465356 15120 net.cpp:386] relu2 -> scale2 (in-place)
I0930 04:42:44.465657 15120 net.cpp:141] Setting up relu2
I0930 04:42:44.465657 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.465657 15120 net.cpp:156] Memory required for data: 262759000
I0930 04:42:44.465657 15120 layer_factory.hpp:77] Creating layer conv2_1
I0930 04:42:44.465657 15120 net.cpp:91] Creating Layer conv2_1
I0930 04:42:44.465657 15120 net.cpp:425] conv2_1 <- scale2
I0930 04:42:44.465657 15120 net.cpp:399] conv2_1 -> conv2_1
I0930 04:42:44.469435 15120 net.cpp:141] Setting up conv2_1
I0930 04:42:44.469435 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.469435 15120 net.cpp:156] Memory required for data: 288973400
I0930 04:42:44.469435 15120 layer_factory.hpp:77] Creating layer bn2_1
I0930 04:42:44.469435 15120 net.cpp:91] Creating Layer bn2_1
I0930 04:42:44.469435 15120 net.cpp:425] bn2_1 <- conv2_1
I0930 04:42:44.469435 15120 net.cpp:399] bn2_1 -> bn2_1
I0930 04:42:44.469435 15120 net.cpp:141] Setting up bn2_1
I0930 04:42:44.469435 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.469435 15120 net.cpp:156] Memory required for data: 315187800
I0930 04:42:44.469435 15120 layer_factory.hpp:77] Creating layer scale2_1
I0930 04:42:44.469435 15120 net.cpp:91] Creating Layer scale2_1
I0930 04:42:44.469435 15120 net.cpp:425] scale2_1 <- bn2_1
I0930 04:42:44.469435 15120 net.cpp:399] scale2_1 -> scale2_1
I0930 04:42:44.469435 15120 layer_factory.hpp:77] Creating layer scale2_1
I0930 04:42:44.469435 15120 net.cpp:141] Setting up scale2_1
I0930 04:42:44.469435 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.469435 15120 net.cpp:156] Memory required for data: 341402200
I0930 04:42:44.469435 15120 layer_factory.hpp:77] Creating layer relu2_1
I0930 04:42:44.469435 15120 net.cpp:91] Creating Layer relu2_1
I0930 04:42:44.469435 15120 net.cpp:425] relu2_1 <- scale2_1
I0930 04:42:44.469435 15120 net.cpp:386] relu2_1 -> scale2_1 (in-place)
I0930 04:42:44.470438 15120 net.cpp:141] Setting up relu2_1
I0930 04:42:44.470438 15120 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0930 04:42:44.470438 15120 net.cpp:156] Memory required for data: 367616600
I0930 04:42:44.470438 15120 layer_factory.hpp:77] Creating layer pool2_1
I0930 04:42:44.470438 15120 net.cpp:91] Creating Layer pool2_1
I0930 04:42:44.470438 15120 net.cpp:425] pool2_1 <- scale2_1
I0930 04:42:44.470438 15120 net.cpp:399] pool2_1 -> pool2_1
I0930 04:42:44.470438 15120 net.cpp:141] Setting up pool2_1
I0930 04:42:44.470438 15120 net.cpp:148] Top shape: 50 128 16 16 (1638400)
I0930 04:42:44.470438 15120 net.cpp:156] Memory required for data: 374170200
I0930 04:42:44.470438 15120 layer_factory.hpp:77] Creating layer conv2_2
I0930 04:42:44.470438 15120 net.cpp:91] Creating Layer conv2_2
I0930 04:42:44.470438 15120 net.cpp:425] conv2_2 <- pool2_1
I0930 04:42:44.470438 15120 net.cpp:399] conv2_2 -> conv2_2
I0930 04:42:44.476632 15120 net.cpp:141] Setting up conv2_2
I0930 04:42:44.476632 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.476632 15120 net.cpp:156] Memory required for data: 387277400
I0930 04:42:44.476632 15120 layer_factory.hpp:77] Creating layer bn2_2
I0930 04:42:44.476632 15120 net.cpp:91] Creating Layer bn2_2
I0930 04:42:44.476632 15120 net.cpp:425] bn2_2 <- conv2_2
I0930 04:42:44.476632 15120 net.cpp:399] bn2_2 -> bn2_2
I0930 04:42:44.477633 15120 net.cpp:141] Setting up bn2_2
I0930 04:42:44.477633 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.477633 15120 net.cpp:156] Memory required for data: 400384600
I0930 04:42:44.477633 15120 layer_factory.hpp:77] Creating layer scale2_2
I0930 04:42:44.477633 15120 net.cpp:91] Creating Layer scale2_2
I0930 04:42:44.477633 15120 net.cpp:425] scale2_2 <- bn2_2
I0930 04:42:44.477633 15120 net.cpp:399] scale2_2 -> scale2_2
I0930 04:42:44.477633 15120 layer_factory.hpp:77] Creating layer scale2_2
I0930 04:42:44.477633 15120 net.cpp:141] Setting up scale2_2
I0930 04:42:44.477633 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.477633 15120 net.cpp:156] Memory required for data: 413491800
I0930 04:42:44.477633 15120 layer_factory.hpp:77] Creating layer relu2_2
I0930 04:42:44.477633 15120 net.cpp:91] Creating Layer relu2_2
I0930 04:42:44.477633 15120 net.cpp:425] relu2_2 <- scale2_2
I0930 04:42:44.477633 15120 net.cpp:386] relu2_2 -> scale2_2 (in-place)
I0930 04:42:44.477633 15120 net.cpp:141] Setting up relu2_2
I0930 04:42:44.478634 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.478634 15120 net.cpp:156] Memory required for data: 426599000
I0930 04:42:44.478634 15120 layer_factory.hpp:77] Creating layer conv3
I0930 04:42:44.478634 15120 net.cpp:91] Creating Layer conv3
I0930 04:42:44.478634 15120 net.cpp:425] conv3 <- scale2_2
I0930 04:42:44.478634 15120 net.cpp:399] conv3 -> conv3
I0930 04:42:44.484925 15120 net.cpp:141] Setting up conv3
I0930 04:42:44.484925 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.484925 15120 net.cpp:156] Memory required for data: 439706200
I0930 04:42:44.484925 15120 layer_factory.hpp:77] Creating layer bn3
I0930 04:42:44.484925 15120 net.cpp:91] Creating Layer bn3
I0930 04:42:44.484925 15120 net.cpp:425] bn3 <- conv3
I0930 04:42:44.484925 15120 net.cpp:399] bn3 -> bn3
I0930 04:42:44.484925 15120 net.cpp:141] Setting up bn3
I0930 04:42:44.484925 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.484925 15120 net.cpp:156] Memory required for data: 452813400
I0930 04:42:44.484925 15120 layer_factory.hpp:77] Creating layer scale3
I0930 04:42:44.484925 15120 net.cpp:91] Creating Layer scale3
I0930 04:42:44.484925 15120 net.cpp:425] scale3 <- bn3
I0930 04:42:44.484925 15120 net.cpp:399] scale3 -> scale3
I0930 04:42:44.485926 15120 layer_factory.hpp:77] Creating layer scale3
I0930 04:42:44.485926 15120 net.cpp:141] Setting up scale3
I0930 04:42:44.485926 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.485926 15120 net.cpp:156] Memory required for data: 465920600
I0930 04:42:44.485926 15120 layer_factory.hpp:77] Creating layer relu3
I0930 04:42:44.485926 15120 net.cpp:91] Creating Layer relu3
I0930 04:42:44.485926 15120 net.cpp:425] relu3 <- scale3
I0930 04:42:44.485926 15120 net.cpp:386] relu3 -> scale3 (in-place)
I0930 04:42:44.486448 15120 net.cpp:141] Setting up relu3
I0930 04:42:44.486448 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.486448 15120 net.cpp:156] Memory required for data: 479027800
I0930 04:42:44.486448 15120 layer_factory.hpp:77] Creating layer conv4
I0930 04:42:44.486448 15120 net.cpp:91] Creating Layer conv4
I0930 04:42:44.486448 15120 net.cpp:425] conv4 <- scale3
I0930 04:42:44.486448 15120 net.cpp:399] conv4 -> conv4
I0930 04:42:44.458372 12176 blocking_queue.cpp:50] Waiting for data
I0930 04:42:44.494454 15120 net.cpp:141] Setting up conv4
I0930 04:42:44.494454 15120 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0930 04:42:44.494454 15120 net.cpp:156] Memory required for data: 492135000
I0930 04:42:44.494454 15120 layer_factory.hpp:77] Creating layer pool4
I0930 04:42:44.494454 15120 net.cpp:91] Creating Layer pool4
I0930 04:42:44.494454 15120 net.cpp:425] pool4 <- conv4
I0930 04:42:44.494454 15120 net.cpp:399] pool4 -> pool4
I0930 04:42:44.494454 15120 net.cpp:141] Setting up pool4
I0930 04:42:44.494454 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.494454 15120 net.cpp:156] Memory required for data: 495411800
I0930 04:42:44.494454 15120 layer_factory.hpp:77] Creating layer bn4
I0930 04:42:44.494454 15120 net.cpp:91] Creating Layer bn4
I0930 04:42:44.494454 15120 net.cpp:425] bn4 <- pool4
I0930 04:42:44.494454 15120 net.cpp:399] bn4 -> bn4
I0930 04:42:44.494454 15120 net.cpp:141] Setting up bn4
I0930 04:42:44.494454 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.494454 15120 net.cpp:156] Memory required for data: 498688600
I0930 04:42:44.494454 15120 layer_factory.hpp:77] Creating layer scale4
I0930 04:42:44.495455 15120 net.cpp:91] Creating Layer scale4
I0930 04:42:44.495455 15120 net.cpp:425] scale4 <- bn4
I0930 04:42:44.495455 15120 net.cpp:399] scale4 -> scale4
I0930 04:42:44.495455 15120 layer_factory.hpp:77] Creating layer scale4
I0930 04:42:44.495455 15120 net.cpp:141] Setting up scale4
I0930 04:42:44.495455 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.495455 15120 net.cpp:156] Memory required for data: 501965400
I0930 04:42:44.495455 15120 layer_factory.hpp:77] Creating layer relu4
I0930 04:42:44.495455 15120 net.cpp:91] Creating Layer relu4
I0930 04:42:44.495455 15120 net.cpp:425] relu4 <- scale4
I0930 04:42:44.495455 15120 net.cpp:386] relu4 -> scale4 (in-place)
I0930 04:42:44.495455 15120 net.cpp:141] Setting up relu4
I0930 04:42:44.495455 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.495455 15120 net.cpp:156] Memory required for data: 505242200
I0930 04:42:44.495455 15120 layer_factory.hpp:77] Creating layer conv4_1
I0930 04:42:44.495455 15120 net.cpp:91] Creating Layer conv4_1
I0930 04:42:44.495455 15120 net.cpp:425] conv4_1 <- scale4
I0930 04:42:44.495455 15120 net.cpp:399] conv4_1 -> conv4_1
I0930 04:42:44.503031 15120 net.cpp:141] Setting up conv4_1
I0930 04:42:44.503031 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.503031 15120 net.cpp:156] Memory required for data: 508519000
I0930 04:42:44.503031 15120 layer_factory.hpp:77] Creating layer bn4_1
I0930 04:42:44.503031 15120 net.cpp:91] Creating Layer bn4_1
I0930 04:42:44.503031 15120 net.cpp:425] bn4_1 <- conv4_1
I0930 04:42:44.503031 15120 net.cpp:399] bn4_1 -> bn4_1
I0930 04:42:44.503031 15120 net.cpp:141] Setting up bn4_1
I0930 04:42:44.503031 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.503031 15120 net.cpp:156] Memory required for data: 511795800
I0930 04:42:44.503031 15120 layer_factory.hpp:77] Creating layer scale4_1
I0930 04:42:44.503031 15120 net.cpp:91] Creating Layer scale4_1
I0930 04:42:44.503031 15120 net.cpp:425] scale4_1 <- bn4_1
I0930 04:42:44.503031 15120 net.cpp:399] scale4_1 -> scale4_1
I0930 04:42:44.503031 15120 layer_factory.hpp:77] Creating layer scale4_1
I0930 04:42:44.503031 15120 net.cpp:141] Setting up scale4_1
I0930 04:42:44.504032 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.504032 15120 net.cpp:156] Memory required for data: 515072600
I0930 04:42:44.504032 15120 layer_factory.hpp:77] Creating layer relu4_1
I0930 04:42:44.504032 15120 net.cpp:91] Creating Layer relu4_1
I0930 04:42:44.504032 15120 net.cpp:425] relu4_1 <- scale4_1
I0930 04:42:44.504032 15120 net.cpp:386] relu4_1 -> scale4_1 (in-place)
I0930 04:42:44.504032 15120 net.cpp:141] Setting up relu4_1
I0930 04:42:44.504032 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.504032 15120 net.cpp:156] Memory required for data: 518349400
I0930 04:42:44.504032 15120 layer_factory.hpp:77] Creating layer conv4_2
I0930 04:42:44.504032 15120 net.cpp:91] Creating Layer conv4_2
I0930 04:42:44.504032 15120 net.cpp:425] conv4_2 <- scale4_1
I0930 04:42:44.504032 15120 net.cpp:399] conv4_2 -> conv4_2
I0930 04:42:44.511296 15120 net.cpp:141] Setting up conv4_2
I0930 04:42:44.511296 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.511296 15120 net.cpp:156] Memory required for data: 521626200
I0930 04:42:44.511296 15120 layer_factory.hpp:77] Creating layer bn4_2
I0930 04:42:44.511296 15120 net.cpp:91] Creating Layer bn4_2
I0930 04:42:44.511296 15120 net.cpp:425] bn4_2 <- conv4_2
I0930 04:42:44.511296 15120 net.cpp:399] bn4_2 -> bn4_2
I0930 04:42:44.511296 15120 net.cpp:141] Setting up bn4_2
I0930 04:42:44.512297 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.512297 15120 net.cpp:156] Memory required for data: 524903000
I0930 04:42:44.512297 15120 layer_factory.hpp:77] Creating layer scale4_2
I0930 04:42:44.512297 15120 net.cpp:91] Creating Layer scale4_2
I0930 04:42:44.512297 15120 net.cpp:425] scale4_2 <- bn4_2
I0930 04:42:44.512297 15120 net.cpp:399] scale4_2 -> scale4_2
I0930 04:42:44.512297 15120 layer_factory.hpp:77] Creating layer scale4_2
I0930 04:42:44.512297 15120 net.cpp:141] Setting up scale4_2
I0930 04:42:44.512297 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.512297 15120 net.cpp:156] Memory required for data: 528179800
I0930 04:42:44.512297 15120 layer_factory.hpp:77] Creating layer relu4_2
I0930 04:42:44.512297 15120 net.cpp:91] Creating Layer relu4_2
I0930 04:42:44.512297 15120 net.cpp:425] relu4_2 <- scale4_2
I0930 04:42:44.512297 15120 net.cpp:386] relu4_2 -> scale4_2 (in-place)
I0930 04:42:44.512297 15120 net.cpp:141] Setting up relu4_2
I0930 04:42:44.512297 15120 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0930 04:42:44.512297 15120 net.cpp:156] Memory required for data: 531456600
I0930 04:42:44.512297 15120 layer_factory.hpp:77] Creating layer pool4_2
I0930 04:42:44.512297 15120 net.cpp:91] Creating Layer pool4_2
I0930 04:42:44.512297 15120 net.cpp:425] pool4_2 <- scale4_2
I0930 04:42:44.512297 15120 net.cpp:399] pool4_2 -> pool4_2
I0930 04:42:44.512297 15120 net.cpp:141] Setting up pool4_2
I0930 04:42:44.512297 15120 net.cpp:148] Top shape: 50 256 4 4 (204800)
I0930 04:42:44.512297 15120 net.cpp:156] Memory required for data: 532275800
I0930 04:42:44.512297 15120 layer_factory.hpp:77] Creating layer conv4_0
I0930 04:42:44.512297 15120 net.cpp:91] Creating Layer conv4_0
I0930 04:42:44.513298 15120 net.cpp:425] conv4_0 <- pool4_2
I0930 04:42:44.513298 15120 net.cpp:399] conv4_0 -> conv4_0
I0930 04:42:44.524951 15120 net.cpp:141] Setting up conv4_0
I0930 04:42:44.524951 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.524951 15120 net.cpp:156] Memory required for data: 533914200
I0930 04:42:44.524951 15120 layer_factory.hpp:77] Creating layer bn4_0
I0930 04:42:44.524951 15120 net.cpp:91] Creating Layer bn4_0
I0930 04:42:44.524951 15120 net.cpp:425] bn4_0 <- conv4_0
I0930 04:42:44.524951 15120 net.cpp:399] bn4_0 -> bn4_0
I0930 04:42:44.524951 15120 net.cpp:141] Setting up bn4_0
I0930 04:42:44.524951 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.524951 15120 net.cpp:156] Memory required for data: 535552600
I0930 04:42:44.524951 15120 layer_factory.hpp:77] Creating layer scale4_0
I0930 04:42:44.524951 15120 net.cpp:91] Creating Layer scale4_0
I0930 04:42:44.524951 15120 net.cpp:425] scale4_0 <- bn4_0
I0930 04:42:44.524951 15120 net.cpp:399] scale4_0 -> scale4_0
I0930 04:42:44.524951 15120 layer_factory.hpp:77] Creating layer scale4_0
I0930 04:42:44.524951 15120 net.cpp:141] Setting up scale4_0
I0930 04:42:44.524951 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.524951 15120 net.cpp:156] Memory required for data: 537191000
I0930 04:42:44.524951 15120 layer_factory.hpp:77] Creating layer relu4_0
I0930 04:42:44.524951 15120 net.cpp:91] Creating Layer relu4_0
I0930 04:42:44.524951 15120 net.cpp:425] relu4_0 <- scale4_0
I0930 04:42:44.524951 15120 net.cpp:386] relu4_0 -> scale4_0 (in-place)
I0930 04:42:44.525954 15120 net.cpp:141] Setting up relu4_0
I0930 04:42:44.525954 15120 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0930 04:42:44.525954 15120 net.cpp:156] Memory required for data: 538829400
I0930 04:42:44.525954 15120 layer_factory.hpp:77] Creating layer cccp4
I0930 04:42:44.525954 15120 net.cpp:91] Creating Layer cccp4
I0930 04:42:44.525954 15120 net.cpp:425] cccp4 <- scale4_0
I0930 04:42:44.525954 15120 net.cpp:399] cccp4 -> cccp4
I0930 04:42:44.536469 15120 net.cpp:141] Setting up cccp4
I0930 04:42:44.536469 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.536469 15120 net.cpp:156] Memory required for data: 545383000
I0930 04:42:44.536469 15120 layer_factory.hpp:77] Creating layer bn_cccp4
I0930 04:42:44.536469 15120 net.cpp:91] Creating Layer bn_cccp4
I0930 04:42:44.536469 15120 net.cpp:425] bn_cccp4 <- cccp4
I0930 04:42:44.536469 15120 net.cpp:399] bn_cccp4 -> bn_cccp4
I0930 04:42:44.536469 15120 net.cpp:141] Setting up bn_cccp4
I0930 04:42:44.536469 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.536469 15120 net.cpp:156] Memory required for data: 551936600
I0930 04:42:44.536469 15120 layer_factory.hpp:77] Creating layer scale_ccp4
I0930 04:42:44.536469 15120 net.cpp:91] Creating Layer scale_ccp4
I0930 04:42:44.536469 15120 net.cpp:425] scale_ccp4 <- bn_cccp4
I0930 04:42:44.536469 15120 net.cpp:399] scale_ccp4 -> scale_ccp4
I0930 04:42:44.536469 15120 layer_factory.hpp:77] Creating layer scale_ccp4
I0930 04:42:44.536469 15120 net.cpp:141] Setting up scale_ccp4
I0930 04:42:44.536469 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.536469 15120 net.cpp:156] Memory required for data: 558490200
I0930 04:42:44.536469 15120 layer_factory.hpp:77] Creating layer relu_cccp4
I0930 04:42:44.536469 15120 net.cpp:91] Creating Layer relu_cccp4
I0930 04:42:44.536469 15120 net.cpp:425] relu_cccp4 <- scale_ccp4
I0930 04:42:44.536469 15120 net.cpp:386] relu_cccp4 -> scale_ccp4 (in-place)
I0930 04:42:44.537469 15120 net.cpp:141] Setting up relu_cccp4
I0930 04:42:44.537469 15120 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0930 04:42:44.537469 15120 net.cpp:156] Memory required for data: 565043800
I0930 04:42:44.537469 15120 layer_factory.hpp:77] Creating layer cccp5
I0930 04:42:44.537469 15120 net.cpp:91] Creating Layer cccp5
I0930 04:42:44.537469 15120 net.cpp:425] cccp5 <- scale_ccp4
I0930 04:42:44.537469 15120 net.cpp:399] cccp5 -> cccp5
I0930 04:42:44.617971 15120 net.cpp:141] Setting up cccp5
I0930 04:42:44.617971 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.617971 15120 net.cpp:156] Memory required for data: 565453400
I0930 04:42:44.617971 15120 layer_factory.hpp:77] Creating layer bn_cccp5
I0930 04:42:44.617971 15120 net.cpp:91] Creating Layer bn_cccp5
I0930 04:42:44.617971 15120 net.cpp:425] bn_cccp5 <- cccp5
I0930 04:42:44.617971 15120 net.cpp:399] bn_cccp5 -> bn_cccp5
I0930 04:42:44.618986 15120 net.cpp:141] Setting up bn_cccp5
I0930 04:42:44.618986 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.618986 15120 net.cpp:156] Memory required for data: 565863000
I0930 04:42:44.618986 15120 layer_factory.hpp:77] Creating layer scale_ccp5
I0930 04:42:44.618986 15120 net.cpp:91] Creating Layer scale_ccp5
I0930 04:42:44.618986 15120 net.cpp:425] scale_ccp5 <- bn_cccp5
I0930 04:42:44.618986 15120 net.cpp:399] scale_ccp5 -> scale_ccp5
I0930 04:42:44.618986 15120 layer_factory.hpp:77] Creating layer scale_ccp5
I0930 04:42:44.618986 15120 net.cpp:141] Setting up scale_ccp5
I0930 04:42:44.618986 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.618986 15120 net.cpp:156] Memory required for data: 566272600
I0930 04:42:44.618986 15120 layer_factory.hpp:77] Creating layer relu_cccp5
I0930 04:42:44.618986 15120 net.cpp:91] Creating Layer relu_cccp5
I0930 04:42:44.618986 15120 net.cpp:425] relu_cccp5 <- scale_ccp5
I0930 04:42:44.618986 15120 net.cpp:386] relu_cccp5 -> scale_ccp5 (in-place)
I0930 04:42:44.618986 15120 net.cpp:141] Setting up relu_cccp5
I0930 04:42:44.618986 15120 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0930 04:42:44.618986 15120 net.cpp:156] Memory required for data: 566682200
I0930 04:42:44.618986 15120 layer_factory.hpp:77] Creating layer poolcp5
I0930 04:42:44.619987 15120 net.cpp:91] Creating Layer poolcp5
I0930 04:42:44.619987 15120 net.cpp:425] poolcp5 <- scale_ccp5
I0930 04:42:44.619987 15120 net.cpp:399] poolcp5 -> poolcp5
I0930 04:42:44.619987 15120 net.cpp:141] Setting up poolcp5
I0930 04:42:44.619987 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.619987 15120 net.cpp:156] Memory required for data: 566784600
I0930 04:42:44.619987 15120 layer_factory.hpp:77] Creating layer cccp6
I0930 04:42:44.619987 15120 net.cpp:91] Creating Layer cccp6
I0930 04:42:44.619987 15120 net.cpp:425] cccp6 <- poolcp5
I0930 04:42:44.619987 15120 net.cpp:399] cccp6 -> cccp6
I0930 04:42:44.642653 15120 net.cpp:141] Setting up cccp6
I0930 04:42:44.642653 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.642653 15120 net.cpp:156] Memory required for data: 566887000
I0930 04:42:44.642653 15120 layer_factory.hpp:77] Creating layer bn_cccp6
I0930 04:42:44.642653 15120 net.cpp:91] Creating Layer bn_cccp6
I0930 04:42:44.642653 15120 net.cpp:425] bn_cccp6 <- cccp6
I0930 04:42:44.642653 15120 net.cpp:399] bn_cccp6 -> bn_cccp6
I0930 04:42:44.642653 15120 net.cpp:141] Setting up bn_cccp6
I0930 04:42:44.642653 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.642653 15120 net.cpp:156] Memory required for data: 566989400
I0930 04:42:44.642653 15120 layer_factory.hpp:77] Creating layer scale_ccp6
I0930 04:42:44.642653 15120 net.cpp:91] Creating Layer scale_ccp6
I0930 04:42:44.642653 15120 net.cpp:425] scale_ccp6 <- bn_cccp6
I0930 04:42:44.642653 15120 net.cpp:399] scale_ccp6 -> scale_ccp6
I0930 04:42:44.642653 15120 layer_factory.hpp:77] Creating layer scale_ccp6
I0930 04:42:44.642653 15120 net.cpp:141] Setting up scale_ccp6
I0930 04:42:44.642653 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.642653 15120 net.cpp:156] Memory required for data: 567091800
I0930 04:42:44.642653 15120 layer_factory.hpp:77] Creating layer relu_cccp6
I0930 04:42:44.642653 15120 net.cpp:91] Creating Layer relu_cccp6
I0930 04:42:44.642653 15120 net.cpp:425] relu_cccp6 <- scale_ccp6
I0930 04:42:44.642653 15120 net.cpp:386] relu_cccp6 -> scale_ccp6 (in-place)
I0930 04:42:44.643666 15120 net.cpp:141] Setting up relu_cccp6
I0930 04:42:44.643666 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.643666 15120 net.cpp:156] Memory required for data: 567194200
I0930 04:42:44.643666 15120 layer_factory.hpp:77] Creating layer poolcp6
I0930 04:42:44.643666 15120 net.cpp:91] Creating Layer poolcp6
I0930 04:42:44.643666 15120 net.cpp:425] poolcp6 <- scale_ccp6
I0930 04:42:44.643666 15120 net.cpp:399] poolcp6 -> poolcp6
I0930 04:42:44.643666 15120 net.cpp:141] Setting up poolcp6
I0930 04:42:44.643666 15120 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0930 04:42:44.643666 15120 net.cpp:156] Memory required for data: 567296600
I0930 04:42:44.643666 15120 layer_factory.hpp:77] Creating layer fc_conv
I0930 04:42:44.643666 15120 net.cpp:91] Creating Layer fc_conv
I0930 04:42:44.643666 15120 net.cpp:425] fc_conv <- poolcp6
I0930 04:42:44.643666 15120 net.cpp:399] fc_conv -> fc_conv
I0930 04:42:44.654495 15120 net.cpp:141] Setting up fc_conv
I0930 04:42:44.654495 15120 net.cpp:148] Top shape: 50 2048 3 3 (921600)
I0930 04:42:44.654495 15120 net.cpp:156] Memory required for data: 570983000
I0930 04:42:44.654495 15120 layer_factory.hpp:77] Creating layer ipf0
I0930 04:42:44.654495 15120 net.cpp:91] Creating Layer ipf0
I0930 04:42:44.654495 15120 net.cpp:425] ipf0 <- fc_conv
I0930 04:42:44.654495 15120 net.cpp:399] ipf0 -> ipf0
I0930 04:42:44.670433 15120 net.cpp:141] Setting up ipf0
I0930 04:42:44.670433 15120 net.cpp:148] Top shape: 50 100 (5000)
I0930 04:42:44.670433 15120 net.cpp:156] Memory required for data: 571003000
I0930 04:42:44.670433 15120 layer_factory.hpp:77] Creating layer ipf0_ipf0_0_split
I0930 04:42:44.670433 15120 net.cpp:91] Creating Layer ipf0_ipf0_0_split
I0930 04:42:44.670433 15120 net.cpp:425] ipf0_ipf0_0_split <- ipf0
I0930 04:42:44.670433 15120 net.cpp:399] ipf0_ipf0_0_split -> ipf0_ipf0_0_split_0
I0930 04:42:44.670433 15120 net.cpp:399] ipf0_ipf0_0_split -> ipf0_ipf0_0_split_1
I0930 04:42:44.670433 15120 net.cpp:141] Setting up ipf0_ipf0_0_split
I0930 04:42:44.670433 15120 net.cpp:148] Top shape: 50 100 (5000)
I0930 04:42:44.670433 15120 net.cpp:148] Top shape: 50 100 (5000)
I0930 04:42:44.670433 15120 net.cpp:156] Memory required for data: 571043000
I0930 04:42:44.670433 15120 layer_factory.hpp:77] Creating layer accuracy
I0930 04:42:44.670433 15120 net.cpp:91] Creating Layer accuracy
I0930 04:42:44.670433 15120 net.cpp:425] accuracy <- ipf0_ipf0_0_split_0
I0930 04:42:44.670433 15120 net.cpp:425] accuracy <- label_fine_cifar_1_split_0
I0930 04:42:44.670433 15120 net.cpp:399] accuracy -> accuracy
I0930 04:42:44.670433 15120 net.cpp:141] Setting up accuracy
I0930 04:42:44.670433 15120 net.cpp:148] Top shape: (1)
I0930 04:42:44.670433 15120 net.cpp:156] Memory required for data: 571043004
I0930 04:42:44.670433 15120 layer_factory.hpp:77] Creating layer loss
I0930 04:42:44.670433 15120 net.cpp:91] Creating Layer loss
I0930 04:42:44.670433 15120 net.cpp:425] loss <- ipf0_ipf0_0_split_1
I0930 04:42:44.670433 15120 net.cpp:425] loss <- label_fine_cifar_1_split_1
I0930 04:42:44.670433 15120 net.cpp:399] loss -> loss
I0930 04:42:44.670433 15120 layer_factory.hpp:77] Creating layer loss
I0930 04:42:44.671433 15120 net.cpp:141] Setting up loss
I0930 04:42:44.671433 15120 net.cpp:148] Top shape: (1)
I0930 04:42:44.671433 15120 net.cpp:151]     with loss weight 1
I0930 04:42:44.671433 15120 net.cpp:156] Memory required for data: 571043008
I0930 04:42:44.671433 15120 net.cpp:217] loss needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:219] accuracy does not need backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] ipf0_ipf0_0_split needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] ipf0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] fc_conv needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] poolcp6 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu_cccp6 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale_ccp6 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn_cccp6 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] cccp6 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] poolcp5 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu_cccp5 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale_ccp5 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn_cccp5 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] cccp5 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu_cccp4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale_ccp4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn_cccp4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] cccp4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu4_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale4_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn4_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv4_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] pool4_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu4_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale4_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn4_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv4_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu4_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale4_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn4_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv4_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] pool4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv4 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu3 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale3 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn3 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv3 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu2_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale2_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn2_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv2_2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] pool2_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu2_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale2_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn2_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv2_1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv2 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu1_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale1_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn1_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv1_0 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] relu1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] scale1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] bn1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:217] conv1 needs backward computation.
I0930 04:42:44.671433 15120 net.cpp:219] label_fine_cifar_1_split does not need backward computation.
I0930 04:42:44.672433 15120 net.cpp:219] cifar does not need backward computation.
I0930 04:42:44.672433 15120 net.cpp:261] This network produces output accuracy
I0930 04:42:44.672433 15120 net.cpp:261] This network produces output loss
I0930 04:42:44.672433 15120 net.cpp:274] Network initialization done.
I0930 04:42:44.672433 15120 solver.cpp:60] Solver scaffolding done.
I0930 04:42:44.678438 15120 caffe.cpp:210] Resuming from examples/cifar10_full_relu_bn_iter_126000.solverstate
I0930 04:42:45.129746 15120 sgd_solver.cpp:318] SGDSolver: restoring history
I0930 04:42:45.238248 15120 caffe.cpp:220] Starting Optimization
I0930 04:42:45.238248 15120 solver.cpp:279] Solving CIFAR100_full
I0930 04:42:45.238248 15120 solver.cpp:280] Learning Rate Policy: multistep
I0930 04:42:45.249256 15120 solver.cpp:337] Iteration 126000, Testing net (#0)
I0930 04:42:53.583494 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0930 04:42:53.583494 15120 solver.cpp:404]     Test net output #1: loss = 1.06011 (* 1 = 1.06011 loss)
I0930 04:42:53.876780 15120 solver.cpp:228] Iteration 126000, loss = 0.01179
I0930 04:42:53.876780 15120 solver.cpp:244]     Train net output #0: loss = 0.01179 (* 1 = 0.01179 loss)
I0930 04:42:53.876780 15120 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I0930 04:43:13.219148 15120 solver.cpp:228] Iteration 126100, loss = 0.0122823
I0930 04:43:13.219650 15120 solver.cpp:244]     Train net output #0: loss = 0.0122823 (* 1 = 0.0122823 loss)
I0930 04:43:13.219650 15120 sgd_solver.cpp:106] Iteration 126100, lr = 0.001
I0930 04:43:32.696962 15120 solver.cpp:228] Iteration 126200, loss = 0.00872615
I0930 04:43:32.696962 15120 solver.cpp:244]     Train net output #0: loss = 0.00872615 (* 1 = 0.00872615 loss)
I0930 04:43:32.696962 15120 sgd_solver.cpp:106] Iteration 126200, lr = 0.001
I0930 04:43:51.962761 15120 solver.cpp:228] Iteration 126300, loss = 0.0107566
I0930 04:43:51.962761 15120 solver.cpp:244]     Train net output #0: loss = 0.0107566 (* 1 = 0.0107566 loss)
I0930 04:43:51.962761 15120 sgd_solver.cpp:106] Iteration 126300, lr = 0.001
I0930 04:44:11.218428 15120 solver.cpp:228] Iteration 126400, loss = 0.0108183
I0930 04:44:11.218428 15120 solver.cpp:244]     Train net output #0: loss = 0.0108183 (* 1 = 0.0108183 loss)
I0930 04:44:11.218428 15120 sgd_solver.cpp:106] Iteration 126400, lr = 0.001
I0930 04:44:30.473628 15120 solver.cpp:228] Iteration 126500, loss = 0.0107209
I0930 04:44:30.473628 15120 solver.cpp:244]     Train net output #0: loss = 0.0107209 (* 1 = 0.0107209 loss)
I0930 04:44:30.473628 15120 sgd_solver.cpp:106] Iteration 126500, lr = 0.001
I0930 04:44:49.741303 15120 solver.cpp:228] Iteration 126600, loss = 0.0129276
I0930 04:44:49.741303 15120 solver.cpp:244]     Train net output #0: loss = 0.0129276 (* 1 = 0.0129276 loss)
I0930 04:44:49.741303 15120 sgd_solver.cpp:106] Iteration 126600, lr = 0.001
I0930 04:45:09.004007 15120 solver.cpp:228] Iteration 126700, loss = 0.0116042
I0930 04:45:09.004007 15120 solver.cpp:244]     Train net output #0: loss = 0.0116042 (* 1 = 0.0116042 loss)
I0930 04:45:09.004007 15120 sgd_solver.cpp:106] Iteration 126700, lr = 0.001
I0930 04:45:28.288408 15120 solver.cpp:228] Iteration 126800, loss = 0.00787662
I0930 04:45:28.288408 15120 solver.cpp:244]     Train net output #0: loss = 0.00787662 (* 1 = 0.00787662 loss)
I0930 04:45:28.288408 15120 sgd_solver.cpp:106] Iteration 126800, lr = 0.001
I0930 04:45:47.595201 15120 solver.cpp:228] Iteration 126900, loss = 0.0083904
I0930 04:45:47.595201 15120 solver.cpp:244]     Train net output #0: loss = 0.0083904 (* 1 = 0.0083904 loss)
I0930 04:45:47.595201 15120 sgd_solver.cpp:106] Iteration 126900, lr = 0.001
I0930 04:46:06.860613 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_127000.caffemodel
I0930 04:46:07.469046 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_127000.solverstate
I0930 04:46:07.823284 15120 solver.cpp:337] Iteration 127000, Testing net (#0)
I0930 04:46:16.013821 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7401
I0930 04:46:16.013821 15120 solver.cpp:404]     Test net output #1: loss = 1.06189 (* 1 = 1.06189 loss)
I0930 04:46:16.065858 15120 solver.cpp:228] Iteration 127000, loss = 0.0084756
I0930 04:46:16.065858 15120 solver.cpp:244]     Train net output #0: loss = 0.0084756 (* 1 = 0.0084756 loss)
I0930 04:46:16.065858 15120 sgd_solver.cpp:106] Iteration 127000, lr = 0.001
I0930 04:46:35.446804 15120 solver.cpp:228] Iteration 127100, loss = 0.0114676
I0930 04:46:35.446804 15120 solver.cpp:244]     Train net output #0: loss = 0.0114676 (* 1 = 0.0114676 loss)
I0930 04:46:35.446804 15120 sgd_solver.cpp:106] Iteration 127100, lr = 0.001
I0930 04:46:54.824223 15120 solver.cpp:228] Iteration 127200, loss = 0.00789474
I0930 04:46:54.825222 15120 solver.cpp:244]     Train net output #0: loss = 0.00789473 (* 1 = 0.00789473 loss)
I0930 04:46:54.825222 15120 sgd_solver.cpp:106] Iteration 127200, lr = 0.001
I0930 04:47:14.182972 15120 solver.cpp:228] Iteration 127300, loss = 0.009382
I0930 04:47:14.182972 15120 solver.cpp:244]     Train net output #0: loss = 0.009382 (* 1 = 0.009382 loss)
I0930 04:47:14.182972 15120 sgd_solver.cpp:106] Iteration 127300, lr = 0.001
I0930 04:47:33.545714 15120 solver.cpp:228] Iteration 127400, loss = 0.0122916
I0930 04:47:33.545714 15120 solver.cpp:244]     Train net output #0: loss = 0.0122916 (* 1 = 0.0122916 loss)
I0930 04:47:33.545714 15120 sgd_solver.cpp:106] Iteration 127400, lr = 0.001
I0930 04:47:52.929291 15120 solver.cpp:228] Iteration 127500, loss = 0.00895806
I0930 04:47:52.929291 15120 solver.cpp:244]     Train net output #0: loss = 0.00895805 (* 1 = 0.00895805 loss)
I0930 04:47:52.929291 15120 sgd_solver.cpp:106] Iteration 127500, lr = 0.001
I0930 04:48:12.304563 15120 solver.cpp:228] Iteration 127600, loss = 0.0104911
I0930 04:48:12.304563 15120 solver.cpp:244]     Train net output #0: loss = 0.0104911 (* 1 = 0.0104911 loss)
I0930 04:48:12.305564 15120 sgd_solver.cpp:106] Iteration 127600, lr = 0.001
I0930 04:48:31.728507 15120 solver.cpp:228] Iteration 127700, loss = 0.00955075
I0930 04:48:31.728507 15120 solver.cpp:244]     Train net output #0: loss = 0.00955075 (* 1 = 0.00955075 loss)
I0930 04:48:31.728507 15120 sgd_solver.cpp:106] Iteration 127700, lr = 0.001
I0930 04:48:51.125170 15120 solver.cpp:228] Iteration 127800, loss = 0.0099626
I0930 04:48:51.125170 15120 solver.cpp:244]     Train net output #0: loss = 0.0099626 (* 1 = 0.0099626 loss)
I0930 04:48:51.125170 15120 sgd_solver.cpp:106] Iteration 127800, lr = 0.001
I0930 04:49:10.518646 15120 solver.cpp:228] Iteration 127900, loss = 0.00840331
I0930 04:49:10.518646 15120 solver.cpp:244]     Train net output #0: loss = 0.00840331 (* 1 = 0.00840331 loss)
I0930 04:49:10.518646 15120 sgd_solver.cpp:106] Iteration 127900, lr = 0.001
I0930 04:49:29.842754 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_128000.caffemodel
I0930 04:49:30.435163 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_128000.solverstate
I0930 04:49:30.797420 15120 solver.cpp:337] Iteration 128000, Testing net (#0)
I0930 04:49:38.996651 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0930 04:49:38.997653 15120 solver.cpp:404]     Test net output #1: loss = 1.06091 (* 1 = 1.06091 loss)
I0930 04:49:39.050690 15120 solver.cpp:228] Iteration 128000, loss = 0.0132874
I0930 04:49:39.050690 15120 solver.cpp:244]     Train net output #0: loss = 0.0132874 (* 1 = 0.0132874 loss)
I0930 04:49:39.050690 15120 sgd_solver.cpp:106] Iteration 128000, lr = 0.001
I0930 04:49:58.418450 15120 solver.cpp:228] Iteration 128100, loss = 0.0130885
I0930 04:49:58.418450 15120 solver.cpp:244]     Train net output #0: loss = 0.0130885 (* 1 = 0.0130885 loss)
I0930 04:49:58.418450 15120 sgd_solver.cpp:106] Iteration 128100, lr = 0.001
I0930 04:50:17.828238 15120 solver.cpp:228] Iteration 128200, loss = 0.0101037
I0930 04:50:17.828238 15120 solver.cpp:244]     Train net output #0: loss = 0.0101037 (* 1 = 0.0101037 loss)
I0930 04:50:17.828238 15120 sgd_solver.cpp:106] Iteration 128200, lr = 0.001
I0930 04:50:37.196971 15120 solver.cpp:228] Iteration 128300, loss = 0.00934061
I0930 04:50:37.196971 15120 solver.cpp:244]     Train net output #0: loss = 0.00934061 (* 1 = 0.00934061 loss)
I0930 04:50:37.196971 15120 sgd_solver.cpp:106] Iteration 128300, lr = 0.001
I0930 04:50:56.584731 15120 solver.cpp:228] Iteration 128400, loss = 0.00825042
I0930 04:50:56.584731 15120 solver.cpp:244]     Train net output #0: loss = 0.00825042 (* 1 = 0.00825042 loss)
I0930 04:50:56.584731 15120 sgd_solver.cpp:106] Iteration 128400, lr = 0.001
I0930 04:51:15.957481 15120 solver.cpp:228] Iteration 128500, loss = 0.00841518
I0930 04:51:15.957481 15120 solver.cpp:244]     Train net output #0: loss = 0.00841518 (* 1 = 0.00841518 loss)
I0930 04:51:15.957481 15120 sgd_solver.cpp:106] Iteration 128500, lr = 0.001
I0930 04:51:35.341266 15120 solver.cpp:228] Iteration 128600, loss = 0.0114175
I0930 04:51:35.341266 15120 solver.cpp:244]     Train net output #0: loss = 0.0114175 (* 1 = 0.0114175 loss)
I0930 04:51:35.341266 15120 sgd_solver.cpp:106] Iteration 128600, lr = 0.001
I0930 04:51:54.731041 15120 solver.cpp:228] Iteration 128700, loss = 0.0151729
I0930 04:51:54.731041 15120 solver.cpp:244]     Train net output #0: loss = 0.0151729 (* 1 = 0.0151729 loss)
I0930 04:51:54.731041 15120 sgd_solver.cpp:106] Iteration 128700, lr = 0.001
I0930 04:52:14.116699 15120 solver.cpp:228] Iteration 128800, loss = 0.012958
I0930 04:52:14.116699 15120 solver.cpp:244]     Train net output #0: loss = 0.012958 (* 1 = 0.012958 loss)
I0930 04:52:14.116699 15120 sgd_solver.cpp:106] Iteration 128800, lr = 0.001
I0930 04:52:33.505069 15120 solver.cpp:228] Iteration 128900, loss = 0.00846917
I0930 04:52:33.505069 15120 solver.cpp:244]     Train net output #0: loss = 0.00846917 (* 1 = 0.00846917 loss)
I0930 04:52:33.505069 15120 sgd_solver.cpp:106] Iteration 128900, lr = 0.001
I0930 04:52:52.844808 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_129000.caffemodel
I0930 04:52:53.448223 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_129000.solverstate
I0930 04:52:53.804476 15120 solver.cpp:337] Iteration 129000, Testing net (#0)
I0930 04:53:01.998291 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7388
I0930 04:53:01.998291 15120 solver.cpp:404]     Test net output #1: loss = 1.06247 (* 1 = 1.06247 loss)
I0930 04:53:02.049327 15120 solver.cpp:228] Iteration 129000, loss = 0.0122425
I0930 04:53:02.049327 15120 solver.cpp:244]     Train net output #0: loss = 0.0122425 (* 1 = 0.0122425 loss)
I0930 04:53:02.049327 15120 sgd_solver.cpp:106] Iteration 129000, lr = 0.001
I0930 04:53:21.441889 15120 solver.cpp:228] Iteration 129100, loss = 0.0152291
I0930 04:53:21.441889 15120 solver.cpp:244]     Train net output #0: loss = 0.0152291 (* 1 = 0.0152291 loss)
I0930 04:53:21.441889 15120 sgd_solver.cpp:106] Iteration 129100, lr = 0.001
I0930 04:53:40.903702 15120 solver.cpp:228] Iteration 129200, loss = 0.0100612
I0930 04:53:40.903702 15120 solver.cpp:244]     Train net output #0: loss = 0.0100612 (* 1 = 0.0100612 loss)
I0930 04:53:40.903702 15120 sgd_solver.cpp:106] Iteration 129200, lr = 0.001
I0930 04:54:00.258105 15120 solver.cpp:228] Iteration 129300, loss = 0.0111067
I0930 04:54:00.258105 15120 solver.cpp:244]     Train net output #0: loss = 0.0111067 (* 1 = 0.0111067 loss)
I0930 04:54:00.258105 15120 sgd_solver.cpp:106] Iteration 129300, lr = 0.001
I0930 04:54:19.595456 15120 solver.cpp:228] Iteration 129400, loss = 0.0123981
I0930 04:54:19.596457 15120 solver.cpp:244]     Train net output #0: loss = 0.0123981 (* 1 = 0.0123981 loss)
I0930 04:54:19.596457 15120 sgd_solver.cpp:106] Iteration 129400, lr = 0.001
I0930 04:54:38.914168 15120 solver.cpp:228] Iteration 129500, loss = 0.00989724
I0930 04:54:38.914168 15120 solver.cpp:244]     Train net output #0: loss = 0.00989725 (* 1 = 0.00989725 loss)
I0930 04:54:38.914168 15120 sgd_solver.cpp:106] Iteration 129500, lr = 0.001
I0930 04:54:58.279561 15120 solver.cpp:228] Iteration 129600, loss = 0.00781838
I0930 04:54:58.279561 15120 solver.cpp:244]     Train net output #0: loss = 0.00781838 (* 1 = 0.00781838 loss)
I0930 04:54:58.279561 15120 sgd_solver.cpp:106] Iteration 129600, lr = 0.001
I0930 04:55:17.599731 15120 solver.cpp:228] Iteration 129700, loss = 0.00859137
I0930 04:55:17.599731 15120 solver.cpp:244]     Train net output #0: loss = 0.00859137 (* 1 = 0.00859137 loss)
I0930 04:55:17.599731 15120 sgd_solver.cpp:106] Iteration 129700, lr = 0.001
I0930 04:55:36.932479 15120 solver.cpp:228] Iteration 129800, loss = 0.00908879
I0930 04:55:36.932479 15120 solver.cpp:244]     Train net output #0: loss = 0.00908879 (* 1 = 0.00908879 loss)
I0930 04:55:36.932479 15120 sgd_solver.cpp:106] Iteration 129800, lr = 0.001
I0930 04:55:56.267202 15120 solver.cpp:228] Iteration 129900, loss = 0.00954911
I0930 04:55:56.267202 15120 solver.cpp:244]     Train net output #0: loss = 0.00954911 (* 1 = 0.00954911 loss)
I0930 04:55:56.267202 15120 sgd_solver.cpp:106] Iteration 129900, lr = 0.001
I0930 04:56:15.544806 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_130000.caffemodel
I0930 04:56:16.141228 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_130000.solverstate
I0930 04:56:16.498481 15120 solver.cpp:337] Iteration 130000, Testing net (#0)
I0930 04:56:24.651417 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0930 04:56:24.652417 15120 solver.cpp:404]     Test net output #1: loss = 1.0579 (* 1 = 1.0579 loss)
I0930 04:56:24.702453 15120 solver.cpp:228] Iteration 130000, loss = 0.0154295
I0930 04:56:24.702453 15120 solver.cpp:244]     Train net output #0: loss = 0.0154295 (* 1 = 0.0154295 loss)
I0930 04:56:24.702453 15120 sgd_solver.cpp:106] Iteration 130000, lr = 0.001
I0930 04:56:44.030680 15120 solver.cpp:228] Iteration 130100, loss = 0.00759502
I0930 04:56:44.030680 15120 solver.cpp:244]     Train net output #0: loss = 0.00759501 (* 1 = 0.00759501 loss)
I0930 04:56:44.030680 15120 sgd_solver.cpp:106] Iteration 130100, lr = 0.001
I0930 04:57:03.344499 15120 solver.cpp:228] Iteration 130200, loss = 0.00634461
I0930 04:57:03.344499 15120 solver.cpp:244]     Train net output #0: loss = 0.0063446 (* 1 = 0.0063446 loss)
I0930 04:57:03.344499 15120 sgd_solver.cpp:106] Iteration 130200, lr = 0.001
I0930 04:57:22.684995 15120 solver.cpp:228] Iteration 130300, loss = 0.0117209
I0930 04:57:22.684995 15120 solver.cpp:244]     Train net output #0: loss = 0.0117209 (* 1 = 0.0117209 loss)
I0930 04:57:22.684995 15120 sgd_solver.cpp:106] Iteration 130300, lr = 0.001
I0930 04:57:42.029726 15120 solver.cpp:228] Iteration 130400, loss = 0.0104968
I0930 04:57:42.029726 15120 solver.cpp:244]     Train net output #0: loss = 0.0104968 (* 1 = 0.0104968 loss)
I0930 04:57:42.029726 15120 sgd_solver.cpp:106] Iteration 130400, lr = 0.001
I0930 04:58:01.365448 15120 solver.cpp:228] Iteration 130500, loss = 0.00779369
I0930 04:58:01.365448 15120 solver.cpp:244]     Train net output #0: loss = 0.00779368 (* 1 = 0.00779368 loss)
I0930 04:58:01.365448 15120 sgd_solver.cpp:106] Iteration 130500, lr = 0.001
I0930 04:58:20.696593 15120 solver.cpp:228] Iteration 130600, loss = 0.015468
I0930 04:58:20.696593 15120 solver.cpp:244]     Train net output #0: loss = 0.015468 (* 1 = 0.015468 loss)
I0930 04:58:20.696593 15120 sgd_solver.cpp:106] Iteration 130600, lr = 0.001
I0930 04:58:40.036064 15120 solver.cpp:228] Iteration 130700, loss = 0.0101023
I0930 04:58:40.036064 15120 solver.cpp:244]     Train net output #0: loss = 0.0101023 (* 1 = 0.0101023 loss)
I0930 04:58:40.036064 15120 sgd_solver.cpp:106] Iteration 130700, lr = 0.001
I0930 04:58:59.368384 15120 solver.cpp:228] Iteration 130800, loss = 0.0088538
I0930 04:58:59.368384 15120 solver.cpp:244]     Train net output #0: loss = 0.00885379 (* 1 = 0.00885379 loss)
I0930 04:58:59.368384 15120 sgd_solver.cpp:106] Iteration 130800, lr = 0.001
I0930 04:59:18.695101 15120 solver.cpp:228] Iteration 130900, loss = 0.00705572
I0930 04:59:18.695101 15120 solver.cpp:244]     Train net output #0: loss = 0.00705571 (* 1 = 0.00705571 loss)
I0930 04:59:18.695101 15120 sgd_solver.cpp:106] Iteration 130900, lr = 0.001
I0930 04:59:37.967779 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_131000.caffemodel
I0930 04:59:38.562202 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_131000.solverstate
I0930 04:59:38.923458 15120 solver.cpp:337] Iteration 131000, Testing net (#0)
I0930 04:59:47.089254 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7393
I0930 04:59:47.089254 15120 solver.cpp:404]     Test net output #1: loss = 1.05463 (* 1 = 1.05463 loss)
I0930 04:59:47.139289 15120 solver.cpp:228] Iteration 131000, loss = 0.0107989
I0930 04:59:47.139289 15120 solver.cpp:244]     Train net output #0: loss = 0.0107989 (* 1 = 0.0107989 loss)
I0930 04:59:47.139289 15120 sgd_solver.cpp:106] Iteration 131000, lr = 0.001
I0930 05:00:06.466006 15120 solver.cpp:228] Iteration 131100, loss = 0.0100996
I0930 05:00:06.466006 15120 solver.cpp:244]     Train net output #0: loss = 0.0100996 (* 1 = 0.0100996 loss)
I0930 05:00:06.466006 15120 sgd_solver.cpp:106] Iteration 131100, lr = 0.001
I0930 05:00:25.796838 15120 solver.cpp:228] Iteration 131200, loss = 0.01096
I0930 05:00:25.796838 15120 solver.cpp:244]     Train net output #0: loss = 0.01096 (* 1 = 0.01096 loss)
I0930 05:00:25.796838 15120 sgd_solver.cpp:106] Iteration 131200, lr = 0.001
I0930 05:00:45.127710 15120 solver.cpp:228] Iteration 131300, loss = 0.00978574
I0930 05:00:45.127710 15120 solver.cpp:244]     Train net output #0: loss = 0.00978574 (* 1 = 0.00978574 loss)
I0930 05:00:45.127710 15120 sgd_solver.cpp:106] Iteration 131300, lr = 0.001
I0930 05:01:04.464426 15120 solver.cpp:228] Iteration 131400, loss = 0.0119481
I0930 05:01:04.464426 15120 solver.cpp:244]     Train net output #0: loss = 0.0119481 (* 1 = 0.0119481 loss)
I0930 05:01:04.465426 15120 sgd_solver.cpp:106] Iteration 131400, lr = 0.001
I0930 05:01:23.789567 15120 solver.cpp:228] Iteration 131500, loss = 0.0139098
I0930 05:01:23.789567 15120 solver.cpp:244]     Train net output #0: loss = 0.0139098 (* 1 = 0.0139098 loss)
I0930 05:01:23.789567 15120 sgd_solver.cpp:106] Iteration 131500, lr = 0.001
I0930 05:01:43.110306 15120 solver.cpp:228] Iteration 131600, loss = 0.00858923
I0930 05:01:43.110306 15120 solver.cpp:244]     Train net output #0: loss = 0.00858923 (* 1 = 0.00858923 loss)
I0930 05:01:43.110306 15120 sgd_solver.cpp:106] Iteration 131600, lr = 0.001
I0930 05:02:02.457931 15120 solver.cpp:228] Iteration 131700, loss = 0.0130426
I0930 05:02:02.457931 15120 solver.cpp:244]     Train net output #0: loss = 0.0130426 (* 1 = 0.0130426 loss)
I0930 05:02:02.457931 15120 sgd_solver.cpp:106] Iteration 131700, lr = 0.001
I0930 05:02:21.784634 15120 solver.cpp:228] Iteration 131800, loss = 0.00752822
I0930 05:02:21.784634 15120 solver.cpp:244]     Train net output #0: loss = 0.00752822 (* 1 = 0.00752822 loss)
I0930 05:02:21.784634 15120 sgd_solver.cpp:106] Iteration 131800, lr = 0.001
I0930 05:02:41.111351 15120 solver.cpp:228] Iteration 131900, loss = 0.0142462
I0930 05:02:41.112352 15120 solver.cpp:244]     Train net output #0: loss = 0.0142462 (* 1 = 0.0142462 loss)
I0930 05:02:41.112352 15120 sgd_solver.cpp:106] Iteration 131900, lr = 0.001
I0930 05:03:00.386487 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_132000.caffemodel
I0930 05:03:00.969902 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_132000.solverstate
I0930 05:03:01.345167 15120 solver.cpp:337] Iteration 132000, Testing net (#0)
I0930 05:03:09.517616 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0930 05:03:09.517616 15120 solver.cpp:404]     Test net output #1: loss = 1.05167 (* 1 = 1.05167 loss)
I0930 05:03:09.568652 15120 solver.cpp:228] Iteration 132000, loss = 0.0109203
I0930 05:03:09.568652 15120 solver.cpp:244]     Train net output #0: loss = 0.0109203 (* 1 = 0.0109203 loss)
I0930 05:03:09.568652 15120 sgd_solver.cpp:106] Iteration 132000, lr = 0.001
I0930 05:03:28.897423 15120 solver.cpp:228] Iteration 132100, loss = 0.0195133
I0930 05:03:28.897423 15120 solver.cpp:244]     Train net output #0: loss = 0.0195133 (* 1 = 0.0195133 loss)
I0930 05:03:28.897423 15120 sgd_solver.cpp:106] Iteration 132100, lr = 0.001
I0930 05:03:48.248245 15120 solver.cpp:228] Iteration 132200, loss = 0.00694344
I0930 05:03:48.248245 15120 solver.cpp:244]     Train net output #0: loss = 0.00694344 (* 1 = 0.00694344 loss)
I0930 05:03:48.248245 15120 sgd_solver.cpp:106] Iteration 132200, lr = 0.001
I0930 05:04:07.571085 15120 solver.cpp:228] Iteration 132300, loss = 0.013345
I0930 05:04:07.571085 15120 solver.cpp:244]     Train net output #0: loss = 0.013345 (* 1 = 0.013345 loss)
I0930 05:04:07.571085 15120 sgd_solver.cpp:106] Iteration 132300, lr = 0.001
I0930 05:04:26.918803 15120 solver.cpp:228] Iteration 132400, loss = 0.00972004
I0930 05:04:26.918803 15120 solver.cpp:244]     Train net output #0: loss = 0.00972003 (* 1 = 0.00972003 loss)
I0930 05:04:26.918803 15120 sgd_solver.cpp:106] Iteration 132400, lr = 0.001
I0930 05:04:46.247766 15120 solver.cpp:228] Iteration 132500, loss = 0.00945496
I0930 05:04:46.247766 15120 solver.cpp:244]     Train net output #0: loss = 0.00945495 (* 1 = 0.00945495 loss)
I0930 05:04:46.247766 15120 sgd_solver.cpp:106] Iteration 132500, lr = 0.001
I0930 05:05:05.585577 15120 solver.cpp:228] Iteration 132600, loss = 0.00749152
I0930 05:05:05.585577 15120 solver.cpp:244]     Train net output #0: loss = 0.00749151 (* 1 = 0.00749151 loss)
I0930 05:05:05.585577 15120 sgd_solver.cpp:106] Iteration 132600, lr = 0.001
I0930 05:05:24.901285 15120 solver.cpp:228] Iteration 132700, loss = 0.0076369
I0930 05:05:24.901285 15120 solver.cpp:244]     Train net output #0: loss = 0.0076369 (* 1 = 0.0076369 loss)
I0930 05:05:24.901285 15120 sgd_solver.cpp:106] Iteration 132700, lr = 0.001
I0930 05:05:44.244014 15120 solver.cpp:228] Iteration 132800, loss = 0.01026
I0930 05:05:44.244014 15120 solver.cpp:244]     Train net output #0: loss = 0.01026 (* 1 = 0.01026 loss)
I0930 05:05:44.244014 15120 sgd_solver.cpp:106] Iteration 132800, lr = 0.001
I0930 05:06:03.587180 15120 solver.cpp:228] Iteration 132900, loss = 0.0117811
I0930 05:06:03.587180 15120 solver.cpp:244]     Train net output #0: loss = 0.0117811 (* 1 = 0.0117811 loss)
I0930 05:06:03.587180 15120 sgd_solver.cpp:106] Iteration 132900, lr = 0.001
I0930 05:06:22.857741 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_133000.caffemodel
I0930 05:06:23.452162 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_133000.solverstate
I0930 05:06:23.810416 15120 solver.cpp:337] Iteration 133000, Testing net (#0)
I0930 05:06:31.975478 15120 solver.cpp:404]     Test net output #0: accuracy = 0.737
I0930 05:06:31.975478 15120 solver.cpp:404]     Test net output #1: loss = 1.05888 (* 1 = 1.05888 loss)
I0930 05:06:32.031519 15120 solver.cpp:228] Iteration 133000, loss = 0.00834277
I0930 05:06:32.031519 15120 solver.cpp:244]     Train net output #0: loss = 0.00834277 (* 1 = 0.00834277 loss)
I0930 05:06:32.031519 15120 sgd_solver.cpp:106] Iteration 133000, lr = 0.001
I0930 05:06:51.352260 15120 solver.cpp:228] Iteration 133100, loss = 0.0124016
I0930 05:06:51.352260 15120 solver.cpp:244]     Train net output #0: loss = 0.0124016 (* 1 = 0.0124016 loss)
I0930 05:06:51.352260 15120 sgd_solver.cpp:106] Iteration 133100, lr = 0.001
I0930 05:07:10.670971 15120 solver.cpp:228] Iteration 133200, loss = 0.0102762
I0930 05:07:10.670971 15120 solver.cpp:244]     Train net output #0: loss = 0.0102762 (* 1 = 0.0102762 loss)
I0930 05:07:10.670971 15120 sgd_solver.cpp:106] Iteration 133200, lr = 0.001
I0930 05:07:30.067786 15120 solver.cpp:228] Iteration 133300, loss = 0.0108698
I0930 05:07:30.067786 15120 solver.cpp:244]     Train net output #0: loss = 0.0108698 (* 1 = 0.0108698 loss)
I0930 05:07:30.067786 15120 sgd_solver.cpp:106] Iteration 133300, lr = 0.001
I0930 05:07:49.427368 15120 solver.cpp:228] Iteration 133400, loss = 0.00997328
I0930 05:07:49.427368 15120 solver.cpp:244]     Train net output #0: loss = 0.00997327 (* 1 = 0.00997327 loss)
I0930 05:07:49.427368 15120 sgd_solver.cpp:106] Iteration 133400, lr = 0.001
I0930 05:08:08.760432 15120 solver.cpp:228] Iteration 133500, loss = 0.0134918
I0930 05:08:08.760432 15120 solver.cpp:244]     Train net output #0: loss = 0.0134918 (* 1 = 0.0134918 loss)
I0930 05:08:08.760432 15120 sgd_solver.cpp:106] Iteration 133500, lr = 0.001
I0930 05:08:28.148838 15120 solver.cpp:228] Iteration 133600, loss = 0.0101954
I0930 05:08:28.148838 15120 solver.cpp:244]     Train net output #0: loss = 0.0101954 (* 1 = 0.0101954 loss)
I0930 05:08:28.148838 15120 sgd_solver.cpp:106] Iteration 133600, lr = 0.001
I0930 05:08:47.483561 15120 solver.cpp:228] Iteration 133700, loss = 0.0120057
I0930 05:08:47.483561 15120 solver.cpp:244]     Train net output #0: loss = 0.0120057 (* 1 = 0.0120057 loss)
I0930 05:08:47.483561 15120 sgd_solver.cpp:106] Iteration 133700, lr = 0.001
I0930 05:09:06.818445 15120 solver.cpp:228] Iteration 133800, loss = 0.00983573
I0930 05:09:06.819447 15120 solver.cpp:244]     Train net output #0: loss = 0.00983573 (* 1 = 0.00983573 loss)
I0930 05:09:06.819447 15120 sgd_solver.cpp:106] Iteration 133800, lr = 0.001
I0930 05:09:26.154597 15120 solver.cpp:228] Iteration 133900, loss = 0.0124481
I0930 05:09:26.154597 15120 solver.cpp:244]     Train net output #0: loss = 0.0124481 (* 1 = 0.0124481 loss)
I0930 05:09:26.154597 15120 sgd_solver.cpp:106] Iteration 133900, lr = 0.001
I0930 05:09:45.425302 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_134000.caffemodel
I0930 05:09:46.032732 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_134000.solverstate
I0930 05:09:46.384982 15120 solver.cpp:337] Iteration 134000, Testing net (#0)
I0930 05:09:54.558887 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7397
I0930 05:09:54.558887 15120 solver.cpp:404]     Test net output #1: loss = 1.05507 (* 1 = 1.05507 loss)
I0930 05:09:54.608923 15120 solver.cpp:228] Iteration 134000, loss = 0.0119428
I0930 05:09:54.608923 15120 solver.cpp:244]     Train net output #0: loss = 0.0119428 (* 1 = 0.0119428 loss)
I0930 05:09:54.608923 15120 sgd_solver.cpp:106] Iteration 134000, lr = 0.001
I0930 05:10:13.969683 15120 solver.cpp:228] Iteration 134100, loss = 0.0109613
I0930 05:10:13.969683 15120 solver.cpp:244]     Train net output #0: loss = 0.0109613 (* 1 = 0.0109613 loss)
I0930 05:10:13.969683 15120 sgd_solver.cpp:106] Iteration 134100, lr = 0.001
I0930 05:10:33.308938 15120 solver.cpp:228] Iteration 134200, loss = 0.00843999
I0930 05:10:33.308938 15120 solver.cpp:244]     Train net output #0: loss = 0.00843999 (* 1 = 0.00843999 loss)
I0930 05:10:33.308938 15120 sgd_solver.cpp:106] Iteration 134200, lr = 0.001
I0930 05:10:52.637642 15120 solver.cpp:228] Iteration 134300, loss = 0.00860641
I0930 05:10:52.637642 15120 solver.cpp:244]     Train net output #0: loss = 0.00860641 (* 1 = 0.00860641 loss)
I0930 05:10:52.637642 15120 sgd_solver.cpp:106] Iteration 134300, lr = 0.001
I0930 05:11:11.957768 15120 solver.cpp:228] Iteration 134400, loss = 0.00808489
I0930 05:11:11.957768 15120 solver.cpp:244]     Train net output #0: loss = 0.00808489 (* 1 = 0.00808489 loss)
I0930 05:11:11.957768 15120 sgd_solver.cpp:106] Iteration 134400, lr = 0.001
I0930 05:11:31.275862 15120 solver.cpp:228] Iteration 134500, loss = 0.00948445
I0930 05:11:31.275862 15120 solver.cpp:244]     Train net output #0: loss = 0.00948444 (* 1 = 0.00948444 loss)
I0930 05:11:31.275862 15120 sgd_solver.cpp:106] Iteration 134500, lr = 0.001
I0930 05:11:50.613574 15120 solver.cpp:228] Iteration 134600, loss = 0.0117411
I0930 05:11:50.613574 15120 solver.cpp:244]     Train net output #0: loss = 0.0117411 (* 1 = 0.0117411 loss)
I0930 05:11:50.613574 15120 sgd_solver.cpp:106] Iteration 134600, lr = 0.001
I0930 05:12:09.932873 15120 solver.cpp:228] Iteration 134700, loss = 0.00950658
I0930 05:12:09.932873 15120 solver.cpp:244]     Train net output #0: loss = 0.00950658 (* 1 = 0.00950658 loss)
I0930 05:12:09.932873 15120 sgd_solver.cpp:106] Iteration 134700, lr = 0.001
I0930 05:12:29.255309 15120 solver.cpp:228] Iteration 134800, loss = 0.0175318
I0930 05:12:29.255309 15120 solver.cpp:244]     Train net output #0: loss = 0.0175318 (* 1 = 0.0175318 loss)
I0930 05:12:29.255309 15120 sgd_solver.cpp:106] Iteration 134800, lr = 0.001
I0930 05:12:48.576009 15120 solver.cpp:228] Iteration 134900, loss = 0.00726262
I0930 05:12:48.576009 15120 solver.cpp:244]     Train net output #0: loss = 0.00726261 (* 1 = 0.00726261 loss)
I0930 05:12:48.576009 15120 sgd_solver.cpp:106] Iteration 134900, lr = 0.001
I0930 05:13:07.833580 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_135000.caffemodel
I0930 05:13:08.441792 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_135000.solverstate
I0930 05:13:08.787035 15120 solver.cpp:337] Iteration 135000, Testing net (#0)
I0930 05:13:16.969843 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7365
I0930 05:13:16.969843 15120 solver.cpp:404]     Test net output #1: loss = 1.05531 (* 1 = 1.05531 loss)
I0930 05:13:17.022881 15120 solver.cpp:228] Iteration 135000, loss = 0.0122127
I0930 05:13:17.022881 15120 solver.cpp:244]     Train net output #0: loss = 0.0122127 (* 1 = 0.0122127 loss)
I0930 05:13:17.022881 15120 sgd_solver.cpp:106] Iteration 135000, lr = 0.001
I0930 05:13:36.360611 15120 solver.cpp:228] Iteration 135100, loss = 0.0103361
I0930 05:13:36.360611 15120 solver.cpp:244]     Train net output #0: loss = 0.0103361 (* 1 = 0.0103361 loss)
I0930 05:13:36.360611 15120 sgd_solver.cpp:106] Iteration 135100, lr = 0.001
I0930 05:13:55.689329 15120 solver.cpp:228] Iteration 135200, loss = 0.0086682
I0930 05:13:55.689329 15120 solver.cpp:244]     Train net output #0: loss = 0.0086682 (* 1 = 0.0086682 loss)
I0930 05:13:55.689329 15120 sgd_solver.cpp:106] Iteration 135200, lr = 0.001
I0930 05:14:15.026137 15120 solver.cpp:228] Iteration 135300, loss = 0.0100327
I0930 05:14:15.026137 15120 solver.cpp:244]     Train net output #0: loss = 0.0100327 (* 1 = 0.0100327 loss)
I0930 05:14:15.026137 15120 sgd_solver.cpp:106] Iteration 135300, lr = 0.001
I0930 05:14:34.342108 15120 solver.cpp:228] Iteration 135400, loss = 0.00990777
I0930 05:14:34.342108 15120 solver.cpp:244]     Train net output #0: loss = 0.00990776 (* 1 = 0.00990776 loss)
I0930 05:14:34.342108 15120 sgd_solver.cpp:106] Iteration 135400, lr = 0.001
I0930 05:14:53.652814 15120 solver.cpp:228] Iteration 135500, loss = 0.00882208
I0930 05:14:53.652814 15120 solver.cpp:244]     Train net output #0: loss = 0.00882208 (* 1 = 0.00882208 loss)
I0930 05:14:53.652814 15120 sgd_solver.cpp:106] Iteration 135500, lr = 0.001
I0930 05:15:12.974081 15120 solver.cpp:228] Iteration 135600, loss = 0.0123849
I0930 05:15:12.974081 15120 solver.cpp:244]     Train net output #0: loss = 0.0123849 (* 1 = 0.0123849 loss)
I0930 05:15:12.974081 15120 sgd_solver.cpp:106] Iteration 135600, lr = 0.001
I0930 05:15:32.294410 15120 solver.cpp:228] Iteration 135700, loss = 0.00935718
I0930 05:15:32.294410 15120 solver.cpp:244]     Train net output #0: loss = 0.00935717 (* 1 = 0.00935717 loss)
I0930 05:15:32.294410 15120 sgd_solver.cpp:106] Iteration 135700, lr = 0.001
I0930 05:15:51.629132 15120 solver.cpp:228] Iteration 135800, loss = 0.00869004
I0930 05:15:51.629132 15120 solver.cpp:244]     Train net output #0: loss = 0.00869004 (* 1 = 0.00869004 loss)
I0930 05:15:51.629132 15120 sgd_solver.cpp:106] Iteration 135800, lr = 0.001
I0930 05:16:10.955850 15120 solver.cpp:228] Iteration 135900, loss = 0.00815988
I0930 05:16:10.955850 15120 solver.cpp:244]     Train net output #0: loss = 0.00815987 (* 1 = 0.00815987 loss)
I0930 05:16:10.955850 15120 sgd_solver.cpp:106] Iteration 135900, lr = 0.001
I0930 05:16:30.227195 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_136000.caffemodel
I0930 05:16:30.813612 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_136000.solverstate
I0930 05:16:31.256507 15120 solver.cpp:337] Iteration 136000, Testing net (#0)
I0930 05:16:39.426481 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7366
I0930 05:16:39.426481 15120 solver.cpp:404]     Test net output #1: loss = 1.0614 (* 1 = 1.0614 loss)
I0930 05:16:39.476516 15120 solver.cpp:228] Iteration 136000, loss = 0.00970343
I0930 05:16:39.476516 15120 solver.cpp:244]     Train net output #0: loss = 0.00970343 (* 1 = 0.00970343 loss)
I0930 05:16:39.476516 15120 sgd_solver.cpp:106] Iteration 136000, lr = 0.001
I0930 05:16:58.812255 15120 solver.cpp:228] Iteration 136100, loss = 0.00944755
I0930 05:16:58.812255 15120 solver.cpp:244]     Train net output #0: loss = 0.00944755 (* 1 = 0.00944755 loss)
I0930 05:16:58.812255 15120 sgd_solver.cpp:106] Iteration 136100, lr = 0.001
I0930 05:17:18.163945 15120 solver.cpp:228] Iteration 136200, loss = 0.00969682
I0930 05:17:18.163945 15120 solver.cpp:244]     Train net output #0: loss = 0.00969682 (* 1 = 0.00969682 loss)
I0930 05:17:18.163945 15120 sgd_solver.cpp:106] Iteration 136200, lr = 0.001
I0930 05:17:37.478147 15120 solver.cpp:228] Iteration 136300, loss = 0.0113467
I0930 05:17:37.478147 15120 solver.cpp:244]     Train net output #0: loss = 0.0113467 (* 1 = 0.0113467 loss)
I0930 05:17:37.478147 15120 sgd_solver.cpp:106] Iteration 136300, lr = 0.001
I0930 05:17:56.799710 15120 solver.cpp:228] Iteration 136400, loss = 0.0127891
I0930 05:17:56.799710 15120 solver.cpp:244]     Train net output #0: loss = 0.0127891 (* 1 = 0.0127891 loss)
I0930 05:17:56.799710 15120 sgd_solver.cpp:106] Iteration 136400, lr = 0.001
I0930 05:18:16.128427 15120 solver.cpp:228] Iteration 136500, loss = 0.00814788
I0930 05:18:16.128427 15120 solver.cpp:244]     Train net output #0: loss = 0.00814787 (* 1 = 0.00814787 loss)
I0930 05:18:16.128427 15120 sgd_solver.cpp:106] Iteration 136500, lr = 0.001
I0930 05:18:35.485152 15120 solver.cpp:228] Iteration 136600, loss = 0.00784655
I0930 05:18:35.485152 15120 solver.cpp:244]     Train net output #0: loss = 0.00784654 (* 1 = 0.00784654 loss)
I0930 05:18:35.485152 15120 sgd_solver.cpp:106] Iteration 136600, lr = 0.001
I0930 05:18:54.832401 15120 solver.cpp:228] Iteration 136700, loss = 0.0142357
I0930 05:18:54.832401 15120 solver.cpp:244]     Train net output #0: loss = 0.0142357 (* 1 = 0.0142357 loss)
I0930 05:18:54.832401 15120 sgd_solver.cpp:106] Iteration 136700, lr = 0.001
I0930 05:19:14.160390 15120 solver.cpp:228] Iteration 136800, loss = 0.00891532
I0930 05:19:14.160390 15120 solver.cpp:244]     Train net output #0: loss = 0.00891531 (* 1 = 0.00891531 loss)
I0930 05:19:14.160390 15120 sgd_solver.cpp:106] Iteration 136800, lr = 0.001
I0930 05:19:33.504119 15120 solver.cpp:228] Iteration 136900, loss = 0.00790795
I0930 05:19:33.505120 15120 solver.cpp:244]     Train net output #0: loss = 0.00790794 (* 1 = 0.00790794 loss)
I0930 05:19:33.505120 15120 sgd_solver.cpp:106] Iteration 136900, lr = 0.001
I0930 05:19:52.796732 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_137000.caffemodel
I0930 05:19:53.402163 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_137000.solverstate
I0930 05:19:53.758415 15120 solver.cpp:337] Iteration 137000, Testing net (#0)
I0930 05:20:01.930215 15120 solver.cpp:404]     Test net output #0: accuracy = 0.74
I0930 05:20:01.930215 15120 solver.cpp:404]     Test net output #1: loss = 1.04856 (* 1 = 1.04856 loss)
I0930 05:20:01.980263 15120 solver.cpp:228] Iteration 137000, loss = 0.0111392
I0930 05:20:01.980263 15120 solver.cpp:244]     Train net output #0: loss = 0.0111392 (* 1 = 0.0111392 loss)
I0930 05:20:01.980263 15120 sgd_solver.cpp:106] Iteration 137000, lr = 0.001
I0930 05:20:21.325485 15120 solver.cpp:228] Iteration 137100, loss = 0.0126269
I0930 05:20:21.325485 15120 solver.cpp:244]     Train net output #0: loss = 0.0126269 (* 1 = 0.0126269 loss)
I0930 05:20:21.325485 15120 sgd_solver.cpp:106] Iteration 137100, lr = 0.001
I0930 05:20:40.664386 15120 solver.cpp:228] Iteration 137200, loss = 0.00853753
I0930 05:20:40.664386 15120 solver.cpp:244]     Train net output #0: loss = 0.00853753 (* 1 = 0.00853753 loss)
I0930 05:20:40.664386 15120 sgd_solver.cpp:106] Iteration 137200, lr = 0.001
I0930 05:21:00.006158 15120 solver.cpp:228] Iteration 137300, loss = 0.0116473
I0930 05:21:00.006158 15120 solver.cpp:244]     Train net output #0: loss = 0.0116473 (* 1 = 0.0116473 loss)
I0930 05:21:00.006158 15120 sgd_solver.cpp:106] Iteration 137300, lr = 0.001
I0930 05:21:19.335876 15120 solver.cpp:228] Iteration 137400, loss = 0.00930975
I0930 05:21:19.335876 15120 solver.cpp:244]     Train net output #0: loss = 0.00930974 (* 1 = 0.00930974 loss)
I0930 05:21:19.335876 15120 sgd_solver.cpp:106] Iteration 137400, lr = 0.001
I0930 05:21:38.679121 15120 solver.cpp:228] Iteration 137500, loss = 0.0093378
I0930 05:21:38.679121 15120 solver.cpp:244]     Train net output #0: loss = 0.00933779 (* 1 = 0.00933779 loss)
I0930 05:21:38.679121 15120 sgd_solver.cpp:106] Iteration 137500, lr = 0.001
I0930 05:21:58.016646 15120 solver.cpp:228] Iteration 137600, loss = 0.0102359
I0930 05:21:58.016646 15120 solver.cpp:244]     Train net output #0: loss = 0.0102359 (* 1 = 0.0102359 loss)
I0930 05:21:58.016646 15120 sgd_solver.cpp:106] Iteration 137600, lr = 0.001
I0930 05:22:17.345366 15120 solver.cpp:228] Iteration 137700, loss = 0.0089323
I0930 05:22:17.345366 15120 solver.cpp:244]     Train net output #0: loss = 0.0089323 (* 1 = 0.0089323 loss)
I0930 05:22:17.345366 15120 sgd_solver.cpp:106] Iteration 137700, lr = 0.001
I0930 05:22:36.712719 15120 solver.cpp:228] Iteration 137800, loss = 0.0123838
I0930 05:22:36.712719 15120 solver.cpp:244]     Train net output #0: loss = 0.0123837 (* 1 = 0.0123837 loss)
I0930 05:22:36.712719 15120 sgd_solver.cpp:106] Iteration 137800, lr = 0.001
I0930 05:22:56.064152 15120 solver.cpp:228] Iteration 137900, loss = 0.0089964
I0930 05:22:56.064152 15120 solver.cpp:244]     Train net output #0: loss = 0.00899639 (* 1 = 0.00899639 loss)
I0930 05:22:56.064152 15120 sgd_solver.cpp:106] Iteration 137900, lr = 0.001
I0930 05:23:15.357190 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_138000.caffemodel
I0930 05:23:15.960620 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_138000.solverstate
I0930 05:23:16.371695 15120 solver.cpp:337] Iteration 138000, Testing net (#0)
I0930 05:23:24.547497 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7364
I0930 05:23:24.547497 15120 solver.cpp:404]     Test net output #1: loss = 1.04791 (* 1 = 1.04791 loss)
I0930 05:23:24.598532 15120 solver.cpp:228] Iteration 138000, loss = 0.00939355
I0930 05:23:24.598532 15120 solver.cpp:244]     Train net output #0: loss = 0.00939354 (* 1 = 0.00939354 loss)
I0930 05:23:24.598532 15120 sgd_solver.cpp:106] Iteration 138000, lr = 0.001
I0930 05:23:43.955768 15120 solver.cpp:228] Iteration 138100, loss = 0.0173593
I0930 05:23:43.955768 15120 solver.cpp:244]     Train net output #0: loss = 0.0173593 (* 1 = 0.0173593 loss)
I0930 05:23:43.955768 15120 sgd_solver.cpp:106] Iteration 138100, lr = 0.001
I0930 05:24:03.279856 15120 solver.cpp:228] Iteration 138200, loss = 0.0100436
I0930 05:24:03.279856 15120 solver.cpp:244]     Train net output #0: loss = 0.0100436 (* 1 = 0.0100436 loss)
I0930 05:24:03.279856 15120 sgd_solver.cpp:106] Iteration 138200, lr = 0.001
I0930 05:24:22.614605 15120 solver.cpp:228] Iteration 138300, loss = 0.0105959
I0930 05:24:22.614605 15120 solver.cpp:244]     Train net output #0: loss = 0.0105959 (* 1 = 0.0105959 loss)
I0930 05:24:22.614605 15120 sgd_solver.cpp:106] Iteration 138300, lr = 0.001
I0930 05:24:41.959290 15120 solver.cpp:228] Iteration 138400, loss = 0.0106618
I0930 05:24:41.959290 15120 solver.cpp:244]     Train net output #0: loss = 0.0106618 (* 1 = 0.0106618 loss)
I0930 05:24:41.959290 15120 sgd_solver.cpp:106] Iteration 138400, lr = 0.001
I0930 05:25:01.284654 15120 solver.cpp:228] Iteration 138500, loss = 0.0102986
I0930 05:25:01.284654 15120 solver.cpp:244]     Train net output #0: loss = 0.0102986 (* 1 = 0.0102986 loss)
I0930 05:25:01.284654 15120 sgd_solver.cpp:106] Iteration 138500, lr = 0.001
I0930 05:25:20.643148 15120 solver.cpp:228] Iteration 138600, loss = 0.00943171
I0930 05:25:20.643148 15120 solver.cpp:244]     Train net output #0: loss = 0.0094317 (* 1 = 0.0094317 loss)
I0930 05:25:20.643148 15120 sgd_solver.cpp:106] Iteration 138600, lr = 0.001
I0930 05:25:39.986804 15120 solver.cpp:228] Iteration 138700, loss = 0.0083127
I0930 05:25:39.987804 15120 solver.cpp:244]     Train net output #0: loss = 0.0083127 (* 1 = 0.0083127 loss)
I0930 05:25:39.987804 15120 sgd_solver.cpp:106] Iteration 138700, lr = 0.001
I0930 05:25:59.324623 15120 solver.cpp:228] Iteration 138800, loss = 0.0106206
I0930 05:25:59.324623 15120 solver.cpp:244]     Train net output #0: loss = 0.0106206 (* 1 = 0.0106206 loss)
I0930 05:25:59.324623 15120 sgd_solver.cpp:106] Iteration 138800, lr = 0.001
I0930 05:26:18.652211 15120 solver.cpp:228] Iteration 138900, loss = 0.011916
I0930 05:26:18.652211 15120 solver.cpp:244]     Train net output #0: loss = 0.011916 (* 1 = 0.011916 loss)
I0930 05:26:18.652211 15120 sgd_solver.cpp:106] Iteration 138900, lr = 0.001
I0930 05:26:37.937911 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_139000.caffemodel
I0930 05:26:38.545331 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_139000.solverstate
I0930 05:26:38.911589 15120 solver.cpp:337] Iteration 139000, Testing net (#0)
I0930 05:26:47.096398 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7385
I0930 05:26:47.096398 15120 solver.cpp:404]     Test net output #1: loss = 1.0515 (* 1 = 1.0515 loss)
I0930 05:26:47.147435 15120 solver.cpp:228] Iteration 139000, loss = 0.00900423
I0930 05:26:47.147435 15120 solver.cpp:244]     Train net output #0: loss = 0.00900422 (* 1 = 0.00900422 loss)
I0930 05:26:47.147435 15120 sgd_solver.cpp:106] Iteration 139000, lr = 0.001
I0930 05:27:06.474153 15120 solver.cpp:228] Iteration 139100, loss = 0.0191081
I0930 05:27:06.474153 15120 solver.cpp:244]     Train net output #0: loss = 0.0191081 (* 1 = 0.0191081 loss)
I0930 05:27:06.474153 15120 sgd_solver.cpp:106] Iteration 139100, lr = 0.001
I0930 05:27:25.800570 15120 solver.cpp:228] Iteration 139200, loss = 0.0145342
I0930 05:27:25.800570 15120 solver.cpp:244]     Train net output #0: loss = 0.0145342 (* 1 = 0.0145342 loss)
I0930 05:27:25.800570 15120 sgd_solver.cpp:106] Iteration 139200, lr = 0.001
I0930 05:27:45.128582 15120 solver.cpp:228] Iteration 139300, loss = 0.0119094
I0930 05:27:45.128582 15120 solver.cpp:244]     Train net output #0: loss = 0.0119093 (* 1 = 0.0119093 loss)
I0930 05:27:45.128582 15120 sgd_solver.cpp:106] Iteration 139300, lr = 0.001
I0930 05:28:04.459302 15120 solver.cpp:228] Iteration 139400, loss = 0.00808909
I0930 05:28:04.459302 15120 solver.cpp:244]     Train net output #0: loss = 0.00808909 (* 1 = 0.00808909 loss)
I0930 05:28:04.459302 15120 sgd_solver.cpp:106] Iteration 139400, lr = 0.001
I0930 05:28:23.771296 15120 solver.cpp:228] Iteration 139500, loss = 0.00902521
I0930 05:28:23.771296 15120 solver.cpp:244]     Train net output #0: loss = 0.0090252 (* 1 = 0.0090252 loss)
I0930 05:28:23.771296 15120 sgd_solver.cpp:106] Iteration 139500, lr = 0.001
I0930 05:28:43.110662 15120 solver.cpp:228] Iteration 139600, loss = 0.0178097
I0930 05:28:43.111663 15120 solver.cpp:244]     Train net output #0: loss = 0.0178097 (* 1 = 0.0178097 loss)
I0930 05:28:43.111663 15120 sgd_solver.cpp:106] Iteration 139600, lr = 0.001
I0930 05:29:02.442369 15120 solver.cpp:228] Iteration 139700, loss = 0.00722958
I0930 05:29:02.442369 15120 solver.cpp:244]     Train net output #0: loss = 0.00722957 (* 1 = 0.00722957 loss)
I0930 05:29:02.442369 15120 sgd_solver.cpp:106] Iteration 139700, lr = 0.001
I0930 05:29:21.768100 15120 solver.cpp:228] Iteration 139800, loss = 0.00778479
I0930 05:29:21.768100 15120 solver.cpp:244]     Train net output #0: loss = 0.00778478 (* 1 = 0.00778478 loss)
I0930 05:29:21.768100 15120 sgd_solver.cpp:106] Iteration 139800, lr = 0.001
I0930 05:29:41.096804 15120 solver.cpp:228] Iteration 139900, loss = 0.00690732
I0930 05:29:41.097805 15120 solver.cpp:244]     Train net output #0: loss = 0.00690731 (* 1 = 0.00690731 loss)
I0930 05:29:41.097805 15120 sgd_solver.cpp:106] Iteration 139900, lr = 0.001
I0930 05:30:00.396551 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_140000.caffemodel
I0930 05:30:00.999980 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_140000.solverstate
I0930 05:30:01.371243 15120 solver.cpp:337] Iteration 140000, Testing net (#0)
I0930 05:30:09.540325 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7435
I0930 05:30:09.540325 15120 solver.cpp:404]     Test net output #1: loss = 1.04355 (* 1 = 1.04355 loss)
I0930 05:30:09.590360 15120 solver.cpp:228] Iteration 140000, loss = 0.00828377
I0930 05:30:09.590360 15120 solver.cpp:244]     Train net output #0: loss = 0.00828376 (* 1 = 0.00828376 loss)
I0930 05:30:09.590360 15120 sgd_solver.cpp:106] Iteration 140000, lr = 0.001
I0930 05:30:28.913903 15120 solver.cpp:228] Iteration 140100, loss = 0.0104382
I0930 05:30:28.914904 15120 solver.cpp:244]     Train net output #0: loss = 0.0104382 (* 1 = 0.0104382 loss)
I0930 05:30:28.914904 15120 sgd_solver.cpp:106] Iteration 140100, lr = 0.001
I0930 05:30:48.253971 15120 solver.cpp:228] Iteration 140200, loss = 0.00759254
I0930 05:30:48.253971 15120 solver.cpp:244]     Train net output #0: loss = 0.00759253 (* 1 = 0.00759253 loss)
I0930 05:30:48.253971 15120 sgd_solver.cpp:106] Iteration 140200, lr = 0.001
I0930 05:31:07.604041 15120 solver.cpp:228] Iteration 140300, loss = 0.00897328
I0930 05:31:07.604041 15120 solver.cpp:244]     Train net output #0: loss = 0.00897327 (* 1 = 0.00897327 loss)
I0930 05:31:07.604041 15120 sgd_solver.cpp:106] Iteration 140300, lr = 0.001
I0930 05:31:26.951366 15120 solver.cpp:228] Iteration 140400, loss = 0.00988289
I0930 05:31:26.951366 15120 solver.cpp:244]     Train net output #0: loss = 0.00988288 (* 1 = 0.00988288 loss)
I0930 05:31:26.951366 15120 sgd_solver.cpp:106] Iteration 140400, lr = 0.001
I0930 05:31:46.262847 15120 solver.cpp:228] Iteration 140500, loss = 0.00692309
I0930 05:31:46.262847 15120 solver.cpp:244]     Train net output #0: loss = 0.00692309 (* 1 = 0.00692309 loss)
I0930 05:31:46.262847 15120 sgd_solver.cpp:106] Iteration 140500, lr = 0.001
I0930 05:32:05.597569 15120 solver.cpp:228] Iteration 140600, loss = 0.0100656
I0930 05:32:05.597569 15120 solver.cpp:244]     Train net output #0: loss = 0.0100656 (* 1 = 0.0100656 loss)
I0930 05:32:05.597569 15120 sgd_solver.cpp:106] Iteration 140600, lr = 0.001
I0930 05:32:24.918751 15120 solver.cpp:228] Iteration 140700, loss = 0.00875124
I0930 05:32:24.918751 15120 solver.cpp:244]     Train net output #0: loss = 0.00875123 (* 1 = 0.00875123 loss)
I0930 05:32:24.918751 15120 sgd_solver.cpp:106] Iteration 140700, lr = 0.001
I0930 05:32:44.247732 15120 solver.cpp:228] Iteration 140800, loss = 0.0095207
I0930 05:32:44.247732 15120 solver.cpp:244]     Train net output #0: loss = 0.0095207 (* 1 = 0.0095207 loss)
I0930 05:32:44.247732 15120 sgd_solver.cpp:106] Iteration 140800, lr = 0.001
I0930 05:33:03.584621 15120 solver.cpp:228] Iteration 140900, loss = 0.0115625
I0930 05:33:03.584621 15120 solver.cpp:244]     Train net output #0: loss = 0.0115625 (* 1 = 0.0115625 loss)
I0930 05:33:03.584621 15120 sgd_solver.cpp:106] Iteration 140900, lr = 0.001
I0930 05:33:22.867574 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_141000.caffemodel
I0930 05:33:23.472990 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_141000.solverstate
I0930 05:33:23.836248 15120 solver.cpp:337] Iteration 141000, Testing net (#0)
I0930 05:33:32.017055 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7404
I0930 05:33:32.017055 15120 solver.cpp:404]     Test net output #1: loss = 1.05196 (* 1 = 1.05196 loss)
I0930 05:33:32.068091 15120 solver.cpp:228] Iteration 141000, loss = 0.0107665
I0930 05:33:32.068091 15120 solver.cpp:244]     Train net output #0: loss = 0.0107665 (* 1 = 0.0107665 loss)
I0930 05:33:32.068091 15120 sgd_solver.cpp:106] Iteration 141000, lr = 0.001
I0930 05:33:51.404829 15120 solver.cpp:228] Iteration 141100, loss = 0.0102928
I0930 05:33:51.404829 15120 solver.cpp:244]     Train net output #0: loss = 0.0102928 (* 1 = 0.0102928 loss)
I0930 05:33:51.404829 15120 sgd_solver.cpp:106] Iteration 141100, lr = 0.001
I0930 05:34:10.737550 15120 solver.cpp:228] Iteration 141200, loss = 0.00840824
I0930 05:34:10.737550 15120 solver.cpp:244]     Train net output #0: loss = 0.00840824 (* 1 = 0.00840824 loss)
I0930 05:34:10.737550 15120 sgd_solver.cpp:106] Iteration 141200, lr = 0.001
I0930 05:34:30.077262 15120 solver.cpp:228] Iteration 141300, loss = 0.0134865
I0930 05:34:30.077262 15120 solver.cpp:244]     Train net output #0: loss = 0.0134865 (* 1 = 0.0134865 loss)
I0930 05:34:30.077262 15120 sgd_solver.cpp:106] Iteration 141300, lr = 0.001
I0930 05:34:49.411370 15120 solver.cpp:228] Iteration 141400, loss = 0.00860367
I0930 05:34:49.411370 15120 solver.cpp:244]     Train net output #0: loss = 0.00860366 (* 1 = 0.00860366 loss)
I0930 05:34:49.411370 15120 sgd_solver.cpp:106] Iteration 141400, lr = 0.001
I0930 05:35:08.731082 15120 solver.cpp:228] Iteration 141500, loss = 0.0101308
I0930 05:35:08.731082 15120 solver.cpp:244]     Train net output #0: loss = 0.0101308 (* 1 = 0.0101308 loss)
I0930 05:35:08.731082 15120 sgd_solver.cpp:106] Iteration 141500, lr = 0.001
I0930 05:35:28.060295 15120 solver.cpp:228] Iteration 141600, loss = 0.007439
I0930 05:35:28.061295 15120 solver.cpp:244]     Train net output #0: loss = 0.00743899 (* 1 = 0.00743899 loss)
I0930 05:35:28.061295 15120 sgd_solver.cpp:106] Iteration 141600, lr = 0.001
I0930 05:35:47.405400 15120 solver.cpp:228] Iteration 141700, loss = 0.00891961
I0930 05:35:47.405400 15120 solver.cpp:244]     Train net output #0: loss = 0.00891961 (* 1 = 0.00891961 loss)
I0930 05:35:47.405400 15120 sgd_solver.cpp:106] Iteration 141700, lr = 0.001
I0930 05:36:06.756814 15120 solver.cpp:228] Iteration 141800, loss = 0.00677017
I0930 05:36:06.756814 15120 solver.cpp:244]     Train net output #0: loss = 0.00677017 (* 1 = 0.00677017 loss)
I0930 05:36:06.756814 15120 sgd_solver.cpp:106] Iteration 141800, lr = 0.001
I0930 05:36:26.079578 15120 solver.cpp:228] Iteration 141900, loss = 0.00692096
I0930 05:36:26.079578 15120 solver.cpp:244]     Train net output #0: loss = 0.00692096 (* 1 = 0.00692096 loss)
I0930 05:36:26.079578 15120 sgd_solver.cpp:106] Iteration 141900, lr = 0.001
I0930 05:36:45.369282 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_142000.caffemodel
I0930 05:36:45.970697 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_142000.solverstate
I0930 05:36:46.335955 15120 solver.cpp:337] Iteration 142000, Testing net (#0)
I0930 05:36:54.494746 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7373
I0930 05:36:54.494746 15120 solver.cpp:404]     Test net output #1: loss = 1.04913 (* 1 = 1.04913 loss)
I0930 05:36:54.544795 15120 solver.cpp:228] Iteration 142000, loss = 0.0054875
I0930 05:36:54.544795 15120 solver.cpp:244]     Train net output #0: loss = 0.00548749 (* 1 = 0.00548749 loss)
I0930 05:36:54.544795 15120 sgd_solver.cpp:106] Iteration 142000, lr = 0.001
I0930 05:37:13.869866 15120 solver.cpp:228] Iteration 142100, loss = 0.00907482
I0930 05:37:13.870867 15120 solver.cpp:244]     Train net output #0: loss = 0.00907482 (* 1 = 0.00907482 loss)
I0930 05:37:13.870867 15120 sgd_solver.cpp:106] Iteration 142100, lr = 0.001
I0930 05:37:33.219599 15120 solver.cpp:228] Iteration 142200, loss = 0.00782052
I0930 05:37:33.219599 15120 solver.cpp:244]     Train net output #0: loss = 0.00782052 (* 1 = 0.00782052 loss)
I0930 05:37:33.219599 15120 sgd_solver.cpp:106] Iteration 142200, lr = 0.001
I0930 05:37:52.570498 15120 solver.cpp:228] Iteration 142300, loss = 0.00934651
I0930 05:37:52.570498 15120 solver.cpp:244]     Train net output #0: loss = 0.0093465 (* 1 = 0.0093465 loss)
I0930 05:37:52.571499 15120 sgd_solver.cpp:106] Iteration 142300, lr = 0.001
I0930 05:38:11.909049 15120 solver.cpp:228] Iteration 142400, loss = 0.0085355
I0930 05:38:11.909049 15120 solver.cpp:244]     Train net output #0: loss = 0.0085355 (* 1 = 0.0085355 loss)
I0930 05:38:11.909049 15120 sgd_solver.cpp:106] Iteration 142400, lr = 0.001
I0930 05:38:31.245271 15120 solver.cpp:228] Iteration 142500, loss = 0.00741172
I0930 05:38:31.245271 15120 solver.cpp:244]     Train net output #0: loss = 0.00741172 (* 1 = 0.00741172 loss)
I0930 05:38:31.245271 15120 sgd_solver.cpp:106] Iteration 142500, lr = 0.001
I0930 05:38:50.582703 15120 solver.cpp:228] Iteration 142600, loss = 0.0155615
I0930 05:38:50.582703 15120 solver.cpp:244]     Train net output #0: loss = 0.0155615 (* 1 = 0.0155615 loss)
I0930 05:38:50.582703 15120 sgd_solver.cpp:106] Iteration 142600, lr = 0.001
I0930 05:39:09.909221 15120 solver.cpp:228] Iteration 142700, loss = 0.00944869
I0930 05:39:09.909221 15120 solver.cpp:244]     Train net output #0: loss = 0.00944868 (* 1 = 0.00944868 loss)
I0930 05:39:09.909221 15120 sgd_solver.cpp:106] Iteration 142700, lr = 0.001
I0930 05:39:29.233937 15120 solver.cpp:228] Iteration 142800, loss = 0.00722196
I0930 05:39:29.233937 15120 solver.cpp:244]     Train net output #0: loss = 0.00722195 (* 1 = 0.00722195 loss)
I0930 05:39:29.233937 15120 sgd_solver.cpp:106] Iteration 142800, lr = 0.001
I0930 05:39:48.568042 15120 solver.cpp:228] Iteration 142900, loss = 0.00836655
I0930 05:39:48.568042 15120 solver.cpp:244]     Train net output #0: loss = 0.00836654 (* 1 = 0.00836654 loss)
I0930 05:39:48.568042 15120 sgd_solver.cpp:106] Iteration 142900, lr = 0.001
I0930 05:40:07.858057 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_143000.caffemodel
I0930 05:40:08.461473 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_143000.solverstate
I0930 05:40:08.831737 15120 solver.cpp:337] Iteration 143000, Testing net (#0)
I0930 05:40:16.993257 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7382
I0930 05:40:16.993257 15120 solver.cpp:404]     Test net output #1: loss = 1.04766 (* 1 = 1.04766 loss)
I0930 05:40:17.044293 15120 solver.cpp:228] Iteration 143000, loss = 0.0127196
I0930 05:40:17.044293 15120 solver.cpp:244]     Train net output #0: loss = 0.0127196 (* 1 = 0.0127196 loss)
I0930 05:40:17.044293 15120 sgd_solver.cpp:106] Iteration 143000, lr = 0.001
I0930 05:40:36.354866 15120 solver.cpp:228] Iteration 143100, loss = 0.0124578
I0930 05:40:36.354866 15120 solver.cpp:244]     Train net output #0: loss = 0.0124578 (* 1 = 0.0124578 loss)
I0930 05:40:36.354866 15120 sgd_solver.cpp:106] Iteration 143100, lr = 0.001
I0930 05:40:55.672235 15120 solver.cpp:228] Iteration 143200, loss = 0.00926189
I0930 05:40:55.672235 15120 solver.cpp:244]     Train net output #0: loss = 0.00926188 (* 1 = 0.00926188 loss)
I0930 05:40:55.672235 15120 sgd_solver.cpp:106] Iteration 143200, lr = 0.001
I0930 05:41:15.007972 15120 solver.cpp:228] Iteration 143300, loss = 0.0100652
I0930 05:41:15.007972 15120 solver.cpp:244]     Train net output #0: loss = 0.0100652 (* 1 = 0.0100652 loss)
I0930 05:41:15.007972 15120 sgd_solver.cpp:106] Iteration 143300, lr = 0.001
I0930 05:41:34.333668 15120 solver.cpp:228] Iteration 143400, loss = 0.0102727
I0930 05:41:34.333668 15120 solver.cpp:244]     Train net output #0: loss = 0.0102727 (* 1 = 0.0102727 loss)
I0930 05:41:34.333668 15120 sgd_solver.cpp:106] Iteration 143400, lr = 0.001
I0930 05:41:53.664388 15120 solver.cpp:228] Iteration 143500, loss = 0.00751585
I0930 05:41:53.664388 15120 solver.cpp:244]     Train net output #0: loss = 0.00751584 (* 1 = 0.00751584 loss)
I0930 05:41:53.664388 15120 sgd_solver.cpp:106] Iteration 143500, lr = 0.001
I0930 05:42:12.984100 15120 solver.cpp:228] Iteration 143600, loss = 0.00930636
I0930 05:42:12.984100 15120 solver.cpp:244]     Train net output #0: loss = 0.00930635 (* 1 = 0.00930635 loss)
I0930 05:42:12.984100 15120 sgd_solver.cpp:106] Iteration 143600, lr = 0.001
I0930 05:42:32.316710 15120 solver.cpp:228] Iteration 143700, loss = 0.00822013
I0930 05:42:32.316710 15120 solver.cpp:244]     Train net output #0: loss = 0.00822012 (* 1 = 0.00822012 loss)
I0930 05:42:32.316710 15120 sgd_solver.cpp:106] Iteration 143700, lr = 0.001
I0930 05:42:51.644487 15120 solver.cpp:228] Iteration 143800, loss = 0.00777863
I0930 05:42:51.644487 15120 solver.cpp:244]     Train net output #0: loss = 0.00777863 (* 1 = 0.00777863 loss)
I0930 05:42:51.644487 15120 sgd_solver.cpp:106] Iteration 143800, lr = 0.001
I0930 05:43:10.984665 15120 solver.cpp:228] Iteration 143900, loss = 0.0108334
I0930 05:43:10.984665 15120 solver.cpp:244]     Train net output #0: loss = 0.0108334 (* 1 = 0.0108334 loss)
I0930 05:43:10.984665 15120 sgd_solver.cpp:106] Iteration 143900, lr = 0.001
I0930 05:43:30.268255 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_144000.caffemodel
I0930 05:43:30.866668 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_144000.solverstate
I0930 05:43:31.279961 15120 solver.cpp:337] Iteration 144000, Testing net (#0)
I0930 05:43:39.435742 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7426
I0930 05:43:39.435742 15120 solver.cpp:404]     Test net output #1: loss = 1.0351 (* 1 = 1.0351 loss)
I0930 05:43:39.486778 15120 solver.cpp:228] Iteration 144000, loss = 0.00952209
I0930 05:43:39.486778 15120 solver.cpp:244]     Train net output #0: loss = 0.00952208 (* 1 = 0.00952208 loss)
I0930 05:43:39.486778 15120 sgd_solver.cpp:106] Iteration 144000, lr = 0.001
I0930 05:43:58.816321 15120 solver.cpp:228] Iteration 144100, loss = 0.0116523
I0930 05:43:58.816321 15120 solver.cpp:244]     Train net output #0: loss = 0.0116523 (* 1 = 0.0116523 loss)
I0930 05:43:58.816321 15120 sgd_solver.cpp:106] Iteration 144100, lr = 0.001
I0930 05:44:18.149119 15120 solver.cpp:228] Iteration 144200, loss = 0.0065232
I0930 05:44:18.150106 15120 solver.cpp:244]     Train net output #0: loss = 0.00652319 (* 1 = 0.00652319 loss)
I0930 05:44:18.150106 15120 sgd_solver.cpp:106] Iteration 144200, lr = 0.001
I0930 05:44:37.501075 15120 solver.cpp:228] Iteration 144300, loss = 0.0143174
I0930 05:44:37.501075 15120 solver.cpp:244]     Train net output #0: loss = 0.0143174 (* 1 = 0.0143174 loss)
I0930 05:44:37.501075 15120 sgd_solver.cpp:106] Iteration 144300, lr = 0.001
I0930 05:44:56.851694 15120 solver.cpp:228] Iteration 144400, loss = 0.0121394
I0930 05:44:56.851694 15120 solver.cpp:244]     Train net output #0: loss = 0.0121394 (* 1 = 0.0121394 loss)
I0930 05:44:56.851694 15120 sgd_solver.cpp:106] Iteration 144400, lr = 0.001
I0930 05:45:16.211822 15120 solver.cpp:228] Iteration 144500, loss = 0.0187482
I0930 05:45:16.211822 15120 solver.cpp:244]     Train net output #0: loss = 0.0187482 (* 1 = 0.0187482 loss)
I0930 05:45:16.211822 15120 sgd_solver.cpp:106] Iteration 144500, lr = 0.001
I0930 05:45:35.620597 15120 solver.cpp:228] Iteration 144600, loss = 0.00878775
I0930 05:45:35.620597 15120 solver.cpp:244]     Train net output #0: loss = 0.00878774 (* 1 = 0.00878774 loss)
I0930 05:45:35.620597 15120 sgd_solver.cpp:106] Iteration 144600, lr = 0.001
I0930 05:45:54.957368 15120 solver.cpp:228] Iteration 144700, loss = 0.00782853
I0930 05:45:54.957368 15120 solver.cpp:244]     Train net output #0: loss = 0.00782852 (* 1 = 0.00782852 loss)
I0930 05:45:54.957368 15120 sgd_solver.cpp:106] Iteration 144700, lr = 0.001
I0930 05:46:14.346130 15120 solver.cpp:228] Iteration 144800, loss = 0.00986004
I0930 05:46:14.346130 15120 solver.cpp:244]     Train net output #0: loss = 0.00986004 (* 1 = 0.00986004 loss)
I0930 05:46:14.346130 15120 sgd_solver.cpp:106] Iteration 144800, lr = 0.001
I0930 05:46:33.673549 15120 solver.cpp:228] Iteration 144900, loss = 0.00906646
I0930 05:46:33.673549 15120 solver.cpp:244]     Train net output #0: loss = 0.00906646 (* 1 = 0.00906646 loss)
I0930 05:46:33.673549 15120 sgd_solver.cpp:106] Iteration 144900, lr = 0.001
I0930 05:46:52.963197 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_145000.caffemodel
I0930 05:46:53.586640 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_145000.solverstate
I0930 05:46:53.949898 15120 solver.cpp:337] Iteration 145000, Testing net (#0)
I0930 05:47:02.132621 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7414
I0930 05:47:02.133621 15120 solver.cpp:404]     Test net output #1: loss = 1.04107 (* 1 = 1.04107 loss)
I0930 05:47:02.183656 15120 solver.cpp:228] Iteration 145000, loss = 0.00931531
I0930 05:47:02.183656 15120 solver.cpp:244]     Train net output #0: loss = 0.0093153 (* 1 = 0.0093153 loss)
I0930 05:47:02.183656 15120 sgd_solver.cpp:106] Iteration 145000, lr = 0.001
I0930 05:47:21.527415 15120 solver.cpp:228] Iteration 145100, loss = 0.00930111
I0930 05:47:21.527415 15120 solver.cpp:244]     Train net output #0: loss = 0.00930111 (* 1 = 0.00930111 loss)
I0930 05:47:21.527415 15120 sgd_solver.cpp:106] Iteration 145100, lr = 0.001
I0930 05:47:40.858482 15120 solver.cpp:228] Iteration 145200, loss = 0.00710695
I0930 05:47:40.858482 15120 solver.cpp:244]     Train net output #0: loss = 0.00710694 (* 1 = 0.00710694 loss)
I0930 05:47:40.858482 15120 sgd_solver.cpp:106] Iteration 145200, lr = 0.001
I0930 05:48:00.188202 15120 solver.cpp:228] Iteration 145300, loss = 0.0104641
I0930 05:48:00.188202 15120 solver.cpp:244]     Train net output #0: loss = 0.0104641 (* 1 = 0.0104641 loss)
I0930 05:48:00.188202 15120 sgd_solver.cpp:106] Iteration 145300, lr = 0.001
I0930 05:48:19.515596 15120 solver.cpp:228] Iteration 145400, loss = 0.00926421
I0930 05:48:19.515596 15120 solver.cpp:244]     Train net output #0: loss = 0.00926421 (* 1 = 0.00926421 loss)
I0930 05:48:19.515596 15120 sgd_solver.cpp:106] Iteration 145400, lr = 0.001
I0930 05:48:38.838963 15120 solver.cpp:228] Iteration 145500, loss = 0.0115092
I0930 05:48:38.838963 15120 solver.cpp:244]     Train net output #0: loss = 0.0115092 (* 1 = 0.0115092 loss)
I0930 05:48:38.838963 15120 sgd_solver.cpp:106] Iteration 145500, lr = 0.001
I0930 05:48:58.179183 15120 solver.cpp:228] Iteration 145600, loss = 0.0107881
I0930 05:48:58.180197 15120 solver.cpp:244]     Train net output #0: loss = 0.010788 (* 1 = 0.010788 loss)
I0930 05:48:58.180197 15120 sgd_solver.cpp:106] Iteration 145600, lr = 0.001
I0930 05:49:17.519908 15120 solver.cpp:228] Iteration 145700, loss = 0.011326
I0930 05:49:17.519908 15120 solver.cpp:244]     Train net output #0: loss = 0.011326 (* 1 = 0.011326 loss)
I0930 05:49:17.519908 15120 sgd_solver.cpp:106] Iteration 145700, lr = 0.001
I0930 05:49:36.874645 15120 solver.cpp:228] Iteration 145800, loss = 0.00906147
I0930 05:49:36.874645 15120 solver.cpp:244]     Train net output #0: loss = 0.00906146 (* 1 = 0.00906146 loss)
I0930 05:49:36.874645 15120 sgd_solver.cpp:106] Iteration 145800, lr = 0.001
I0930 05:49:56.235386 15120 solver.cpp:228] Iteration 145900, loss = 0.00808947
I0930 05:49:56.235386 15120 solver.cpp:244]     Train net output #0: loss = 0.00808946 (* 1 = 0.00808946 loss)
I0930 05:49:56.235386 15120 sgd_solver.cpp:106] Iteration 145900, lr = 0.001
I0930 05:50:15.603868 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_146000.caffemodel
I0930 05:50:16.212287 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_146000.solverstate
I0930 05:50:16.571542 15120 solver.cpp:337] Iteration 146000, Testing net (#0)
I0930 05:50:24.739456 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7427
I0930 05:50:24.739456 15120 solver.cpp:404]     Test net output #1: loss = 1.04694 (* 1 = 1.04694 loss)
I0930 05:50:24.790479 15120 solver.cpp:228] Iteration 146000, loss = 0.00945741
I0930 05:50:24.790479 15120 solver.cpp:244]     Train net output #0: loss = 0.0094574 (* 1 = 0.0094574 loss)
I0930 05:50:24.790479 15120 sgd_solver.cpp:106] Iteration 146000, lr = 0.001
I0930 05:50:44.115195 15120 solver.cpp:228] Iteration 146100, loss = 0.00731879
I0930 05:50:44.115195 15120 solver.cpp:244]     Train net output #0: loss = 0.00731878 (* 1 = 0.00731878 loss)
I0930 05:50:44.115195 15120 sgd_solver.cpp:106] Iteration 146100, lr = 0.001
I0930 05:51:03.469480 15120 solver.cpp:228] Iteration 146200, loss = 0.0119543
I0930 05:51:03.469480 15120 solver.cpp:244]     Train net output #0: loss = 0.0119543 (* 1 = 0.0119543 loss)
I0930 05:51:03.469480 15120 sgd_solver.cpp:106] Iteration 146200, lr = 0.001
I0930 05:51:22.795181 15120 solver.cpp:228] Iteration 146300, loss = 0.0113978
I0930 05:51:22.796181 15120 solver.cpp:244]     Train net output #0: loss = 0.0113977 (* 1 = 0.0113977 loss)
I0930 05:51:22.796181 15120 sgd_solver.cpp:106] Iteration 146300, lr = 0.001
I0930 05:51:42.128481 15120 solver.cpp:228] Iteration 146400, loss = 0.0143082
I0930 05:51:42.128481 15120 solver.cpp:244]     Train net output #0: loss = 0.0143081 (* 1 = 0.0143081 loss)
I0930 05:51:42.128481 15120 sgd_solver.cpp:106] Iteration 146400, lr = 0.001
I0930 05:52:01.466207 15120 solver.cpp:228] Iteration 146500, loss = 0.00844697
I0930 05:52:01.466207 15120 solver.cpp:244]     Train net output #0: loss = 0.00844696 (* 1 = 0.00844696 loss)
I0930 05:52:01.466207 15120 sgd_solver.cpp:106] Iteration 146500, lr = 0.001
I0930 05:52:20.789921 15120 solver.cpp:228] Iteration 146600, loss = 0.0118878
I0930 05:52:20.789921 15120 solver.cpp:244]     Train net output #0: loss = 0.0118878 (* 1 = 0.0118878 loss)
I0930 05:52:20.789921 15120 sgd_solver.cpp:106] Iteration 146600, lr = 0.001
I0930 05:52:40.100627 15120 solver.cpp:228] Iteration 146700, loss = 0.0127321
I0930 05:52:40.100627 15120 solver.cpp:244]     Train net output #0: loss = 0.0127321 (* 1 = 0.0127321 loss)
I0930 05:52:40.100627 15120 sgd_solver.cpp:106] Iteration 146700, lr = 0.001
I0930 05:52:59.430416 15120 solver.cpp:228] Iteration 146800, loss = 0.00934124
I0930 05:52:59.430416 15120 solver.cpp:244]     Train net output #0: loss = 0.00934123 (* 1 = 0.00934123 loss)
I0930 05:52:59.430416 15120 sgd_solver.cpp:106] Iteration 146800, lr = 0.001
I0930 05:53:18.769141 15120 solver.cpp:228] Iteration 146900, loss = 0.0109182
I0930 05:53:18.769141 15120 solver.cpp:244]     Train net output #0: loss = 0.0109182 (* 1 = 0.0109182 loss)
I0930 05:53:18.770143 15120 sgd_solver.cpp:106] Iteration 146900, lr = 0.001
I0930 05:53:38.055830 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_147000.caffemodel
I0930 05:53:38.664263 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_147000.solverstate
I0930 05:53:39.037528 15120 solver.cpp:337] Iteration 147000, Testing net (#0)
I0930 05:53:47.212329 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7397
I0930 05:53:47.212329 15120 solver.cpp:404]     Test net output #1: loss = 1.04702 (* 1 = 1.04702 loss)
I0930 05:53:47.262364 15120 solver.cpp:228] Iteration 147000, loss = 0.0102812
I0930 05:53:47.262364 15120 solver.cpp:244]     Train net output #0: loss = 0.0102812 (* 1 = 0.0102812 loss)
I0930 05:53:47.262364 15120 sgd_solver.cpp:106] Iteration 147000, lr = 0.001
I0930 05:54:06.583077 15120 solver.cpp:228] Iteration 147100, loss = 0.0112416
I0930 05:54:06.583077 15120 solver.cpp:244]     Train net output #0: loss = 0.0112416 (* 1 = 0.0112416 loss)
I0930 05:54:06.583077 15120 sgd_solver.cpp:106] Iteration 147100, lr = 0.001
I0930 05:54:25.921387 15120 solver.cpp:228] Iteration 147200, loss = 0.0100633
I0930 05:54:25.921387 15120 solver.cpp:244]     Train net output #0: loss = 0.0100633 (* 1 = 0.0100633 loss)
I0930 05:54:25.921387 15120 sgd_solver.cpp:106] Iteration 147200, lr = 0.001
I0930 05:54:45.237084 15120 solver.cpp:228] Iteration 147300, loss = 0.0104634
I0930 05:54:45.237084 15120 solver.cpp:244]     Train net output #0: loss = 0.0104633 (* 1 = 0.0104633 loss)
I0930 05:54:45.237084 15120 sgd_solver.cpp:106] Iteration 147300, lr = 0.001
I0930 05:55:04.567852 15120 solver.cpp:228] Iteration 147400, loss = 0.00942298
I0930 05:55:04.567852 15120 solver.cpp:244]     Train net output #0: loss = 0.00942297 (* 1 = 0.00942297 loss)
I0930 05:55:04.567852 15120 sgd_solver.cpp:106] Iteration 147400, lr = 0.001
I0930 05:55:23.922349 15120 solver.cpp:228] Iteration 147500, loss = 0.00868704
I0930 05:55:23.922349 15120 solver.cpp:244]     Train net output #0: loss = 0.00868703 (* 1 = 0.00868703 loss)
I0930 05:55:23.922349 15120 sgd_solver.cpp:106] Iteration 147500, lr = 0.001
I0930 05:55:43.276123 15120 solver.cpp:228] Iteration 147600, loss = 0.0122644
I0930 05:55:43.276123 15120 solver.cpp:244]     Train net output #0: loss = 0.0122644 (* 1 = 0.0122644 loss)
I0930 05:55:43.276123 15120 sgd_solver.cpp:106] Iteration 147600, lr = 0.001
I0930 05:56:02.647871 15120 solver.cpp:228] Iteration 147700, loss = 0.00935824
I0930 05:56:02.647871 15120 solver.cpp:244]     Train net output #0: loss = 0.00935823 (* 1 = 0.00935823 loss)
I0930 05:56:02.647871 15120 sgd_solver.cpp:106] Iteration 147700, lr = 0.001
I0930 05:56:21.980592 15120 solver.cpp:228] Iteration 147800, loss = 0.00888187
I0930 05:56:21.980592 15120 solver.cpp:244]     Train net output #0: loss = 0.00888186 (* 1 = 0.00888186 loss)
I0930 05:56:21.980592 15120 sgd_solver.cpp:106] Iteration 147800, lr = 0.001
I0930 05:56:41.318830 15120 solver.cpp:228] Iteration 147900, loss = 0.00931834
I0930 05:56:41.318830 15120 solver.cpp:244]     Train net output #0: loss = 0.00931832 (* 1 = 0.00931832 loss)
I0930 05:56:41.318830 15120 sgd_solver.cpp:106] Iteration 147900, lr = 0.001
I0930 05:57:00.608520 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_148000.caffemodel
I0930 05:57:01.196939 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_148000.solverstate
I0930 05:57:01.562197 15120 solver.cpp:337] Iteration 148000, Testing net (#0)
I0930 05:57:09.754442 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7423
I0930 05:57:09.754442 15120 solver.cpp:404]     Test net output #1: loss = 1.04827 (* 1 = 1.04827 loss)
I0930 05:57:09.804478 15120 solver.cpp:228] Iteration 148000, loss = 0.00855511
I0930 05:57:09.804478 15120 solver.cpp:244]     Train net output #0: loss = 0.0085551 (* 1 = 0.0085551 loss)
I0930 05:57:09.804478 15120 sgd_solver.cpp:106] Iteration 148000, lr = 0.001
I0930 05:57:29.144590 15120 solver.cpp:228] Iteration 148100, loss = 0.0111144
I0930 05:57:29.144590 15120 solver.cpp:244]     Train net output #0: loss = 0.0111143 (* 1 = 0.0111143 loss)
I0930 05:57:29.144590 15120 sgd_solver.cpp:106] Iteration 148100, lr = 0.001
I0930 05:57:48.472306 15120 solver.cpp:228] Iteration 148200, loss = 0.0073641
I0930 05:57:48.472306 15120 solver.cpp:244]     Train net output #0: loss = 0.00736409 (* 1 = 0.00736409 loss)
I0930 05:57:48.472306 15120 sgd_solver.cpp:106] Iteration 148200, lr = 0.001
I0930 05:58:07.819269 15120 solver.cpp:228] Iteration 148300, loss = 0.0130057
I0930 05:58:07.819269 15120 solver.cpp:244]     Train net output #0: loss = 0.0130057 (* 1 = 0.0130057 loss)
I0930 05:58:07.819269 15120 sgd_solver.cpp:106] Iteration 148300, lr = 0.001
I0930 05:58:27.146057 15120 solver.cpp:228] Iteration 148400, loss = 0.00902736
I0930 05:58:27.146057 15120 solver.cpp:244]     Train net output #0: loss = 0.00902735 (* 1 = 0.00902735 loss)
I0930 05:58:27.146057 15120 sgd_solver.cpp:106] Iteration 148400, lr = 0.001
I0930 05:58:46.478304 15120 solver.cpp:228] Iteration 148500, loss = 0.00636646
I0930 05:58:46.478304 15120 solver.cpp:244]     Train net output #0: loss = 0.00636646 (* 1 = 0.00636646 loss)
I0930 05:58:46.478304 15120 sgd_solver.cpp:106] Iteration 148500, lr = 0.001
I0930 05:59:05.815028 15120 solver.cpp:228] Iteration 148600, loss = 0.0108893
I0930 05:59:05.815028 15120 solver.cpp:244]     Train net output #0: loss = 0.0108893 (* 1 = 0.0108893 loss)
I0930 05:59:05.815028 15120 sgd_solver.cpp:106] Iteration 148600, lr = 0.001
I0930 05:59:25.122731 15120 solver.cpp:228] Iteration 148700, loss = 0.00864268
I0930 05:59:25.122731 15120 solver.cpp:244]     Train net output #0: loss = 0.00864267 (* 1 = 0.00864267 loss)
I0930 05:59:25.122731 15120 sgd_solver.cpp:106] Iteration 148700, lr = 0.001
I0930 05:59:44.467461 15120 solver.cpp:228] Iteration 148800, loss = 0.00951111
I0930 05:59:44.467461 15120 solver.cpp:244]     Train net output #0: loss = 0.0095111 (* 1 = 0.0095111 loss)
I0930 05:59:44.467461 15120 sgd_solver.cpp:106] Iteration 148800, lr = 0.001
I0930 06:00:03.809811 15120 solver.cpp:228] Iteration 148900, loss = 0.00994739
I0930 06:00:03.809811 15120 solver.cpp:244]     Train net output #0: loss = 0.00994738 (* 1 = 0.00994738 loss)
I0930 06:00:03.809811 15120 sgd_solver.cpp:106] Iteration 148900, lr = 0.001
I0930 06:00:23.097702 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_149000.caffemodel
I0930 06:00:23.699120 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_149000.solverstate
I0930 06:00:24.064378 15120 solver.cpp:337] Iteration 149000, Testing net (#0)
I0930 06:00:32.229539 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7419
I0930 06:00:32.229539 15120 solver.cpp:404]     Test net output #1: loss = 1.03789 (* 1 = 1.03789 loss)
I0930 06:00:32.279574 15120 solver.cpp:228] Iteration 149000, loss = 0.00832592
I0930 06:00:32.279574 15120 solver.cpp:244]     Train net output #0: loss = 0.00832592 (* 1 = 0.00832592 loss)
I0930 06:00:32.279574 15120 sgd_solver.cpp:106] Iteration 149000, lr = 0.001
I0930 06:00:51.615463 15120 solver.cpp:228] Iteration 149100, loss = 0.008952
I0930 06:00:51.615463 15120 solver.cpp:244]     Train net output #0: loss = 0.00895199 (* 1 = 0.00895199 loss)
I0930 06:00:51.615463 15120 sgd_solver.cpp:106] Iteration 149100, lr = 0.001
I0930 06:01:10.962663 15120 solver.cpp:228] Iteration 149200, loss = 0.0122516
I0930 06:01:10.962663 15120 solver.cpp:244]     Train net output #0: loss = 0.0122516 (* 1 = 0.0122516 loss)
I0930 06:01:10.962663 15120 sgd_solver.cpp:106] Iteration 149200, lr = 0.001
I0930 06:01:30.309038 15120 solver.cpp:228] Iteration 149300, loss = 0.0099673
I0930 06:01:30.309038 15120 solver.cpp:244]     Train net output #0: loss = 0.00996729 (* 1 = 0.00996729 loss)
I0930 06:01:30.309038 15120 sgd_solver.cpp:106] Iteration 149300, lr = 0.001
I0930 06:01:49.659785 15120 solver.cpp:228] Iteration 149400, loss = 0.00911703
I0930 06:01:49.659785 15120 solver.cpp:244]     Train net output #0: loss = 0.00911702 (* 1 = 0.00911702 loss)
I0930 06:01:49.659785 15120 sgd_solver.cpp:106] Iteration 149400, lr = 0.001
I0930 06:02:08.994495 15120 solver.cpp:228] Iteration 149500, loss = 0.00997236
I0930 06:02:08.994495 15120 solver.cpp:244]     Train net output #0: loss = 0.00997235 (* 1 = 0.00997235 loss)
I0930 06:02:08.994495 15120 sgd_solver.cpp:106] Iteration 149500, lr = 0.001
I0930 06:02:28.325214 15120 solver.cpp:228] Iteration 149600, loss = 0.00981426
I0930 06:02:28.325214 15120 solver.cpp:244]     Train net output #0: loss = 0.00981424 (* 1 = 0.00981424 loss)
I0930 06:02:28.325214 15120 sgd_solver.cpp:106] Iteration 149600, lr = 0.001
I0930 06:02:47.659476 15120 solver.cpp:228] Iteration 149700, loss = 0.00730875
I0930 06:02:47.659476 15120 solver.cpp:244]     Train net output #0: loss = 0.00730874 (* 1 = 0.00730874 loss)
I0930 06:02:47.659476 15120 sgd_solver.cpp:106] Iteration 149700, lr = 0.001
I0930 06:03:06.999588 15120 solver.cpp:228] Iteration 149800, loss = 0.00841984
I0930 06:03:06.999588 15120 solver.cpp:244]     Train net output #0: loss = 0.00841983 (* 1 = 0.00841983 loss)
I0930 06:03:06.999588 15120 sgd_solver.cpp:106] Iteration 149800, lr = 0.001
I0930 06:03:26.343514 15120 solver.cpp:228] Iteration 149900, loss = 0.0120121
I0930 06:03:26.343514 15120 solver.cpp:244]     Train net output #0: loss = 0.0120121 (* 1 = 0.0120121 loss)
I0930 06:03:26.343514 15120 sgd_solver.cpp:106] Iteration 149900, lr = 0.001
I0930 06:03:45.647177 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_150000.caffemodel
I0930 06:03:46.264603 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_150000.solverstate
I0930 06:03:46.611850 15120 solver.cpp:337] Iteration 150000, Testing net (#0)
I0930 06:03:54.805392 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7398
I0930 06:03:54.805392 15120 solver.cpp:404]     Test net output #1: loss = 1.04164 (* 1 = 1.04164 loss)
I0930 06:03:54.855428 15120 solver.cpp:228] Iteration 150000, loss = 0.00813154
I0930 06:03:54.855428 15120 solver.cpp:244]     Train net output #0: loss = 0.00813153 (* 1 = 0.00813153 loss)
I0930 06:03:54.855428 15120 sgd_solver.cpp:106] Iteration 150000, lr = 0.001
I0930 06:04:14.194233 15120 solver.cpp:228] Iteration 150100, loss = 0.013295
I0930 06:04:14.195235 15120 solver.cpp:244]     Train net output #0: loss = 0.013295 (* 1 = 0.013295 loss)
I0930 06:04:14.195235 15120 sgd_solver.cpp:106] Iteration 150100, lr = 0.001
I0930 06:04:33.535259 15120 solver.cpp:228] Iteration 150200, loss = 0.00818288
I0930 06:04:33.536244 15120 solver.cpp:244]     Train net output #0: loss = 0.00818287 (* 1 = 0.00818287 loss)
I0930 06:04:33.536244 15120 sgd_solver.cpp:106] Iteration 150200, lr = 0.001
I0930 06:04:52.849514 15120 solver.cpp:228] Iteration 150300, loss = 0.012366
I0930 06:04:52.849514 15120 solver.cpp:244]     Train net output #0: loss = 0.012366 (* 1 = 0.012366 loss)
I0930 06:04:52.849514 15120 sgd_solver.cpp:106] Iteration 150300, lr = 0.001
I0930 06:05:12.175230 15120 solver.cpp:228] Iteration 150400, loss = 0.0088373
I0930 06:05:12.175230 15120 solver.cpp:244]     Train net output #0: loss = 0.00883729 (* 1 = 0.00883729 loss)
I0930 06:05:12.175230 15120 sgd_solver.cpp:106] Iteration 150400, lr = 0.001
I0930 06:05:31.500946 15120 solver.cpp:228] Iteration 150500, loss = 0.0106211
I0930 06:05:31.500946 15120 solver.cpp:244]     Train net output #0: loss = 0.0106211 (* 1 = 0.0106211 loss)
I0930 06:05:31.500946 15120 sgd_solver.cpp:106] Iteration 150500, lr = 0.001
I0930 06:05:50.844902 15120 solver.cpp:228] Iteration 150600, loss = 0.0101315
I0930 06:05:50.844902 15120 solver.cpp:244]     Train net output #0: loss = 0.0101315 (* 1 = 0.0101315 loss)
I0930 06:05:50.844902 15120 sgd_solver.cpp:106] Iteration 150600, lr = 0.001
I0930 06:06:10.185755 15120 solver.cpp:228] Iteration 150700, loss = 0.00673117
I0930 06:06:10.185755 15120 solver.cpp:244]     Train net output #0: loss = 0.00673116 (* 1 = 0.00673116 loss)
I0930 06:06:10.185755 15120 sgd_solver.cpp:106] Iteration 150700, lr = 0.001
I0930 06:06:29.502358 15120 solver.cpp:228] Iteration 150800, loss = 0.00797351
I0930 06:06:29.502358 15120 solver.cpp:244]     Train net output #0: loss = 0.0079735 (* 1 = 0.0079735 loss)
I0930 06:06:29.502358 15120 sgd_solver.cpp:106] Iteration 150800, lr = 0.001
I0930 06:06:48.851706 15120 solver.cpp:228] Iteration 150900, loss = 0.0109603
I0930 06:06:48.851706 15120 solver.cpp:244]     Train net output #0: loss = 0.0109603 (* 1 = 0.0109603 loss)
I0930 06:06:48.851706 15120 sgd_solver.cpp:106] Iteration 150900, lr = 0.001
I0930 06:07:08.149885 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_151000.caffemodel
I0930 06:07:08.738303 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_151000.solverstate
I0930 06:07:09.094557 15120 solver.cpp:337] Iteration 151000, Testing net (#0)
I0930 06:07:17.260351 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7418
I0930 06:07:17.260351 15120 solver.cpp:404]     Test net output #1: loss = 1.03914 (* 1 = 1.03914 loss)
I0930 06:07:17.311388 15120 solver.cpp:228] Iteration 151000, loss = 0.0117711
I0930 06:07:17.311388 15120 solver.cpp:244]     Train net output #0: loss = 0.011771 (* 1 = 0.011771 loss)
I0930 06:07:17.311388 15120 sgd_solver.cpp:106] Iteration 151000, lr = 0.001
I0930 06:07:36.674130 15120 solver.cpp:228] Iteration 151100, loss = 0.00832479
I0930 06:07:36.674130 15120 solver.cpp:244]     Train net output #0: loss = 0.00832478 (* 1 = 0.00832478 loss)
I0930 06:07:36.674130 15120 sgd_solver.cpp:106] Iteration 151100, lr = 0.001
I0930 06:07:55.994843 15120 solver.cpp:228] Iteration 151200, loss = 0.00777953
I0930 06:07:55.994843 15120 solver.cpp:244]     Train net output #0: loss = 0.00777952 (* 1 = 0.00777952 loss)
I0930 06:07:55.995843 15120 sgd_solver.cpp:106] Iteration 151200, lr = 0.001
I0930 06:08:15.327110 15120 solver.cpp:228] Iteration 151300, loss = 0.00973078
I0930 06:08:15.327110 15120 solver.cpp:244]     Train net output #0: loss = 0.00973077 (* 1 = 0.00973077 loss)
I0930 06:08:15.327110 15120 sgd_solver.cpp:106] Iteration 151300, lr = 0.001
I0930 06:08:34.658151 15120 solver.cpp:228] Iteration 151400, loss = 0.00874352
I0930 06:08:34.658151 15120 solver.cpp:244]     Train net output #0: loss = 0.00874351 (* 1 = 0.00874351 loss)
I0930 06:08:34.658151 15120 sgd_solver.cpp:106] Iteration 151400, lr = 0.001
I0930 06:08:54.006922 15120 solver.cpp:228] Iteration 151500, loss = 0.0131384
I0930 06:08:54.006922 15120 solver.cpp:244]     Train net output #0: loss = 0.0131384 (* 1 = 0.0131384 loss)
I0930 06:08:54.006922 15120 sgd_solver.cpp:106] Iteration 151500, lr = 0.001
I0930 06:09:13.341689 15120 solver.cpp:228] Iteration 151600, loss = 0.0113964
I0930 06:09:13.341689 15120 solver.cpp:244]     Train net output #0: loss = 0.0113964 (* 1 = 0.0113964 loss)
I0930 06:09:13.341689 15120 sgd_solver.cpp:106] Iteration 151600, lr = 0.001
I0930 06:09:32.664589 15120 solver.cpp:228] Iteration 151700, loss = 0.0104287
I0930 06:09:32.664589 15120 solver.cpp:244]     Train net output #0: loss = 0.0104287 (* 1 = 0.0104287 loss)
I0930 06:09:32.664589 15120 sgd_solver.cpp:106] Iteration 151700, lr = 0.001
I0930 06:09:51.989704 15120 solver.cpp:228] Iteration 151800, loss = 0.0105233
I0930 06:09:51.989704 15120 solver.cpp:244]     Train net output #0: loss = 0.0105233 (* 1 = 0.0105233 loss)
I0930 06:09:51.989704 15120 sgd_solver.cpp:106] Iteration 151800, lr = 0.001
I0930 06:10:11.304426 15120 solver.cpp:228] Iteration 151900, loss = 0.0109753
I0930 06:10:11.304426 15120 solver.cpp:244]     Train net output #0: loss = 0.0109753 (* 1 = 0.0109753 loss)
I0930 06:10:11.304426 15120 sgd_solver.cpp:106] Iteration 151900, lr = 0.001
I0930 06:10:30.601147 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_152000.caffemodel
I0930 06:10:31.219004 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_152000.solverstate
I0930 06:10:31.570253 15120 solver.cpp:337] Iteration 152000, Testing net (#0)
I0930 06:10:39.735129 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7407
I0930 06:10:39.735129 15120 solver.cpp:404]     Test net output #1: loss = 1.04046 (* 1 = 1.04046 loss)
I0930 06:10:39.786165 15120 solver.cpp:228] Iteration 152000, loss = 0.00833089
I0930 06:10:39.786165 15120 solver.cpp:244]     Train net output #0: loss = 0.00833088 (* 1 = 0.00833088 loss)
I0930 06:10:39.786165 15120 sgd_solver.cpp:106] Iteration 152000, lr = 0.001
I0930 06:10:59.119689 15120 solver.cpp:228] Iteration 152100, loss = 0.0102548
I0930 06:10:59.119689 15120 solver.cpp:244]     Train net output #0: loss = 0.0102548 (* 1 = 0.0102548 loss)
I0930 06:10:59.119689 15120 sgd_solver.cpp:106] Iteration 152100, lr = 0.001
I0930 06:11:18.463827 15120 solver.cpp:228] Iteration 152200, loss = 0.0107077
I0930 06:11:18.463827 15120 solver.cpp:244]     Train net output #0: loss = 0.0107077 (* 1 = 0.0107077 loss)
I0930 06:11:18.463827 15120 sgd_solver.cpp:106] Iteration 152200, lr = 0.001
I0930 06:11:37.814574 15120 solver.cpp:228] Iteration 152300, loss = 0.0084589
I0930 06:11:37.814574 15120 solver.cpp:244]     Train net output #0: loss = 0.0084589 (* 1 = 0.0084589 loss)
I0930 06:11:37.814574 15120 sgd_solver.cpp:106] Iteration 152300, lr = 0.001
I0930 06:11:57.156289 15120 solver.cpp:228] Iteration 152400, loss = 0.00977238
I0930 06:11:57.156289 15120 solver.cpp:244]     Train net output #0: loss = 0.00977237 (* 1 = 0.00977237 loss)
I0930 06:11:57.156289 15120 sgd_solver.cpp:106] Iteration 152400, lr = 0.001
I0930 06:12:16.497371 15120 solver.cpp:228] Iteration 152500, loss = 0.0110518
I0930 06:12:16.497371 15120 solver.cpp:244]     Train net output #0: loss = 0.0110518 (* 1 = 0.0110518 loss)
I0930 06:12:16.497371 15120 sgd_solver.cpp:106] Iteration 152500, lr = 0.001
I0930 06:12:35.832466 15120 solver.cpp:228] Iteration 152600, loss = 0.00945075
I0930 06:12:35.832466 15120 solver.cpp:244]     Train net output #0: loss = 0.00945075 (* 1 = 0.00945075 loss)
I0930 06:12:35.832466 15120 sgd_solver.cpp:106] Iteration 152600, lr = 0.001
I0930 06:12:55.165174 15120 solver.cpp:228] Iteration 152700, loss = 0.00922671
I0930 06:12:55.165174 15120 solver.cpp:244]     Train net output #0: loss = 0.0092267 (* 1 = 0.0092267 loss)
I0930 06:12:55.165174 15120 sgd_solver.cpp:106] Iteration 152700, lr = 0.001
I0930 06:13:14.499897 15120 solver.cpp:228] Iteration 152800, loss = 0.0111086
I0930 06:13:14.499897 15120 solver.cpp:244]     Train net output #0: loss = 0.0111085 (* 1 = 0.0111085 loss)
I0930 06:13:14.499897 15120 sgd_solver.cpp:106] Iteration 152800, lr = 0.001
I0930 06:13:33.849680 15120 solver.cpp:228] Iteration 152900, loss = 0.00796112
I0930 06:13:33.849680 15120 solver.cpp:244]     Train net output #0: loss = 0.00796112 (* 1 = 0.00796112 loss)
I0930 06:13:33.849680 15120 sgd_solver.cpp:106] Iteration 152900, lr = 0.001
I0930 06:13:53.144104 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_153000.caffemodel
I0930 06:13:53.736538 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_153000.solverstate
I0930 06:13:54.102435 15120 solver.cpp:337] Iteration 153000, Testing net (#0)
I0930 06:14:02.291247 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7414
I0930 06:14:02.291247 15120 solver.cpp:404]     Test net output #1: loss = 1.03255 (* 1 = 1.03255 loss)
I0930 06:14:02.342283 15120 solver.cpp:228] Iteration 153000, loss = 0.00898627
I0930 06:14:02.342283 15120 solver.cpp:244]     Train net output #0: loss = 0.00898627 (* 1 = 0.00898627 loss)
I0930 06:14:02.342283 15120 sgd_solver.cpp:106] Iteration 153000, lr = 0.001
I0930 06:14:21.671016 15120 solver.cpp:228] Iteration 153100, loss = 0.0128423
I0930 06:14:21.671016 15120 solver.cpp:244]     Train net output #0: loss = 0.0128423 (* 1 = 0.0128423 loss)
I0930 06:14:21.671016 15120 sgd_solver.cpp:106] Iteration 153100, lr = 0.001
I0930 06:14:41.018482 15120 solver.cpp:228] Iteration 153200, loss = 0.00725263
I0930 06:14:41.018482 15120 solver.cpp:244]     Train net output #0: loss = 0.00725263 (* 1 = 0.00725263 loss)
I0930 06:14:41.019484 15120 sgd_solver.cpp:106] Iteration 153200, lr = 0.001
I0930 06:15:00.361667 15120 solver.cpp:228] Iteration 153300, loss = 0.0124427
I0930 06:15:00.361667 15120 solver.cpp:244]     Train net output #0: loss = 0.0124427 (* 1 = 0.0124427 loss)
I0930 06:15:00.361667 15120 sgd_solver.cpp:106] Iteration 153300, lr = 0.001
I0930 06:15:19.683936 15120 solver.cpp:228] Iteration 153400, loss = 0.00926309
I0930 06:15:19.683936 15120 solver.cpp:244]     Train net output #0: loss = 0.00926309 (* 1 = 0.00926309 loss)
I0930 06:15:19.683936 15120 sgd_solver.cpp:106] Iteration 153400, lr = 0.001
I0930 06:15:39.002648 15120 solver.cpp:228] Iteration 153500, loss = 0.0078726
I0930 06:15:39.002648 15120 solver.cpp:244]     Train net output #0: loss = 0.0078726 (* 1 = 0.0078726 loss)
I0930 06:15:39.002648 15120 sgd_solver.cpp:106] Iteration 153500, lr = 0.001
I0930 06:15:58.320358 15120 solver.cpp:228] Iteration 153600, loss = 0.00810784
I0930 06:15:58.320358 15120 solver.cpp:244]     Train net output #0: loss = 0.00810783 (* 1 = 0.00810783 loss)
I0930 06:15:58.320358 15120 sgd_solver.cpp:106] Iteration 153600, lr = 0.001
I0930 06:16:17.651299 15120 solver.cpp:228] Iteration 153700, loss = 0.00681539
I0930 06:16:17.651299 15120 solver.cpp:244]     Train net output #0: loss = 0.00681539 (* 1 = 0.00681539 loss)
I0930 06:16:17.651299 15120 sgd_solver.cpp:106] Iteration 153700, lr = 0.001
I0930 06:16:36.973073 15120 solver.cpp:228] Iteration 153800, loss = 0.00839288
I0930 06:16:36.973073 15120 solver.cpp:244]     Train net output #0: loss = 0.00839287 (* 1 = 0.00839287 loss)
I0930 06:16:36.973073 15120 sgd_solver.cpp:106] Iteration 153800, lr = 0.001
I0930 06:16:56.306794 15120 solver.cpp:228] Iteration 153900, loss = 0.00985328
I0930 06:16:56.306794 15120 solver.cpp:244]     Train net output #0: loss = 0.00985327 (* 1 = 0.00985327 loss)
I0930 06:16:56.306794 15120 sgd_solver.cpp:106] Iteration 153900, lr = 0.001
I0930 06:17:15.583477 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_154000.caffemodel
I0930 06:17:16.181901 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_154000.solverstate
I0930 06:17:16.539155 15120 solver.cpp:337] Iteration 154000, Testing net (#0)
I0930 06:17:24.735973 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7433
I0930 06:17:24.735973 15120 solver.cpp:404]     Test net output #1: loss = 1.03069 (* 1 = 1.03069 loss)
I0930 06:17:24.787021 15120 solver.cpp:228] Iteration 154000, loss = 0.00789589
I0930 06:17:24.787021 15120 solver.cpp:244]     Train net output #0: loss = 0.00789589 (* 1 = 0.00789589 loss)
I0930 06:17:24.787021 15120 sgd_solver.cpp:106] Iteration 154000, lr = 0.001
I0930 06:17:44.119730 15120 solver.cpp:228] Iteration 154100, loss = 0.0109154
I0930 06:17:44.119730 15120 solver.cpp:244]     Train net output #0: loss = 0.0109154 (* 1 = 0.0109154 loss)
I0930 06:17:44.119730 15120 sgd_solver.cpp:106] Iteration 154100, lr = 0.001
I0930 06:18:03.435438 15120 solver.cpp:228] Iteration 154200, loss = 0.00825677
I0930 06:18:03.435438 15120 solver.cpp:244]     Train net output #0: loss = 0.00825677 (* 1 = 0.00825677 loss)
I0930 06:18:03.435438 15120 sgd_solver.cpp:106] Iteration 154200, lr = 0.001
I0930 06:18:22.761155 15120 solver.cpp:228] Iteration 154300, loss = 0.00907269
I0930 06:18:22.762156 15120 solver.cpp:244]     Train net output #0: loss = 0.00907268 (* 1 = 0.00907268 loss)
I0930 06:18:22.762156 15120 sgd_solver.cpp:106] Iteration 154300, lr = 0.001
I0930 06:18:42.095878 15120 solver.cpp:228] Iteration 154400, loss = 0.00821677
I0930 06:18:42.095878 15120 solver.cpp:244]     Train net output #0: loss = 0.00821676 (* 1 = 0.00821676 loss)
I0930 06:18:42.095878 15120 sgd_solver.cpp:106] Iteration 154400, lr = 0.001
I0930 06:19:01.441608 15120 solver.cpp:228] Iteration 154500, loss = 0.00796214
I0930 06:19:01.441608 15120 solver.cpp:244]     Train net output #0: loss = 0.00796213 (* 1 = 0.00796213 loss)
I0930 06:19:01.441608 15120 sgd_solver.cpp:106] Iteration 154500, lr = 0.001
I0930 06:19:20.777575 15120 solver.cpp:228] Iteration 154600, loss = 0.00910104
I0930 06:19:20.777575 15120 solver.cpp:244]     Train net output #0: loss = 0.00910103 (* 1 = 0.00910103 loss)
I0930 06:19:20.777575 15120 sgd_solver.cpp:106] Iteration 154600, lr = 0.001
I0930 06:19:40.111024 15120 solver.cpp:228] Iteration 154700, loss = 0.0108141
I0930 06:19:40.111024 15120 solver.cpp:244]     Train net output #0: loss = 0.0108141 (* 1 = 0.0108141 loss)
I0930 06:19:40.111024 15120 sgd_solver.cpp:106] Iteration 154700, lr = 0.001
I0930 06:19:59.447865 15120 solver.cpp:228] Iteration 154800, loss = 0.00866164
I0930 06:19:59.447865 15120 solver.cpp:244]     Train net output #0: loss = 0.00866163 (* 1 = 0.00866163 loss)
I0930 06:19:59.447865 15120 sgd_solver.cpp:106] Iteration 154800, lr = 0.001
I0930 06:20:18.769592 15120 solver.cpp:228] Iteration 154900, loss = 0.00871429
I0930 06:20:18.769592 15120 solver.cpp:244]     Train net output #0: loss = 0.00871428 (* 1 = 0.00871428 loss)
I0930 06:20:18.769592 15120 sgd_solver.cpp:106] Iteration 154900, lr = 0.001
I0930 06:20:38.044908 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_155000.caffemodel
I0930 06:20:38.634326 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_155000.solverstate
I0930 06:20:39.008925 15120 solver.cpp:337] Iteration 155000, Testing net (#0)
I0930 06:20:47.190732 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7423
I0930 06:20:47.190732 15120 solver.cpp:404]     Test net output #1: loss = 1.03486 (* 1 = 1.03486 loss)
I0930 06:20:47.241780 15120 solver.cpp:228] Iteration 155000, loss = 0.00779294
I0930 06:20:47.241780 15120 solver.cpp:244]     Train net output #0: loss = 0.00779293 (* 1 = 0.00779293 loss)
I0930 06:20:47.241780 15120 sgd_solver.cpp:106] Iteration 155000, lr = 0.001
I0930 06:21:06.577545 15120 solver.cpp:228] Iteration 155100, loss = 0.0160917
I0930 06:21:06.577545 15120 solver.cpp:244]     Train net output #0: loss = 0.0160917 (* 1 = 0.0160917 loss)
I0930 06:21:06.577545 15120 sgd_solver.cpp:106] Iteration 155100, lr = 0.001
I0930 06:21:25.908718 15120 solver.cpp:228] Iteration 155200, loss = 0.00718831
I0930 06:21:25.908718 15120 solver.cpp:244]     Train net output #0: loss = 0.0071883 (* 1 = 0.0071883 loss)
I0930 06:21:25.908718 15120 sgd_solver.cpp:106] Iteration 155200, lr = 0.001
I0930 06:21:45.229086 15120 solver.cpp:228] Iteration 155300, loss = 0.00742737
I0930 06:21:45.229086 15120 solver.cpp:244]     Train net output #0: loss = 0.00742736 (* 1 = 0.00742736 loss)
I0930 06:21:45.229086 15120 sgd_solver.cpp:106] Iteration 155300, lr = 0.001
I0930 06:22:04.544147 15120 solver.cpp:228] Iteration 155400, loss = 0.0100505
I0930 06:22:04.544147 15120 solver.cpp:244]     Train net output #0: loss = 0.0100505 (* 1 = 0.0100505 loss)
I0930 06:22:04.544147 15120 sgd_solver.cpp:106] Iteration 155400, lr = 0.001
I0930 06:22:23.880553 15120 solver.cpp:228] Iteration 155500, loss = 0.00688565
I0930 06:22:23.880553 15120 solver.cpp:244]     Train net output #0: loss = 0.00688564 (* 1 = 0.00688564 loss)
I0930 06:22:23.880553 15120 sgd_solver.cpp:106] Iteration 155500, lr = 0.001
I0930 06:22:43.231292 15120 solver.cpp:228] Iteration 155600, loss = 0.00922459
I0930 06:22:43.231292 15120 solver.cpp:244]     Train net output #0: loss = 0.00922458 (* 1 = 0.00922458 loss)
I0930 06:22:43.231292 15120 sgd_solver.cpp:106] Iteration 155600, lr = 0.001
I0930 06:23:02.564013 15120 solver.cpp:228] Iteration 155700, loss = 0.0122551
I0930 06:23:02.564013 15120 solver.cpp:244]     Train net output #0: loss = 0.0122551 (* 1 = 0.0122551 loss)
I0930 06:23:02.564013 15120 sgd_solver.cpp:106] Iteration 155700, lr = 0.001
I0930 06:23:21.874804 15120 solver.cpp:228] Iteration 155800, loss = 0.0105119
I0930 06:23:21.874804 15120 solver.cpp:244]     Train net output #0: loss = 0.0105119 (* 1 = 0.0105119 loss)
I0930 06:23:21.874804 15120 sgd_solver.cpp:106] Iteration 155800, lr = 0.001
I0930 06:23:41.200036 15120 solver.cpp:228] Iteration 155900, loss = 0.0103757
I0930 06:23:41.200036 15120 solver.cpp:244]     Train net output #0: loss = 0.0103757 (* 1 = 0.0103757 loss)
I0930 06:23:41.200036 15120 sgd_solver.cpp:106] Iteration 155900, lr = 0.001
I0930 06:24:00.469766 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_156000.caffemodel
I0930 06:24:01.072527 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_156000.solverstate
I0930 06:24:01.427779 15120 solver.cpp:337] Iteration 156000, Testing net (#0)
I0930 06:24:09.586804 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7406
I0930 06:24:09.586804 15120 solver.cpp:404]     Test net output #1: loss = 1.03491 (* 1 = 1.03491 loss)
I0930 06:24:09.636839 15120 solver.cpp:228] Iteration 156000, loss = 0.0101422
I0930 06:24:09.636839 15120 solver.cpp:244]     Train net output #0: loss = 0.0101422 (* 1 = 0.0101422 loss)
I0930 06:24:09.636839 15120 sgd_solver.cpp:106] Iteration 156000, lr = 0.001
I0930 06:24:28.941393 15120 solver.cpp:228] Iteration 156100, loss = 0.0119679
I0930 06:24:28.941393 15120 solver.cpp:244]     Train net output #0: loss = 0.0119679 (* 1 = 0.0119679 loss)
I0930 06:24:28.941393 15120 sgd_solver.cpp:106] Iteration 156100, lr = 0.001
I0930 06:24:48.270112 15120 solver.cpp:228] Iteration 156200, loss = 0.00875171
I0930 06:24:48.270112 15120 solver.cpp:244]     Train net output #0: loss = 0.0087517 (* 1 = 0.0087517 loss)
I0930 06:24:48.270112 15120 sgd_solver.cpp:106] Iteration 156200, lr = 0.001
I0930 06:25:07.600903 15120 solver.cpp:228] Iteration 156300, loss = 0.0127422
I0930 06:25:07.600903 15120 solver.cpp:244]     Train net output #0: loss = 0.0127422 (* 1 = 0.0127422 loss)
I0930 06:25:07.600903 15120 sgd_solver.cpp:106] Iteration 156300, lr = 0.001
I0930 06:25:26.922304 15120 solver.cpp:228] Iteration 156400, loss = 0.00824091
I0930 06:25:26.922304 15120 solver.cpp:244]     Train net output #0: loss = 0.0082409 (* 1 = 0.0082409 loss)
I0930 06:25:26.922304 15120 sgd_solver.cpp:106] Iteration 156400, lr = 0.001
I0930 06:25:46.277531 15120 solver.cpp:228] Iteration 156500, loss = 0.00800893
I0930 06:25:46.277531 15120 solver.cpp:244]     Train net output #0: loss = 0.00800892 (* 1 = 0.00800892 loss)
I0930 06:25:46.277531 15120 sgd_solver.cpp:106] Iteration 156500, lr = 0.001
I0930 06:26:05.617260 15120 solver.cpp:228] Iteration 156600, loss = 0.0102541
I0930 06:26:05.617260 15120 solver.cpp:244]     Train net output #0: loss = 0.0102541 (* 1 = 0.0102541 loss)
I0930 06:26:05.617260 15120 sgd_solver.cpp:106] Iteration 156600, lr = 0.001
I0930 06:26:24.935842 15120 solver.cpp:228] Iteration 156700, loss = 0.0105714
I0930 06:26:24.935842 15120 solver.cpp:244]     Train net output #0: loss = 0.0105714 (* 1 = 0.0105714 loss)
I0930 06:26:24.935842 15120 sgd_solver.cpp:106] Iteration 156700, lr = 0.001
I0930 06:26:44.257118 15120 solver.cpp:228] Iteration 156800, loss = 0.00932794
I0930 06:26:44.257118 15120 solver.cpp:244]     Train net output #0: loss = 0.00932792 (* 1 = 0.00932792 loss)
I0930 06:26:44.257118 15120 sgd_solver.cpp:106] Iteration 156800, lr = 0.001
I0930 06:27:03.604647 15120 solver.cpp:228] Iteration 156900, loss = 0.00742821
I0930 06:27:03.604647 15120 solver.cpp:244]     Train net output #0: loss = 0.0074282 (* 1 = 0.0074282 loss)
I0930 06:27:03.604647 15120 sgd_solver.cpp:106] Iteration 156900, lr = 0.001
I0930 06:27:22.875177 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_157000.caffemodel
I0930 06:27:23.482610 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_157000.solverstate
I0930 06:27:23.835860 15120 solver.cpp:337] Iteration 157000, Testing net (#0)
I0930 06:27:32.009661 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7424
I0930 06:27:32.009661 15120 solver.cpp:404]     Test net output #1: loss = 1.03208 (* 1 = 1.03208 loss)
I0930 06:27:32.059696 15120 solver.cpp:228] Iteration 157000, loss = 0.008711
I0930 06:27:32.060698 15120 solver.cpp:244]     Train net output #0: loss = 0.00871099 (* 1 = 0.00871099 loss)
I0930 06:27:32.060698 15120 sgd_solver.cpp:106] Iteration 157000, lr = 0.001
I0930 06:27:51.410588 15120 solver.cpp:228] Iteration 157100, loss = 0.0144109
I0930 06:27:51.410588 15120 solver.cpp:244]     Train net output #0: loss = 0.0144108 (* 1 = 0.0144108 loss)
I0930 06:27:51.410588 15120 sgd_solver.cpp:106] Iteration 157100, lr = 0.001
I0930 06:28:10.734163 15120 solver.cpp:228] Iteration 157200, loss = 0.0088589
I0930 06:28:10.734163 15120 solver.cpp:244]     Train net output #0: loss = 0.00885889 (* 1 = 0.00885889 loss)
I0930 06:28:10.734163 15120 sgd_solver.cpp:106] Iteration 157200, lr = 0.001
I0930 06:28:30.068197 15120 solver.cpp:228] Iteration 157300, loss = 0.00696127
I0930 06:28:30.068197 15120 solver.cpp:244]     Train net output #0: loss = 0.00696126 (* 1 = 0.00696126 loss)
I0930 06:28:30.068197 15120 sgd_solver.cpp:106] Iteration 157300, lr = 0.001
I0930 06:28:49.416908 15120 solver.cpp:228] Iteration 157400, loss = 0.0127796
I0930 06:28:49.416908 15120 solver.cpp:244]     Train net output #0: loss = 0.0127795 (* 1 = 0.0127795 loss)
I0930 06:28:49.416908 15120 sgd_solver.cpp:106] Iteration 157400, lr = 0.001
I0930 06:29:08.771018 15120 solver.cpp:228] Iteration 157500, loss = 0.0110698
I0930 06:29:08.771018 15120 solver.cpp:244]     Train net output #0: loss = 0.0110698 (* 1 = 0.0110698 loss)
I0930 06:29:08.771018 15120 sgd_solver.cpp:106] Iteration 157500, lr = 0.001
I0930 06:29:28.115552 15120 solver.cpp:228] Iteration 157600, loss = 0.0106057
I0930 06:29:28.115552 15120 solver.cpp:244]     Train net output #0: loss = 0.0106057 (* 1 = 0.0106057 loss)
I0930 06:29:28.115552 15120 sgd_solver.cpp:106] Iteration 157600, lr = 0.001
I0930 06:29:47.457406 15120 solver.cpp:228] Iteration 157700, loss = 0.0116722
I0930 06:29:47.457406 15120 solver.cpp:244]     Train net output #0: loss = 0.0116722 (* 1 = 0.0116722 loss)
I0930 06:29:47.457406 15120 sgd_solver.cpp:106] Iteration 157700, lr = 0.001
I0930 06:30:06.794005 15120 solver.cpp:228] Iteration 157800, loss = 0.00981613
I0930 06:30:06.794005 15120 solver.cpp:244]     Train net output #0: loss = 0.00981612 (* 1 = 0.00981612 loss)
I0930 06:30:06.794005 15120 sgd_solver.cpp:106] Iteration 157800, lr = 0.001
I0930 06:30:26.110716 15120 solver.cpp:228] Iteration 157900, loss = 0.00912204
I0930 06:30:26.110716 15120 solver.cpp:244]     Train net output #0: loss = 0.00912203 (* 1 = 0.00912203 loss)
I0930 06:30:26.110716 15120 sgd_solver.cpp:106] Iteration 157900, lr = 0.001
I0930 06:30:45.383407 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_158000.caffemodel
I0930 06:30:45.977874 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_158000.solverstate
I0930 06:30:46.340131 15120 solver.cpp:337] Iteration 158000, Testing net (#0)
I0930 06:30:54.512621 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7422
I0930 06:30:54.512621 15120 solver.cpp:404]     Test net output #1: loss = 1.03369 (* 1 = 1.03369 loss)
I0930 06:30:54.562659 15120 solver.cpp:228] Iteration 158000, loss = 0.0140813
I0930 06:30:54.562659 15120 solver.cpp:244]     Train net output #0: loss = 0.0140812 (* 1 = 0.0140812 loss)
I0930 06:30:54.562659 15120 sgd_solver.cpp:106] Iteration 158000, lr = 0.001
I0930 06:31:13.892352 15120 solver.cpp:228] Iteration 158100, loss = 0.00764684
I0930 06:31:13.892352 15120 solver.cpp:244]     Train net output #0: loss = 0.00764683 (* 1 = 0.00764683 loss)
I0930 06:31:13.892352 15120 sgd_solver.cpp:106] Iteration 158100, lr = 0.001
I0930 06:31:33.213078 15120 solver.cpp:228] Iteration 158200, loss = 0.0101886
I0930 06:31:33.213078 15120 solver.cpp:244]     Train net output #0: loss = 0.0101886 (* 1 = 0.0101886 loss)
I0930 06:31:33.213078 15120 sgd_solver.cpp:106] Iteration 158200, lr = 0.001
I0930 06:31:52.569816 15120 solver.cpp:228] Iteration 158300, loss = 0.0116171
I0930 06:31:52.569816 15120 solver.cpp:244]     Train net output #0: loss = 0.0116171 (* 1 = 0.0116171 loss)
I0930 06:31:52.569816 15120 sgd_solver.cpp:106] Iteration 158300, lr = 0.001
I0930 06:32:11.903877 15120 solver.cpp:228] Iteration 158400, loss = 0.00853513
I0930 06:32:11.903877 15120 solver.cpp:244]     Train net output #0: loss = 0.00853512 (* 1 = 0.00853512 loss)
I0930 06:32:11.903877 15120 sgd_solver.cpp:106] Iteration 158400, lr = 0.001
I0930 06:32:31.219586 15120 solver.cpp:228] Iteration 158500, loss = 0.0112678
I0930 06:32:31.219586 15120 solver.cpp:244]     Train net output #0: loss = 0.0112678 (* 1 = 0.0112678 loss)
I0930 06:32:31.219586 15120 sgd_solver.cpp:106] Iteration 158500, lr = 0.001
I0930 06:32:50.541369 15120 solver.cpp:228] Iteration 158600, loss = 0.0122083
I0930 06:32:50.541369 15120 solver.cpp:244]     Train net output #0: loss = 0.0122083 (* 1 = 0.0122083 loss)
I0930 06:32:50.541369 15120 sgd_solver.cpp:106] Iteration 158600, lr = 0.001
I0930 06:33:09.879107 15120 solver.cpp:228] Iteration 158700, loss = 0.0110042
I0930 06:33:09.880108 15120 solver.cpp:244]     Train net output #0: loss = 0.0110042 (* 1 = 0.0110042 loss)
I0930 06:33:09.880108 15120 sgd_solver.cpp:106] Iteration 158700, lr = 0.001
I0930 06:33:29.206198 15120 solver.cpp:228] Iteration 158800, loss = 0.0104235
I0930 06:33:29.206198 15120 solver.cpp:244]     Train net output #0: loss = 0.0104234 (* 1 = 0.0104234 loss)
I0930 06:33:29.206198 15120 sgd_solver.cpp:106] Iteration 158800, lr = 0.001
I0930 06:33:48.558735 15120 solver.cpp:228] Iteration 158900, loss = 0.0102175
I0930 06:33:48.558735 15120 solver.cpp:244]     Train net output #0: loss = 0.0102175 (* 1 = 0.0102175 loss)
I0930 06:33:48.558735 15120 sgd_solver.cpp:106] Iteration 158900, lr = 0.001
I0930 06:34:07.835472 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_159000.caffemodel
I0930 06:34:08.443891 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_159000.solverstate
I0930 06:34:08.795025 15120 solver.cpp:337] Iteration 159000, Testing net (#0)
I0930 06:34:16.975589 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7405
I0930 06:34:16.975589 15120 solver.cpp:404]     Test net output #1: loss = 1.03948 (* 1 = 1.03948 loss)
I0930 06:34:17.027626 15120 solver.cpp:228] Iteration 159000, loss = 0.01069
I0930 06:34:17.027626 15120 solver.cpp:244]     Train net output #0: loss = 0.01069 (* 1 = 0.01069 loss)
I0930 06:34:17.027626 15120 sgd_solver.cpp:106] Iteration 159000, lr = 0.001
I0930 06:34:36.359262 15120 solver.cpp:228] Iteration 159100, loss = 0.0138863
I0930 06:34:36.359262 15120 solver.cpp:244]     Train net output #0: loss = 0.0138862 (* 1 = 0.0138862 loss)
I0930 06:34:36.359262 15120 sgd_solver.cpp:106] Iteration 159100, lr = 0.001
I0930 06:34:55.684978 15120 solver.cpp:228] Iteration 159200, loss = 0.00731944
I0930 06:34:55.684978 15120 solver.cpp:244]     Train net output #0: loss = 0.00731944 (* 1 = 0.00731944 loss)
I0930 06:34:55.684978 15120 sgd_solver.cpp:106] Iteration 159200, lr = 0.001
I0930 06:35:15.052726 15120 solver.cpp:228] Iteration 159300, loss = 0.0100711
I0930 06:35:15.052726 15120 solver.cpp:244]     Train net output #0: loss = 0.010071 (* 1 = 0.010071 loss)
I0930 06:35:15.052726 15120 sgd_solver.cpp:106] Iteration 159300, lr = 0.001
I0930 06:35:34.406474 15120 solver.cpp:228] Iteration 159400, loss = 0.0110435
I0930 06:35:34.406474 15120 solver.cpp:244]     Train net output #0: loss = 0.0110435 (* 1 = 0.0110435 loss)
I0930 06:35:34.406474 15120 sgd_solver.cpp:106] Iteration 159400, lr = 0.001
I0930 06:35:53.736193 15120 solver.cpp:228] Iteration 159500, loss = 0.00733365
I0930 06:35:53.736193 15120 solver.cpp:244]     Train net output #0: loss = 0.00733364 (* 1 = 0.00733364 loss)
I0930 06:35:53.736193 15120 sgd_solver.cpp:106] Iteration 159500, lr = 0.001
I0930 06:36:13.082911 15120 solver.cpp:228] Iteration 159600, loss = 0.0108305
I0930 06:36:13.083912 15120 solver.cpp:244]     Train net output #0: loss = 0.0108304 (* 1 = 0.0108304 loss)
I0930 06:36:13.083912 15120 sgd_solver.cpp:106] Iteration 159600, lr = 0.001
I0930 06:36:32.420234 15120 solver.cpp:228] Iteration 159700, loss = 0.014315
I0930 06:36:32.420234 15120 solver.cpp:244]     Train net output #0: loss = 0.014315 (* 1 = 0.014315 loss)
I0930 06:36:32.420234 15120 sgd_solver.cpp:106] Iteration 159700, lr = 0.001
I0930 06:36:51.766132 15120 solver.cpp:228] Iteration 159800, loss = 0.00990877
I0930 06:36:51.766132 15120 solver.cpp:244]     Train net output #0: loss = 0.00990876 (* 1 = 0.00990876 loss)
I0930 06:36:51.766132 15120 sgd_solver.cpp:106] Iteration 159800, lr = 0.001
I0930 06:37:11.090606 15120 solver.cpp:228] Iteration 159900, loss = 0.0100501
I0930 06:37:11.090606 15120 solver.cpp:244]     Train net output #0: loss = 0.0100501 (* 1 = 0.0100501 loss)
I0930 06:37:11.090606 15120 sgd_solver.cpp:106] Iteration 159900, lr = 0.001
I0930 06:37:30.369148 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_160000.caffemodel
I0930 06:37:30.961567 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_160000.solverstate
I0930 06:37:31.336107 15120 solver.cpp:337] Iteration 160000, Testing net (#0)
I0930 06:37:39.508906 15120 solver.cpp:404]     Test net output #0: accuracy = 0.741
I0930 06:37:39.509907 15120 solver.cpp:404]     Test net output #1: loss = 1.03113 (* 1 = 1.03113 loss)
I0930 06:37:39.558954 15120 solver.cpp:228] Iteration 160000, loss = 0.00888805
I0930 06:37:39.558954 15120 solver.cpp:244]     Train net output #0: loss = 0.00888804 (* 1 = 0.00888804 loss)
I0930 06:37:39.559957 15120 sgd_solver.cpp:106] Iteration 160000, lr = 0.001
I0930 06:37:58.884706 15120 solver.cpp:228] Iteration 160100, loss = 0.0109296
I0930 06:37:58.884706 15120 solver.cpp:244]     Train net output #0: loss = 0.0109296 (* 1 = 0.0109296 loss)
I0930 06:37:58.884706 15120 sgd_solver.cpp:106] Iteration 160100, lr = 0.001
I0930 06:38:18.220522 15120 solver.cpp:228] Iteration 160200, loss = 0.00917567
I0930 06:38:18.220522 15120 solver.cpp:244]     Train net output #0: loss = 0.00917567 (* 1 = 0.00917567 loss)
I0930 06:38:18.220522 15120 sgd_solver.cpp:106] Iteration 160200, lr = 0.001
I0930 06:38:37.564566 15120 solver.cpp:228] Iteration 160300, loss = 0.0131038
I0930 06:38:37.565567 15120 solver.cpp:244]     Train net output #0: loss = 0.0131038 (* 1 = 0.0131038 loss)
I0930 06:38:37.565567 15120 sgd_solver.cpp:106] Iteration 160300, lr = 0.001
I0930 06:38:56.889295 15120 solver.cpp:228] Iteration 160400, loss = 0.0100165
I0930 06:38:56.889295 15120 solver.cpp:244]     Train net output #0: loss = 0.0100165 (* 1 = 0.0100165 loss)
I0930 06:38:56.889295 15120 sgd_solver.cpp:106] Iteration 160400, lr = 0.001
I0930 06:39:16.211843 15120 solver.cpp:228] Iteration 160500, loss = 0.00967885
I0930 06:39:16.211843 15120 solver.cpp:244]     Train net output #0: loss = 0.00967884 (* 1 = 0.00967884 loss)
I0930 06:39:16.211843 15120 sgd_solver.cpp:106] Iteration 160500, lr = 0.001
I0930 06:39:35.537467 15120 solver.cpp:228] Iteration 160600, loss = 0.0105667
I0930 06:39:35.537467 15120 solver.cpp:244]     Train net output #0: loss = 0.0105667 (* 1 = 0.0105667 loss)
I0930 06:39:35.537467 15120 sgd_solver.cpp:106] Iteration 160600, lr = 0.001
I0930 06:39:54.870187 15120 solver.cpp:228] Iteration 160700, loss = 0.00952697
I0930 06:39:54.870187 15120 solver.cpp:244]     Train net output #0: loss = 0.00952696 (* 1 = 0.00952696 loss)
I0930 06:39:54.870187 15120 sgd_solver.cpp:106] Iteration 160700, lr = 0.001
I0930 06:40:14.209926 15120 solver.cpp:228] Iteration 160800, loss = 0.00943051
I0930 06:40:14.209926 15120 solver.cpp:244]     Train net output #0: loss = 0.0094305 (* 1 = 0.0094305 loss)
I0930 06:40:14.209926 15120 sgd_solver.cpp:106] Iteration 160800, lr = 0.001
I0930 06:40:33.531626 15120 solver.cpp:228] Iteration 160900, loss = 0.00898777
I0930 06:40:33.531626 15120 solver.cpp:244]     Train net output #0: loss = 0.00898776 (* 1 = 0.00898776 loss)
I0930 06:40:33.531626 15120 sgd_solver.cpp:106] Iteration 160900, lr = 0.001
I0930 06:40:52.806377 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_161000.caffemodel
I0930 06:40:53.400799 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_161000.solverstate
I0930 06:40:53.750061 15120 solver.cpp:337] Iteration 161000, Testing net (#0)
I0930 06:41:01.929368 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7436
I0930 06:41:01.929368 15120 solver.cpp:404]     Test net output #1: loss = 1.02709 (* 1 = 1.02709 loss)
I0930 06:41:01.979404 15120 solver.cpp:228] Iteration 161000, loss = 0.00773348
I0930 06:41:01.979404 15120 solver.cpp:244]     Train net output #0: loss = 0.00773347 (* 1 = 0.00773347 loss)
I0930 06:41:01.979404 15120 sgd_solver.cpp:106] Iteration 161000, lr = 0.001
I0930 06:41:21.307854 15120 solver.cpp:228] Iteration 161100, loss = 0.0111833
I0930 06:41:21.307854 15120 solver.cpp:244]     Train net output #0: loss = 0.0111833 (* 1 = 0.0111833 loss)
I0930 06:41:21.307854 15120 sgd_solver.cpp:106] Iteration 161100, lr = 0.001
I0930 06:41:40.649297 15120 solver.cpp:228] Iteration 161200, loss = 0.00657264
I0930 06:41:40.649297 15120 solver.cpp:244]     Train net output #0: loss = 0.00657263 (* 1 = 0.00657263 loss)
I0930 06:41:40.649297 15120 sgd_solver.cpp:106] Iteration 161200, lr = 0.001
I0930 06:41:59.964993 15120 solver.cpp:228] Iteration 161300, loss = 0.0110565
I0930 06:41:59.964993 15120 solver.cpp:244]     Train net output #0: loss = 0.0110565 (* 1 = 0.0110565 loss)
I0930 06:41:59.964993 15120 sgd_solver.cpp:106] Iteration 161300, lr = 0.001
I0930 06:42:19.287562 15120 solver.cpp:228] Iteration 161400, loss = 0.00844689
I0930 06:42:19.287562 15120 solver.cpp:244]     Train net output #0: loss = 0.00844688 (* 1 = 0.00844688 loss)
I0930 06:42:19.287562 15120 sgd_solver.cpp:106] Iteration 161400, lr = 0.001
I0930 06:42:38.615092 15120 solver.cpp:228] Iteration 161500, loss = 0.00831554
I0930 06:42:38.615092 15120 solver.cpp:244]     Train net output #0: loss = 0.00831553 (* 1 = 0.00831553 loss)
I0930 06:42:38.615092 15120 sgd_solver.cpp:106] Iteration 161500, lr = 0.001
I0930 06:42:57.937806 15120 solver.cpp:228] Iteration 161600, loss = 0.00845362
I0930 06:42:57.937806 15120 solver.cpp:244]     Train net output #0: loss = 0.00845361 (* 1 = 0.00845361 loss)
I0930 06:42:57.937806 15120 sgd_solver.cpp:106] Iteration 161600, lr = 0.001
I0930 06:43:17.269371 15120 solver.cpp:228] Iteration 161700, loss = 0.0115135
I0930 06:43:17.269371 15120 solver.cpp:244]     Train net output #0: loss = 0.0115135 (* 1 = 0.0115135 loss)
I0930 06:43:17.269371 15120 sgd_solver.cpp:106] Iteration 161700, lr = 0.001
I0930 06:43:36.602622 15120 solver.cpp:228] Iteration 161800, loss = 0.0101969
I0930 06:43:36.602622 15120 solver.cpp:244]     Train net output #0: loss = 0.0101969 (* 1 = 0.0101969 loss)
I0930 06:43:36.602622 15120 sgd_solver.cpp:106] Iteration 161800, lr = 0.001
I0930 06:43:55.922582 15120 solver.cpp:228] Iteration 161900, loss = 0.010343
I0930 06:43:55.922582 15120 solver.cpp:244]     Train net output #0: loss = 0.010343 (* 1 = 0.010343 loss)
I0930 06:43:55.922582 15120 sgd_solver.cpp:106] Iteration 161900, lr = 0.001
I0930 06:44:15.191689 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_162000.caffemodel
I0930 06:44:15.812999 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_162000.solverstate
I0930 06:44:16.179258 15120 solver.cpp:337] Iteration 162000, Testing net (#0)
I0930 06:44:24.353868 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7415
I0930 06:44:24.353868 15120 solver.cpp:404]     Test net output #1: loss = 1.03128 (* 1 = 1.03128 loss)
I0930 06:44:24.403903 15120 solver.cpp:228] Iteration 162000, loss = 0.0102008
I0930 06:44:24.403903 15120 solver.cpp:244]     Train net output #0: loss = 0.0102008 (* 1 = 0.0102008 loss)
I0930 06:44:24.403903 15120 sgd_solver.cpp:106] Iteration 162000, lr = 0.001
I0930 06:44:43.734948 15120 solver.cpp:228] Iteration 162100, loss = 0.008906
I0930 06:44:43.734948 15120 solver.cpp:244]     Train net output #0: loss = 0.008906 (* 1 = 0.008906 loss)
I0930 06:44:43.734948 15120 sgd_solver.cpp:106] Iteration 162100, lr = 0.001
I0930 06:45:03.073674 15120 solver.cpp:228] Iteration 162200, loss = 0.00776874
I0930 06:45:03.073674 15120 solver.cpp:244]     Train net output #0: loss = 0.00776873 (* 1 = 0.00776873 loss)
I0930 06:45:03.073674 15120 sgd_solver.cpp:106] Iteration 162200, lr = 0.001
I0930 06:45:22.399349 15120 solver.cpp:228] Iteration 162300, loss = 0.0115395
I0930 06:45:22.399349 15120 solver.cpp:244]     Train net output #0: loss = 0.0115395 (* 1 = 0.0115395 loss)
I0930 06:45:22.399349 15120 sgd_solver.cpp:106] Iteration 162300, lr = 0.001
I0930 06:45:41.715487 15120 solver.cpp:228] Iteration 162400, loss = 0.00900016
I0930 06:45:41.715487 15120 solver.cpp:244]     Train net output #0: loss = 0.00900015 (* 1 = 0.00900015 loss)
I0930 06:45:41.715487 15120 sgd_solver.cpp:106] Iteration 162400, lr = 0.001
I0930 06:46:01.036555 15120 solver.cpp:228] Iteration 162500, loss = 0.00801921
I0930 06:46:01.036555 15120 solver.cpp:244]     Train net output #0: loss = 0.00801921 (* 1 = 0.00801921 loss)
I0930 06:46:01.036555 15120 sgd_solver.cpp:106] Iteration 162500, lr = 0.001
I0930 06:46:20.365348 15120 solver.cpp:228] Iteration 162600, loss = 0.00816483
I0930 06:46:20.365348 15120 solver.cpp:244]     Train net output #0: loss = 0.00816482 (* 1 = 0.00816482 loss)
I0930 06:46:20.365348 15120 sgd_solver.cpp:106] Iteration 162600, lr = 0.001
I0930 06:46:39.684100 15120 solver.cpp:228] Iteration 162700, loss = 0.00799095
I0930 06:46:39.684100 15120 solver.cpp:244]     Train net output #0: loss = 0.00799094 (* 1 = 0.00799094 loss)
I0930 06:46:39.684100 15120 sgd_solver.cpp:106] Iteration 162700, lr = 0.001
I0930 06:46:59.021826 15120 solver.cpp:228] Iteration 162800, loss = 0.0111556
I0930 06:46:59.021826 15120 solver.cpp:244]     Train net output #0: loss = 0.0111556 (* 1 = 0.0111556 loss)
I0930 06:46:59.021826 15120 sgd_solver.cpp:106] Iteration 162800, lr = 0.001
I0930 06:47:18.345540 15120 solver.cpp:228] Iteration 162900, loss = 0.00871749
I0930 06:47:18.345540 15120 solver.cpp:244]     Train net output #0: loss = 0.00871748 (* 1 = 0.00871748 loss)
I0930 06:47:18.345540 15120 sgd_solver.cpp:106] Iteration 162900, lr = 0.001
I0930 06:47:37.619477 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_163000.caffemodel
I0930 06:47:38.228910 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_163000.solverstate
I0930 06:47:38.583128 15120 solver.cpp:337] Iteration 163000, Testing net (#0)
I0930 06:47:46.750035 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7424
I0930 06:47:46.750035 15120 solver.cpp:404]     Test net output #1: loss = 1.03584 (* 1 = 1.03584 loss)
I0930 06:47:46.800071 15120 solver.cpp:228] Iteration 163000, loss = 0.00935218
I0930 06:47:46.800071 15120 solver.cpp:244]     Train net output #0: loss = 0.00935218 (* 1 = 0.00935218 loss)
I0930 06:47:46.800071 15120 sgd_solver.cpp:106] Iteration 163000, lr = 0.001
I0930 06:48:06.137802 15120 solver.cpp:228] Iteration 163100, loss = 0.00858843
I0930 06:48:06.137802 15120 solver.cpp:244]     Train net output #0: loss = 0.00858842 (* 1 = 0.00858842 loss)
I0930 06:48:06.137802 15120 sgd_solver.cpp:106] Iteration 163100, lr = 0.001
I0930 06:48:25.474581 15120 solver.cpp:228] Iteration 163200, loss = 0.00901573
I0930 06:48:25.475582 15120 solver.cpp:244]     Train net output #0: loss = 0.00901572 (* 1 = 0.00901572 loss)
I0930 06:48:25.475582 15120 sgd_solver.cpp:106] Iteration 163200, lr = 0.001
I0930 06:48:44.834322 15120 solver.cpp:228] Iteration 163300, loss = 0.0110101
I0930 06:48:44.834322 15120 solver.cpp:244]     Train net output #0: loss = 0.0110101 (* 1 = 0.0110101 loss)
I0930 06:48:44.834322 15120 sgd_solver.cpp:106] Iteration 163300, lr = 0.001
I0930 06:49:04.158854 15120 solver.cpp:228] Iteration 163400, loss = 0.00831203
I0930 06:49:04.158854 15120 solver.cpp:244]     Train net output #0: loss = 0.00831202 (* 1 = 0.00831202 loss)
I0930 06:49:04.158854 15120 sgd_solver.cpp:106] Iteration 163400, lr = 0.001
I0930 06:49:23.482537 15120 solver.cpp:228] Iteration 163500, loss = 0.0095347
I0930 06:49:23.482537 15120 solver.cpp:244]     Train net output #0: loss = 0.0095347 (* 1 = 0.0095347 loss)
I0930 06:49:23.482537 15120 sgd_solver.cpp:106] Iteration 163500, lr = 0.001
I0930 06:49:42.813000 15120 solver.cpp:228] Iteration 163600, loss = 0.00900455
I0930 06:49:42.813000 15120 solver.cpp:244]     Train net output #0: loss = 0.00900454 (* 1 = 0.00900454 loss)
I0930 06:49:42.813000 15120 sgd_solver.cpp:106] Iteration 163600, lr = 0.001
I0930 06:50:02.155045 15120 solver.cpp:228] Iteration 163700, loss = 0.00895566
I0930 06:50:02.155045 15120 solver.cpp:244]     Train net output #0: loss = 0.00895565 (* 1 = 0.00895565 loss)
I0930 06:50:02.156046 15120 sgd_solver.cpp:106] Iteration 163700, lr = 0.001
I0930 06:50:21.470754 15120 solver.cpp:228] Iteration 163800, loss = 0.00999295
I0930 06:50:21.470754 15120 solver.cpp:244]     Train net output #0: loss = 0.00999295 (* 1 = 0.00999295 loss)
I0930 06:50:21.470754 15120 sgd_solver.cpp:106] Iteration 163800, lr = 0.001
I0930 06:50:40.795482 15120 solver.cpp:228] Iteration 163900, loss = 0.00925424
I0930 06:50:40.796484 15120 solver.cpp:244]     Train net output #0: loss = 0.00925423 (* 1 = 0.00925423 loss)
I0930 06:50:40.796484 15120 sgd_solver.cpp:106] Iteration 163900, lr = 0.001
I0930 06:51:00.069149 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_164000.caffemodel
I0930 06:51:00.657483 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_164000.solverstate
I0930 06:51:01.011735 15120 solver.cpp:337] Iteration 164000, Testing net (#0)
I0930 06:51:09.212057 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7414
I0930 06:51:09.212057 15120 solver.cpp:404]     Test net output #1: loss = 1.02957 (* 1 = 1.02957 loss)
I0930 06:51:09.262105 15120 solver.cpp:228] Iteration 164000, loss = 0.00921849
I0930 06:51:09.262105 15120 solver.cpp:244]     Train net output #0: loss = 0.00921848 (* 1 = 0.00921848 loss)
I0930 06:51:09.262105 15120 sgd_solver.cpp:106] Iteration 164000, lr = 0.001
I0930 06:51:28.586791 15120 solver.cpp:228] Iteration 164100, loss = 0.0118103
I0930 06:51:28.586791 15120 solver.cpp:244]     Train net output #0: loss = 0.0118103 (* 1 = 0.0118103 loss)
I0930 06:51:28.586791 15120 sgd_solver.cpp:106] Iteration 164100, lr = 0.001
I0930 06:51:47.923501 15120 solver.cpp:228] Iteration 164200, loss = 0.00836751
I0930 06:51:47.923501 15120 solver.cpp:244]     Train net output #0: loss = 0.0083675 (* 1 = 0.0083675 loss)
I0930 06:51:47.923501 15120 sgd_solver.cpp:106] Iteration 164200, lr = 0.001
I0930 06:52:07.287257 15120 solver.cpp:228] Iteration 164300, loss = 0.00918328
I0930 06:52:07.287257 15120 solver.cpp:244]     Train net output #0: loss = 0.00918328 (* 1 = 0.00918328 loss)
I0930 06:52:07.287257 15120 sgd_solver.cpp:106] Iteration 164300, lr = 0.001
I0930 06:52:26.600791 15120 solver.cpp:228] Iteration 164400, loss = 0.00853566
I0930 06:52:26.600791 15120 solver.cpp:244]     Train net output #0: loss = 0.00853565 (* 1 = 0.00853565 loss)
I0930 06:52:26.600791 15120 sgd_solver.cpp:106] Iteration 164400, lr = 0.001
I0930 06:52:45.928509 15120 solver.cpp:228] Iteration 164500, loss = 0.00862071
I0930 06:52:45.928509 15120 solver.cpp:244]     Train net output #0: loss = 0.0086207 (* 1 = 0.0086207 loss)
I0930 06:52:45.928509 15120 sgd_solver.cpp:106] Iteration 164500, lr = 0.001
I0930 06:53:05.249222 15120 solver.cpp:228] Iteration 164600, loss = 0.0127958
I0930 06:53:05.249222 15120 solver.cpp:244]     Train net output #0: loss = 0.0127958 (* 1 = 0.0127958 loss)
I0930 06:53:05.249222 15120 sgd_solver.cpp:106] Iteration 164600, lr = 0.001
I0930 06:53:24.569934 15120 solver.cpp:228] Iteration 164700, loss = 0.0105845
I0930 06:53:24.569934 15120 solver.cpp:244]     Train net output #0: loss = 0.0105845 (* 1 = 0.0105845 loss)
I0930 06:53:24.569934 15120 sgd_solver.cpp:106] Iteration 164700, lr = 0.001
I0930 06:53:43.891649 15120 solver.cpp:228] Iteration 164800, loss = 0.0122378
I0930 06:53:43.891649 15120 solver.cpp:244]     Train net output #0: loss = 0.0122378 (* 1 = 0.0122378 loss)
I0930 06:53:43.891649 15120 sgd_solver.cpp:106] Iteration 164800, lr = 0.001
I0930 06:54:03.227262 15120 solver.cpp:228] Iteration 164900, loss = 0.0100981
I0930 06:54:03.227262 15120 solver.cpp:244]     Train net output #0: loss = 0.010098 (* 1 = 0.010098 loss)
I0930 06:54:03.227262 15120 sgd_solver.cpp:106] Iteration 164900, lr = 0.001
I0930 06:54:22.505902 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_165000.caffemodel
I0930 06:54:23.107329 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_165000.solverstate
I0930 06:54:23.483764 15120 solver.cpp:337] Iteration 165000, Testing net (#0)
I0930 06:54:31.656846 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0930 06:54:31.656846 15120 solver.cpp:404]     Test net output #1: loss = 1.02146 (* 1 = 1.02146 loss)
I0930 06:54:31.706894 15120 solver.cpp:228] Iteration 165000, loss = 0.0102907
I0930 06:54:31.706894 15120 solver.cpp:244]     Train net output #0: loss = 0.0102907 (* 1 = 0.0102907 loss)
I0930 06:54:31.706894 15120 sgd_solver.cpp:106] Iteration 165000, lr = 0.001
I0930 06:54:51.023900 15120 solver.cpp:228] Iteration 165100, loss = 0.0114548
I0930 06:54:51.023900 15120 solver.cpp:244]     Train net output #0: loss = 0.0114548 (* 1 = 0.0114548 loss)
I0930 06:54:51.023900 15120 sgd_solver.cpp:106] Iteration 165100, lr = 0.001
I0930 06:55:10.341609 15120 solver.cpp:228] Iteration 165200, loss = 0.00900299
I0930 06:55:10.341609 15120 solver.cpp:244]     Train net output #0: loss = 0.00900299 (* 1 = 0.00900299 loss)
I0930 06:55:10.341609 15120 sgd_solver.cpp:106] Iteration 165200, lr = 0.001
I0930 06:55:29.656708 15120 solver.cpp:228] Iteration 165300, loss = 0.0124823
I0930 06:55:29.656708 15120 solver.cpp:244]     Train net output #0: loss = 0.0124823 (* 1 = 0.0124823 loss)
I0930 06:55:29.656708 15120 sgd_solver.cpp:106] Iteration 165300, lr = 0.001
I0930 06:55:48.982429 15120 solver.cpp:228] Iteration 165400, loss = 0.00954968
I0930 06:55:48.982429 15120 solver.cpp:244]     Train net output #0: loss = 0.00954967 (* 1 = 0.00954967 loss)
I0930 06:55:48.982429 15120 sgd_solver.cpp:106] Iteration 165400, lr = 0.001
I0930 06:56:08.327167 15120 solver.cpp:228] Iteration 165500, loss = 0.0133107
I0930 06:56:08.327167 15120 solver.cpp:244]     Train net output #0: loss = 0.0133107 (* 1 = 0.0133107 loss)
I0930 06:56:08.327167 15120 sgd_solver.cpp:106] Iteration 165500, lr = 0.001
I0930 06:56:27.646878 15120 solver.cpp:228] Iteration 165600, loss = 0.015112
I0930 06:56:27.646878 15120 solver.cpp:244]     Train net output #0: loss = 0.015112 (* 1 = 0.015112 loss)
I0930 06:56:27.646878 15120 sgd_solver.cpp:106] Iteration 165600, lr = 0.001
I0930 06:56:46.989433 15120 solver.cpp:228] Iteration 165700, loss = 0.0103606
I0930 06:56:46.989433 15120 solver.cpp:244]     Train net output #0: loss = 0.0103606 (* 1 = 0.0103606 loss)
I0930 06:56:46.989433 15120 sgd_solver.cpp:106] Iteration 165700, lr = 0.001
I0930 06:57:06.317163 15120 solver.cpp:228] Iteration 165800, loss = 0.00936535
I0930 06:57:06.317163 15120 solver.cpp:244]     Train net output #0: loss = 0.00936535 (* 1 = 0.00936535 loss)
I0930 06:57:06.317163 15120 sgd_solver.cpp:106] Iteration 165800, lr = 0.001
I0930 06:57:25.635861 15120 solver.cpp:228] Iteration 165900, loss = 0.0098494
I0930 06:57:25.636862 15120 solver.cpp:244]     Train net output #0: loss = 0.00984939 (* 1 = 0.00984939 loss)
I0930 06:57:25.636862 15120 sgd_solver.cpp:106] Iteration 165900, lr = 0.001
I0930 06:57:44.924904 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_166000.caffemodel
I0930 06:57:45.598829 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_166000.solverstate
I0930 06:57:45.951076 15120 solver.cpp:337] Iteration 166000, Testing net (#0)
I0930 06:57:54.122895 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7404
I0930 06:57:54.122895 15120 solver.cpp:404]     Test net output #1: loss = 1.03019 (* 1 = 1.03019 loss)
I0930 06:57:54.173931 15120 solver.cpp:228] Iteration 166000, loss = 0.00914032
I0930 06:57:54.173931 15120 solver.cpp:244]     Train net output #0: loss = 0.00914031 (* 1 = 0.00914031 loss)
I0930 06:57:54.173931 15120 sgd_solver.cpp:106] Iteration 166000, lr = 0.001
I0930 06:58:13.493630 15120 solver.cpp:228] Iteration 166100, loss = 0.0117466
I0930 06:58:13.493630 15120 solver.cpp:244]     Train net output #0: loss = 0.0117466 (* 1 = 0.0117466 loss)
I0930 06:58:13.493630 15120 sgd_solver.cpp:106] Iteration 166100, lr = 0.001
I0930 06:58:32.830354 15120 solver.cpp:228] Iteration 166200, loss = 0.00718415
I0930 06:58:32.830354 15120 solver.cpp:244]     Train net output #0: loss = 0.00718415 (* 1 = 0.00718415 loss)
I0930 06:58:32.830354 15120 sgd_solver.cpp:106] Iteration 166200, lr = 0.001
I0930 06:58:52.159216 15120 solver.cpp:228] Iteration 166300, loss = 0.0112263
I0930 06:58:52.159216 15120 solver.cpp:244]     Train net output #0: loss = 0.0112263 (* 1 = 0.0112263 loss)
I0930 06:58:52.159216 15120 sgd_solver.cpp:106] Iteration 166300, lr = 0.001
I0930 06:59:11.490016 15120 solver.cpp:228] Iteration 166400, loss = 0.0123233
I0930 06:59:11.490016 15120 solver.cpp:244]     Train net output #0: loss = 0.0123233 (* 1 = 0.0123233 loss)
I0930 06:59:11.490016 15120 sgd_solver.cpp:106] Iteration 166400, lr = 0.001
I0930 06:59:30.815807 15120 solver.cpp:228] Iteration 166500, loss = 0.0157644
I0930 06:59:30.815807 15120 solver.cpp:244]     Train net output #0: loss = 0.0157644 (* 1 = 0.0157644 loss)
I0930 06:59:30.815807 15120 sgd_solver.cpp:106] Iteration 166500, lr = 0.001
I0930 06:59:50.148545 15120 solver.cpp:228] Iteration 166600, loss = 0.0102088
I0930 06:59:50.148545 15120 solver.cpp:244]     Train net output #0: loss = 0.0102088 (* 1 = 0.0102088 loss)
I0930 06:59:50.148545 15120 sgd_solver.cpp:106] Iteration 166600, lr = 0.001
I0930 07:00:09.784939 15120 solver.cpp:228] Iteration 166700, loss = 0.00870822
I0930 07:00:09.784939 15120 solver.cpp:244]     Train net output #0: loss = 0.00870821 (* 1 = 0.00870821 loss)
I0930 07:00:09.784939 15120 sgd_solver.cpp:106] Iteration 166700, lr = 0.001
I0930 07:00:29.175771 15120 solver.cpp:228] Iteration 166800, loss = 0.00904519
I0930 07:00:29.176772 15120 solver.cpp:244]     Train net output #0: loss = 0.00904518 (* 1 = 0.00904518 loss)
I0930 07:00:29.176772 15120 sgd_solver.cpp:106] Iteration 166800, lr = 0.001
I0930 07:00:48.501962 15120 solver.cpp:228] Iteration 166900, loss = 0.00848633
I0930 07:00:48.501962 15120 solver.cpp:244]     Train net output #0: loss = 0.00848633 (* 1 = 0.00848633 loss)
I0930 07:00:48.501962 15120 sgd_solver.cpp:106] Iteration 166900, lr = 0.001
I0930 07:01:07.801669 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_167000.caffemodel
I0930 07:01:08.409091 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_167000.solverstate
I0930 07:01:08.768347 15120 solver.cpp:337] Iteration 167000, Testing net (#0)
I0930 07:01:16.930783 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7423
I0930 07:01:16.930783 15120 solver.cpp:404]     Test net output #1: loss = 1.02685 (* 1 = 1.02685 loss)
I0930 07:01:16.980831 15120 solver.cpp:228] Iteration 167000, loss = 0.0143196
I0930 07:01:16.980831 15120 solver.cpp:244]     Train net output #0: loss = 0.0143195 (* 1 = 0.0143195 loss)
I0930 07:01:16.980831 15120 sgd_solver.cpp:106] Iteration 167000, lr = 0.001
I0930 07:01:36.678172 15120 solver.cpp:228] Iteration 167100, loss = 0.00997716
I0930 07:01:36.678172 15120 solver.cpp:244]     Train net output #0: loss = 0.00997715 (* 1 = 0.00997715 loss)
I0930 07:01:36.678172 15120 sgd_solver.cpp:106] Iteration 167100, lr = 0.001
I0930 07:01:56.136806 15120 solver.cpp:228] Iteration 167200, loss = 0.00834229
I0930 07:01:56.136806 15120 solver.cpp:244]     Train net output #0: loss = 0.00834229 (* 1 = 0.00834229 loss)
I0930 07:01:56.136806 15120 sgd_solver.cpp:106] Iteration 167200, lr = 0.001
I0930 07:02:15.608189 15120 solver.cpp:228] Iteration 167300, loss = 0.0106632
I0930 07:02:15.608189 15120 solver.cpp:244]     Train net output #0: loss = 0.0106632 (* 1 = 0.0106632 loss)
I0930 07:02:15.608189 15120 sgd_solver.cpp:106] Iteration 167300, lr = 0.001
I0930 07:02:35.044214 15120 solver.cpp:228] Iteration 167400, loss = 0.00974747
I0930 07:02:35.045214 15120 solver.cpp:244]     Train net output #0: loss = 0.00974747 (* 1 = 0.00974747 loss)
I0930 07:02:35.045214 15120 sgd_solver.cpp:106] Iteration 167400, lr = 0.001
I0930 07:02:54.440507 15120 solver.cpp:228] Iteration 167500, loss = 0.00862828
I0930 07:02:54.440507 15120 solver.cpp:244]     Train net output #0: loss = 0.00862828 (* 1 = 0.00862828 loss)
I0930 07:02:54.440507 15120 sgd_solver.cpp:106] Iteration 167500, lr = 0.001
I0930 07:03:13.827914 15120 solver.cpp:228] Iteration 167600, loss = 0.0108566
I0930 07:03:13.827914 15120 solver.cpp:244]     Train net output #0: loss = 0.0108566 (* 1 = 0.0108566 loss)
I0930 07:03:13.827914 15120 sgd_solver.cpp:106] Iteration 167600, lr = 0.001
I0930 07:03:33.215401 15120 solver.cpp:228] Iteration 167700, loss = 0.0129229
I0930 07:03:33.215401 15120 solver.cpp:244]     Train net output #0: loss = 0.0129229 (* 1 = 0.0129229 loss)
I0930 07:03:33.215401 15120 sgd_solver.cpp:106] Iteration 167700, lr = 0.001
I0930 07:03:52.617172 15120 solver.cpp:228] Iteration 167800, loss = 0.00964381
I0930 07:03:52.617172 15120 solver.cpp:244]     Train net output #0: loss = 0.0096438 (* 1 = 0.0096438 loss)
I0930 07:03:52.617172 15120 sgd_solver.cpp:106] Iteration 167800, lr = 0.001
I0930 07:04:12.010345 15120 solver.cpp:228] Iteration 167900, loss = 0.0104908
I0930 07:04:12.010345 15120 solver.cpp:244]     Train net output #0: loss = 0.0104908 (* 1 = 0.0104908 loss)
I0930 07:04:12.010345 15120 sgd_solver.cpp:106] Iteration 167900, lr = 0.001
I0930 07:04:31.348124 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_168000.caffemodel
I0930 07:04:31.947536 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_168000.solverstate
I0930 07:04:32.312795 15120 solver.cpp:337] Iteration 168000, Testing net (#0)
I0930 07:04:40.486798 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7404
I0930 07:04:40.486798 15120 solver.cpp:404]     Test net output #1: loss = 1.03576 (* 1 = 1.03576 loss)
I0930 07:04:40.537834 15120 solver.cpp:228] Iteration 168000, loss = 0.00881158
I0930 07:04:40.537834 15120 solver.cpp:244]     Train net output #0: loss = 0.00881157 (* 1 = 0.00881157 loss)
I0930 07:04:40.537834 15120 sgd_solver.cpp:106] Iteration 168000, lr = 0.001
I0930 07:04:59.947641 15120 solver.cpp:228] Iteration 168100, loss = 0.0120328
I0930 07:04:59.947641 15120 solver.cpp:244]     Train net output #0: loss = 0.0120328 (* 1 = 0.0120328 loss)
I0930 07:04:59.947641 15120 sgd_solver.cpp:106] Iteration 168100, lr = 0.001
I0930 07:05:19.329903 15120 solver.cpp:228] Iteration 168200, loss = 0.00858512
I0930 07:05:19.329903 15120 solver.cpp:244]     Train net output #0: loss = 0.00858511 (* 1 = 0.00858511 loss)
I0930 07:05:19.329903 15120 sgd_solver.cpp:106] Iteration 168200, lr = 0.001
I0930 07:05:38.710515 15120 solver.cpp:228] Iteration 168300, loss = 0.0126994
I0930 07:05:38.710515 15120 solver.cpp:244]     Train net output #0: loss = 0.0126994 (* 1 = 0.0126994 loss)
I0930 07:05:38.710515 15120 sgd_solver.cpp:106] Iteration 168300, lr = 0.001
I0930 07:05:58.075258 15120 solver.cpp:228] Iteration 168400, loss = 0.0098146
I0930 07:05:58.075258 15120 solver.cpp:244]     Train net output #0: loss = 0.00981459 (* 1 = 0.00981459 loss)
I0930 07:05:58.075258 15120 sgd_solver.cpp:106] Iteration 168400, lr = 0.001
I0930 07:06:17.455153 15120 solver.cpp:228] Iteration 168500, loss = 0.0120905
I0930 07:06:17.455153 15120 solver.cpp:244]     Train net output #0: loss = 0.0120905 (* 1 = 0.0120905 loss)
I0930 07:06:17.455153 15120 sgd_solver.cpp:106] Iteration 168500, lr = 0.001
I0930 07:06:36.829041 15120 solver.cpp:228] Iteration 168600, loss = 0.0117186
I0930 07:06:36.829041 15120 solver.cpp:244]     Train net output #0: loss = 0.0117186 (* 1 = 0.0117186 loss)
I0930 07:06:36.829041 15120 sgd_solver.cpp:106] Iteration 168600, lr = 0.001
I0930 07:06:56.210796 15120 solver.cpp:228] Iteration 168700, loss = 0.00827192
I0930 07:06:56.210796 15120 solver.cpp:244]     Train net output #0: loss = 0.00827192 (* 1 = 0.00827192 loss)
I0930 07:06:56.210796 15120 sgd_solver.cpp:106] Iteration 168700, lr = 0.001
I0930 07:07:15.584547 15120 solver.cpp:228] Iteration 168800, loss = 0.0116023
I0930 07:07:15.584547 15120 solver.cpp:244]     Train net output #0: loss = 0.0116023 (* 1 = 0.0116023 loss)
I0930 07:07:15.584547 15120 sgd_solver.cpp:106] Iteration 168800, lr = 0.001
I0930 07:07:35.032428 15120 solver.cpp:228] Iteration 168900, loss = 0.00988382
I0930 07:07:35.032428 15120 solver.cpp:244]     Train net output #0: loss = 0.00988382 (* 1 = 0.00988382 loss)
I0930 07:07:35.032428 15120 sgd_solver.cpp:106] Iteration 168900, lr = 0.001
I0930 07:07:54.369782 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_169000.caffemodel
I0930 07:07:55.008514 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_169000.solverstate
I0930 07:07:55.377776 15120 solver.cpp:337] Iteration 169000, Testing net (#0)
I0930 07:08:03.582645 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7415
I0930 07:08:03.582645 15120 solver.cpp:404]     Test net output #1: loss = 1.03451 (* 1 = 1.03451 loss)
I0930 07:08:03.632680 15120 solver.cpp:228] Iteration 169000, loss = 0.0108931
I0930 07:08:03.632680 15120 solver.cpp:244]     Train net output #0: loss = 0.0108931 (* 1 = 0.0108931 loss)
I0930 07:08:03.632680 15120 sgd_solver.cpp:106] Iteration 169000, lr = 0.001
I0930 07:08:23.029942 15120 solver.cpp:228] Iteration 169100, loss = 0.00837981
I0930 07:08:23.029942 15120 solver.cpp:244]     Train net output #0: loss = 0.0083798 (* 1 = 0.0083798 loss)
I0930 07:08:23.029942 15120 sgd_solver.cpp:106] Iteration 169100, lr = 0.001
I0930 07:08:42.444679 15120 solver.cpp:228] Iteration 169200, loss = 0.00833388
I0930 07:08:42.444679 15120 solver.cpp:244]     Train net output #0: loss = 0.00833388 (* 1 = 0.00833388 loss)
I0930 07:08:42.444679 15120 sgd_solver.cpp:106] Iteration 169200, lr = 0.001
I0930 07:09:01.828865 15120 solver.cpp:228] Iteration 169300, loss = 0.0104407
I0930 07:09:01.828865 15120 solver.cpp:244]     Train net output #0: loss = 0.0104407 (* 1 = 0.0104407 loss)
I0930 07:09:01.828865 15120 sgd_solver.cpp:106] Iteration 169300, lr = 0.001
I0930 07:09:21.214637 15120 solver.cpp:228] Iteration 169400, loss = 0.00931584
I0930 07:09:21.214637 15120 solver.cpp:244]     Train net output #0: loss = 0.00931583 (* 1 = 0.00931583 loss)
I0930 07:09:21.214637 15120 sgd_solver.cpp:106] Iteration 169400, lr = 0.001
I0930 07:09:40.602254 15120 solver.cpp:228] Iteration 169500, loss = 0.00949304
I0930 07:09:40.602254 15120 solver.cpp:244]     Train net output #0: loss = 0.00949304 (* 1 = 0.00949304 loss)
I0930 07:09:40.602254 15120 sgd_solver.cpp:106] Iteration 169500, lr = 0.001
I0930 07:09:59.992827 15120 solver.cpp:228] Iteration 169600, loss = 0.0150128
I0930 07:09:59.992827 15120 solver.cpp:244]     Train net output #0: loss = 0.0150128 (* 1 = 0.0150128 loss)
I0930 07:09:59.992827 15120 sgd_solver.cpp:106] Iteration 169600, lr = 0.001
I0930 07:10:19.414698 15120 solver.cpp:228] Iteration 169700, loss = 0.0130181
I0930 07:10:19.414698 15120 solver.cpp:244]     Train net output #0: loss = 0.0130181 (* 1 = 0.0130181 loss)
I0930 07:10:19.414698 15120 sgd_solver.cpp:106] Iteration 169700, lr = 0.001
I0930 07:10:38.811640 15120 solver.cpp:228] Iteration 169800, loss = 0.0116775
I0930 07:10:38.811640 15120 solver.cpp:244]     Train net output #0: loss = 0.0116775 (* 1 = 0.0116775 loss)
I0930 07:10:38.811640 15120 sgd_solver.cpp:106] Iteration 169800, lr = 0.001
I0930 07:10:58.197160 15120 solver.cpp:228] Iteration 169900, loss = 0.00747558
I0930 07:10:58.197160 15120 solver.cpp:244]     Train net output #0: loss = 0.00747558 (* 1 = 0.00747558 loss)
I0930 07:10:58.197160 15120 sgd_solver.cpp:106] Iteration 169900, lr = 0.001
I0930 07:11:17.530661 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_170000.caffemodel
I0930 07:11:18.137662 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_170000.solverstate
I0930 07:11:18.489912 15120 solver.cpp:337] Iteration 170000, Testing net (#0)
I0930 07:11:26.685729 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7418
I0930 07:11:26.685729 15120 solver.cpp:404]     Test net output #1: loss = 1.02102 (* 1 = 1.02102 loss)
I0930 07:11:26.735764 15120 solver.cpp:228] Iteration 170000, loss = 0.0109803
I0930 07:11:26.736765 15120 solver.cpp:244]     Train net output #0: loss = 0.0109803 (* 1 = 0.0109803 loss)
I0930 07:11:26.736765 15120 sgd_solver.cpp:106] Iteration 170000, lr = 0.001
I0930 07:11:46.128528 15120 solver.cpp:228] Iteration 170100, loss = 0.0099479
I0930 07:11:46.128528 15120 solver.cpp:244]     Train net output #0: loss = 0.0099479 (* 1 = 0.0099479 loss)
I0930 07:11:46.128528 15120 sgd_solver.cpp:106] Iteration 170100, lr = 0.001
I0930 07:12:05.495671 15120 solver.cpp:228] Iteration 170200, loss = 0.00762679
I0930 07:12:05.495671 15120 solver.cpp:244]     Train net output #0: loss = 0.00762679 (* 1 = 0.00762679 loss)
I0930 07:12:05.496671 15120 sgd_solver.cpp:106] Iteration 170200, lr = 0.001
I0930 07:12:24.861428 15120 solver.cpp:228] Iteration 170300, loss = 0.0084259
I0930 07:12:24.861428 15120 solver.cpp:244]     Train net output #0: loss = 0.0084259 (* 1 = 0.0084259 loss)
I0930 07:12:24.861428 15120 sgd_solver.cpp:106] Iteration 170300, lr = 0.001
I0930 07:12:44.237224 15120 solver.cpp:228] Iteration 170400, loss = 0.00872578
I0930 07:12:44.237224 15120 solver.cpp:244]     Train net output #0: loss = 0.00872578 (* 1 = 0.00872578 loss)
I0930 07:12:44.237224 15120 sgd_solver.cpp:106] Iteration 170400, lr = 0.001
I0930 07:13:03.608265 15120 solver.cpp:228] Iteration 170500, loss = 0.00848348
I0930 07:13:03.608265 15120 solver.cpp:244]     Train net output #0: loss = 0.00848348 (* 1 = 0.00848348 loss)
I0930 07:13:03.608265 15120 sgd_solver.cpp:106] Iteration 170500, lr = 0.001
I0930 07:13:22.989715 15120 solver.cpp:228] Iteration 170600, loss = 0.0103548
I0930 07:13:22.989715 15120 solver.cpp:244]     Train net output #0: loss = 0.0103548 (* 1 = 0.0103548 loss)
I0930 07:13:22.989715 15120 sgd_solver.cpp:106] Iteration 170600, lr = 0.001
I0930 07:13:42.362478 15120 solver.cpp:228] Iteration 170700, loss = 0.00907018
I0930 07:13:42.362478 15120 solver.cpp:244]     Train net output #0: loss = 0.00907018 (* 1 = 0.00907018 loss)
I0930 07:13:42.362478 15120 sgd_solver.cpp:106] Iteration 170700, lr = 0.001
I0930 07:14:01.745218 15120 solver.cpp:228] Iteration 170800, loss = 0.0115866
I0930 07:14:01.745218 15120 solver.cpp:244]     Train net output #0: loss = 0.0115866 (* 1 = 0.0115866 loss)
I0930 07:14:01.745218 15120 sgd_solver.cpp:106] Iteration 170800, lr = 0.001
I0930 07:14:21.110079 15120 solver.cpp:228] Iteration 170900, loss = 0.0103436
I0930 07:14:21.110079 15120 solver.cpp:244]     Train net output #0: loss = 0.0103436 (* 1 = 0.0103436 loss)
I0930 07:14:21.110079 15120 sgd_solver.cpp:106] Iteration 170900, lr = 0.001
I0930 07:14:40.437796 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_171000.caffemodel
I0930 07:14:41.050104 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_171000.solverstate
I0930 07:14:41.403354 15120 solver.cpp:337] Iteration 171000, Testing net (#0)
I0930 07:14:49.594995 15120 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0930 07:14:49.594995 15120 solver.cpp:404]     Test net output #1: loss = 1.02264 (* 1 = 1.02264 loss)
I0930 07:14:49.646030 15120 solver.cpp:228] Iteration 171000, loss = 0.00971305
I0930 07:14:49.646030 15120 solver.cpp:244]     Train net output #0: loss = 0.00971305 (* 1 = 0.00971305 loss)
I0930 07:14:49.646030 15120 sgd_solver.cpp:106] Iteration 171000, lr = 0.001
I0930 07:15:09.025686 15120 solver.cpp:228] Iteration 171100, loss = 0.0107783
I0930 07:15:09.025686 15120 solver.cpp:244]     Train net output #0: loss = 0.0107783 (* 1 = 0.0107783 loss)
I0930 07:15:09.025686 15120 sgd_solver.cpp:106] Iteration 171100, lr = 0.001
I0930 07:15:28.395498 15120 solver.cpp:228] Iteration 171200, loss = 0.00744083
I0930 07:15:28.395498 15120 solver.cpp:244]     Train net output #0: loss = 0.00744083 (* 1 = 0.00744083 loss)
I0930 07:15:28.395498 15120 sgd_solver.cpp:106] Iteration 171200, lr = 0.001
I0930 07:15:47.790647 15120 solver.cpp:228] Iteration 171300, loss = 0.00964691
I0930 07:15:47.790647 15120 solver.cpp:244]     Train net output #0: loss = 0.00964691 (* 1 = 0.00964691 loss)
I0930 07:15:47.790647 15120 sgd_solver.cpp:106] Iteration 171300, lr = 0.001
I0930 07:16:07.224725 15120 solver.cpp:228] Iteration 171400, loss = 0.01033
I0930 07:16:07.224725 15120 solver.cpp:244]     Train net output #0: loss = 0.01033 (* 1 = 0.01033 loss)
I0930 07:16:07.224725 15120 sgd_solver.cpp:106] Iteration 171400, lr = 0.001
I0930 07:16:26.675530 15120 solver.cpp:228] Iteration 171500, loss = 0.00965789
I0930 07:16:26.675530 15120 solver.cpp:244]     Train net output #0: loss = 0.00965789 (* 1 = 0.00965789 loss)
I0930 07:16:26.675530 15120 sgd_solver.cpp:106] Iteration 171500, lr = 0.001
I0930 07:16:46.147351 15120 solver.cpp:228] Iteration 171600, loss = 0.00944548
I0930 07:16:46.148351 15120 solver.cpp:244]     Train net output #0: loss = 0.00944548 (* 1 = 0.00944548 loss)
I0930 07:16:46.148351 15120 sgd_solver.cpp:106] Iteration 171600, lr = 0.001
I0930 07:17:05.567343 15120 solver.cpp:228] Iteration 171700, loss = 0.00868877
I0930 07:17:05.567343 15120 solver.cpp:244]     Train net output #0: loss = 0.00868877 (* 1 = 0.00868877 loss)
I0930 07:17:05.567343 15120 sgd_solver.cpp:106] Iteration 171700, lr = 0.001
I0930 07:17:25.006139 15120 solver.cpp:228] Iteration 171800, loss = 0.00839604
I0930 07:17:25.006139 15120 solver.cpp:244]     Train net output #0: loss = 0.00839604 (* 1 = 0.00839604 loss)
I0930 07:17:25.006139 15120 sgd_solver.cpp:106] Iteration 171800, lr = 0.001
I0930 07:17:44.413914 15120 solver.cpp:228] Iteration 171900, loss = 0.00816666
I0930 07:17:44.413914 15120 solver.cpp:244]     Train net output #0: loss = 0.00816666 (* 1 = 0.00816666 loss)
I0930 07:17:44.413914 15120 sgd_solver.cpp:106] Iteration 171900, lr = 0.001
I0930 07:18:03.928946 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_172000.caffemodel
I0930 07:18:04.570401 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_172000.solverstate
I0930 07:18:04.946668 15120 solver.cpp:337] Iteration 172000, Testing net (#0)
I0930 07:18:13.168503 15120 solver.cpp:404]     Test net output #0: accuracy = 0.745
I0930 07:18:13.168503 15120 solver.cpp:404]     Test net output #1: loss = 1.02461 (* 1 = 1.02461 loss)
I0930 07:18:13.220541 15120 solver.cpp:228] Iteration 172000, loss = 0.00799397
I0930 07:18:13.220541 15120 solver.cpp:244]     Train net output #0: loss = 0.00799397 (* 1 = 0.00799397 loss)
I0930 07:18:13.220541 15120 sgd_solver.cpp:106] Iteration 172000, lr = 0.001
I0930 07:18:32.602231 15120 solver.cpp:228] Iteration 172100, loss = 0.00981436
I0930 07:18:32.602231 15120 solver.cpp:244]     Train net output #0: loss = 0.00981436 (* 1 = 0.00981436 loss)
I0930 07:18:32.602231 15120 sgd_solver.cpp:106] Iteration 172100, lr = 0.001
I0930 07:18:52.021013 15120 solver.cpp:228] Iteration 172200, loss = 0.00755092
I0930 07:18:52.021013 15120 solver.cpp:244]     Train net output #0: loss = 0.00755092 (* 1 = 0.00755092 loss)
I0930 07:18:52.021013 15120 sgd_solver.cpp:106] Iteration 172200, lr = 0.001
I0930 07:19:11.389652 15120 solver.cpp:228] Iteration 172300, loss = 0.0118007
I0930 07:19:11.389652 15120 solver.cpp:244]     Train net output #0: loss = 0.0118007 (* 1 = 0.0118007 loss)
I0930 07:19:11.389652 15120 sgd_solver.cpp:106] Iteration 172300, lr = 0.001
I0930 07:19:30.787420 15120 solver.cpp:228] Iteration 172400, loss = 0.0103705
I0930 07:19:30.787420 15120 solver.cpp:244]     Train net output #0: loss = 0.0103705 (* 1 = 0.0103705 loss)
I0930 07:19:30.787420 15120 sgd_solver.cpp:106] Iteration 172400, lr = 0.001
I0930 07:19:50.179713 15120 solver.cpp:228] Iteration 172500, loss = 0.0117399
I0930 07:19:50.179713 15120 solver.cpp:244]     Train net output #0: loss = 0.0117399 (* 1 = 0.0117399 loss)
I0930 07:19:50.179713 15120 sgd_solver.cpp:106] Iteration 172500, lr = 0.001
I0930 07:20:09.603703 15120 solver.cpp:228] Iteration 172600, loss = 0.00986097
I0930 07:20:09.603703 15120 solver.cpp:244]     Train net output #0: loss = 0.00986097 (* 1 = 0.00986097 loss)
I0930 07:20:09.603703 15120 sgd_solver.cpp:106] Iteration 172600, lr = 0.001
I0930 07:20:28.968708 15120 solver.cpp:228] Iteration 172700, loss = 0.00806162
I0930 07:20:28.968708 15120 solver.cpp:244]     Train net output #0: loss = 0.00806162 (* 1 = 0.00806162 loss)
I0930 07:20:28.968708 15120 sgd_solver.cpp:106] Iteration 172700, lr = 0.001
I0930 07:20:48.346210 15120 solver.cpp:228] Iteration 172800, loss = 0.0116738
I0930 07:20:48.346210 15120 solver.cpp:244]     Train net output #0: loss = 0.0116738 (* 1 = 0.0116738 loss)
I0930 07:20:48.346210 15120 sgd_solver.cpp:106] Iteration 172800, lr = 0.001
I0930 07:21:07.707726 15120 solver.cpp:228] Iteration 172900, loss = 0.00778255
I0930 07:21:07.707726 15120 solver.cpp:244]     Train net output #0: loss = 0.00778255 (* 1 = 0.00778255 loss)
I0930 07:21:07.707726 15120 sgd_solver.cpp:106] Iteration 172900, lr = 0.001
I0930 07:21:27.040002 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_173000.caffemodel
I0930 07:21:27.638003 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_173000.solverstate
I0930 07:21:27.985250 15120 solver.cpp:337] Iteration 173000, Testing net (#0)
I0930 07:21:36.185258 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7421
I0930 07:21:36.185258 15120 solver.cpp:404]     Test net output #1: loss = 1.02149 (* 1 = 1.02149 loss)
I0930 07:21:36.235306 15120 solver.cpp:228] Iteration 173000, loss = 0.00782117
I0930 07:21:36.236307 15120 solver.cpp:244]     Train net output #0: loss = 0.00782118 (* 1 = 0.00782118 loss)
I0930 07:21:36.236307 15120 sgd_solver.cpp:106] Iteration 173000, lr = 0.001
I0930 07:21:55.626056 15120 solver.cpp:228] Iteration 173100, loss = 0.0111693
I0930 07:21:55.626056 15120 solver.cpp:244]     Train net output #0: loss = 0.0111693 (* 1 = 0.0111693 loss)
I0930 07:21:55.626056 15120 sgd_solver.cpp:106] Iteration 173100, lr = 0.001
I0930 07:22:15.006222 15120 solver.cpp:228] Iteration 173200, loss = 0.00669669
I0930 07:22:15.006222 15120 solver.cpp:244]     Train net output #0: loss = 0.00669669 (* 1 = 0.00669669 loss)
I0930 07:22:15.006222 15120 sgd_solver.cpp:106] Iteration 173200, lr = 0.001
I0930 07:22:34.398054 15120 solver.cpp:228] Iteration 173300, loss = 0.00939145
I0930 07:22:34.398054 15120 solver.cpp:244]     Train net output #0: loss = 0.00939145 (* 1 = 0.00939145 loss)
I0930 07:22:34.398054 15120 sgd_solver.cpp:106] Iteration 173300, lr = 0.001
I0930 07:22:53.792687 15120 solver.cpp:228] Iteration 173400, loss = 0.0098965
I0930 07:22:53.792687 15120 solver.cpp:244]     Train net output #0: loss = 0.0098965 (* 1 = 0.0098965 loss)
I0930 07:22:53.792687 15120 sgd_solver.cpp:106] Iteration 173400, lr = 0.001
I0930 07:23:13.161600 15120 solver.cpp:228] Iteration 173500, loss = 0.00689688
I0930 07:23:13.161600 15120 solver.cpp:244]     Train net output #0: loss = 0.00689688 (* 1 = 0.00689688 loss)
I0930 07:23:13.161600 15120 sgd_solver.cpp:106] Iteration 173500, lr = 0.001
I0930 07:23:32.526865 15120 solver.cpp:228] Iteration 173600, loss = 0.0101419
I0930 07:23:32.526865 15120 solver.cpp:244]     Train net output #0: loss = 0.0101419 (* 1 = 0.0101419 loss)
I0930 07:23:32.526865 15120 sgd_solver.cpp:106] Iteration 173600, lr = 0.001
I0930 07:23:51.928308 15120 solver.cpp:228] Iteration 173700, loss = 0.0092406
I0930 07:23:51.928308 15120 solver.cpp:244]     Train net output #0: loss = 0.0092406 (* 1 = 0.0092406 loss)
I0930 07:23:51.928308 15120 sgd_solver.cpp:106] Iteration 173700, lr = 0.001
I0930 07:24:11.303045 15120 solver.cpp:228] Iteration 173800, loss = 0.00962563
I0930 07:24:11.303045 15120 solver.cpp:244]     Train net output #0: loss = 0.00962563 (* 1 = 0.00962563 loss)
I0930 07:24:11.303045 15120 sgd_solver.cpp:106] Iteration 173800, lr = 0.001
I0930 07:24:30.776981 15120 solver.cpp:228] Iteration 173900, loss = 0.00750244
I0930 07:24:30.776981 15120 solver.cpp:244]     Train net output #0: loss = 0.00750244 (* 1 = 0.00750244 loss)
I0930 07:24:30.776981 15120 sgd_solver.cpp:106] Iteration 173900, lr = 0.001
I0930 07:24:50.178751 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_174000.caffemodel
I0930 07:24:50.854226 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_174000.solverstate
I0930 07:24:51.207476 15120 solver.cpp:337] Iteration 174000, Testing net (#0)
I0930 07:24:59.411063 15120 solver.cpp:404]     Test net output #0: accuracy = 0.743
I0930 07:24:59.411063 15120 solver.cpp:404]     Test net output #1: loss = 1.01859 (* 1 = 1.01859 loss)
I0930 07:24:59.461112 15120 solver.cpp:228] Iteration 174000, loss = 0.00974429
I0930 07:24:59.461112 15120 solver.cpp:244]     Train net output #0: loss = 0.00974429 (* 1 = 0.00974429 loss)
I0930 07:24:59.461112 15120 sgd_solver.cpp:106] Iteration 174000, lr = 0.001
I0930 07:25:18.871440 15120 solver.cpp:228] Iteration 174100, loss = 0.0106286
I0930 07:25:18.871440 15120 solver.cpp:244]     Train net output #0: loss = 0.0106286 (* 1 = 0.0106286 loss)
I0930 07:25:18.871440 15120 sgd_solver.cpp:106] Iteration 174100, lr = 0.001
I0930 07:25:38.256198 15120 solver.cpp:228] Iteration 174200, loss = 0.00791466
I0930 07:25:38.256198 15120 solver.cpp:244]     Train net output #0: loss = 0.00791466 (* 1 = 0.00791466 loss)
I0930 07:25:38.256198 15120 sgd_solver.cpp:106] Iteration 174200, lr = 0.001
I0930 07:25:57.633988 15120 solver.cpp:228] Iteration 174300, loss = 0.00745131
I0930 07:25:57.633988 15120 solver.cpp:244]     Train net output #0: loss = 0.00745131 (* 1 = 0.00745131 loss)
I0930 07:25:57.633988 15120 sgd_solver.cpp:106] Iteration 174300, lr = 0.001
I0930 07:26:17.025259 15120 solver.cpp:228] Iteration 174400, loss = 0.0108749
I0930 07:26:17.026258 15120 solver.cpp:244]     Train net output #0: loss = 0.0108749 (* 1 = 0.0108749 loss)
I0930 07:26:17.026258 15120 sgd_solver.cpp:106] Iteration 174400, lr = 0.001
I0930 07:26:36.392016 15120 solver.cpp:228] Iteration 174500, loss = 0.00822148
I0930 07:26:36.392016 15120 solver.cpp:244]     Train net output #0: loss = 0.00822148 (* 1 = 0.00822148 loss)
I0930 07:26:36.392016 15120 sgd_solver.cpp:106] Iteration 174500, lr = 0.001
I0930 07:26:55.780041 15120 solver.cpp:228] Iteration 174600, loss = 0.00900129
I0930 07:26:55.780041 15120 solver.cpp:244]     Train net output #0: loss = 0.00900129 (* 1 = 0.00900129 loss)
I0930 07:26:55.780041 15120 sgd_solver.cpp:106] Iteration 174600, lr = 0.001
I0930 07:27:15.158236 15120 solver.cpp:228] Iteration 174700, loss = 0.0084953
I0930 07:27:15.158236 15120 solver.cpp:244]     Train net output #0: loss = 0.00849531 (* 1 = 0.00849531 loss)
I0930 07:27:15.158236 15120 sgd_solver.cpp:106] Iteration 174700, lr = 0.001
I0930 07:27:34.558728 15120 solver.cpp:228] Iteration 174800, loss = 0.00878045
I0930 07:27:34.558728 15120 solver.cpp:244]     Train net output #0: loss = 0.00878045 (* 1 = 0.00878045 loss)
I0930 07:27:34.558728 15120 sgd_solver.cpp:106] Iteration 174800, lr = 0.001
I0930 07:27:53.944541 15120 solver.cpp:228] Iteration 174900, loss = 0.0103941
I0930 07:27:53.944541 15120 solver.cpp:244]     Train net output #0: loss = 0.0103941 (* 1 = 0.0103941 loss)
I0930 07:27:53.944541 15120 sgd_solver.cpp:106] Iteration 174900, lr = 0.001
I0930 07:28:13.273676 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_175000.caffemodel
I0930 07:28:13.969913 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_175000.solverstate
I0930 07:28:14.323163 15120 solver.cpp:337] Iteration 175000, Testing net (#0)
I0930 07:28:22.502096 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7418
I0930 07:28:22.502096 15120 solver.cpp:404]     Test net output #1: loss = 1.02217 (* 1 = 1.02217 loss)
I0930 07:28:22.552131 15120 solver.cpp:228] Iteration 175000, loss = 0.00691949
I0930 07:28:22.552131 15120 solver.cpp:244]     Train net output #0: loss = 0.00691949 (* 1 = 0.00691949 loss)
I0930 07:28:22.552131 15120 sgd_solver.cpp:106] Iteration 175000, lr = 0.001
I0930 07:28:41.937918 15120 solver.cpp:228] Iteration 175100, loss = 0.0109746
I0930 07:28:41.937918 15120 solver.cpp:244]     Train net output #0: loss = 0.0109746 (* 1 = 0.0109746 loss)
I0930 07:28:41.937918 15120 sgd_solver.cpp:106] Iteration 175100, lr = 0.001
I0930 07:29:01.330550 15120 solver.cpp:228] Iteration 175200, loss = 0.00936777
I0930 07:29:01.330550 15120 solver.cpp:244]     Train net output #0: loss = 0.00936777 (* 1 = 0.00936777 loss)
I0930 07:29:01.330550 15120 sgd_solver.cpp:106] Iteration 175200, lr = 0.001
I0930 07:29:20.716639 15120 solver.cpp:228] Iteration 175300, loss = 0.00935083
I0930 07:29:20.716639 15120 solver.cpp:244]     Train net output #0: loss = 0.00935084 (* 1 = 0.00935084 loss)
I0930 07:29:20.716639 15120 sgd_solver.cpp:106] Iteration 175300, lr = 0.001
I0930 07:29:40.084408 15120 solver.cpp:228] Iteration 175400, loss = 0.00980846
I0930 07:29:40.084408 15120 solver.cpp:244]     Train net output #0: loss = 0.00980846 (* 1 = 0.00980846 loss)
I0930 07:29:40.084408 15120 sgd_solver.cpp:106] Iteration 175400, lr = 0.001
I0930 07:29:59.464679 15120 solver.cpp:228] Iteration 175500, loss = 0.00763082
I0930 07:29:59.464679 15120 solver.cpp:244]     Train net output #0: loss = 0.00763082 (* 1 = 0.00763082 loss)
I0930 07:29:59.464679 15120 sgd_solver.cpp:106] Iteration 175500, lr = 0.001
I0930 07:30:18.872985 15120 solver.cpp:228] Iteration 175600, loss = 0.0128011
I0930 07:30:18.872985 15120 solver.cpp:244]     Train net output #0: loss = 0.0128011 (* 1 = 0.0128011 loss)
I0930 07:30:18.872985 15120 sgd_solver.cpp:106] Iteration 175600, lr = 0.001
I0930 07:30:38.257743 15120 solver.cpp:228] Iteration 175700, loss = 0.00988453
I0930 07:30:38.257743 15120 solver.cpp:244]     Train net output #0: loss = 0.00988453 (* 1 = 0.00988453 loss)
I0930 07:30:38.257743 15120 sgd_solver.cpp:106] Iteration 175700, lr = 0.001
I0930 07:30:57.633496 15120 solver.cpp:228] Iteration 175800, loss = 0.0108855
I0930 07:30:57.633496 15120 solver.cpp:244]     Train net output #0: loss = 0.0108855 (* 1 = 0.0108855 loss)
I0930 07:30:57.633496 15120 sgd_solver.cpp:106] Iteration 175800, lr = 0.001
I0930 07:31:17.038931 15120 solver.cpp:228] Iteration 175900, loss = 0.0106102
I0930 07:31:17.038931 15120 solver.cpp:244]     Train net output #0: loss = 0.0106102 (* 1 = 0.0106102 loss)
I0930 07:31:17.038931 15120 sgd_solver.cpp:106] Iteration 175900, lr = 0.001
I0930 07:31:36.370721 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_176000.caffemodel
I0930 07:31:36.988062 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_176000.solverstate
I0930 07:31:37.335310 15120 solver.cpp:337] Iteration 176000, Testing net (#0)
I0930 07:31:45.533524 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0930 07:31:45.533524 15120 solver.cpp:404]     Test net output #1: loss = 1.01796 (* 1 = 1.01796 loss)
I0930 07:31:45.586562 15120 solver.cpp:228] Iteration 176000, loss = 0.00816038
I0930 07:31:45.586562 15120 solver.cpp:244]     Train net output #0: loss = 0.00816039 (* 1 = 0.00816039 loss)
I0930 07:31:45.586562 15120 sgd_solver.cpp:106] Iteration 176000, lr = 0.001
I0930 07:32:04.967989 15120 solver.cpp:228] Iteration 176100, loss = 0.0110371
I0930 07:32:04.967989 15120 solver.cpp:244]     Train net output #0: loss = 0.0110371 (* 1 = 0.0110371 loss)
I0930 07:32:04.967989 15120 sgd_solver.cpp:106] Iteration 176100, lr = 0.001
I0930 07:32:24.351569 15120 solver.cpp:228] Iteration 176200, loss = 0.00640346
I0930 07:32:24.351569 15120 solver.cpp:244]     Train net output #0: loss = 0.00640346 (* 1 = 0.00640346 loss)
I0930 07:32:24.351569 15120 sgd_solver.cpp:106] Iteration 176200, lr = 0.001
I0930 07:32:43.747741 15120 solver.cpp:228] Iteration 176300, loss = 0.0106187
I0930 07:32:43.747741 15120 solver.cpp:244]     Train net output #0: loss = 0.0106187 (* 1 = 0.0106187 loss)
I0930 07:32:43.747741 15120 sgd_solver.cpp:106] Iteration 176300, lr = 0.001
I0930 07:33:03.140260 15120 solver.cpp:228] Iteration 176400, loss = 0.0133427
I0930 07:33:03.140260 15120 solver.cpp:244]     Train net output #0: loss = 0.0133427 (* 1 = 0.0133427 loss)
I0930 07:33:03.140260 15120 sgd_solver.cpp:106] Iteration 176400, lr = 0.001
I0930 07:33:22.533063 15120 solver.cpp:228] Iteration 176500, loss = 0.00766051
I0930 07:33:22.533063 15120 solver.cpp:244]     Train net output #0: loss = 0.00766052 (* 1 = 0.00766052 loss)
I0930 07:33:22.533063 15120 sgd_solver.cpp:106] Iteration 176500, lr = 0.001
I0930 07:33:41.935040 15120 solver.cpp:228] Iteration 176600, loss = 0.00935738
I0930 07:33:41.935040 15120 solver.cpp:244]     Train net output #0: loss = 0.00935739 (* 1 = 0.00935739 loss)
I0930 07:33:41.935040 15120 sgd_solver.cpp:106] Iteration 176600, lr = 0.001
I0930 07:34:01.308789 15120 solver.cpp:228] Iteration 176700, loss = 0.00821928
I0930 07:34:01.308789 15120 solver.cpp:244]     Train net output #0: loss = 0.00821928 (* 1 = 0.00821928 loss)
I0930 07:34:01.308789 15120 sgd_solver.cpp:106] Iteration 176700, lr = 0.001
I0930 07:34:20.700593 15120 solver.cpp:228] Iteration 176800, loss = 0.00840124
I0930 07:34:20.701594 15120 solver.cpp:244]     Train net output #0: loss = 0.00840125 (* 1 = 0.00840125 loss)
I0930 07:34:20.701594 15120 sgd_solver.cpp:106] Iteration 176800, lr = 0.001
I0930 07:34:40.121471 15120 solver.cpp:228] Iteration 176900, loss = 0.0087805
I0930 07:34:40.121471 15120 solver.cpp:244]     Train net output #0: loss = 0.0087805 (* 1 = 0.0087805 loss)
I0930 07:34:40.121471 15120 sgd_solver.cpp:106] Iteration 176900, lr = 0.001
I0930 07:34:59.461197 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_177000.caffemodel
I0930 07:35:00.177901 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_177000.solverstate
I0930 07:35:00.532152 15120 solver.cpp:337] Iteration 177000, Testing net (#0)
I0930 07:35:08.719868 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7437
I0930 07:35:08.719868 15120 solver.cpp:404]     Test net output #1: loss = 1.01546 (* 1 = 1.01546 loss)
I0930 07:35:08.770905 15120 solver.cpp:228] Iteration 177000, loss = 0.00847843
I0930 07:35:08.770905 15120 solver.cpp:244]     Train net output #0: loss = 0.00847844 (* 1 = 0.00847844 loss)
I0930 07:35:08.770905 15120 sgd_solver.cpp:106] Iteration 177000, lr = 0.001
I0930 07:35:28.162752 15120 solver.cpp:228] Iteration 177100, loss = 0.010153
I0930 07:35:28.163753 15120 solver.cpp:244]     Train net output #0: loss = 0.010153 (* 1 = 0.010153 loss)
I0930 07:35:28.163753 15120 sgd_solver.cpp:106] Iteration 177100, lr = 0.001
I0930 07:35:47.544813 15120 solver.cpp:228] Iteration 177200, loss = 0.00584021
I0930 07:35:47.545814 15120 solver.cpp:244]     Train net output #0: loss = 0.00584022 (* 1 = 0.00584022 loss)
I0930 07:35:47.545814 15120 sgd_solver.cpp:106] Iteration 177200, lr = 0.001
I0930 07:36:06.951871 15120 solver.cpp:228] Iteration 177300, loss = 0.00863881
I0930 07:36:06.951871 15120 solver.cpp:244]     Train net output #0: loss = 0.00863881 (* 1 = 0.00863881 loss)
I0930 07:36:06.951871 15120 sgd_solver.cpp:106] Iteration 177300, lr = 0.001
I0930 07:36:26.427695 15120 solver.cpp:228] Iteration 177400, loss = 0.00826437
I0930 07:36:26.427695 15120 solver.cpp:244]     Train net output #0: loss = 0.00826438 (* 1 = 0.00826438 loss)
I0930 07:36:26.427695 15120 sgd_solver.cpp:106] Iteration 177400, lr = 0.001
I0930 07:36:45.907519 15120 solver.cpp:228] Iteration 177500, loss = 0.00919825
I0930 07:36:45.907519 15120 solver.cpp:244]     Train net output #0: loss = 0.00919825 (* 1 = 0.00919825 loss)
I0930 07:36:45.907519 15120 sgd_solver.cpp:106] Iteration 177500, lr = 0.001
I0930 07:37:05.337755 15120 solver.cpp:228] Iteration 177600, loss = 0.0106757
I0930 07:37:05.337755 15120 solver.cpp:244]     Train net output #0: loss = 0.0106757 (* 1 = 0.0106757 loss)
I0930 07:37:05.337755 15120 sgd_solver.cpp:106] Iteration 177600, lr = 0.001
I0930 07:37:24.715522 15120 solver.cpp:228] Iteration 177700, loss = 0.010044
I0930 07:37:24.715522 15120 solver.cpp:244]     Train net output #0: loss = 0.010044 (* 1 = 0.010044 loss)
I0930 07:37:24.715522 15120 sgd_solver.cpp:106] Iteration 177700, lr = 0.001
I0930 07:37:44.104282 15120 solver.cpp:228] Iteration 177800, loss = 0.00879506
I0930 07:37:44.104282 15120 solver.cpp:244]     Train net output #0: loss = 0.00879506 (* 1 = 0.00879506 loss)
I0930 07:37:44.104282 15120 sgd_solver.cpp:106] Iteration 177800, lr = 0.001
I0930 07:38:03.482714 15120 solver.cpp:228] Iteration 177900, loss = 0.010706
I0930 07:38:03.482714 15120 solver.cpp:244]     Train net output #0: loss = 0.010706 (* 1 = 0.010706 loss)
I0930 07:38:03.482714 15120 sgd_solver.cpp:106] Iteration 177900, lr = 0.001
I0930 07:38:22.794450 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_178000.caffemodel
I0930 07:38:23.395877 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_178000.solverstate
I0930 07:38:23.775713 15120 solver.cpp:337] Iteration 178000, Testing net (#0)
I0930 07:38:31.960522 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7422
I0930 07:38:31.960522 15120 solver.cpp:404]     Test net output #1: loss = 1.02107 (* 1 = 1.02107 loss)
I0930 07:38:32.012560 15120 solver.cpp:228] Iteration 178000, loss = 0.00938069
I0930 07:38:32.012560 15120 solver.cpp:244]     Train net output #0: loss = 0.0093807 (* 1 = 0.0093807 loss)
I0930 07:38:32.012560 15120 sgd_solver.cpp:106] Iteration 178000, lr = 0.001
I0930 07:38:51.408368 15120 solver.cpp:228] Iteration 178100, loss = 0.0102273
I0930 07:38:51.408368 15120 solver.cpp:244]     Train net output #0: loss = 0.0102273 (* 1 = 0.0102273 loss)
I0930 07:38:51.408368 15120 sgd_solver.cpp:106] Iteration 178100, lr = 0.001
I0930 07:39:10.818909 15120 solver.cpp:228] Iteration 178200, loss = 0.00751709
I0930 07:39:10.818909 15120 solver.cpp:244]     Train net output #0: loss = 0.00751709 (* 1 = 0.00751709 loss)
I0930 07:39:10.818909 15120 sgd_solver.cpp:106] Iteration 178200, lr = 0.001
I0930 07:39:30.222930 15120 solver.cpp:228] Iteration 178300, loss = 0.00924346
I0930 07:39:30.222930 15120 solver.cpp:244]     Train net output #0: loss = 0.00924346 (* 1 = 0.00924346 loss)
I0930 07:39:30.222930 15120 sgd_solver.cpp:106] Iteration 178300, lr = 0.001
I0930 07:39:49.607689 15120 solver.cpp:228] Iteration 178400, loss = 0.0125077
I0930 07:39:49.607689 15120 solver.cpp:244]     Train net output #0: loss = 0.0125077 (* 1 = 0.0125077 loss)
I0930 07:39:49.607689 15120 sgd_solver.cpp:106] Iteration 178400, lr = 0.001
I0930 07:40:09.004897 15120 solver.cpp:228] Iteration 178500, loss = 0.0109312
I0930 07:40:09.004897 15120 solver.cpp:244]     Train net output #0: loss = 0.0109312 (* 1 = 0.0109312 loss)
I0930 07:40:09.004897 15120 sgd_solver.cpp:106] Iteration 178500, lr = 0.001
I0930 07:40:28.445446 15120 solver.cpp:228] Iteration 178600, loss = 0.0101184
I0930 07:40:28.445446 15120 solver.cpp:244]     Train net output #0: loss = 0.0101184 (* 1 = 0.0101184 loss)
I0930 07:40:28.445446 15120 sgd_solver.cpp:106] Iteration 178600, lr = 0.001
I0930 07:40:47.896672 15120 solver.cpp:228] Iteration 178700, loss = 0.00757191
I0930 07:40:47.897171 15120 solver.cpp:244]     Train net output #0: loss = 0.00757191 (* 1 = 0.00757191 loss)
I0930 07:40:47.897171 15120 sgd_solver.cpp:106] Iteration 178700, lr = 0.001
I0930 07:41:07.313395 15120 solver.cpp:228] Iteration 178800, loss = 0.0071253
I0930 07:41:07.313395 15120 solver.cpp:244]     Train net output #0: loss = 0.00712531 (* 1 = 0.00712531 loss)
I0930 07:41:07.313395 15120 sgd_solver.cpp:106] Iteration 178800, lr = 0.001
I0930 07:41:26.872743 15120 solver.cpp:228] Iteration 178900, loss = 0.00858866
I0930 07:41:26.873244 15120 solver.cpp:244]     Train net output #0: loss = 0.00858867 (* 1 = 0.00858867 loss)
I0930 07:41:26.873244 15120 sgd_solver.cpp:106] Iteration 178900, lr = 0.001
I0930 07:41:46.282161 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_179000.caffemodel
I0930 07:41:46.936753 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_179000.solverstate
I0930 07:41:47.382972 15120 solver.cpp:337] Iteration 179000, Testing net (#0)
I0930 07:41:55.594271 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7423
I0930 07:41:55.595273 15120 solver.cpp:404]     Test net output #1: loss = 1.00816 (* 1 = 1.00816 loss)
I0930 07:41:55.646308 15120 solver.cpp:228] Iteration 179000, loss = 0.00777669
I0930 07:41:55.646308 15120 solver.cpp:244]     Train net output #0: loss = 0.0077767 (* 1 = 0.0077767 loss)
I0930 07:41:55.646308 15120 sgd_solver.cpp:106] Iteration 179000, lr = 0.001
I0930 07:42:15.181720 15120 solver.cpp:228] Iteration 179100, loss = 0.0110955
I0930 07:42:15.181720 15120 solver.cpp:244]     Train net output #0: loss = 0.0110955 (* 1 = 0.0110955 loss)
I0930 07:42:15.181720 15120 sgd_solver.cpp:106] Iteration 179100, lr = 0.001
I0930 07:42:34.559144 15120 solver.cpp:228] Iteration 179200, loss = 0.00609275
I0930 07:42:34.559144 15120 solver.cpp:244]     Train net output #0: loss = 0.00609275 (* 1 = 0.00609275 loss)
I0930 07:42:34.559144 15120 sgd_solver.cpp:106] Iteration 179200, lr = 0.001
I0930 07:42:54.089354 15120 solver.cpp:228] Iteration 179300, loss = 0.00860876
I0930 07:42:54.089354 15120 solver.cpp:244]     Train net output #0: loss = 0.00860876 (* 1 = 0.00860876 loss)
I0930 07:42:54.089354 15120 sgd_solver.cpp:106] Iteration 179300, lr = 0.001
I0930 07:43:14.333812 15120 solver.cpp:228] Iteration 179400, loss = 0.00896687
I0930 07:43:14.333812 15120 solver.cpp:244]     Train net output #0: loss = 0.00896687 (* 1 = 0.00896687 loss)
I0930 07:43:14.333812 15120 sgd_solver.cpp:106] Iteration 179400, lr = 0.001
I0930 07:43:34.668658 15120 solver.cpp:228] Iteration 179500, loss = 0.00745054
I0930 07:43:34.669159 15120 solver.cpp:244]     Train net output #0: loss = 0.00745055 (* 1 = 0.00745055 loss)
I0930 07:43:34.669159 15120 sgd_solver.cpp:106] Iteration 179500, lr = 0.001
I0930 07:43:55.134388 15120 solver.cpp:228] Iteration 179600, loss = 0.00949996
I0930 07:43:55.134388 15120 solver.cpp:244]     Train net output #0: loss = 0.00949997 (* 1 = 0.00949997 loss)
I0930 07:43:55.134388 15120 sgd_solver.cpp:106] Iteration 179600, lr = 0.001
I0930 07:44:14.805804 15120 solver.cpp:228] Iteration 179700, loss = 0.00741377
I0930 07:44:14.805804 15120 solver.cpp:244]     Train net output #0: loss = 0.00741377 (* 1 = 0.00741377 loss)
I0930 07:44:14.805804 15120 sgd_solver.cpp:106] Iteration 179700, lr = 0.001
I0930 07:44:34.648702 15120 solver.cpp:228] Iteration 179800, loss = 0.00898487
I0930 07:44:34.649204 15120 solver.cpp:244]     Train net output #0: loss = 0.00898487 (* 1 = 0.00898487 loss)
I0930 07:44:34.649204 15120 sgd_solver.cpp:106] Iteration 179800, lr = 0.001
I0930 07:44:54.853658 15120 solver.cpp:228] Iteration 179900, loss = 0.00958441
I0930 07:44:54.854158 15120 solver.cpp:244]     Train net output #0: loss = 0.00958442 (* 1 = 0.00958442 loss)
I0930 07:44:54.854158 15120 sgd_solver.cpp:106] Iteration 179900, lr = 0.001
I0930 07:45:14.973142 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_180000.caffemodel
I0930 07:45:15.847864 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_180000.solverstate
I0930 07:45:16.375346 15120 solver.cpp:337] Iteration 180000, Testing net (#0)
I0930 07:45:25.151576 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7447
I0930 07:45:25.151576 15120 solver.cpp:404]     Test net output #1: loss = 1.00808 (* 1 = 1.00808 loss)
I0930 07:45:25.205615 15120 solver.cpp:228] Iteration 180000, loss = 0.0079597
I0930 07:45:25.205615 15120 solver.cpp:244]     Train net output #0: loss = 0.0079597 (* 1 = 0.0079597 loss)
I0930 07:45:25.205615 15120 sgd_solver.cpp:106] Iteration 180000, lr = 0.001
I0930 07:45:45.315719 15120 solver.cpp:228] Iteration 180100, loss = 0.0105847
I0930 07:45:45.315719 15120 solver.cpp:244]     Train net output #0: loss = 0.0105848 (* 1 = 0.0105848 loss)
I0930 07:45:45.315719 15120 sgd_solver.cpp:106] Iteration 180100, lr = 0.001
I0930 07:46:05.065286 15120 solver.cpp:228] Iteration 180200, loss = 0.00895033
I0930 07:46:05.065286 15120 solver.cpp:244]     Train net output #0: loss = 0.00895033 (* 1 = 0.00895033 loss)
I0930 07:46:05.065286 15120 sgd_solver.cpp:106] Iteration 180200, lr = 0.001
I0930 07:46:25.294442 15120 solver.cpp:228] Iteration 180300, loss = 0.0098512
I0930 07:46:25.294442 15120 solver.cpp:244]     Train net output #0: loss = 0.0098512 (* 1 = 0.0098512 loss)
I0930 07:46:25.294442 15120 sgd_solver.cpp:106] Iteration 180300, lr = 0.001
I0930 07:46:45.464972 15120 solver.cpp:228] Iteration 180400, loss = 0.0131429
I0930 07:46:45.464972 15120 solver.cpp:244]     Train net output #0: loss = 0.0131429 (* 1 = 0.0131429 loss)
I0930 07:46:45.464972 15120 sgd_solver.cpp:106] Iteration 180400, lr = 0.001
I0930 07:47:05.484961 15120 solver.cpp:228] Iteration 180500, loss = 0.0100847
I0930 07:47:05.484961 15120 solver.cpp:244]     Train net output #0: loss = 0.0100847 (* 1 = 0.0100847 loss)
I0930 07:47:05.484961 15120 sgd_solver.cpp:106] Iteration 180500, lr = 0.001
I0930 07:47:25.529603 15120 solver.cpp:228] Iteration 180600, loss = 0.0101731
I0930 07:47:25.529603 15120 solver.cpp:244]     Train net output #0: loss = 0.0101731 (* 1 = 0.0101731 loss)
I0930 07:47:25.529603 15120 sgd_solver.cpp:106] Iteration 180600, lr = 0.001
I0930 07:47:45.706260 15120 solver.cpp:228] Iteration 180700, loss = 0.0122651
I0930 07:47:45.706260 15120 solver.cpp:244]     Train net output #0: loss = 0.0122651 (* 1 = 0.0122651 loss)
I0930 07:47:45.706260 15120 sgd_solver.cpp:106] Iteration 180700, lr = 0.001
I0930 07:48:05.760680 15120 solver.cpp:228] Iteration 180800, loss = 0.00977034
I0930 07:48:05.760680 15120 solver.cpp:244]     Train net output #0: loss = 0.00977034 (* 1 = 0.00977034 loss)
I0930 07:48:05.760680 15120 sgd_solver.cpp:106] Iteration 180800, lr = 0.001
I0930 07:48:26.287078 15120 solver.cpp:228] Iteration 180900, loss = 0.0108876
I0930 07:48:26.287078 15120 solver.cpp:244]     Train net output #0: loss = 0.0108876 (* 1 = 0.0108876 loss)
I0930 07:48:26.287078 15120 sgd_solver.cpp:106] Iteration 180900, lr = 0.001
I0930 07:48:46.449574 15120 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_181000.caffemodel
I0930 07:48:47.483852 15120 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_181000.solverstate
I0930 07:48:48.057132 15120 solver.cpp:337] Iteration 181000, Testing net (#0)
I0930 07:48:56.590901 15120 solver.cpp:404]     Test net output #0: accuracy = 0.7424
I0930 07:48:56.590901 15120 solver.cpp:404]     Test net output #1: loss = 1.01644 (* 1 = 1.01644 loss)
I0930 07:48:56.643939 15120 solver.cpp:228] Iteration 181000, loss = 0.0138695
I0930 07:48:56.644439 15120 solver.cpp:244]     Train net output #0: loss = 0.0138695 (* 1 = 0.0138695 loss)
I0930 07:48:56.644439 15120 sgd_solver.cpp:106] Iteration 181000, lr = 0.001
I0930 07:49:16.799140 15120 solver.cpp:228] Iteration 181100, loss = 0.0126614
I0930 07:49:16.799140 15120 solver.cpp:244]     Train net output #0: loss = 0.0126614 (* 1 = 0.0126614 loss)
I0930 07:49:16.799140 15120 sgd_solver.cpp:106] Iteration 181100, lr = 0.001
I0930 07:49:36.807570 15120 solver.cpp:228] Iteration 181200, loss = 0.00759038
I0930 07:49:36.807570 15120 solver.cpp:244]     Train net output #0: loss = 0.00759038 (* 1 = 0.00759038 loss)
I0930 07:49:36.807570 15120 sgd_solver.cpp:106] Iteration 181200, lr = 0.001
I0930 07:49:56.878525 15120 solver.cpp:228] Iteration 181300, loss = 0.0125677
I0930 07:49:56.878525 15120 solver.cpp:244]     Train net output #0: loss = 0.0125677 (* 1 = 0.0125677 loss)
I0930 07:49:56.878525 15120 sgd_solver.cpp:106] Iteration 181300, lr = 0.001
I0930 07:50:16.882673 15120 solver.cpp:228] Iteration 181400, loss = 0.00962526
I0930 07:50:16.882673 15120 solver.cpp:244]     Train net output #0: loss = 0.00962526 (* 1 = 0.00962526 loss)
I0930 07:50:16.882673 15120 sgd_solver.cpp:106] Iteration 181400, lr = 0.001
I0930 07:50:36.874867 15120 solver.cpp:228] Iteration 181500, loss = 0.0114726
I0930 07:50:36.874867 15120 solver.cpp:244]     Train net output #0: loss = 0.0114726 (* 1 = 0.0114726 loss)
I0930 07:50:36.874867 15120 sgd_solver.cpp:106] Iteration 181500, lr = 0.001
I0930 07:50:56.982038 15120 solver.cpp:228] Iteration 181600, loss = 0.00999216
I0930 07:50:56.982038 15120 solver.cpp:244]     Train net output #0: loss = 0.00999216 (* 1 = 0.00999216 loss)
I0930 07:50:56.982038 15120 sgd_solver.cpp:106] Iteration 181600, lr = 0.001
I0930 07:51:17.278344 15120 solver.cpp:228] Iteration 181700, loss = 0.0141372
I0930 07:51:17.278344 15120 solver.cpp:244]     Train net output #0: loss = 0.0141372 (* 1 = 0.0141372 loss)
I0930 07:51:17.278344 15120 sgd_solver.cpp:106] Iteration 181700, lr = 0.001
I0930 07:51:37.430107 15120 solver.cpp:228] Iteration 181800, loss = 0.00970546
I0930 07:51:37.430107 15120 solver.cpp:244]     Train net output #0: loss = 0.00970546 (* 1 = 0.00970546 loss)
I0930 07:51:37.430107 15120 sgd_solver.cpp:106] Iteration 181800, lr = 0.001
I0930 07:51:57.295498 15120 solver.cpp:228] Iteration 181900, loss = 0.0122269
I0930 07:51:57.296000 15120 solver.cpp:244]     Train net output #0: loss = 0*** Check failure stack trace: ***
