num_classes = 41

# Preprocessor
semantic_pointcloud_preprocess.num_points_to_randomly_sample = 5000000
semantic_pointcloud_preprocess.points_pad_or_clip_size = 5000000
semantic_pointcloud_preprocess.point_feature_keys = ('point_normals',)
semantic_pointcloud_preprocess.voxels_pad_or_clip_size = 120000
semantic_pointcloud_preprocess.voxel_grid_cell_size = (0.02, 0.02, 0.02)
semantic_pointcloud_preprocess.x_random_crop_size = 3.0
semantic_pointcloud_preprocess.y_random_crop_size = 3.0
semantic_pointcloud_preprocess.x_min_degree_rotation = -10.0
semantic_pointcloud_preprocess.x_max_degree_rotation = 10.0
semantic_pointcloud_preprocess.y_min_degree_rotation = -10.0
semantic_pointcloud_preprocess.y_max_degree_rotation = 10.0
semantic_pointcloud_preprocess.z_min_degree_rotation = -180.0
semantic_pointcloud_preprocess.z_max_degree_rotation = 180.0
semantic_pointcloud_preprocess.min_scale_ratio = 0.9
semantic_pointcloud_preprocess.max_scale_ratio = 1.1
semantic_pointcloud_preprocess.points_key = 'mesh/vertices/positions'
semantic_pointcloud_preprocess.normals_key = 'mesh/vertices/normals'
semantic_pointcloud_preprocess.colors_key = None
semantic_pointcloud_preprocess.intensities_key = None
semantic_pointcloud_preprocess.elongations_key = None
semantic_pointcloud_preprocess.semantic_labels_key = 'mesh/vertices/semantic_labels'
semantic_pointcloud_preprocess.motion_labels_key = None
semantic_pointcloud_preprocess.ignore_labels = (0, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 31, 32, 35, 37, 38, 40, 255)


# Dataset
get_tf_data_dataset.dataset_name = 'scannet_scene'
get_tf_data_dataset.split_name = 'train'
get_tf_data_dataset.shuffle_buffer_size = 20
get_tf_data_dataset.filenames_shuffle_buffer_size = 20
get_tf_data_dataset.read_block_length = 2
get_tf_data_dataset.num_readers = 20
get_tf_data_dataset.preprocess_fn = @semantic_pointcloud_preprocess
get_tf_data_dataset.feature_keys = ('voxel_features',
                                    'voxel_xyz_indices',
                                    'num_valid_voxels',
                                    'voxel_loss_weights')
get_tf_data_dataset.label_keys = ('object_class_voxels',)


# 3D Network
SparseConvUNet.conv_filter_size = 3
SparseConvUNet.encoder_dimensions = ((64, 64), (64, 96), (96, 128), (128, 160), (160, 192), (192, 224), (224, 256))
SparseConvUNet.bottleneck_dimensions = (256, 256)
SparseConvUNet.decoder_dimensions = ((256, 256), (224, 224), (192, 192), (160, 160), (128, 128), (96, 96), (64, 64))
SparseConvUNet.use_batch_norm = True
SemanticSegmentationModel.num_classes = %num_classes


# Training
step_decay.boundary_list = [4000, 5000, 5500, 6000, 6500]
step_decay.ratio_list = [1.0, 0.3, 0.1, 0.03, 0.01, 0.001]
step_decay.initial_learning_rate = 0.01

train.learning_rate_fn = @step_decay
train.input_fn = @get_tf_data_dataset
train.optimizer_fn = @tf.keras.optimizers.SGD
train.model_class = @SemanticSegmentationModel
