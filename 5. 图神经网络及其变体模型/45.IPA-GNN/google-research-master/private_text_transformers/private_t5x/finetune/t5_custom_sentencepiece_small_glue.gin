# Config to fine tune a t5 with a custom Sentence Piece on glue.
include 't5x/t5x/configs/runs/finetune.gin'
include 't5x/t5x/examples/t5/t5_1_0/small.gin'

# Register necessary SeqIO Tasks/Mixtures.
import t5.data.mixtures

INITIAL_CHECKPOINT_PATH = ''
TRAIN_STEPS = 2500000  # includes 1000000 pretrain steps
MIXTURE_OR_TASK_NAME = 'glue_v002_proportional_custom_sp'
TASK_FEATURE_LENGTHS = {'inputs': 512, 'targets': 84}
DROPOUT_RATE = 0.1

# NOTE: When fine-tuning the public T5 checkpoints (trained in T5 MeshTF)
# the loss normalizing factor should be set to 1024 * 228 (pretraining
# batch_size * target_token_length).
LOSS_NORMALIZING_FACTOR = 233472