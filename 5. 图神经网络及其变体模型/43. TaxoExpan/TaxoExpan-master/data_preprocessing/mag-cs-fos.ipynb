{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T17:55:51.923148Z",
     "start_time": "2019-06-06T17:55:50.686576Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from gensim.models.wrappers import FastText\n",
    "import re\n",
    "import os, sys\n",
    "import networkx as nx\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# np.set_printoptions(suppress=True, formatter={'float_kind':'{:0.4f}'.format})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T18:04:15.861749Z",
     "start_time": "2019-06-06T17:55:51.926177Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FastText.load_fasttext_format('/datadrive/fastText-pretrained-embedding/fastText.wiki.en.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T18:52:27.471707Z",
     "start_time": "2019-06-06T18:52:27.423681Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class Taxon(object):\n",
    "    def __init__(self, tx_id, rank=-1, norm_name=\"none\", display_name=\"None\", main_type=\"\", level=\"-100\", p_count=0, c_count=0, create_date=\"None\"):\n",
    "        self.tx_id = tx_id\n",
    "        self.rank = int(rank)\n",
    "        self.norm_name = norm_name\n",
    "        self.display_name = display_name\n",
    "        self.main_type = main_type\n",
    "        self.level = int(level)\n",
    "        self.p_count = int(p_count)\n",
    "        self.c_count = int(c_count)\n",
    "        self.create_date = create_date\n",
    "        \n",
    "    def __str__(self):\n",
    "        return \"Taxon {} (name: {}, level: {})\".format(self.tx_id, self.norm_name, self.level)\n",
    "        \n",
    "    def __lt__(self, another_taxon):\n",
    "        if self.level < another_taxon.level:\n",
    "            return True\n",
    "        else:\n",
    "            return self.rank < another_taxon.rank\n",
    "\n",
    "        \n",
    "class Taxonomy(object):\n",
    "    def __init__(self, name=\"\", node_list=None, edge_list=None):\n",
    "        self.name = name\n",
    "        self.graph = nx.DiGraph()\n",
    "        self.tx_id2taxon = {}\n",
    "        self.root = None\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"=== Taxonomy {self.name} ===\\nNumber of nodes: {self.graph.number_of_nodes()}\\nNumber of edges: {self.graph.number_of_edges()}\"\n",
    "    \n",
    "    def get_number_of_nodes(self):\n",
    "        return self.graph.number_of_nodes()\n",
    "\n",
    "    def get_number_of_edges(self):\n",
    "        return self.graph.number_of_edges()\n",
    "    \n",
    "    def get_nodes(self):\n",
    "        \"\"\"\n",
    "        return: a generator of nodes\n",
    "        \"\"\"\n",
    "        return self.graph.nodes()\n",
    "    \n",
    "    def get_edges(self):\n",
    "        \"\"\"\n",
    "        return: a generator of edges\n",
    "        \"\"\"\n",
    "        return self.graph.edges()\n",
    "    \n",
    "    def get_root_node(self):\n",
    "        \"\"\"\n",
    "        return: a taxon object\n",
    "        \"\"\"\n",
    "        if not self.root:\n",
    "            self.root = list(nx.topological_sort(self.graph))[0]\n",
    "        return self.root\n",
    "    \n",
    "    def get_leaf_nodes(self):\n",
    "        \"\"\"\n",
    "        return: a list of taxon objects\n",
    "        \"\"\"\n",
    "        leaf_nodes = []\n",
    "        for node in self.graph.nodes():\n",
    "            if self.graph.out_degree(node) == 0:\n",
    "                leaf_nodes.append(node)\n",
    "        return leaf_nodes\n",
    "    \n",
    "    def get_children(self, parent_node):\n",
    "        \"\"\"\n",
    "        parent_node: a taxon object\n",
    "        return: a list of taxon object representing the children taxons\n",
    "        \"\"\"\n",
    "        assert parent_node in self.graph, \"parent node not in taxonomy\"\n",
    "        return [edge[1] for edge in self.graph.out_edges(parent_node)]\n",
    "    \n",
    "    def get_parent(self, child_node):\n",
    "        \"\"\"\n",
    "        child_node: a taxon object\n",
    "        return: a list of taxon object representing the parent taxons\n",
    "        \"\"\"\n",
    "        assert child_node in self.graph, \"child node not in taxonomy\"\n",
    "        return [edge[0] for edge in self.graph.in_edges(child_node)]\n",
    "    \n",
    "    def get_descendants(self, parent_node):\n",
    "        \"\"\"\n",
    "        parent_node: a taxon object\n",
    "        return: a list of taxon object representing the descendant taxons\n",
    "        \"\"\"\n",
    "        assert parent_node in self.graph, \"parent node not in taxonomy\"\n",
    "        return list(nx.descendants(self.graph, parent_node))\n",
    "    \n",
    "    def get_ancestors(self, child_node):\n",
    "        \"\"\"\n",
    "        child_node: a taxon object\n",
    "        return: a list of taxon object representing the ancestor taxons\n",
    "        \"\"\"\n",
    "        assert child_node in self.graph, \"child node not in taxonomy\"\n",
    "        return list(nx.ancestors(self.graph, child_node))\n",
    "    \n",
    "    def is_valid_DAG(self):\n",
    "        return nx.is_directed_acyclic_graph(self.graph)\n",
    "    \n",
    "    def is_weakly_connected(self):\n",
    "        return nx.number_weakly_connected_components(self.graph) == 1\n",
    "    \n",
    "    def get_max_depth(self):\n",
    "        return nx.dag_longest_path_length(self.graph)\n",
    "    \n",
    "    def add_node(self, node):\n",
    "        self.graph.add_node(node)\n",
    "        self.tx_id2taxon[node.tx_id] = node\n",
    "        \n",
    "    def add_edge(self, start, end):\n",
    "        \"\"\"\n",
    "        start: a taxon object\n",
    "        end: a taxon object\n",
    "        \"\"\"\n",
    "        self.graph.add_edge(start, end)\n",
    "    \n",
    "    def add_nodes_from_list(self, node_list):\n",
    "        self.graph.add_nodes_from(node_list)\n",
    "        for node in node_list:\n",
    "            self.tx_id2taxon[node.tx_id] = node\n",
    "\n",
    "    def add_edges_from_list(self, edge_list):\n",
    "        \"\"\"\n",
    "        edge_list: a list of taxon object pairs from parent_taxon -> child_taxon\n",
    "        \"\"\"\n",
    "        self.graph.add_edges_from(edge_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample CS Field-of-study Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T17:41:05.366526Z",
     "start_time": "2019-06-03T17:40:55.208059Z"
    }
   },
   "outputs": [],
   "source": [
    "taxonomy = Taxonomy(name=\"mag-cs-fos\")\n",
    "tx_id2taxon = {}\n",
    "with open(\"/home/t-jishen/mag-taxonomy/FieldsOfStudy.txt\" , \"r\") as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            segs = line.split(\"\\t\")\n",
    "            assert len(segs) == 9, \"Wrong number of segmentations\"\n",
    "            taxon = Taxon(tx_id=segs[0], display_name=segs[3], norm_name=segs[2])\n",
    "            tx_id2taxon[segs[0]] = taxon \n",
    "            taxonomy.add_node(taxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T17:41:07.930471Z",
     "start_time": "2019-06-03T17:41:05.368518Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"/home/t-jishen/mag-taxonomy/FieldOfStudyChildren.txt\", \"r\") as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            segs = line.split()\n",
    "            assert len(segs) == 2, \"Wrong number of segmentations\"\n",
    "            parent_taxon = tx_id2taxon[segs[0]]\n",
    "            child_taxon = tx_id2taxon[segs[1]]\n",
    "            taxonomy.add_edge(parent_taxon, child_taxon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T18:01:52.973524Z",
     "start_time": "2019-06-03T18:01:52.844364Z"
    }
   },
   "outputs": [],
   "source": [
    "dag = sample_dag(taxonomy, tx_id2taxon['41008148'], depth_limit=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T18:04:36.645274Z",
     "start_time": "2019-06-03T18:04:36.396911Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24508"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaf_node_cnt = 0\n",
    "for node in dag:\n",
    "    if dag.out_degree(node) == 0:\n",
    "        leaf_node_cnt += 1\n",
    "leaf_node_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T17:58:36.226268Z",
     "start_time": "2019-06-03T17:58:36.203747Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_dag(taxonomy, source_node, depth_limit=7):\n",
    "    subgraph_nodes = taxonomy.get_descendants(source_node)\n",
    "    subgraph_nodes.append(source_node)\n",
    "    return taxonomy.graph.subgraph(subgraph_nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T18:10:43.417127Z",
     "start_time": "2019-06-03T18:10:42.212974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taxon 41008148 (name: computer science, level: -100)\n",
      "Number of nodes: 29654\n",
      "Number of edges: 46248\n",
      "Taxon 33923547 (name: mathematics, level: -100)\n",
      "Number of nodes: 21365\n",
      "Number of edges: 34270\n"
     ]
    }
   ],
   "source": [
    "interested_fields = [\"computer science\", \"mathematics\"]\n",
    "for interested_field in interested_fields: \n",
    "    # find the source taxon\n",
    "    for tx_id, taxon in tx_id2taxon.items():\n",
    "        if taxon.norm_name == interested_field:\n",
    "            source_taxon = taxon\n",
    "            print(source_taxon)\n",
    "            break\n",
    "    \n",
    "    # edges = list(nx.bfs_edges(taxonomy.graph, source=source_taxon, depth_limit=7))\n",
    "    # tree = nx.DiGraph()\n",
    "    # tree.add_edges_from(edges)\n",
    "    dag = sample_dag(taxonomy, source_taxon, depth_limit=7)\n",
    "    print(f\"Number of nodes: {dag.number_of_nodes()}\")\n",
    "    print(f\"Number of edges: {dag.number_of_edges()}\")\n",
    "    \n",
    "    field_name = \"_\".join(interested_field.split())\n",
    "    with open(f\"../data/MAG_FoS/{field_name}.terms\", \"w\") as fout:\n",
    "        for node in dag:\n",
    "            fout.write(f\"{node.tx_id}\\t{node.norm_name}\\n\")\n",
    "            \n",
    "    with open(f\"../data/MAG_FoS/{field_name}.taxo\", \"w\") as fout:\n",
    "        for edge in dag.edges():\n",
    "            fout.write(f\"{edge[0].tx_id}\\t{edge[1].tx_id}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save to Embedding files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:00:12.189311Z",
     "start_time": "2019-06-06T21:00:12.162406Z"
    }
   },
   "outputs": [],
   "source": [
    "word_w_no_embed2description = {\n",
    "    'x3d': \"3d computer graphics file format\", \n",
    "    '576i': \"a standard-definition video mode\" , \n",
    "    'n100': \"a large, negative-going evoked potential\", \n",
    "    's5': \"s5 model logic\", \n",
    "    'p600': \"p600 neuroscience erp\",\n",
    "    'p3b': \"a subcompoent of the p300\",\n",
    "    '4b3t': \"4 binary 3 ternary\", \n",
    "    'p3a': \"novelty p3, component of of time-locked signals\", \n",
    "    'z39 50': \"a client-server standard and an application layer communications protocol\", \n",
    "    'i2o': \"intelligent input/output\",\n",
    "    'x3j13': \"ansi common lisp subcommittee\",\n",
    "    '2b1q': \"four-level pulse amplitude modulation scheme\", \n",
    "    '5g': \"fifth generation cellular network technology\", \n",
    "    '3g 324m': \"3gpp umbrella protocal for video telephony\", \n",
    "    '6to4': \"an internet transition mechanism for migrating from ipv4 to ipv6\", \n",
    "    'x86': \"a family of instruction set architectures\", \n",
    "    '480p': \"480 display resolutions\", \n",
    "    '576p': \"576 display resolutions\", \n",
    "    'n400': \"a component of event-related potentials\", \n",
    "    '6in4': \"an internet transition mechanism for migrating from ipv4 to ipv6\", \n",
    "    '4320p': \"4320 display resolutions\", \n",
    "    '2 1 2d': \"pseudo 3d\", \n",
    "    'f16c': \"cvt16 instruction set\", \n",
    "    'x87': \"a floating point related subset of x86 instruction set\", \n",
    "    'c37 94': \"ieee c37.94 optical interface\", \n",
    "    '4in6': \"tunneling of IPv4 in IPv6\", \n",
    "    'c11': \"a past standard for the c programming language\",\n",
    "    \"e8\": \"an exceptional simple lie groups in mathematics\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-06T21:01:18.567494Z",
     "start_time": "2019-06-06T21:01:01.216899Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/MAG_FoS/mathematics.terms, number of terms: 21365\n",
      "../data/MAG_FoS/computer_science.terms, number of terms: 29654\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../data/MAG_FoS\"\n",
    "for filename in os.listdir(data_dir):\n",
    "    if filename.endswith(\".terms\"):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # generated node embedding feature\n",
    "        idx2term = {}\n",
    "        term2idx = {}\n",
    "        idx2embed = {}\n",
    "        with open(file_path, \"r\") as fin:\n",
    "            for line in fin:\n",
    "                line = line.strip()\n",
    "                if line:\n",
    "                    segs = line.split(\"\\t\")\n",
    "                    idx = segs[0]\n",
    "                    term = segs[1].lower()\n",
    "                    idx2term[idx] = term\n",
    "                    term2idx[term] = idx\n",
    "                    embed = np.zeros(model.vector_size)\n",
    "                    token_list = re.split(r\"\\s|, |-\", term)\n",
    "                    for token in token_list:\n",
    "                        if token in model:  # whenever a character ngrams appaer in the token\n",
    "                            embed += model[token]\n",
    "                    embed /= len(token_list)\n",
    "                    if np.sum(embed ** 2) == 0:\n",
    "                        # print(idx, term)  # uncomment this line to find oov word\n",
    "                        embed = np.zeros(model.vector_size)\n",
    "                        alternative_term_form = word_w_no_embed2description[term]\n",
    "                        token_list = re.split(r\"\\s|, |-\", alternative_term_form)\n",
    "                        for token in token_list:\n",
    "                            if token in model:  # whenever a character ngrams appaer in the token\n",
    "                                embed += model[token]\n",
    "                        embed /= len(token_list)\n",
    "                    idx2embed[idx] = embed\n",
    "        \n",
    "        print(f\"{file_path}, number of terms: {len(idx2embed)}\")\n",
    "        \n",
    "        # write to file\n",
    "        with open(f\"{file_path}.embed\", \"w\") as fout:\n",
    "            fout.write(f\"{len(idx2embed)} {model.vector_size}\\n\")\n",
    "            for ele in sorted(idx2embed.items(), key=lambda x:x[0]):\n",
    "                embed_string = \" \".join([str(a) for a in ele[1]])\n",
    "                fout.write(f\"{ele[0]} {embed_string}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
