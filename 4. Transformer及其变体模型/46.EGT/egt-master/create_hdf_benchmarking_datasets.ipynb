{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "create_hdf_datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0g-JTMJcMHzg",
        "DrzCtDPZRm7w",
        "9XnEW2NS6m8u",
        "VzGgzL8rqXuz",
        "Tb3iNPVcljOU",
        "iZaIBGpmgkFU",
        "02PQ5Hu9p7mG",
        "PZpEXt-MYgPT",
        "6JNDwF24YmGa",
        "CztP0sgkGseB",
        "ai1GUxtdSboV"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone Repository and Download Datasets from Dwivedi et al."
      ],
      "metadata": {
        "id": "0g-JTMJcMHzg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!git clone https://github.com/shamim-hussain/benchmarking-gnns.git\r\n",
        "%cd benchmarking-gnns/data/\r\n",
        "!bash script_download_all_datasets.sh\r\n",
        "%cd .."
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqjU1dDCMDFK",
        "outputId": "11b4e95c-61bd-4599-c0db-7c3e3bf096fa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Libraries"
      ],
      "metadata": {
        "id": "DrzCtDPZRm7w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!pip install ogb==1.1.1\r\n",
        "!pip install dgl==0.4.2\r\n",
        "\r\n",
        "import ogb, dgl\r\n",
        "\r\n",
        "print(ogb.__version__)\r\n",
        "print(dgl.__version__)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "byyiWorlOu6A",
        "outputId": "6dd7f8b1-02b9-4953-d4da-370f7a76979d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convert Datasets"
      ],
      "metadata": {
        "id": "obJryCgq_iuk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SBM_PATTERN"
      ],
      "metadata": {
        "id": "9XnEW2NS6m8u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "class DotDict(dict):\r\n",
        "    def __init__(self, **kwds):\r\n",
        "        self.update(kwds)\r\n",
        "        self.__dict__ = self\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "DATASET_NAME = 'SBM_PATTERN'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "id": "pCxG-CBR6m8w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6de32f9-e966-4795-f93c-811e038c5c57"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp= dgrp.create_group('features/nodes')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['node_labels'] = np.array(l, dtype=int)\r\n",
        "\r\n",
        "\r\n",
        "dest_file = r'../datasets/SBM_PATTERN/SBM_PATTERN.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('SBM_PATTERN')\r\n",
        "    ds.attrs['max_node_feat'] = 2\r\n",
        "    ds.attrs['min_node_feat'] = 0\r\n",
        "    ds.attrs['num_min_nodes'] = 44\r\n",
        "    ds.attrs['num_max_nodes'] = 188\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, trainset)\r\n",
        "    save_dataset(val_ds, valset)\r\n",
        "    save_dataset(test_ds, testset)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJiZennk6m8y",
        "outputId": "51da0321-257c-45ba-9a6f-6b470c1e0b93"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "0-O7baZGNprD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SBM_CLUSTER"
      ],
      "metadata": {
        "id": "VzGgzL8rqXuz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "class DotDict(dict):\r\n",
        "    def __init__(self, **kwds):\r\n",
        "        self.update(kwds)\r\n",
        "        self.__dict__ = self\r\n",
        "\r\n",
        "DATASET_NAME = 'SBM_CLUSTER'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdG8zDFtqXu1",
        "outputId": "55fc86af-3fd8-4351-87f4-c2de2cada5a7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp= dgrp.create_group('features/nodes')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['node_labels'] = np.array(l, dtype=int)\r\n",
        "\r\n",
        "dest_file = r'../datasets/SBM_CLUSTER/SBM_CLUSTER.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('SBM_CLUSTER')\r\n",
        "    ds.attrs['max_node_feat'] = 6\r\n",
        "    ds.attrs['min_node_feat'] = 0\r\n",
        "    ds.attrs['num_node_classes'] = 6\r\n",
        "    ds.attrs['num_min_nodes'] = 41\r\n",
        "    ds.attrs['num_max_nodes'] = 190\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, trainset)\r\n",
        "    save_dataset(val_ds, valset)\r\n",
        "    save_dataset(test_ds, testset)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yeIrgQLqXu4",
        "outputId": "93c57ce8-dfa8-41f0-85d4-dcdaa9e1879b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "r4ToKuw1Ns4c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST"
      ],
      "metadata": {
        "id": "Tb3iNPVcljOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "DATASET_NAME = 'MNIST'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPye9cNCljOb",
        "outputId": "8f9d6270-af21-447a-88eb-330239b0e9c7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp,defgrp = dgrp.create_group('features/nodes'), dgrp.create_group('features/edges')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        for fname, fval in g.edata.items():\r\n",
        "            defgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['label'] = l.numpy()\r\n",
        "\r\n",
        "\r\n",
        "dest_file = r'../datasets/MNIST/MNIST.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('MNIST')\r\n",
        "    ds.attrs['num_node_feat'] = 3\r\n",
        "    ds.attrs['num_edge_feat'] = 1\r\n",
        "    ds.attrs['num_classes'] = 10\r\n",
        "    ds.attrs['num_min_nodes'] = 40\r\n",
        "    ds.attrs['num_max_nodes'] = 75\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, dataset.train)\r\n",
        "    save_dataset(val_ds, dataset.val)\r\n",
        "    save_dataset(test_ds, dataset.test)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zR0ZYVY4ljOc",
        "outputId": "7987da11-f26e-42e2-f52a-66286e0aab7e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "XJjK6EBdNvIN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CIFAR10"
      ],
      "metadata": {
        "id": "iZaIBGpmgkFU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "DATASET_NAME = 'CIFAR10'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggsOg4mGgkFX",
        "outputId": "8db94b47-3da8-4aba-ede8-9c6c70fac578"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp,defgrp = dgrp.create_group('features/nodes'), dgrp.create_group('features/edges')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        for fname, fval in g.edata.items():\r\n",
        "            defgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['label'] = l.numpy()\r\n",
        "\r\n",
        "\r\n",
        "dest_file = r'../datasets/CIFAR10/CIFAR10.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('CIFAR10')\r\n",
        "    ds.attrs['num_node_feat'] = 5\r\n",
        "    ds.attrs['num_edge_feat'] = 1\r\n",
        "    ds.attrs['num_classes'] = 10\r\n",
        "    ds.attrs['num_min_nodes'] = 85\r\n",
        "    ds.attrs['num_max_nodes'] = 150\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, dataset.train)\r\n",
        "    save_dataset(val_ds, dataset.val)\r\n",
        "    save_dataset(test_ds, dataset.test)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_7q1RBDgkFY",
        "outputId": "23305c1d-b229-48be-a748-935dd367ff3f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "IbIyYCQ_Nyl8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TSP"
      ],
      "metadata": {
        "id": "02PQ5Hu9p7mG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "DATASET_NAME = 'TSP'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4K-xhLlYp7mI",
        "outputId": "c2a74d48-ef82-471e-ddc5-feaedffd2d2c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp,defgrp = dgrp.create_group('features/nodes'), dgrp.create_group('features/edges')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        for fname, fval in g.edata.items():\r\n",
        "            defgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['edge_labels'] = np.array(l, dtype=int)\r\n",
        "\r\n",
        "dest_file = r'../datasets/TSP/TSP.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('TSP')\r\n",
        "    ds.attrs['num_node_feat'] = 2\r\n",
        "    ds.attrs['num_edge_feat'] = 1\r\n",
        "    ds.attrs['num_min_nodes'] = 50\r\n",
        "    ds.attrs['num_max_nodes'] = 499\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, dataset.train)\r\n",
        "    save_dataset(val_ds, dataset.val)\r\n",
        "    save_dataset(test_ds, dataset.test)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8RB0D7T2p7mJ",
        "outputId": "0372993c-4828-4e67-bb1b-10e943712d97"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "_giG_aLKN3JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZINC"
      ],
      "metadata": {
        "id": "PZpEXt-MYgPT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "DATASET_NAME = 'ZINC'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test"
      ],
      "outputs": [],
      "metadata": {
        "id": "Vc-01cHRYie6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c55281c-34dc-4366-ea2d-f66c125184ab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\r\n",
        "\r\n",
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in tqdm(enumerate(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp,defgrp = dgrp.create_group('features/nodes'), dgrp.create_group('features/edges')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        for fname, fval in g.edata.items():\r\n",
        "            defgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['value'] = l.numpy()\r\n",
        "\r\n",
        "dest_file = r'../datasets/ZINC/ZINC.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('ZINC')\r\n",
        "    ds.attrs['num_atom_type'] = 28\r\n",
        "    ds.attrs['num_bond_type'] = 4\r\n",
        "    ds.attrs['num_min_atoms'] = 9\r\n",
        "    ds.attrs['num_max_atoms'] = 37\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, dataset.train)\r\n",
        "    save_dataset(val_ds, dataset.val)\r\n",
        "    save_dataset(test_ds, dataset.test)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WYoPyMFdTENJ",
        "outputId": "3d14c8be-5d04-41f2-d021-63dcfa525e44"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "mz4hYr7KN548"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ZINC-full"
      ],
      "metadata": {
        "id": "6JNDwF24YmGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "import h5py\r\n",
        "import torch\r\n",
        "from tqdm import tqdm\r\n",
        "from pathlib import Path\r\n",
        "\r\n",
        "from data.data import LoadData\r\n",
        "\r\n",
        "DATASET_NAME = 'ZINC-full'\r\n",
        "dataset = LoadData(DATASET_NAME)\r\n",
        "trainset, valset, testset = dataset.train, dataset.val, dataset.test #154s"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vECgVD9AYmGf",
        "outputId": "fa972ca2-c44f-48d5-92d4-77302bea485d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def save_dataset(ds,data):\r\n",
        "    for i, (g,l) in enumerate(tqdm(data)):\r\n",
        "        grp = ds.create_group(f'{i:0>10d}')\r\n",
        "        dgrp = grp.create_group('data')\r\n",
        "        \r\n",
        "        dgrp.attrs['num_nodes'] = g.number_of_nodes()\r\n",
        "        dgrp.attrs['num_edges'] = g.number_of_edges()\r\n",
        "        \r\n",
        "        dgrp['edges'] = torch.stack(g.edges(),axis=-1).numpy()\r\n",
        "        \r\n",
        "        dnfgrp,defgrp = dgrp.create_group('features/nodes'), dgrp.create_group('features/edges')\r\n",
        "        for fname, fval in g.ndata.items():\r\n",
        "            dnfgrp[fname] = fval.numpy()\r\n",
        "        for fname, fval in g.edata.items():\r\n",
        "            defgrp[fname] = fval.numpy()\r\n",
        "        \r\n",
        "        tgrp = grp.create_group('targets')\r\n",
        "        tgrp['value'] = l.numpy()\r\n",
        "\r\n",
        "dest_file = r'../datasets/ZINC_full/ZINC_full.h5'\r\n",
        "Path(dest_file).parent.mkdir(exist_ok=True, parents=True)\r\n",
        "with h5py.File(dest_file, 'w') as file:\r\n",
        "    ds = file.create_group('ZINC_full')\r\n",
        "    ds.attrs['num_atom_type'] = 28\r\n",
        "    ds.attrs['num_bond_type'] = 4\r\n",
        "    ds.attrs['num_min_atoms'] = 6\r\n",
        "    ds.attrs['num_max_atoms'] = 38\r\n",
        "    train_ds, val_ds, test_ds = ds.create_group('training'), ds.create_group('validation'), ds.create_group('test')\r\n",
        "    save_dataset(train_ds, dataset.train)\r\n",
        "    save_dataset(val_ds, dataset.val)\r\n",
        "    save_dataset(test_ds, dataset.test)"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGrNlpzmYmGf",
        "outputId": "4747c1d6-69aa-4ca7-8152-bd4d18d07cc8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%reset"
      ],
      "outputs": [],
      "metadata": {
        "id": "slnYEKKYN9UU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Parent HDF with External Soft-links (Optional)"
      ],
      "metadata": {
        "id": "CztP0sgkGseB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd ../datasets/\r\n",
        "%ls"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ooOnr8Z5GrOc",
        "outputId": "8dd2a87b-df0f-40cc-ac36-18a8e79b8f90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import h5py as h5\r\n",
        "\r\n",
        "def add_link(data_file, dataset_name):\r\n",
        "    data_file[f'{dataset_name}'] = h5.ExternalLink(f\"{dataset_name}/{dataset_name}.h5\", f\"/{dataset_name}\")\r\n",
        "\r\n",
        "\r\n",
        "with h5.File(\"gnn_benchmark.h5\", 'w') as data_file:\r\n",
        "    add_link(data_file,\"SBM_PATTERN\")\r\n",
        "    add_link(data_file,\"SBM_CLUSTER\")\r\n",
        "    add_link(data_file,\"MNIST\")\r\n",
        "    add_link(data_file,\"CIFAR10\")\r\n",
        "    add_link(data_file,\"TSP\")\r\n",
        "    add_link(data_file,\"ZINC\")\r\n",
        "    add_link(data_file,\"ZINC_full\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "x_fyKPtRHA57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the File"
      ],
      "metadata": {
        "id": "QVw9QvgtJVxi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "with h5.File(\"gnn_benchmark.h5\", 'r') as data_file:\r\n",
        "    datasets = list(data_file.keys())\r\n",
        "    print(datasets)\r\n",
        "    for dset in datasets:\r\n",
        "        print()\r\n",
        "        print(dset)\r\n",
        "        print('------------')\r\n",
        "        print(f'Training examples  : {len(data_file[dset][\"training\"])}')\r\n",
        "        print(f'Validation examples: {len(data_file[dset][\"validation\"])}')\r\n",
        "        print(f'Test examples      : {len(data_file[dset][\"test\"])}')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93ujrGH9JUq8",
        "outputId": "9a1509bc-f117-44bb-8e72-afc154da4770"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compress Files for Storage, Download etc. (Optional)"
      ],
      "metadata": {
        "id": "qw_UfnjWK1q8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%cd ../"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBpl2PJGK02M",
        "outputId": "ed590e6d-4903-442e-b5ee-fe7bf5e67b49"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "!tar -czf datasets.tar.gz datasets"
      ],
      "outputs": [],
      "metadata": {
        "id": "GyNH3vXXL15D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%ls -alh"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npYXEaInOBlk",
        "outputId": "d0564d68-8074-49b7-cc8c-5aaa71da5db2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (On Google Colab) Download File"
      ],
      "metadata": {
        "id": "M_PNy78vRkdB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "files.download('datasets.tar.gz')"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "8N_IznFhRhV0",
        "outputId": "7457b26b-b5fe-4d14-961c-c8d19979a2f0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (On Google Colab) Or Transfer to Google Drive"
      ],
      "metadata": {
        "id": "ai1GUxtdSboV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('./drive')\r\n",
        "!cp -v datasets.tar.gz ./drive/MyDrive/\r\n",
        "drive.flush_and_unmount()"
      ],
      "outputs": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hdYLs0RSbMW",
        "outputId": "3655fa1c-f0fc-477b-af16-de620adcee5a"
      }
    }
  ]
}