num_classes = 5
label_map_path = 'tf3d/datasets/labelmaps/waymo_open_labelmap.pbtxt'


# Preprocessor
waymo_prepare_lidar_images_and_correspondences.resized_image_height = 481
waymo_prepare_lidar_images_and_correspondences.resized_image_width = 721

prepare_waymo_open_dataset.valid_object_classes = [1, 2, 3, 4]
object_detection_preprocess.input_field_mapping_fn = @prepare_waymo_open_dataset
object_detection_preprocess.images_points_correspondence_fn = @waymo_prepare_lidar_images_and_correspondences
object_detection_preprocess.points_pad_or_clip_size = None
object_detection_preprocess.voxel_grid_cell_size = (0.2, 0.2, 0.2)
object_detection_preprocess.voxels_pad_or_clip_size = None
object_detection_preprocess.point_feature_keys = ('point_offset_bins',)
object_detection_preprocess.x_min_degree_rotation = None
object_detection_preprocess.x_max_degree_rotation = None
object_detection_preprocess.y_min_degree_rotation = None
object_detection_preprocess.y_max_degree_rotation = None
object_detection_preprocess.z_min_degree_rotation = None
object_detection_preprocess.z_max_degree_rotation = None
object_detection_preprocess.min_scale_ratio = None
object_detection_preprocess.max_scale_ratio = None
object_detection_preprocess.translation_range = None
object_detection_preprocess.points_within_box_margin = 0.1
object_detection_preprocess.min_num_points_in_objects = 5


# Dataset
get_tf_data_dataset.dataset_name = 'waymo_object_per_frame'
get_tf_data_dataset.split_name = 'val'
get_tf_data_dataset.preprocess_fn = @object_detection_preprocess
get_tf_data_dataset.feature_keys = ['point_positions',
                                    'num_valid_points',
                                    'voxel_positions',
                                    'voxel_features',
                                    'voxel_xyz_indices',
                                    'num_valid_voxels',
                                    'points_to_voxel_mapping',
                                    'camera_image_name']
get_tf_data_dataset.label_keys = ['object_class_points',
                                  'object_class_voxels',
                                  'object_instance_id_points',
                                  'object_instance_id_voxels',
                                  'objects_class']
get_tf_data_dataset.shuffle_buffer_size = 4
get_tf_data_dataset.filenames_shuffle_buffer_size = 4
get_tf_data_dataset.read_block_length = 1
get_tf_data_dataset.num_readers = 16


# 3D Network
SparseConvUNet.conv_filter_size = 3
SparseConvUNet.encoder_dimensions = ((64, 64), (64, 96), (96, 128), (128, 160), (160, 192), (192, 224), (256, 256))
SparseConvUNet.bottleneck_dimensions = (256, 256)
SparseConvUNet.decoder_dimensions = ((256, 256), (224, 224), (192, 192), (160, 160), (128, 128), (96, 96), (64, 64))
SparseConvUNet.use_batch_norm = True


# Model
InstanceSegmentationModel.num_classes = %num_classes
InstanceSegmentationModel.embedding_dims = 64
InstanceSegmentationModel.embedding_similarity_strategy = 'distance'
InstanceSegmentationModel.embedding_similarity_threshold = 0.5
InstanceSegmentationModel.apply_nms = True
InstanceSegmentationModel.nms_score_threshold = 0.1
InstanceSegmentationModel.nms_iou_threshold = 0.3
InstanceSegmentationModel.num_furthest_voxel_samples = 1000
InstanceSegmentationModel.sampler_score_vs_distance_coef = 0.5


# Evaluation
evaluation.input_fn = @get_tf_data_dataset
evaluation.model_class = @InstanceSegmentationModel
evaluation.num_quantitative_examples = 1000
evaluation.num_qualitative_examples = 10

m1/InstanceSegmentationMetric.iou_threshold = 0.25
m1/InstanceSegmentationMetric.num_classes = %num_classes
m1/InstanceSegmentationMetric.label_map_path = %label_map_path

m2/InstanceSegmentationMetric.iou_threshold = 0.5
m2/InstanceSegmentationMetric.num_classes = %num_classes
m2/InstanceSegmentationMetric.label_map_path = %label_map_path

m3/InstanceSegmentationMetric.iou_threshold = 0.7
m3/InstanceSegmentationMetric.num_classes = %num_classes
m3/InstanceSegmentationMetric.label_map_path = %label_map_path

CustomTensorBoard.metric_classes = [
    @m1/InstanceSegmentationMetric,
    @m2/InstanceSegmentationMetric,
    @m3/InstanceSegmentationMetric
]
