num_classes = 5

# Preprocessor
waymo_prepare_lidar_images_and_correspondences.resized_image_height = 481
waymo_prepare_lidar_images_and_correspondences.resized_image_width = 721

semantic_pointcloud_preprocess.images_points_correspondence_fn = @waymo_prepare_lidar_images_and_correspondences
semantic_pointcloud_preprocess.compute_semantic_labels_fn = @waymo_object_per_frame_compute_semantic_labels
semantic_pointcloud_preprocess.points_pad_or_clip_size = 200000
semantic_pointcloud_preprocess.point_feature_keys = ('point_offset_bins',)
semantic_pointcloud_preprocess.voxel_grid_cell_size = (0.2, 0.2, 0.2)
semantic_pointcloud_preprocess.voxels_pad_or_clip_size = 70000
semantic_pointcloud_preprocess.z_min_degree_rotation = -180.0
semantic_pointcloud_preprocess.z_max_degree_rotation = 180.0
semantic_pointcloud_preprocess.points_key = 'points_position'
semantic_pointcloud_preprocess.intensities_key = 'points_intensity'
semantic_pointcloud_preprocess.elongations_key = 'points_elongation'
semantic_pointcloud_preprocess.colors_key = None
semantic_pointcloud_preprocess.normals_key = None
semantic_pointcloud_preprocess.semantic_labels_key = 'semantic_labels'
semantic_pointcloud_preprocess.spin_coords_key = None
semantic_pointcloud_preprocess.semantic_labels_offset = 0
semantic_pointcloud_preprocess.view_names = ('rgb_view',)
semantic_pointcloud_preprocess.points_in_image_frame_key = None
semantic_pointcloud_preprocess.ignore_labels = (255,)
semantic_pointcloud_preprocess.only_keep_first_return_lidar_points = False


# Dataset
get_tf_data_dataset.dataset_name = 'waymo_object_per_frame'
get_tf_data_dataset.split_name = 'train'
get_tf_data_dataset.preprocess_fn = @semantic_pointcloud_preprocess
get_tf_data_dataset.feature_keys = ('voxel_features',
                                    'voxel_xyz_indices',
                                    'num_valid_voxels',
                                    'voxel_loss_weights')
get_tf_data_dataset.label_keys = ('object_class_voxels',)
get_tf_data_dataset.shuffle_buffer_size = 32
get_tf_data_dataset.filenames_shuffle_buffer_size = 30
get_tf_data_dataset.read_block_length = 2
get_tf_data_dataset.num_readers = 16


# 3D Network
SparseConvUNet.conv_filter_size = 3
SparseConvUNet.encoder_dimensions = ((24, 24), (24, 32), (32, 48), (48, 64), (64, 80), (80, 96), (96, 112))
SparseConvUNet.bottleneck_dimensions = (112, 112)
SparseConvUNet.decoder_dimensions = ((112, 112), (96, 96), (80, 80), (64, 64), (48, 48), (32, 32), (16, 16))
SparseConvUNet.use_batch_norm = True
SemanticSegmentationModel.num_classes = %num_classes


# Training
step_decay.boundary_list = [5000, 6000, 6500, 7000, 7500]
step_decay.ratio_list = [1.0, 0.3, 0.1, 0.03, 0.01, 0.001]
step_decay.initial_learning_rate = 0.01

train.learning_rate_fn = @step_decay
train.input_fn = @get_tf_data_dataset
train.optimizer_fn = @tf.keras.optimizers.SGD
train.model_class = @SemanticSegmentationModel

