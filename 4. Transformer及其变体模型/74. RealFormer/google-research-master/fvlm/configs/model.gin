import modeling.clip_models
import modeling.fpn
import modeling.heads
import modeling.multitask_model
import modeling.task_heads
import ops.generate_detections


MIN_LEVEL = %gin.REQUIRED
MAX_LEVEL = %gin.REQUIRED
BN_GROUP_SIZE = %gin.REQUIRED
CLIP_NAME = 'resnet_50'
CLS_BOX_REG = False
TEMP = 0.01
TEXT_DIM = 512
USE_TEXT_FEAT = True
USE_CLS_BIAS = False

# Mask RCNN backbone and heads.
Fpn.min_level = %MIN_LEVEL
Fpn.max_level = %MAX_LEVEL
RpnHead.num_convs = 2
RpnHead.min_level = %MIN_LEVEL
RpnHead.max_level = %MAX_LEVEL
RpnHead.batch_norm_group_size = %BN_GROUP_SIZE
FastrcnnHead.num_convs = 4
FastrcnnHead.num_fcs = 1
FastrcnnHead.num_classes = %TEXT_DIM
FastrcnnHead.class_box_regression = %CLS_BOX_REG
FastrcnnHead.batch_norm_group_size = %BN_GROUP_SIZE
FastrcnnHead.use_class_bias = %USE_CLS_BIAS

process_and_generate_detections.class_box_regression = %CLS_BOX_REG
process_and_generate_detections.pre_nms_num_detections = 1000

# MultitaskModel model.
get_clip_vision_model.model_name = %CLIP_NAME
AttentionPool.num_heads = 32
AttentionPool.features = %TEXT_DIM
MultitaskModel.vision_model_fn = @get_clip_vision_model()
MultitaskModel.train_vision_model = True

# CLIP Mask RCNN Head.
MaskrcnnHead.num_classes = 1
MaskrcnnHead.use_class_agnostic = True
ClipFasterRCNNHead.feature_pyramid = @Fpn
ClipFasterRCNNHead.region_proposal_head = @RpnHead
ClipFasterRCNNHead.fastrcnn_head = @FastrcnnHead
ClipFasterRCNNHead.maskrcnn_head = @MaskrcnnHead
ClipFasterRCNNHead.generate_detections_fn = @process_and_generate_detections
ClipFasterRCNNHead.temperature_scale = %TEMP
ClipFasterRCNNHead.roi_head_fn = @AttentionPool
