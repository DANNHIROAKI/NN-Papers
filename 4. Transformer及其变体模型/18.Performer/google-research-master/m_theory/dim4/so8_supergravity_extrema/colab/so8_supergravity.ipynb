{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "so8_supergravity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "naN9CKGafLWX"
      },
      "source": [
        "Copyright 2020 Google LLC\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "    https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZrvQXzD5qEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let us explicitly ask for TensorFlow2.\n",
        "# This installs a lot of stuff - and will take a while.\n",
        "!pip3 install tensorflow==2.0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c3jYvsbX6ING",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import collections\n",
        "import dataclasses\n",
        "import hashlib\n",
        "import itertools\n",
        "import math\n",
        "import numpy\n",
        "import pprint\n",
        "import scipy.optimize\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "print('TF version is:', tf.__version__)\n",
        "print('NumPy version is:', numpy.__version__)\n",
        "\n",
        "\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class Solution(object):\n",
        "  potential: float\n",
        "  stationarity: float\n",
        "  pos: numpy.ndarray\n",
        "\n",
        "\n",
        "def np_esum(spec, *arrays, optimize='greedy'):\n",
	"  \"\"\"Numpy einsum with default greedy optimization.\"\"\"\n",
        "  return numpy.einsum(spec, *arrays, optimize=optimize)\n",
        "\n",
        "\n",
        "def get_onb_transform(k_ab):\n",
        "  if not numpy.allclose(k_ab, k_ab.real) or not numpy.allclose(k_ab, k_ab.T):\n",
        "    raise ValueError('Bad Gramian.')\n",
        "  eigvals, eigvecsT = numpy.linalg.eigh(k_ab)\n",
        "  if not all(v * eigvals[0] > 0 for v in eigvals):\n",
        "    raise ValueError('Non-definite Gramian.')\n",
        "  onb_transform = numpy.einsum('a,na->an', eigvals**(-.5), eigvecsT)\n",
        "  g = np_esum('ab,Aa,Bb->AB', k_ab, onb_transform, onb_transform)\n",
        "  assert numpy.allclose(\n",
        "    g, numpy.eye(g.shape[0]) * ((-1, 1)[int(eigvals[0] > 0)])\n",
        "    ), 'Bad ONB-transform.'\n",
        "  return onb_transform, numpy.linalg.inv(onb_transform)\n",
        "\n",
        "\n",
        "def numpy_signature(a, digits=3):\n",
        "  \"\"\"Produces a signature-fingerprint of a numpy array.\"\"\"\n",
        "  # Hack to ensure that -0.0 gets consistently shown as 0.0.\n",
        "  minus_zero_hack = 1e-100+1e-100j\n",
        "  return base64.b64encode(\n",
        "      hashlib.sha256(\n",
        "          str((a.shape,\n",
        "               ','.join(repr(x)\n",
        "               for x in numpy.round(a + minus_zero_hack, digits).flat))\n",
        "          ).encode('utf-8')\n",
        "      ).digest()).decode('utf-8').strip('\\n=')\n",
        "\n",
        "\n",
        "def tformat(array,\n",
        "            name=None,\n",
        "            elem_filter=lambda x: abs(x) > 1e-8,\n",
        "            fmt='%s',\n",
        "            max_rows=numpy.inf,\n",
        "            cols=120):\n",
        "    \"\"\"Formats a numpy-array in human readable table form.\"\"\"\n",
        "    # Leading row will be replaced if caller asked for a name-row.\n",
        "    dim_widths = [\n",
        "        max(1, int(math.ceil(math.log(dim + 1e-100, 10))))\n",
        "        for dim in array.shape]\n",
        "    format_str = '%s: %s' % (' '.join('%%%dd' % w for w in dim_widths), fmt)\n",
        "    rows = []\n",
        "    for indices in itertools.product(*[range(dim) for dim in array.shape]):\n",
        "        v = array[indices]\n",
        "        if elem_filter(v):\n",
        "            rows.append(format_str % (indices + (v, )))\n",
        "    num_entries = len(rows)\n",
        "    if num_entries > max_rows:\n",
        "      rows = rows[:max_rows]\n",
        "    if cols is not None:\n",
        "      width = max(map(len, rows))\n",
        "      num_cols = max(1, cols // (3 + width))\n",
        "      num_xrows = int(math.ceil(len(rows) / num_cols))\n",
        "      padded = [('%%-%ds' % width) % s\n",
        "                for s in rows + [''] * (num_cols * num_xrows - len(rows))]\n",
        "      table = numpy.array(padded, dtype=object).reshape(num_cols, num_xrows).T\n",
        "      xrows = [' | '.join(row) for row in table]\n",
        "    else:\n",
        "      xrows = rows\n",
        "    if name is not None:\n",
        "      return '\\n'.join(\n",
        "          ['=== %s, shape=%r, %d%s / %d non-small entries ===' % (\n",
        "              name, array.shape,\n",
        "            num_entries,\n",
        "            '' if num_entries == len(rows) else '(%d shown)' % num_entries,\n",
        "            array.size)] +\n",
        "          [r.strip() for r in xrows])\n",
        "    return '\\n'.join(xrows)\n",
        "\n",
        "\n",
        "def tprint(array, sep=' ', end='\\n', file=sys.stdout, **tformat_kwargs):\n",
        "    \"\"\"Prints a numpy array in human readable table form.\"\"\"\n",
        "    print(tformat(array, **tformat_kwargs), sep=sep, end=end, file=file)\n",
        "\n",
        "\n",
        "### Lie Algebra definitions for Spin(8), SU(8), E7.\n",
        "\n",
        "def permutation_sign(p):\n",
        "  q = [x for x in p]  # Copy to list.\n",
        "  parity = 1\n",
        "  for n in range(len(p)):\n",
        "    while n != q[n]:\n",
        "      qn = q[n]\n",
        "      q[n], q[qn] = q[qn], q[n]  # Swap to make q[qn] = qn.\n",
        "      parity = -parity\n",
        "  return parity\n",
        "\n",
        "\n",
        "def asymm2(a, einsum_spec):\n",
        "  \"\"\"Antisymmetrizes.\"\"\"\n",
        "  return 0.5 * (a - numpy.einsum(einsum_spec, a))\n",
        "\n",
        "\n",
        "class Spin8(object):\n",
        "  \"\"\"Container class for Spin(8) tensor invariants.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    r8 = range(8)\n",
        "    self.gamma_vsc = gamma_vsc = self._get_gamma_vsc()\n",
        "    #\n",
        "    # The gamma^{ab}_{alpha beta} tensor that translates between antisymmetric\n",
        "    # matrices over vectors [ij] and antisymmetric matrices over spinors [sS].\n",
        "    self.gamma_vvss = asymm2(\n",
        "        numpy.einsum('isc,jSc->ijsS', gamma_vsc, gamma_vsc), 'ijsS->jisS')\n",
        "    # The gamma^{ab}_{alpha* beta*} tensor that translates between antisymmetric\n",
        "    # matrices over vectors [ij] and antisymmetric matrices over cospinors [cC].\n",
        "    self.gamma_vvcc = asymm2(\n",
        "        numpy.einsum('isc,jsC->ijcC', gamma_vsc, gamma_vsc), 'ijcC->jicC')\n",
        "    #\n",
        "    # The gamma^{ijkl}_{alpha beta} tensor that translates between antisymmetric\n",
        "    # 4-forms [ijkl] and symmetric traceless matrices over the spinors (sS).\n",
        "    g_ijsS = numpy.einsum('isc,jSc->ijsS', self.gamma_vsc, self.gamma_vsc)\n",
        "    g_ijcC = numpy.einsum('isc,jsC->ijcC', self.gamma_vsc, self.gamma_vsc)\n",
        "    g_ijklsS = numpy.einsum('ijst,kltS->ijklsS', g_ijsS, g_ijsS)\n",
        "    g_ijklcC = numpy.einsum('ijcd,kldC->ijklcC', g_ijcC, g_ijcC)\n",
        "    gamma_vvvvss = numpy.zeros([8] * 6)\n",
        "    gamma_vvvvcc = numpy.zeros([8] * 6)\n",
        "    for perm in itertools.permutations(range(4)):\n",
        "      perm_ijkl = ''.join('ijkl'[p] for p in perm)\n",
        "      sign = permutation_sign(perm)\n",
        "      gamma_vvvvss += sign * numpy.einsum(perm_ijkl + 'sS->ijklsS', g_ijklsS)\n",
        "      gamma_vvvvcc += sign * numpy.einsum(perm_ijkl + 'cC->ijklcC', g_ijklcC)\n",
        "    self.gamma_vvvvss = gamma_vvvvss / 24.0\n",
        "    self.gamma_vvvvcc = gamma_vvvvcc / 24.0\n",
        "\n",
        "  def _get_gamma_vsc(self):\n",
        "    \"\"\"Computes SO(8) gamma-matrices.\"\"\"\n",
        "    # Conventions match Green, Schwarz, Witten's, but with index-counting\n",
        "    # starting at zero.\n",
        "    entries = (\n",
        "        \"007+ 016- 025- 034+ 043- 052+ 061+ 070- \"\n",
        "        \"101+ 110- 123- 132+ 145+ 154- 167- 176+ \"\n",
        "        \"204+ 215- 226+ 237- 240- 251+ 262- 273+ \"\n",
        "        \"302+ 313+ 320- 331- 346- 357- 364+ 375+ \"\n",
        "        \"403+ 412- 421+ 430- 447+ 456- 465+ 474- \"\n",
        "        \"505+ 514+ 527+ 536+ 541- 550- 563- 572- \"\n",
        "        \"606+ 617+ 624- 635- 642+ 653+ 660- 671- \"\n",
        "        \"700+ 711+ 722+ 733+ 744+ 755+ 766+ 777+\")\n",
        "    ret = numpy.zeros([8, 8, 8])\n",
        "    for ijkc in entries.split():\n",
        "     ijk = tuple(map(int, ijkc[:-1]))\n",
        "     ret[ijk] = +1 if ijkc[-1] == '+' else -1\n",
        "    return ret\n",
        "\n",
        "\n",
        "class SU8(object):\n",
        "  \"\"\"Container class for su(8) tensor invariants.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    # Tensor that translates between adjoint indices 'a' and\n",
        "    # (vector) x (vector) indices 'ij'\n",
        "    ij_map = [(i, j) for i in range(8) for j in range(8) if i < j]\n",
        "    #\n",
        "    # We also need the mapping between 8 x 8 and 35 representations, using\n",
        "    # common conventions for a basis of the 35-representation, and likewise\n",
        "    # for 8 x 8 and 28.\n",
        "    m_35_8_8 = numpy.zeros([35, 8, 8], dtype=numpy.complex128)\n",
        "    m_28_8_8 = numpy.zeros([28, 8, 8], dtype=numpy.complex128)\n",
        "    for n in range(7):\n",
        "      m_35_8_8[n, n, n] = +1.0\n",
        "      m_35_8_8[n, n + 1, n + 1] = -1.0\n",
        "    for a, (m, n) in enumerate(ij_map):\n",
        "      m_35_8_8[a + 7, m, n] = m_35_8_8[a + 7, n, m] = 1.0\n",
        "      m_28_8_8[a, m, n] = 1.0\n",
        "      m_28_8_8[a, n, m] = -1.0\n",
        "    #\n",
        "    # The su8 'Generator Matrices'.\n",
        "    t_aij = numpy.zeros([63, 8, 8], dtype=numpy.complex128)\n",
        "    t_aij[:35, :, :] = 1.0j * m_35_8_8\n",
        "    for a, (i, j) in enumerate(ij_map):\n",
        "      t_aij[a + 35, i, j] = -1.0\n",
        "      t_aij[a + 35, j, i] = 1.0\n",
        "    self.ij_map = ij_map\n",
        "    self.m_35_8_8 = m_35_8_8\n",
        "    self.m_28_8_8 = m_28_8_8\n",
        "    self.t_aij = t_aij\n",
        "\n",
        "\n",
        "class E7(object):\n",
        "  \"\"\"Container class for e7 tensor invariants.\"\"\"\n",
        "\n",
        "  def __init__(self, spin8, su8):\n",
        "    self._spin8 = spin8\n",
        "    self._su8 = su8\n",
        "    ij_map = su8.ij_map\n",
        "    t_a_ij_kl = numpy.zeros([133, 56, 56], dtype=numpy.complex128)\n",
        "    t_a_ij_kl[:35, 28:, :28] = (1 / 8.0) * (\n",
        "        np_esum('ijklsS,qsS,Iij,Kkl->qIK',\n",
        "                spin8.gamma_vvvvss, su8.m_35_8_8, su8.m_28_8_8, su8.m_28_8_8))\n",
        "    t_a_ij_kl[:35, :28, 28:] = t_a_ij_kl[:35, 28:, :28]\n",
        "    t_a_ij_kl[35:70, 28:, :28] = (1.0j / 8.0) * (\n",
        "        np_esum('ijklcC,qcC,Iij,Kkl->qIK',\n",
        "                spin8.gamma_vvvvcc, su8.m_35_8_8, su8.m_28_8_8, su8.m_28_8_8))\n",
        "    t_a_ij_kl[35:70, :28, 28:] = -t_a_ij_kl[35:70, 28:, :28]\n",
        "    #\n",
        "    # We need to find the action of the su(8) algebra on the\n",
        "    # 28-representation.\n",
        "    su8_28 = 2 * np_esum('aij,mn,Iim,Jjn->aIJ',\n",
        "                          su8.t_aij,\n",
        "                          numpy.eye(8, dtype=numpy.complex128),\n",
        "                          su8.m_28_8_8, su8.m_28_8_8)\n",
        "    t_a_ij_kl[70:, :28, :28] = su8_28\n",
        "    t_a_ij_kl[70:, 28:, 28:] = su8_28.conjugate()\n",
        "    self.t_a_ij_kl = t_a_ij_kl\n",
        "    #\n",
        "    self.k_ab = numpy.einsum('aMN,bNM->ab', t_a_ij_kl, t_a_ij_kl)\n",
        "    self.v70_as_sc8x8 = numpy.einsum('sc,xab->sxcab',\n",
        "                                      numpy.eye(2),\n",
        "                                      su8.m_35_8_8).reshape(70, 2, 8, 8)\n",
        "    # For e7, there actually is a better orthonormal basis:\n",
        "    # the sd/asd 4-forms. The approach used here however readily generalizes\n",
        "    # to all other groups.\n",
        "    self.v70_onb_onbinv = get_onb_transform(self.k_ab[:70, :70])\n",
        "\n",
        "\n",
        "def get_proj_35_8888(want_selfdual=True):\n",
        "  \"\"\"Computes the (35, 8, 8, 8, 8)-projector to the (anti)self-dual 4-forms.\"\"\"\n",
        "  # We first need some basis for the 35 self-dual 4-forms.\n",
        "  # Our convention is that we lexicographically list those 8-choose-4\n",
        "  # combinations that contain the index 0.\n",
        "  sign_selfdual = 1 if want_selfdual else -1\n",
        "  ret = numpy.zeros([35, 8, 8, 8, 8], dtype=numpy.float64)\n",
        "  #\n",
        "  def get_selfdual(ijkl):\n",
        "    mnpq = tuple(n for n in range(8) if n not in ijkl)\n",
        "    return (sign_selfdual * permutation_sign(ijkl + mnpq),\n",
        "            ijkl, mnpq)\n",
        "  selfduals = [get_selfdual(ijkl)\n",
        "               for ijkl in itertools.combinations(range(8), 4)\n",
        "               if 0 in ijkl]\n",
        "  for num_sd, (sign_sd, ijkl, mnpq) in enumerate(selfduals):\n",
        "    for abcd in itertools.permutations(range(4)):\n",
        "      sign_abcd = permutation_sign(abcd)\n",
        "      ret[num_sd,\n",
        "          ijkl[abcd[0]],\n",
        "          ijkl[abcd[1]],\n",
        "          ijkl[abcd[2]],\n",
        "          ijkl[abcd[3]]] = sign_abcd\n",
        "      ret[num_sd,\n",
        "          mnpq[abcd[0]],\n",
        "          mnpq[abcd[1]],\n",
        "          mnpq[abcd[2]],\n",
        "          mnpq[abcd[3]]] = sign_abcd * sign_sd\n",
        "  return ret / 24.0\n",
        "\n",
        "\n",
        "spin8 = Spin8()\n",
        "su8 = SU8()\n",
        "e7 = E7(spin8, su8)\n",
        "\n",
        "\n",
        "assert (numpy_signature(e7.t_a_ij_kl) ==\n",
        "        'MMExYjC6Qr6gunZIYfRLLgM2PDtwUDYujBNzAIukAVY'), 'Bad E7(7) definitions.'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jc160kpJXxho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### SO(p, 8-p) gaugings\n",
        "\n",
        "def get_so_pq_E(p=8):\n",
        "  if p == 8 or p == 0:\n",
        "    return numpy.eye(56, dtype=complex)\n",
        "  q = 8 - p\n",
        "  pq_ratio = p / q\n",
        "  x88 = numpy.diag([-1.0] * p + [1.0 * pq_ratio] * q)\n",
        "  t = 0.25j * numpy.pi / (1 + pq_ratio)\n",
        "  k_ab = numpy.einsum('aij,bij->ab', su8.m_35_8_8, su8.m_35_8_8)\n",
        "  v35 = numpy.einsum('mab,ab,mM->M', su8.m_35_8_8, x88, numpy.linalg.inv(k_ab))\n",
        "  gen_E = numpy.einsum(\n",
        "    'aMN,a->NM',\n",
        "    e7.t_a_ij_kl,\n",
        "    numpy.pad(v35, [(0, 133 - 35)], 'constant'))\n",
        "  return scipy.linalg.expm(-t * gen_E)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pHqqZAKjRjkn",
        "colab": {}
      },
      "source": [
        "### Supergravity.\n",
        "\n",
        "@dataclasses.dataclass(frozen=True)\n",
        "class SUGRATensors(object):\n",
        "  v70: tf.Tensor\n",
        "  vielbein: tf.Tensor\n",
        "  tee_tensor: tf.Tensor\n",
        "  a1: tf.Tensor\n",
        "  a2: tf.Tensor\n",
        "  potential: tf.Tensor\n",
        "\n",
        "\n",
        "def get_tf_stationarity(fn_potential, **fn_potential_kwargs):\n",
        "  \"\"\"Returns a @tf.function that computes |grad potential|^2.\"\"\"\n",
        "  @tf.function\n",
        "  def stationarity(pos):\n",
        "    tape = tf.GradientTape()\n",
        "    with tape:\n",
        "      tape.watch(pos)\n",
        "      potential = fn_potential(pos, **fn_potential_kwargs)\n",
        "    grad_potential = tape.gradient(potential, pos)\n",
        "    return tf.reduce_sum(grad_potential * grad_potential)\n",
        "  return stationarity\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def dwn_stationarity(t_a1, t_a2):\n",
        "  \"\"\"Computes the de Wit-Nicolai stationarity-condition tensor.\"\"\"\n",
        "  # See: https://arxiv.org/pdf/1302.6219.pdf, text after (3.2).\n",
        "  t_x0 = (\n",
        "      +4.0 * tf.einsum('mi,mjkl->ijkl', t_a1, t_a2)\n",
        "      -3.0 * tf.einsum('mnij,nklm->ijkl', t_a2, t_a2))\n",
        "  t_x0_real = tf.math.real(t_x0)\n",
        "  t_x0_imag = tf.math.imag(t_x0)\n",
        "  tc_sd = tf.constant(get_proj_35_8888(True))\n",
        "  tc_asd = tf.constant(get_proj_35_8888(False))\n",
        "  t_x_real_sd = tf.einsum('aijkl,ijkl->a', tc_sd, t_x0_real)\n",
        "  t_x_imag_asd = tf.einsum('aijkl,ijkl->a', tc_asd, t_x0_imag)\n",
        "  return (tf.einsum('a,a->', t_x_real_sd, t_x_real_sd) +\n",
        "          tf.einsum('a,a->', t_x_imag_asd, t_x_imag_asd))\n",
        "\n",
        "\n",
        "def tf_sugra_tensors(t_v70, compute_masses, t_lhs_vielbein, t_rhs_E):\n",
        "  \"\"\"Returns key tensors for D=4 supergravity.\"\"\"\n",
        "  tc_28_8_8 = tf.constant(su8.m_28_8_8)\n",
        "  t_e7_generator_v70 = tf.einsum(\n",
        "      'v,vIJ->JI',\n",
        "      tf.complex(t_v70, tf.constant([0.0] * 70, dtype=tf.float64)),\n",
        "      tf.constant(e7.t_a_ij_kl[:70, :, :], dtype=tf.complex128))\n",
        "  t_complex_vielbein0 = tf.linalg.expm(t_e7_generator_v70) @ t_rhs_E\n",
        "  if compute_masses:\n",
        "    t_complex_vielbein = t_lhs_vielbein @ t_complex_vielbein0\n",
        "  else:\n",
        "    t_complex_vielbein = t_complex_vielbein0\n",
        "  @tf.function\n",
        "  def expand_ijkl(t_ab):\n",
        "    return 0.5 * tf.einsum(\n",
        "        'ijB,BIJ->ijIJ',\n",
        "        tf.einsum('AB,Aij->ijB', t_ab, tc_28_8_8),\n",
        "        tc_28_8_8)\n",
        "  #\n",
        "  t_u_ijIJ = expand_ijkl(t_complex_vielbein[:28, :28])\n",
        "  t_u_klKL = expand_ijkl(t_complex_vielbein[28:, 28:])\n",
        "  t_v_ijKL = expand_ijkl(t_complex_vielbein[:28, 28:])\n",
        "  t_v_klIJ = expand_ijkl(t_complex_vielbein[28:, :28])\n",
        "  #\n",
        "  t_uv = t_u_klKL + t_v_klIJ\n",
        "  t_uuvv = (tf.einsum('lmJK,kmKI->lkIJ', t_u_ijIJ, t_u_klKL) -\n",
        "            tf.einsum('lmJK,kmKI->lkIJ', t_v_ijKL, t_v_klIJ))\n",
        "  t_T = tf.einsum('ijIJ,lkIJ->lkij', t_uv, t_uuvv)\n",
        "  t_A1 = (-4.0 / 21.0) * tf.linalg.trace(tf.einsum('mijn->ijmn', t_T))\n",
        "  t_A2 = (-4.0 / (3 * 3)) * (\n",
        "      # Antisymmetrize in last 3 indices, taking into account antisymmetry\n",
        "      # in last two indices.\n",
        "      t_T\n",
        "      + tf.einsum('lijk->ljki', t_T)\n",
        "      + tf.einsum('lijk->lkij', t_T))\n",
        "  t_A1_real = tf.math.real(t_A1)\n",
        "  t_A1_imag = tf.math.imag(t_A1)\n",
        "  t_A2_real = tf.math.real(t_A2)\n",
        "  t_A2_imag = tf.math.imag(t_A2)\n",
        "  t_A1_potential = (-3.0 / 4) * (\n",
        "      tf.einsum('ij,ij->', t_A1_real, t_A1_real) +\n",
        "      tf.einsum('ij,ij->', t_A1_imag, t_A1_imag))\n",
        "  t_A2_potential = (1.0 / 24) * (\n",
        "      tf.einsum('ijkl,ijkl->', t_A2_real, t_A2_real) +\n",
        "      tf.einsum('ijkl,ijkl->', t_A2_imag, t_A2_imag))\n",
        "  t_potential = t_A1_potential + t_A2_potential\n",
        "  #\n",
        "  return t_v70, t_complex_vielbein, t_T, t_A1, t_A2, t_potential\n",
        "\n",
        "\n",
        "def so8_sugra_tensors(t_v70, tc_rhs_E):\n",
        "  t_v70, t_complex_vielbein, t_T, t_A1, t_A2, t_potential = (\n",
        "     tf_sugra_tensors(t_v70, False, 0.0, tc_rhs_E))\n",
        "  return SUGRATensors(\n",
        "      v70=t_v70,\n",
        "      vielbein=t_complex_vielbein,\n",
        "      tee_tensor=t_T,\n",
        "      a1=t_A1,\n",
        "      a2=t_A2,\n",
        "      potential=t_potential)\n",
        "\n",
        "\n",
        "def so8_sugra_scalar_masses(v70, so_pq_p):\n",
        "  # Note: In some situations, small deviations in the input give quite\n",
        "  # noticeable deviations in the scalar mass-spectrum.\n",
        "  # Getting reliable numbers here really requires satisfying\n",
        "  # the stationarity-condition to high accuracy.\n",
        "  tc_rhs_E = tf.constant(get_so_pq_E(so_pq_p), dtype=tf.complex128)\n",
        "  tc_e7_onb = tf.constant(e7.v70_onb_onbinv[0], dtype=tf.complex128)\n",
        "  tc_e7_taMN = tf.constant(e7.t_a_ij_kl[:70, :, :], dtype=tf.complex128)\n",
        "  t_v70 = tf.constant(v70, dtype=tf.float64)\n",
        "  #\n",
        "  def tf_grad_potential_lhs_onb(t_d_v70_onb):\n",
        "    tape = tf.GradientTape()\n",
        "    with tape:\n",
        "      tape.watch(t_d_v70_onb)\n",
        "      t_d_gen_e7 = tf.einsum(\n",
        "          'a,aMN->NM',\n",
        "          tf.einsum('Aa,A->a',\n",
        "                    tc_e7_onb,\n",
        "                    tf.complex(t_d_v70_onb, tf.zeros_like(t_d_v70_onb))),\n",
        "          tc_e7_taMN)\n",
        "      t_lhs_vielbein = (tf.eye(56, dtype=tf.complex128) +\n",
        "                        t_d_gen_e7 + 0.5 * t_d_gen_e7 @ t_d_gen_e7)\n",
        "      t_potential = (\n",
        "          tf_sugra_tensors(t_v70,\n",
        "                           tf.constant(True),\n",
        "                           t_lhs_vielbein,\n",
        "                           tc_rhs_E))[-1]\n",
        "    return tape.gradient(t_potential, t_d_v70_onb)\n",
        "  #\n",
        "  t_d_v70_onb = tf.Variable(numpy.zeros(70), dtype=tf.float64)\n",
        "  tape = tf.GradientTape(persistent=True)\n",
        "  with tape:\n",
        "    tape.watch(t_d_v70_onb)\n",
        "    grad_potential = tf.unstack(tf_grad_potential_lhs_onb(t_d_v70_onb))\n",
        "\n",
        "  t_mm = tf.stack([tape.gradient(grad_potential[k], t_d_v70_onb)\n",
        "                  for k in range(70)], axis=1)\n",
        "  stensors = so8_sugra_tensors(t_v70, tc_rhs_E)\n",
        "  return (t_mm * (36.0 / tf.abs(stensors.potential))).numpy()\n",
        "\n",
        "\n",
        "### Scanning\n",
        "\n",
        "def scanner(\n",
        "    use_dwn_stationarity=True,\n",
        "    so_pq_p=8,\n",
        "    seed=1,\n",
        "    scale=0.15,\n",
        "    stationarity_threshold=1e-4,\n",
        "    relu_coordinate_threshold=3.0,\n",
        "    gtol=1e-4,\n",
        "    f_squashed=tf.math.asinh):\n",
        "  \"\"\"Scans for critical points in the scalar potential.\n",
        "\n",
        "  Args:\n",
        "    use_dwn_stationarity: Whether to use the explicit stationarity condition\n",
        "      from `dwn_stationarity`.\n",
        "    so_pq_p: SO(p, 8-p) non-compact form of the gauge group to use.\n",
        "    seed: Random number generator seed for generating starting points.\n",
        "    scale: Scale for normal-distributed search starting point coordinates.\n",
        "    stationarity_threshold: Upper bound on permissible post-optimization\n",
        "      stationarity for a solution to be considered good.\n",
        "    relu_coordinate_threshold: Threshold for any coordinate-value at which\n",
        "      a ReLU-term kicks in, in order to move coordinates back to near zero.\n",
        "      (This is relevant for noncompact gaugings with flat directions,\n",
        "      where solutions can move 'very far out'.)\n",
        "    gtol: `gtol` parameter for scipy.optimize.fmin_bfgs.\n",
        "    f_squashed: Squashing-function for stationarity.\n",
        "      Should be approximately linear near zero, monotonic, and not growing\n",
        "      faster than logarithmic.\n",
        "  Yields:\n",
        "    `Solution` numerical solutions.\n",
        "  \"\"\"\n",
        "  # Use a seeded random number generator for better reproducibility\n",
        "  # (but note that scipy's optimizers may themselves use independent\n",
        "  # and not-easily-controllable random state).\n",
        "  rng = numpy.random.RandomState(seed=seed)\n",
        "  def get_x0():\n",
        "    return rng.normal(scale=scale, size=70)\n",
        "  #\n",
        "  tc_rhs_E = tf.constant(get_so_pq_E(so_pq_p), dtype=tf.complex128)\n",
        "  def f_potential(scalars):\n",
        "    return so8_sugra_tensors(tf.constant(scalars), tc_rhs_E).potential.numpy()\n",
        "  #\n",
        "  f_grad_pot_sq_stationarity = (\n",
        "      None if use_dwn_stationarity\n",
        "      else get_tf_stationarity(\n",
        "          lambda t_pos: so8_sugra_tensors(t_pos, tc_rhs_E).potential))\n",
        "  #\n",
        "  def f_t_stationarity(t_pos):\n",
        "    if use_dwn_stationarity:\n",
        "      stensors = so8_sugra_tensors(t_pos, tc_rhs_E)\n",
        "      stationarity = dwn_stationarity(stensors.a1, stensors.a2)\n",
        "    else:\n",
        "      stationarity = f_grad_pot_sq_stationarity(t_pos)\n",
        "    eff_stationarity = stationarity + tf.reduce_sum(\n",
        "        tf.nn.relu(abs(t_pos) - relu_coordinate_threshold))\n",
        "    return eff_stationarity\n",
        "  #\n",
        "  def f_opt(pos):\n",
        "    t_pos = tf.constant(pos)\n",
        "    t_stationarity = f_squashed(f_t_stationarity(t_pos))\n",
        "    return t_stationarity.numpy()\n",
        "  #\n",
        "  def fprime_opt(pos):\n",
        "    t_pos = tf.constant(pos)\n",
        "    tape = tf.GradientTape()\n",
        "    with tape:\n",
        "      tape.watch(t_pos)\n",
        "      t_stationarity = f_squashed(f_t_stationarity(t_pos))\n",
        "    t_grad_opt = tape.gradient(t_stationarity, t_pos)\n",
        "    return t_grad_opt.numpy()\n",
        "  #\n",
        "  while True:\n",
        "    opt = scipy.optimize.fmin_bfgs(\n",
        "        f_opt, get_x0(), fprime=fprime_opt, gtol=gtol, maxiter=10**4, disp=0)\n",
        "    opt_pot = f_potential(opt)\n",
        "    opt_stat = f_opt(opt)\n",
        "    if numpy.isnan(opt_pot) or not opt_stat < stationarity_threshold:\n",
        "      continue  # Optimization ran into a bad solution.\n",
        "    solution = Solution(potential=opt_pot,\n",
        "                        stationarity=opt_stat,\n",
        "                        pos=opt)\n",
        "    yield solution\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "paC8SebISgVX",
        "colab": {}
      },
      "source": [
        "### Demo.\n",
        "\n",
        "def demo(seed=0,\n",
        "         scale=0.2,\n",
        "         use_dwn_stationarity=True,\n",
        "         so_pq_p=8,\n",
        "         num_solutions=5,\n",
        "         f_squashed=tf.math.asinh):\n",
        "  solutions_iter = scanner(scale=scale, seed=seed,\n",
        "                           use_dwn_stationarity=use_dwn_stationarity,\n",
        "                           so_pq_p=so_pq_p, f_squashed=f_squashed)\n",
        "  for num_solution in range(num_solutions):\n",
        "    sol = next(solutions_iter)\n",
        "    print('=== Solution ===')\n",
        "    pprint.pprint(sol)\n",
        "    mm0 = so8_sugra_scalar_masses(sol.pos, so_pq_p)\n",
        "    print('\\nScalar Masses for: V/g^2=%s:' % sol.potential)\n",
        "    print(sorted(collections.Counter(\n",
        "        numpy.round(numpy.linalg.eigh(mm0)[0], 3)).items()))\n",
        "\n",
        "demo()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}