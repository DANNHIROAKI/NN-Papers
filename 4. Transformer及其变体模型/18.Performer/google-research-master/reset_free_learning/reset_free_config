# licenses(["notice"])
# reset_free config file
--root_dir=/usr/local/google/home/architsh/tmp/playpen
#--offline_dir=/usr/local/google/home/architsh/DriveFS/My Drive/local_experimental_data/offline_data/playpen_reduced/rc_o-rc_k/forward/replay_buffer

# env config
--max_episode_steps=50
--eval_episode_steps=50
--env_name=playpen_reduced
--reward_type=sparse

# environment videos
--video_record_interval=10000000000
--num_videos_per_interval=0

# reset wrapper properties
--num_success_states=1
--variable_reset_horizon=0
--reset_goal_frequency=50000

# SAC train hyperparameters
--num_iterations=10
--initial_collect_steps=100
--batch_size=256
--collect_steps_per_iteration=1
--train_steps_per_iteration=1
--actor_net_size=256,256
--critic_net_size=-1
--reward_scale_factor=10.0
--actor_learning_rate=3e-4
--critic_learning_rate=3e-4
--alpha_learning_rate=3e-4
--discount_factor=0.99
--replay_buffer_capacity=1000000


# reset-free algorithm hyperparameters
--use_reset_goals=0
--num_action_samples=10
--num_reset_candidates=-1
--reset_lagrange_learning_rate=0
--value_threshold=0.01
--lagrange_max=1
--use_minimum=0
--use_no_entropy_q=0

# relabelling goals
--relabel_goals=0
--goal_relabel_type=2
--num_relabelled_goals=2
--relabel_offline_data=0

# point mass type
--point_mass_env_type=default
--playpen_task=rc_o-rc_k

# debug
--reset_at_goal=0
--num_chunks=10
--num_success_for_switch=20