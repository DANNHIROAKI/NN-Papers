# Preprocessor
prepare_scannet_scene_dataset.valid_object_classes = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 16, 24, 28, 33, 34, 36, 39]
object_detection_preprocess.input_field_mapping_fn = @prepare_scannet_scene_dataset
object_detection_preprocess.images_points_correspondence_fn = None
object_detection_preprocess.points_pad_or_clip_size = 280000
object_detection_preprocess.voxel_grid_cell_size = (0.03, 0.03, 0.03)
object_detection_preprocess.voxels_pad_or_clip_size = 140000
object_detection_preprocess.point_feature_keys = ('point_normals',)
object_detection_preprocess.x_min_degree_rotation = None
object_detection_preprocess.x_max_degree_rotation = None
object_detection_preprocess.y_min_degree_rotation = None
object_detection_preprocess.y_max_degree_rotation = None
object_detection_preprocess.z_min_degree_rotation = -180.0
object_detection_preprocess.z_max_degree_rotation = 180.0
object_detection_preprocess.min_scale_ratio = 0.9
object_detection_preprocess.max_scale_ratio = 1.1
object_detection_preprocess.translation_range = 0.1
object_detection_preprocess.points_within_box_margin = 0.0
object_detection_preprocess.min_num_points_in_objects = 5
object_detection_preprocess.num_points_to_randomly_sample = 280000
object_detection_preprocess.crop_points_around_random_seed_point = False
object_detection_preprocess.fit_objects_to_instance_id_points = True


# Dataset
get_tf_data_dataset.dataset_name = 'scannet_scene'
get_tf_data_dataset.split_name = 'train'
get_tf_data_dataset.preprocess_fn = @object_detection_preprocess
get_tf_data_dataset.feature_keys = ['voxel_positions',
                                    'voxel_features',
                                    'voxel_xyz_indices',
                                    'points_to_voxel_mapping',
                                    'num_valid_voxels']
get_tf_data_dataset.label_keys = ['object_class_voxels',
                                  'object_rotation_matrix_voxels',
                                  'object_length_voxels',
                                  'object_height_voxels',
                                  'object_width_voxels',
                                  'object_center_voxels',
                                  'object_instance_id_voxels']
get_tf_data_dataset.shuffle_buffer_size = 4
get_tf_data_dataset.filenames_shuffle_buffer_size = 4
get_tf_data_dataset.read_block_length = 2
get_tf_data_dataset.num_readers = 4


# 3D Network
SparseConvHourGlass.num_stacked_networks = 1
SparseConvHourGlass.conv_filter_size = 3
SparseConvHourGlass.encoder_dimensions = ((32, 64), (64, 96), (96, 128), (128, 160), (160, 192), (192, 224), (224, 256))
SparseConvHourGlass.bottleneck_dimensions = (256, 256)
SparseConvHourGlass.decoder_dimensions = ((256, 256), (224, 224), (192, 192), (160, 160), (128, 128), (96, 96), (64, 64))
SparseConvHourGlass.use_batch_norm = True


# Losses
box_corner_distance_loss_on_voxel_tensors.is_intermediate = False
box_corner_distance_loss_on_voxel_tensors.loss_type = 'absolute_difference'
box_corner_distance_loss_on_voxel_tensors.is_balanced = True

box_classification_using_center_distance_loss.is_intermediate = False
box_classification_using_center_distance_loss.is_balanced = True
box_classification_using_center_distance_loss.max_positive_normalized_distance = 0.3

hard_negative_classification_loss.is_intermediate = False
hard_negative_classification_loss.gamma = 1.0


# Model
ObjectDetectionModel.num_classes = 41
ObjectDetectionModel.predict_rotation_x = False
ObjectDetectionModel.predict_rotation_y = False
ObjectDetectionModel.predict_rotation_z = False
ObjectDetectionModel.loss_names_to_functions = {
    'box_corner_distance_loss': @box_corner_distance_loss_on_voxel_tensors,
    'box_classification_using_center_distance_loss': @box_classification_using_center_distance_loss,
    'hard_negative_classification_loss': @hard_negative_classification_loss,
}
ObjectDetectionModel.loss_names_to_weights = {
    'box_corner_distance_loss': 5.0,
    'box_classification_using_center_distance_loss': 1.0,
    'hard_negative_classification_loss': 1.0,
}

# Training
step_decay.initial_learning_rate = 0.1
step_decay.boundary_list = [4000, 5000, 5500, 6000, 6500]
step_decay.ratio_list = [1.0, 0.3, 0.1, 0.03, 0.01, 0.001]

train.learning_rate_fn = @step_decay
train.input_fn = @get_tf_data_dataset
train.optimizer_fn = @tf.keras.optimizers.SGD
train.model_class = @ObjectDetectionModel
