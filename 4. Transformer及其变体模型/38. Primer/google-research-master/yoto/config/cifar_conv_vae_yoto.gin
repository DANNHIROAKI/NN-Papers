# Parameters for AdamOptimizer:
# ==============================================================================
AdamOptimizer.beta1 = 0.9
AdamOptimizer.beta2 = 0.999
AdamOptimizer.epsilon = 1e-08
AdamOptimizer.name = 'Adam'
AdamOptimizer.use_locking = False

# Parameters for decoder/ConditionalConvnet:
# ==============================================================================
decoder/ConditionalConvnet.alpha = 0.3
decoder/ConditionalConvnet.base_num_channels = 16
decoder/ConditionalConvnet.channels_out = 6
decoder/ConditionalConvnet.conditioning_layer_sizes = [512]
decoder/ConditionalConvnet.conditioning_postprocessing = \
    @ConditioningPostprocessing
decoder/ConditionalConvnet.conditioning_type = 'mult_and_add'
decoder/ConditionalConvnet.fc_layer_sizes = [512, 1024]
decoder/ConditionalConvnet.final_sigmoid = False
decoder/ConditionalConvnet.kernel_initializer_mode = 'fan_avg'
decoder/ConditionalConvnet.layers_per_block = 2
decoder/ConditionalConvnet.num_blocks = 3
decoder/ConditionalConvnet.upconv = True
decoder/ConditionalConvnet.upconv_reshape_size = [4, 4, 64]

# Parameters for encoder/ConditionalConvnet:
# ==============================================================================
encoder/ConditionalConvnet.alpha = 0.3
encoder/ConditionalConvnet.base_num_channels = 16
encoder/ConditionalConvnet.channels_out = 3
encoder/ConditionalConvnet.conditioning_layer_sizes = [512]
encoder/ConditionalConvnet.conditioning_postprocessing = \
    @ConditioningPostprocessing
encoder/ConditionalConvnet.conditioning_type = 'mult_and_add'
encoder/ConditionalConvnet.fc_layer_sizes = [512, 512]
encoder/ConditionalConvnet.final_sigmoid = False
encoder/ConditionalConvnet.kernel_initializer_mode = 'fan_avg'
encoder/ConditionalConvnet.layers_per_block = 2
encoder/ConditionalConvnet.num_blocks = 3
encoder/ConditionalConvnet.upconv = False
encoder/ConditionalConvnet.upconv_reshape_size = None

# Parameters for ConditionalVaeProblem:
# ==============================================================================
ConditionalVaeProblem.decoder = @decoder/ConditionalConvnet
ConditionalVaeProblem.encoder = @encoder/ConditionalConvnet
ConditionalVaeProblem.epsilon = 1e-06
ConditionalVaeProblem.features_key = 'image'
ConditionalVaeProblem.latent_dimensions = 256
ConditionalVaeProblem.output_distribution = 'gaussian'

# Parameters for decoder/ConditioningPostprocessing:
# ==============================================================================
decoder/ConditioningPostprocessing.scales_add = 1.0
decoder/ConditioningPostprocessing.scales_mult = 0.1
decoder/ConditioningPostprocessing.shifts_add = 0.0
decoder/ConditioningPostprocessing.shifts_mult = 0.1

# Parameters for encoder/ConditioningPostprocessing:
# ==============================================================================
encoder/ConditioningPostprocessing.scales_add = 1.0
encoder/ConditioningPostprocessing.scales_mult = 0.1
encoder/ConditioningPostprocessing.shifts_add = 0.0
encoder/ConditioningPostprocessing.shifts_mult = 0.1

# Parameters for train/DistributionSpec:
# ==============================================================================
train/DistributionSpec.distribution_type = %DistributionType.LOG_UNIFORM
train/DistributionSpec.params = \
    [{'high': 512.0, 'low': 0.125}, {'high': 1.001, 'low': 0.999}]
train/DistributionSpec.transform = %TransformType.IDENTITY

# Parameters for experiment:
# ==============================================================================
experiment.base_optimizer_class = @AdamOptimizer
experiment.base_optimizer_conditioning_class = None
experiment.batch_size = 128
experiment.dataset_name = 'cifar10'
experiment.eval_batch_size = 64
experiment.eval_on_test = True
experiment.eval_steps = 1000
experiment.eval_weights = \
    [{'kl_loss': 0.125, 'reconstruction_loss': 1.0},
     {'kl_loss': 0.25, 'reconstruction_loss': 1.0},
     {'kl_loss': 0.5, 'reconstruction_loss': 1.0},
     {'kl_loss': 1.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 2.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 4.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 8.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 16.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 32.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 64.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 128.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 256.0, 'reconstruction_loss': 1.0},
     {'kl_loss': 512.0, 'reconstruction_loss': 1.0}]
experiment.iterations_per_loop = 2000
experiment.keep_checkpoint_max = 0
experiment.optimizer_class = @YotoOptimizer
experiment.preprocess = 'resize(40)|random_crop(32)|flip_lr()|value_range(-1,1)'
experiment.preprocess_eval = 'value_range(-1,1)'
experiment.problem_class = @ConditionalVaeProblem
experiment.save_checkpoints_steps = 10000
experiment.train_steps = 1200000
experiment.training_params_class = @TrainingParams
experiment.training_params_conditioning_class = None

# Parameters for TrainingParams:
# ==============================================================================
TrainingParams.initial_lr = 0.0001
TrainingParams.lr_decay_factor = 0.5
TrainingParams.lr_decay_steps_str = '600000,780000,960000,1140000'
TrainingParams.weight_decay = 1e-05

# Parameters for YotoOptimizer:
# ==============================================================================
YotoOptimizer.extra_inputs_preprocessing = %TransformType.LOG
YotoOptimizer.normalize_loss_weights = False
YotoOptimizer.train_distribution_spec_class = @train/DistributionSpec
YotoOptimizer.weights_per_sample = True
