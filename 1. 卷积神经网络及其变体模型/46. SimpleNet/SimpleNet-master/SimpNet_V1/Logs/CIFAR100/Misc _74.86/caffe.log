
N:\Caffe\examples\cifar100>REM go to the caffe root 

N:\Caffe\examples\cifar100>cd ../../ 

N:\Caffe>set BIN=build/x64/Release 

N:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar100/fcifar100_full_relu_solver_bn.prototxt 
I0929 17:30:48.068542 11684 caffe.cpp:186] Using GPUs 0
I0929 17:30:48.482028 11684 caffe.cpp:191] GPU 0: GeForce GTX 980
I0929 17:30:48.706589 11684 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0929 17:30:48.706589 11684 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 1000
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.002
snapshot: 1000
snapshot_prefix: "examples/cifar10_full_relu_bn"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
delta: 0.001
stepvalue: 18000
stepvalue: 54000
stepvalue: 220000
stepvalue: 295000
stepvalue: 320000
stepvalue: 270000
type: "AdaDelta"
I0929 17:30:48.707590 11684 solver.cpp:91] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp4
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp5
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn_cccp6
I0929 17:30:48.709092 11684 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0929 17:30:48.709592 11684 net.cpp:49] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TRAIN
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label_fine"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "bn_cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp4"
  type: "Scale"
  bottom: "bn_cccp4"
  top: "scale_ccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "scale_ccp4"
  top: "scale_ccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "scale_ccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "bn_cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp5"
  type: "Scale"
  bottom: "bn_cccp5"
  top: "scale_ccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "scale_ccp5"
  top: "scale_ccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "scale_ccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "bn_cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp6"
  type: "Scale"
  bottom: "bn_cccp6"
  top: "scale_ccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "scale_ccp6"
  top: "scale_ccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "scale_ccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc_conv"
  type: "Convolution"
  bottom: "poolcp6"
  top: "fc_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    pad: 1
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ipf0"
  type: "InnerProduct"
  bottom: "fc_conv"
  top: "ipf0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "loss"
}
I0929 17:30:48.710093 11684 layer_factory.hpp:77] Creating layer cifar
I0929 17:30:48.711093 11684 net.cpp:91] Creating Layer cifar
I0929 17:30:48.711093 11684 net.cpp:399] cifar -> data
I0929 17:30:48.711093 11684 net.cpp:399] cifar -> label_fine
I0929 17:30:48.711594 10320 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0929 17:30:48.716596 10320 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I0929 17:30:48.743616 11684 data_layer.cpp:41] output data size: 50,3,32,32
I0929 17:30:48.746521 11684 net.cpp:141] Setting up cifar
I0929 17:30:48.747021 11684 net.cpp:148] Top shape: 50 3 32 32 (153600)
I0929 17:30:48.747021 11684 net.cpp:148] Top shape: 50 (50)
I0929 17:30:48.747021 11684 net.cpp:156] Memory required for data: 614600
I0929 17:30:48.747021 11684 layer_factory.hpp:77] Creating layer conv1
I0929 17:30:48.747021 11684 net.cpp:91] Creating Layer conv1
I0929 17:30:48.747021 11684 net.cpp:425] conv1 <- data
I0929 17:30:48.747021 11684 net.cpp:399] conv1 -> conv1
I0929 17:30:48.750025 12572 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0929 17:30:48.982864 11684 net.cpp:141] Setting up conv1
I0929 17:30:48.982864 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:48.982864 11684 net.cpp:156] Memory required for data: 13721800
I0929 17:30:48.982864 11684 layer_factory.hpp:77] Creating layer bn1
I0929 17:30:48.982864 11684 net.cpp:91] Creating Layer bn1
I0929 17:30:48.982864 11684 net.cpp:425] bn1 <- conv1
I0929 17:30:48.982864 11684 net.cpp:399] bn1 -> bn1
I0929 17:30:48.982864 11684 net.cpp:141] Setting up bn1
I0929 17:30:48.982864 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:48.982864 11684 net.cpp:156] Memory required for data: 26829000
I0929 17:30:48.983865 11684 layer_factory.hpp:77] Creating layer scale1
I0929 17:30:48.983865 11684 net.cpp:91] Creating Layer scale1
I0929 17:30:48.983865 11684 net.cpp:425] scale1 <- bn1
I0929 17:30:48.983865 11684 net.cpp:399] scale1 -> scale1
I0929 17:30:48.983865 11684 layer_factory.hpp:77] Creating layer scale1
I0929 17:30:48.983865 11684 net.cpp:141] Setting up scale1
I0929 17:30:48.983865 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:48.983865 11684 net.cpp:156] Memory required for data: 39936200
I0929 17:30:48.983865 11684 layer_factory.hpp:77] Creating layer relu1
I0929 17:30:48.983865 11684 net.cpp:91] Creating Layer relu1
I0929 17:30:48.983865 11684 net.cpp:425] relu1 <- scale1
I0929 17:30:48.983865 11684 net.cpp:386] relu1 -> scale1 (in-place)
I0929 17:30:48.983865 11684 net.cpp:141] Setting up relu1
I0929 17:30:48.983865 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:48.983865 11684 net.cpp:156] Memory required for data: 53043400
I0929 17:30:48.983865 11684 layer_factory.hpp:77] Creating layer conv1_0
I0929 17:30:48.983865 11684 net.cpp:91] Creating Layer conv1_0
I0929 17:30:48.983865 11684 net.cpp:425] conv1_0 <- scale1
I0929 17:30:48.983865 11684 net.cpp:399] conv1_0 -> conv1_0
I0929 17:30:48.985867 11684 net.cpp:141] Setting up conv1_0
I0929 17:30:48.985867 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.985867 11684 net.cpp:156] Memory required for data: 79257800
I0929 17:30:48.985867 11684 layer_factory.hpp:77] Creating layer bn1_0
I0929 17:30:48.985867 11684 net.cpp:91] Creating Layer bn1_0
I0929 17:30:48.985867 11684 net.cpp:425] bn1_0 <- conv1_0
I0929 17:30:48.985867 11684 net.cpp:399] bn1_0 -> bn1_0
I0929 17:30:48.985867 11684 net.cpp:141] Setting up bn1_0
I0929 17:30:48.985867 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.985867 11684 net.cpp:156] Memory required for data: 105472200
I0929 17:30:48.985867 11684 layer_factory.hpp:77] Creating layer scale1_0
I0929 17:30:48.985867 11684 net.cpp:91] Creating Layer scale1_0
I0929 17:30:48.985867 11684 net.cpp:425] scale1_0 <- bn1_0
I0929 17:30:48.985867 11684 net.cpp:399] scale1_0 -> scale1_0
I0929 17:30:48.985867 11684 layer_factory.hpp:77] Creating layer scale1_0
I0929 17:30:48.986867 11684 net.cpp:141] Setting up scale1_0
I0929 17:30:48.986867 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.986867 11684 net.cpp:156] Memory required for data: 131686600
I0929 17:30:48.986867 11684 layer_factory.hpp:77] Creating layer relu1_0
I0929 17:30:48.986867 11684 net.cpp:91] Creating Layer relu1_0
I0929 17:30:48.986867 11684 net.cpp:425] relu1_0 <- scale1_0
I0929 17:30:48.986867 11684 net.cpp:386] relu1_0 -> scale1_0 (in-place)
I0929 17:30:48.986867 11684 net.cpp:141] Setting up relu1_0
I0929 17:30:48.986867 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.986867 11684 net.cpp:156] Memory required for data: 157901000
I0929 17:30:48.986867 11684 layer_factory.hpp:77] Creating layer conv2
I0929 17:30:48.986867 11684 net.cpp:91] Creating Layer conv2
I0929 17:30:48.986867 11684 net.cpp:425] conv2 <- scale1_0
I0929 17:30:48.986867 11684 net.cpp:399] conv2 -> conv2
I0929 17:30:48.990870 11684 net.cpp:141] Setting up conv2
I0929 17:30:48.990870 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.990870 11684 net.cpp:156] Memory required for data: 184115400
I0929 17:30:48.990870 11684 layer_factory.hpp:77] Creating layer bn2
I0929 17:30:48.990870 11684 net.cpp:91] Creating Layer bn2
I0929 17:30:48.990870 11684 net.cpp:425] bn2 <- conv2
I0929 17:30:48.990870 11684 net.cpp:399] bn2 -> bn2
I0929 17:30:48.991870 11684 net.cpp:141] Setting up bn2
I0929 17:30:48.991870 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.991870 11684 net.cpp:156] Memory required for data: 210329800
I0929 17:30:48.991870 11684 layer_factory.hpp:77] Creating layer scale2
I0929 17:30:48.991870 11684 net.cpp:91] Creating Layer scale2
I0929 17:30:48.991870 11684 net.cpp:425] scale2 <- bn2
I0929 17:30:48.991870 11684 net.cpp:399] scale2 -> scale2
I0929 17:30:48.991870 11684 layer_factory.hpp:77] Creating layer scale2
I0929 17:30:48.991870 11684 net.cpp:141] Setting up scale2
I0929 17:30:48.991870 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.991870 11684 net.cpp:156] Memory required for data: 236544200
I0929 17:30:48.991870 11684 layer_factory.hpp:77] Creating layer relu2
I0929 17:30:48.991870 11684 net.cpp:91] Creating Layer relu2
I0929 17:30:48.991870 11684 net.cpp:425] relu2 <- scale2
I0929 17:30:48.991870 11684 net.cpp:386] relu2 -> scale2 (in-place)
I0929 17:30:48.991870 11684 net.cpp:141] Setting up relu2
I0929 17:30:48.991870 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.992871 11684 net.cpp:156] Memory required for data: 262758600
I0929 17:30:48.992871 11684 layer_factory.hpp:77] Creating layer conv2_1
I0929 17:30:48.992871 11684 net.cpp:91] Creating Layer conv2_1
I0929 17:30:48.992871 11684 net.cpp:425] conv2_1 <- scale2
I0929 17:30:48.992871 11684 net.cpp:399] conv2_1 -> conv2_1
I0929 17:30:48.997875 11684 net.cpp:141] Setting up conv2_1
I0929 17:30:48.997875 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.997875 11684 net.cpp:156] Memory required for data: 288973000
I0929 17:30:48.998877 11684 layer_factory.hpp:77] Creating layer bn2_1
I0929 17:30:48.998877 11684 net.cpp:91] Creating Layer bn2_1
I0929 17:30:48.998877 11684 net.cpp:425] bn2_1 <- conv2_1
I0929 17:30:48.998877 11684 net.cpp:399] bn2_1 -> bn2_1
I0929 17:30:48.998877 11684 net.cpp:141] Setting up bn2_1
I0929 17:30:48.998877 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.998877 11684 net.cpp:156] Memory required for data: 315187400
I0929 17:30:48.998877 11684 layer_factory.hpp:77] Creating layer scale2_1
I0929 17:30:48.998877 11684 net.cpp:91] Creating Layer scale2_1
I0929 17:30:48.998877 11684 net.cpp:425] scale2_1 <- bn2_1
I0929 17:30:48.998877 11684 net.cpp:399] scale2_1 -> scale2_1
I0929 17:30:48.998877 11684 layer_factory.hpp:77] Creating layer scale2_1
I0929 17:30:48.998877 11684 net.cpp:141] Setting up scale2_1
I0929 17:30:48.998877 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.998877 11684 net.cpp:156] Memory required for data: 341401800
I0929 17:30:48.998877 11684 layer_factory.hpp:77] Creating layer relu2_1
I0929 17:30:48.998877 11684 net.cpp:91] Creating Layer relu2_1
I0929 17:30:48.998877 11684 net.cpp:425] relu2_1 <- scale2_1
I0929 17:30:48.998877 11684 net.cpp:386] relu2_1 -> scale2_1 (in-place)
I0929 17:30:48.998877 11684 net.cpp:141] Setting up relu2_1
I0929 17:30:48.998877 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:48.998877 11684 net.cpp:156] Memory required for data: 367616200
I0929 17:30:48.998877 11684 layer_factory.hpp:77] Creating layer pool2_1
I0929 17:30:48.998877 11684 net.cpp:91] Creating Layer pool2_1
I0929 17:30:48.998877 11684 net.cpp:425] pool2_1 <- scale2_1
I0929 17:30:48.998877 11684 net.cpp:399] pool2_1 -> pool2_1
I0929 17:30:48.999876 11684 net.cpp:141] Setting up pool2_1
I0929 17:30:48.999876 11684 net.cpp:148] Top shape: 50 128 16 16 (1638400)
I0929 17:30:48.999876 11684 net.cpp:156] Memory required for data: 374169800
I0929 17:30:48.999876 11684 layer_factory.hpp:77] Creating layer conv2_2
I0929 17:30:48.999876 11684 net.cpp:91] Creating Layer conv2_2
I0929 17:30:48.999876 11684 net.cpp:425] conv2_2 <- pool2_1
I0929 17:30:48.999876 11684 net.cpp:399] conv2_2 -> conv2_2
I0929 17:30:49.004879 11684 net.cpp:141] Setting up conv2_2
I0929 17:30:49.004879 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.004879 11684 net.cpp:156] Memory required for data: 387277000
I0929 17:30:49.004879 11684 layer_factory.hpp:77] Creating layer bn2_2
I0929 17:30:49.004879 11684 net.cpp:91] Creating Layer bn2_2
I0929 17:30:49.004879 11684 net.cpp:425] bn2_2 <- conv2_2
I0929 17:30:49.004879 11684 net.cpp:399] bn2_2 -> bn2_2
I0929 17:30:49.005880 11684 net.cpp:141] Setting up bn2_2
I0929 17:30:49.005880 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.005880 11684 net.cpp:156] Memory required for data: 400384200
I0929 17:30:49.005880 11684 layer_factory.hpp:77] Creating layer scale2_2
I0929 17:30:49.005880 11684 net.cpp:91] Creating Layer scale2_2
I0929 17:30:49.005880 11684 net.cpp:425] scale2_2 <- bn2_2
I0929 17:30:49.005880 11684 net.cpp:399] scale2_2 -> scale2_2
I0929 17:30:49.005880 11684 layer_factory.hpp:77] Creating layer scale2_2
I0929 17:30:49.005880 11684 net.cpp:141] Setting up scale2_2
I0929 17:30:49.005880 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.005880 11684 net.cpp:156] Memory required for data: 413491400
I0929 17:30:49.005880 11684 layer_factory.hpp:77] Creating layer relu2_2
I0929 17:30:49.005880 11684 net.cpp:91] Creating Layer relu2_2
I0929 17:30:49.005880 11684 net.cpp:425] relu2_2 <- scale2_2
I0929 17:30:49.005880 11684 net.cpp:386] relu2_2 -> scale2_2 (in-place)
I0929 17:30:49.006881 11684 net.cpp:141] Setting up relu2_2
I0929 17:30:49.006881 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.006881 11684 net.cpp:156] Memory required for data: 426598600
I0929 17:30:49.006881 11684 layer_factory.hpp:77] Creating layer conv3
I0929 17:30:49.006881 11684 net.cpp:91] Creating Layer conv3
I0929 17:30:49.006881 11684 net.cpp:425] conv3 <- scale2_2
I0929 17:30:49.006881 11684 net.cpp:399] conv3 -> conv3
I0929 17:30:49.012886 11684 net.cpp:141] Setting up conv3
I0929 17:30:49.012886 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.012886 11684 net.cpp:156] Memory required for data: 439705800
I0929 17:30:49.012886 11684 layer_factory.hpp:77] Creating layer bn3
I0929 17:30:49.012886 11684 net.cpp:91] Creating Layer bn3
I0929 17:30:49.012886 11684 net.cpp:425] bn3 <- conv3
I0929 17:30:49.012886 11684 net.cpp:399] bn3 -> bn3
I0929 17:30:49.012886 11684 net.cpp:141] Setting up bn3
I0929 17:30:49.012886 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.012886 11684 net.cpp:156] Memory required for data: 452813000
I0929 17:30:49.012886 11684 layer_factory.hpp:77] Creating layer scale3
I0929 17:30:49.012886 11684 net.cpp:91] Creating Layer scale3
I0929 17:30:49.012886 11684 net.cpp:425] scale3 <- bn3
I0929 17:30:49.012886 11684 net.cpp:399] scale3 -> scale3
I0929 17:30:49.012886 11684 layer_factory.hpp:77] Creating layer scale3
I0929 17:30:49.012886 11684 net.cpp:141] Setting up scale3
I0929 17:30:49.012886 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.012886 11684 net.cpp:156] Memory required for data: 465920200
I0929 17:30:49.012886 11684 layer_factory.hpp:77] Creating layer relu3
I0929 17:30:49.012886 11684 net.cpp:91] Creating Layer relu3
I0929 17:30:49.012886 11684 net.cpp:425] relu3 <- scale3
I0929 17:30:49.012886 11684 net.cpp:386] relu3 -> scale3 (in-place)
I0929 17:30:49.013886 11684 net.cpp:141] Setting up relu3
I0929 17:30:49.013886 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.013886 11684 net.cpp:156] Memory required for data: 479027400
I0929 17:30:49.013886 11684 layer_factory.hpp:77] Creating layer conv4
I0929 17:30:49.014888 11684 net.cpp:91] Creating Layer conv4
I0929 17:30:49.014888 11684 net.cpp:425] conv4 <- scale3
I0929 17:30:49.014888 11684 net.cpp:399] conv4 -> conv4
I0929 17:30:49.022892 11684 net.cpp:141] Setting up conv4
I0929 17:30:49.022892 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.022892 11684 net.cpp:156] Memory required for data: 492134600
I0929 17:30:49.022892 11684 layer_factory.hpp:77] Creating layer pool4
I0929 17:30:49.022892 11684 net.cpp:91] Creating Layer pool4
I0929 17:30:49.022892 11684 net.cpp:425] pool4 <- conv4
I0929 17:30:49.022892 11684 net.cpp:399] pool4 -> pool4
I0929 17:30:49.022892 11684 net.cpp:141] Setting up pool4
I0929 17:30:49.022892 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.022892 11684 net.cpp:156] Memory required for data: 495411400
I0929 17:30:49.022892 11684 layer_factory.hpp:77] Creating layer bn4
I0929 17:30:49.022892 11684 net.cpp:91] Creating Layer bn4
I0929 17:30:49.022892 11684 net.cpp:425] bn4 <- pool4
I0929 17:30:49.022892 11684 net.cpp:399] bn4 -> bn4
I0929 17:30:49.023893 11684 net.cpp:141] Setting up bn4
I0929 17:30:49.023893 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.023893 11684 net.cpp:156] Memory required for data: 498688200
I0929 17:30:49.023893 11684 layer_factory.hpp:77] Creating layer scale4
I0929 17:30:49.023893 11684 net.cpp:91] Creating Layer scale4
I0929 17:30:49.023893 11684 net.cpp:425] scale4 <- bn4
I0929 17:30:49.023893 11684 net.cpp:399] scale4 -> scale4
I0929 17:30:49.023893 11684 layer_factory.hpp:77] Creating layer scale4
I0929 17:30:49.023893 11684 net.cpp:141] Setting up scale4
I0929 17:30:49.023893 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.023893 11684 net.cpp:156] Memory required for data: 501965000
I0929 17:30:49.023893 11684 layer_factory.hpp:77] Creating layer relu4
I0929 17:30:49.023893 11684 net.cpp:91] Creating Layer relu4
I0929 17:30:49.023893 11684 net.cpp:425] relu4 <- scale4
I0929 17:30:49.023893 11684 net.cpp:386] relu4 -> scale4 (in-place)
I0929 17:30:49.023893 11684 net.cpp:141] Setting up relu4
I0929 17:30:49.023893 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.023893 11684 net.cpp:156] Memory required for data: 505241800
I0929 17:30:49.023893 11684 layer_factory.hpp:77] Creating layer conv4_1
I0929 17:30:49.023893 11684 net.cpp:91] Creating Layer conv4_1
I0929 17:30:49.023893 11684 net.cpp:425] conv4_1 <- scale4
I0929 17:30:49.023893 11684 net.cpp:399] conv4_1 -> conv4_1
I0929 17:30:49.030899 11684 net.cpp:141] Setting up conv4_1
I0929 17:30:49.031899 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.031899 11684 net.cpp:156] Memory required for data: 508518600
I0929 17:30:49.031899 11684 layer_factory.hpp:77] Creating layer bn4_1
I0929 17:30:49.031899 11684 net.cpp:91] Creating Layer bn4_1
I0929 17:30:49.031899 11684 net.cpp:425] bn4_1 <- conv4_1
I0929 17:30:49.031899 11684 net.cpp:399] bn4_1 -> bn4_1
I0929 17:30:49.032901 11684 net.cpp:141] Setting up bn4_1
I0929 17:30:49.032901 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.032901 11684 net.cpp:156] Memory required for data: 511795400
I0929 17:30:49.032901 11684 layer_factory.hpp:77] Creating layer scale4_1
I0929 17:30:49.032901 11684 net.cpp:91] Creating Layer scale4_1
I0929 17:30:49.032901 11684 net.cpp:425] scale4_1 <- bn4_1
I0929 17:30:49.032901 11684 net.cpp:399] scale4_1 -> scale4_1
I0929 17:30:49.032901 11684 layer_factory.hpp:77] Creating layer scale4_1
I0929 17:30:49.032901 11684 net.cpp:141] Setting up scale4_1
I0929 17:30:49.032901 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.032901 11684 net.cpp:156] Memory required for data: 515072200
I0929 17:30:49.032901 11684 layer_factory.hpp:77] Creating layer relu4_1
I0929 17:30:49.032901 11684 net.cpp:91] Creating Layer relu4_1
I0929 17:30:49.032901 11684 net.cpp:425] relu4_1 <- scale4_1
I0929 17:30:49.032901 11684 net.cpp:386] relu4_1 -> scale4_1 (in-place)
I0929 17:30:49.035902 11684 net.cpp:141] Setting up relu4_1
I0929 17:30:49.035902 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.035902 11684 net.cpp:156] Memory required for data: 518349000
I0929 17:30:49.035902 11684 layer_factory.hpp:77] Creating layer conv4_2
I0929 17:30:49.035902 11684 net.cpp:91] Creating Layer conv4_2
I0929 17:30:49.036903 11684 net.cpp:425] conv4_2 <- scale4_1
I0929 17:30:49.036903 11684 net.cpp:399] conv4_2 -> conv4_2
I0929 17:30:49.043907 11684 net.cpp:141] Setting up conv4_2
I0929 17:30:49.043907 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.043907 11684 net.cpp:156] Memory required for data: 521625800
I0929 17:30:49.043907 11684 layer_factory.hpp:77] Creating layer bn4_2
I0929 17:30:49.043907 11684 net.cpp:91] Creating Layer bn4_2
I0929 17:30:49.043907 11684 net.cpp:425] bn4_2 <- conv4_2
I0929 17:30:49.043907 11684 net.cpp:399] bn4_2 -> bn4_2
I0929 17:30:49.043907 11684 net.cpp:141] Setting up bn4_2
I0929 17:30:49.043907 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.043907 11684 net.cpp:156] Memory required for data: 524902600
I0929 17:30:49.043907 11684 layer_factory.hpp:77] Creating layer scale4_2
I0929 17:30:49.043907 11684 net.cpp:91] Creating Layer scale4_2
I0929 17:30:49.043907 11684 net.cpp:425] scale4_2 <- bn4_2
I0929 17:30:49.043907 11684 net.cpp:399] scale4_2 -> scale4_2
I0929 17:30:49.043907 11684 layer_factory.hpp:77] Creating layer scale4_2
I0929 17:30:49.043907 11684 net.cpp:141] Setting up scale4_2
I0929 17:30:49.043907 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.043907 11684 net.cpp:156] Memory required for data: 528179400
I0929 17:30:49.043907 11684 layer_factory.hpp:77] Creating layer relu4_2
I0929 17:30:49.043907 11684 net.cpp:91] Creating Layer relu4_2
I0929 17:30:49.043907 11684 net.cpp:425] relu4_2 <- scale4_2
I0929 17:30:49.043907 11684 net.cpp:386] relu4_2 -> scale4_2 (in-place)
I0929 17:30:49.044908 11684 net.cpp:141] Setting up relu4_2
I0929 17:30:49.044908 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.044908 11684 net.cpp:156] Memory required for data: 531456200
I0929 17:30:49.044908 11684 layer_factory.hpp:77] Creating layer pool4_2
I0929 17:30:49.044908 11684 net.cpp:91] Creating Layer pool4_2
I0929 17:30:49.044908 11684 net.cpp:425] pool4_2 <- scale4_2
I0929 17:30:49.044908 11684 net.cpp:399] pool4_2 -> pool4_2
I0929 17:30:49.044908 11684 net.cpp:141] Setting up pool4_2
I0929 17:30:49.044908 11684 net.cpp:148] Top shape: 50 256 4 4 (204800)
I0929 17:30:49.044908 11684 net.cpp:156] Memory required for data: 532275400
I0929 17:30:49.044908 11684 layer_factory.hpp:77] Creating layer conv4_0
I0929 17:30:49.044908 11684 net.cpp:91] Creating Layer conv4_0
I0929 17:30:49.044908 11684 net.cpp:425] conv4_0 <- pool4_2
I0929 17:30:49.044908 11684 net.cpp:399] conv4_0 -> conv4_0
I0929 17:30:49.063921 11684 net.cpp:141] Setting up conv4_0
I0929 17:30:49.063921 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.063921 11684 net.cpp:156] Memory required for data: 533913800
I0929 17:30:49.063921 11684 layer_factory.hpp:77] Creating layer bn4_0
I0929 17:30:49.063921 11684 net.cpp:91] Creating Layer bn4_0
I0929 17:30:49.063921 11684 net.cpp:425] bn4_0 <- conv4_0
I0929 17:30:49.063921 11684 net.cpp:399] bn4_0 -> bn4_0
I0929 17:30:49.063921 11684 net.cpp:141] Setting up bn4_0
I0929 17:30:49.063921 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.063921 11684 net.cpp:156] Memory required for data: 535552200
I0929 17:30:49.063921 11684 layer_factory.hpp:77] Creating layer scale4_0
I0929 17:30:49.063921 11684 net.cpp:91] Creating Layer scale4_0
I0929 17:30:49.063921 11684 net.cpp:425] scale4_0 <- bn4_0
I0929 17:30:49.063921 11684 net.cpp:399] scale4_0 -> scale4_0
I0929 17:30:49.063921 11684 layer_factory.hpp:77] Creating layer scale4_0
I0929 17:30:49.063921 11684 net.cpp:141] Setting up scale4_0
I0929 17:30:49.063921 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.064923 11684 net.cpp:156] Memory required for data: 537190600
I0929 17:30:49.064923 11684 layer_factory.hpp:77] Creating layer relu4_0
I0929 17:30:49.064923 11684 net.cpp:91] Creating Layer relu4_0
I0929 17:30:49.064923 11684 net.cpp:425] relu4_0 <- scale4_0
I0929 17:30:49.064923 11684 net.cpp:386] relu4_0 -> scale4_0 (in-place)
I0929 17:30:49.065419 11684 net.cpp:141] Setting up relu4_0
I0929 17:30:49.065419 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.065419 11684 net.cpp:156] Memory required for data: 538829000
I0929 17:30:49.065419 11684 layer_factory.hpp:77] Creating layer cccp4
I0929 17:30:49.065419 11684 net.cpp:91] Creating Layer cccp4
I0929 17:30:49.065419 11684 net.cpp:425] cccp4 <- scale4_0
I0929 17:30:49.065419 11684 net.cpp:399] cccp4 -> cccp4
I0929 17:30:49.075929 11684 net.cpp:141] Setting up cccp4
I0929 17:30:49.075929 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.075929 11684 net.cpp:156] Memory required for data: 545382600
I0929 17:30:49.075929 11684 layer_factory.hpp:77] Creating layer bn_cccp4
I0929 17:30:49.075929 11684 net.cpp:91] Creating Layer bn_cccp4
I0929 17:30:49.075929 11684 net.cpp:425] bn_cccp4 <- cccp4
I0929 17:30:49.075929 11684 net.cpp:399] bn_cccp4 -> bn_cccp4
I0929 17:30:49.075929 11684 net.cpp:141] Setting up bn_cccp4
I0929 17:30:49.075929 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.075929 11684 net.cpp:156] Memory required for data: 551936200
I0929 17:30:49.075929 11684 layer_factory.hpp:77] Creating layer scale_ccp4
I0929 17:30:49.075929 11684 net.cpp:91] Creating Layer scale_ccp4
I0929 17:30:49.075929 11684 net.cpp:425] scale_ccp4 <- bn_cccp4
I0929 17:30:49.075929 11684 net.cpp:399] scale_ccp4 -> scale_ccp4
I0929 17:30:49.075929 11684 layer_factory.hpp:77] Creating layer scale_ccp4
I0929 17:30:49.076429 11684 net.cpp:141] Setting up scale_ccp4
I0929 17:30:49.076429 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.076429 11684 net.cpp:156] Memory required for data: 558489800
I0929 17:30:49.076429 11684 layer_factory.hpp:77] Creating layer relu_cccp4
I0929 17:30:49.076429 11684 net.cpp:91] Creating Layer relu_cccp4
I0929 17:30:49.076429 11684 net.cpp:425] relu_cccp4 <- scale_ccp4
I0929 17:30:49.076429 11684 net.cpp:386] relu_cccp4 -> scale_ccp4 (in-place)
I0929 17:30:49.076930 11684 net.cpp:141] Setting up relu_cccp4
I0929 17:30:49.076930 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.076930 11684 net.cpp:156] Memory required for data: 565043400
I0929 17:30:49.076930 11684 layer_factory.hpp:77] Creating layer cccp5
I0929 17:30:49.076930 11684 net.cpp:91] Creating Layer cccp5
I0929 17:30:49.076930 11684 net.cpp:425] cccp5 <- scale_ccp4
I0929 17:30:49.076930 11684 net.cpp:399] cccp5 -> cccp5
I0929 17:30:49.162490 11684 net.cpp:141] Setting up cccp5
I0929 17:30:49.162490 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.162490 11684 net.cpp:156] Memory required for data: 565453000
I0929 17:30:49.162490 11684 layer_factory.hpp:77] Creating layer bn_cccp5
I0929 17:30:49.162490 11684 net.cpp:91] Creating Layer bn_cccp5
I0929 17:30:49.162490 11684 net.cpp:425] bn_cccp5 <- cccp5
I0929 17:30:49.162490 11684 net.cpp:399] bn_cccp5 -> bn_cccp5
I0929 17:30:49.162490 11684 net.cpp:141] Setting up bn_cccp5
I0929 17:30:49.162490 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.162490 11684 net.cpp:156] Memory required for data: 565862600
I0929 17:30:49.162490 11684 layer_factory.hpp:77] Creating layer scale_ccp5
I0929 17:30:49.162490 11684 net.cpp:91] Creating Layer scale_ccp5
I0929 17:30:49.162490 11684 net.cpp:425] scale_ccp5 <- bn_cccp5
I0929 17:30:49.162490 11684 net.cpp:399] scale_ccp5 -> scale_ccp5
I0929 17:30:49.162490 11684 layer_factory.hpp:77] Creating layer scale_ccp5
I0929 17:30:49.162991 11684 net.cpp:141] Setting up scale_ccp5
I0929 17:30:49.162991 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.162991 11684 net.cpp:156] Memory required for data: 566272200
I0929 17:30:49.162991 11684 layer_factory.hpp:77] Creating layer relu_cccp5
I0929 17:30:49.162991 11684 net.cpp:91] Creating Layer relu_cccp5
I0929 17:30:49.162991 11684 net.cpp:425] relu_cccp5 <- scale_ccp5
I0929 17:30:49.162991 11684 net.cpp:386] relu_cccp5 -> scale_ccp5 (in-place)
I0929 17:30:49.163491 11684 net.cpp:141] Setting up relu_cccp5
I0929 17:30:49.163491 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.163491 11684 net.cpp:156] Memory required for data: 566681800
I0929 17:30:49.163491 11684 layer_factory.hpp:77] Creating layer poolcp5
I0929 17:30:49.163491 11684 net.cpp:91] Creating Layer poolcp5
I0929 17:30:49.163491 11684 net.cpp:425] poolcp5 <- scale_ccp5
I0929 17:30:49.163491 11684 net.cpp:399] poolcp5 -> poolcp5
I0929 17:30:49.163491 11684 net.cpp:141] Setting up poolcp5
I0929 17:30:49.163491 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.163491 11684 net.cpp:156] Memory required for data: 566784200
I0929 17:30:49.163491 11684 layer_factory.hpp:77] Creating layer cccp6
I0929 17:30:49.163491 11684 net.cpp:91] Creating Layer cccp6
I0929 17:30:49.163491 11684 net.cpp:425] cccp6 <- poolcp5
I0929 17:30:49.163491 11684 net.cpp:399] cccp6 -> cccp6
I0929 17:30:49.218030 11684 net.cpp:141] Setting up cccp6
I0929 17:30:49.218030 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.218030 11684 net.cpp:156] Memory required for data: 566886600
I0929 17:30:49.218030 11684 layer_factory.hpp:77] Creating layer bn_cccp6
I0929 17:30:49.218030 11684 net.cpp:91] Creating Layer bn_cccp6
I0929 17:30:49.218030 11684 net.cpp:425] bn_cccp6 <- cccp6
I0929 17:30:49.218030 11684 net.cpp:399] bn_cccp6 -> bn_cccp6
I0929 17:30:49.218530 11684 net.cpp:141] Setting up bn_cccp6
I0929 17:30:49.218530 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.218530 11684 net.cpp:156] Memory required for data: 566989000
I0929 17:30:49.218530 11684 layer_factory.hpp:77] Creating layer scale_ccp6
I0929 17:30:49.218530 11684 net.cpp:91] Creating Layer scale_ccp6
I0929 17:30:49.218530 11684 net.cpp:425] scale_ccp6 <- bn_cccp6
I0929 17:30:49.218530 11684 net.cpp:399] scale_ccp6 -> scale_ccp6
I0929 17:30:49.218530 11684 layer_factory.hpp:77] Creating layer scale_ccp6
I0929 17:30:49.219032 11684 net.cpp:141] Setting up scale_ccp6
I0929 17:30:49.219032 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.219032 11684 net.cpp:156] Memory required for data: 567091400
I0929 17:30:49.219032 11684 layer_factory.hpp:77] Creating layer relu_cccp6
I0929 17:30:49.219032 11684 net.cpp:91] Creating Layer relu_cccp6
I0929 17:30:49.219032 11684 net.cpp:425] relu_cccp6 <- scale_ccp6
I0929 17:30:49.219032 11684 net.cpp:386] relu_cccp6 -> scale_ccp6 (in-place)
I0929 17:30:49.219532 11684 net.cpp:141] Setting up relu_cccp6
I0929 17:30:49.219532 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.219532 11684 net.cpp:156] Memory required for data: 567193800
I0929 17:30:49.219532 11684 layer_factory.hpp:77] Creating layer poolcp6
I0929 17:30:49.219532 11684 net.cpp:91] Creating Layer poolcp6
I0929 17:30:49.219532 11684 net.cpp:425] poolcp6 <- scale_ccp6
I0929 17:30:49.219532 11684 net.cpp:399] poolcp6 -> poolcp6
I0929 17:30:49.219532 11684 net.cpp:141] Setting up poolcp6
I0929 17:30:49.219532 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.219532 11684 net.cpp:156] Memory required for data: 567296200
I0929 17:30:49.219532 11684 layer_factory.hpp:77] Creating layer fc_conv
I0929 17:30:49.219532 11684 net.cpp:91] Creating Layer fc_conv
I0929 17:30:49.219532 11684 net.cpp:425] fc_conv <- poolcp6
I0929 17:30:49.219532 11684 net.cpp:399] fc_conv -> fc_conv
I0929 17:30:49.232540 11684 net.cpp:141] Setting up fc_conv
I0929 17:30:49.233042 11684 net.cpp:148] Top shape: 50 2048 3 3 (921600)
I0929 17:30:49.233042 11684 net.cpp:156] Memory required for data: 570982600
I0929 17:30:49.233042 11684 layer_factory.hpp:77] Creating layer ipf0
I0929 17:30:49.233042 11684 net.cpp:91] Creating Layer ipf0
I0929 17:30:49.233042 11684 net.cpp:425] ipf0 <- fc_conv
I0929 17:30:49.233042 11684 net.cpp:399] ipf0 -> ipf0
I0929 17:30:49.249722 11684 net.cpp:141] Setting up ipf0
I0929 17:30:49.249722 11684 net.cpp:148] Top shape: 50 100 (5000)
I0929 17:30:49.249722 11684 net.cpp:156] Memory required for data: 571002600
I0929 17:30:49.249722 11684 layer_factory.hpp:77] Creating layer loss
I0929 17:30:49.249722 11684 net.cpp:91] Creating Layer loss
I0929 17:30:49.249722 11684 net.cpp:425] loss <- ipf0
I0929 17:30:49.249722 11684 net.cpp:425] loss <- label_fine
I0929 17:30:49.249722 11684 net.cpp:399] loss -> loss
I0929 17:30:49.249722 11684 layer_factory.hpp:77] Creating layer loss
I0929 17:30:49.251724 11684 net.cpp:141] Setting up loss
I0929 17:30:49.251724 11684 net.cpp:148] Top shape: (1)
I0929 17:30:49.251724 11684 net.cpp:151]     with loss weight 1
I0929 17:30:49.251724 11684 net.cpp:156] Memory required for data: 571002604
I0929 17:30:49.251724 11684 net.cpp:217] loss needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] ipf0 needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] fc_conv needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] poolcp6 needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] relu_cccp6 needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] scale_ccp6 needs backward computation.
I0929 17:30:49.251724 11684 net.cpp:217] bn_cccp6 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] cccp6 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] poolcp5 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu_cccp5 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale_ccp5 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn_cccp5 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] cccp5 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu_cccp4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale_ccp4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn_cccp4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] cccp4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu4_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale4_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn4_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv4_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] pool4_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu4_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale4_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn4_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv4_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu4_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale4_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn4_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv4_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] pool4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv4 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu3 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale3 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn3 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv3 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu2_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale2_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn2_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv2_2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] pool2_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu2_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale2_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn2_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv2_1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv2 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu1_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale1_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn1_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv1_0 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] relu1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] scale1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] bn1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:217] conv1 needs backward computation.
I0929 17:30:49.252725 11684 net.cpp:219] cifar does not need backward computation.
I0929 17:30:49.252725 11684 net.cpp:261] This network produces output loss
I0929 17:30:49.252725 11684 net.cpp:274] Network initialization done.
I0929 17:30:49.253725 11684 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp4
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp5
I0929 17:30:49.253725 11684 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn_cccp6
I0929 17:30:49.254725 11684 net.cpp:49] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label_fine"
  include {
    phase: TEST
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "scale1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "scale1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "scale1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "scale1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "scale2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "scale2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "scale2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "scale2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "scale2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "scale2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "scale3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "scale3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "scale4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "scale4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "scale4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "scale4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "scale4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "scale4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "scale4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "scale4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp4"
  type: "BatchNorm"
  bottom: "cccp4"
  top: "bn_cccp4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp4"
  type: "Scale"
  bottom: "bn_cccp4"
  top: "scale_ccp4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "scale_ccp4"
  top: "scale_ccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "scale_ccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp5"
  type: "BatchNorm"
  bottom: "cccp5"
  top: "bn_cccp5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp5"
  type: "Scale"
  bottom: "bn_cccp5"
  top: "scale_ccp5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "scale_ccp5"
  top: "scale_ccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "scale_ccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "bn_cccp6"
  type: "BatchNorm"
  bottom: "cccp6"
  top: "bn_cccp6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale_ccp6"
  type: "Scale"
  bottom: "bn_cccp6"
  top: "scale_ccp6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "scale_ccp6"
  top: "scale_ccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "scale_ccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc_conv"
  type: "Convolution"
  bottom: "poolcp6"
  top: "fc_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    pad: 1
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "ipf0"
  type: "InnerProduct"
  bottom: "fc_conv"
  top: "ipf0"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ipf0"
  bottom: "label_fine"
  top: "loss"
}
I0929 17:30:49.254725 11684 layer_factory.hpp:77] Creating layer cifar
I0929 17:30:49.255726 11684 net.cpp:91] Creating Layer cifar
I0929 17:30:49.255726 11684 net.cpp:399] cifar -> data
I0929 17:30:49.255726 11684 net.cpp:399] cifar -> label_fine
I0929 17:30:49.256727 11788 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0929 17:30:49.262732 11788 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I0929 17:30:49.263732 11684 data_layer.cpp:41] output data size: 50,3,32,32
I0929 17:30:49.269737 11684 net.cpp:141] Setting up cifar
I0929 17:30:49.269737 11684 net.cpp:148] Top shape: 50 3 32 32 (153600)
I0929 17:30:49.269737 11684 net.cpp:148] Top shape: 50 (50)
I0929 17:30:49.269737 11684 net.cpp:156] Memory required for data: 614600
I0929 17:30:49.269737 11684 layer_factory.hpp:77] Creating layer label_fine_cifar_1_split
I0929 17:30:49.269737 11684 net.cpp:91] Creating Layer label_fine_cifar_1_split
I0929 17:30:49.269737 11684 net.cpp:425] label_fine_cifar_1_split <- label_fine
I0929 17:30:49.269737 11684 net.cpp:399] label_fine_cifar_1_split -> label_fine_cifar_1_split_0
I0929 17:30:49.269737 11684 net.cpp:399] label_fine_cifar_1_split -> label_fine_cifar_1_split_1
I0929 17:30:49.269737 11684 net.cpp:141] Setting up label_fine_cifar_1_split
I0929 17:30:49.269737 11684 net.cpp:148] Top shape: 50 (50)
I0929 17:30:49.269737 11684 net.cpp:148] Top shape: 50 (50)
I0929 17:30:49.269737 11684 net.cpp:156] Memory required for data: 615000
I0929 17:30:49.269737 11684 layer_factory.hpp:77] Creating layer conv1
I0929 17:30:49.271739 11684 net.cpp:91] Creating Layer conv1
I0929 17:30:49.271739 11684 net.cpp:425] conv1 <- data
I0929 17:30:49.271739 11684 net.cpp:399] conv1 -> conv1
I0929 17:30:49.272739 11684 net.cpp:141] Setting up conv1
I0929 17:30:49.272739 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:49.272739 11684 net.cpp:156] Memory required for data: 13722200
I0929 17:30:49.272739 11684 layer_factory.hpp:77] Creating layer bn1
I0929 17:30:49.272739 11684 net.cpp:91] Creating Layer bn1
I0929 17:30:49.272739 11684 net.cpp:425] bn1 <- conv1
I0929 17:30:49.272739 11684 net.cpp:399] bn1 -> bn1
I0929 17:30:49.273739 13184 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0929 17:30:49.273739 11684 net.cpp:141] Setting up bn1
I0929 17:30:49.273739 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:49.273739 11684 net.cpp:156] Memory required for data: 26829400
I0929 17:30:49.273739 11684 layer_factory.hpp:77] Creating layer scale1
I0929 17:30:49.273739 11684 net.cpp:91] Creating Layer scale1
I0929 17:30:49.273739 11684 net.cpp:425] scale1 <- bn1
I0929 17:30:49.273739 11684 net.cpp:399] scale1 -> scale1
I0929 17:30:49.273739 11684 layer_factory.hpp:77] Creating layer scale1
I0929 17:30:49.273739 11684 net.cpp:141] Setting up scale1
I0929 17:30:49.273739 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:49.273739 11684 net.cpp:156] Memory required for data: 39936600
I0929 17:30:49.273739 11684 layer_factory.hpp:77] Creating layer relu1
I0929 17:30:49.273739 11684 net.cpp:91] Creating Layer relu1
I0929 17:30:49.273739 11684 net.cpp:425] relu1 <- scale1
I0929 17:30:49.274740 11684 net.cpp:386] relu1 -> scale1 (in-place)
I0929 17:30:49.274740 11684 net.cpp:141] Setting up relu1
I0929 17:30:49.274740 11684 net.cpp:148] Top shape: 50 64 32 32 (3276800)
I0929 17:30:49.274740 11684 net.cpp:156] Memory required for data: 53043800
I0929 17:30:49.274740 11684 layer_factory.hpp:77] Creating layer conv1_0
I0929 17:30:49.274740 11684 net.cpp:91] Creating Layer conv1_0
I0929 17:30:49.274740 11684 net.cpp:425] conv1_0 <- scale1
I0929 17:30:49.274740 11684 net.cpp:399] conv1_0 -> conv1_0
I0929 17:30:49.275741 13184 blocking_queue.cpp:50] Waiting for data
I0929 17:30:49.277742 11684 net.cpp:141] Setting up conv1_0
I0929 17:30:49.277742 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.277742 11684 net.cpp:156] Memory required for data: 79258200
I0929 17:30:49.277742 11684 layer_factory.hpp:77] Creating layer bn1_0
I0929 17:30:49.277742 11684 net.cpp:91] Creating Layer bn1_0
I0929 17:30:49.277742 11684 net.cpp:425] bn1_0 <- conv1_0
I0929 17:30:49.277742 11684 net.cpp:399] bn1_0 -> bn1_0
I0929 17:30:49.277742 11684 net.cpp:141] Setting up bn1_0
I0929 17:30:49.277742 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.277742 11684 net.cpp:156] Memory required for data: 105472600
I0929 17:30:49.277742 11684 layer_factory.hpp:77] Creating layer scale1_0
I0929 17:30:49.277742 11684 net.cpp:91] Creating Layer scale1_0
I0929 17:30:49.277742 11684 net.cpp:425] scale1_0 <- bn1_0
I0929 17:30:49.277742 11684 net.cpp:399] scale1_0 -> scale1_0
I0929 17:30:49.277742 11684 layer_factory.hpp:77] Creating layer scale1_0
I0929 17:30:49.277742 11684 net.cpp:141] Setting up scale1_0
I0929 17:30:49.277742 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.277742 11684 net.cpp:156] Memory required for data: 131687000
I0929 17:30:49.277742 11684 layer_factory.hpp:77] Creating layer relu1_0
I0929 17:30:49.277742 11684 net.cpp:91] Creating Layer relu1_0
I0929 17:30:49.277742 11684 net.cpp:425] relu1_0 <- scale1_0
I0929 17:30:49.277742 11684 net.cpp:386] relu1_0 -> scale1_0 (in-place)
I0929 17:30:49.278743 11684 net.cpp:141] Setting up relu1_0
I0929 17:30:49.278743 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.278743 11684 net.cpp:156] Memory required for data: 157901400
I0929 17:30:49.278743 11684 layer_factory.hpp:77] Creating layer conv2
I0929 17:30:49.278743 11684 net.cpp:91] Creating Layer conv2
I0929 17:30:49.278743 11684 net.cpp:425] conv2 <- scale1_0
I0929 17:30:49.278743 11684 net.cpp:399] conv2 -> conv2
I0929 17:30:49.284747 11684 net.cpp:141] Setting up conv2
I0929 17:30:49.284747 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.284747 11684 net.cpp:156] Memory required for data: 184115800
I0929 17:30:49.284747 11684 layer_factory.hpp:77] Creating layer bn2
I0929 17:30:49.284747 11684 net.cpp:91] Creating Layer bn2
I0929 17:30:49.284747 11684 net.cpp:425] bn2 <- conv2
I0929 17:30:49.284747 11684 net.cpp:399] bn2 -> bn2
I0929 17:30:49.285748 11684 net.cpp:141] Setting up bn2
I0929 17:30:49.285748 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.285748 11684 net.cpp:156] Memory required for data: 210330200
I0929 17:30:49.285748 11684 layer_factory.hpp:77] Creating layer scale2
I0929 17:30:49.285748 11684 net.cpp:91] Creating Layer scale2
I0929 17:30:49.285748 11684 net.cpp:425] scale2 <- bn2
I0929 17:30:49.285748 11684 net.cpp:399] scale2 -> scale2
I0929 17:30:49.285748 11684 layer_factory.hpp:77] Creating layer scale2
I0929 17:30:49.285748 11684 net.cpp:141] Setting up scale2
I0929 17:30:49.285748 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.285748 11684 net.cpp:156] Memory required for data: 236544600
I0929 17:30:49.285748 11684 layer_factory.hpp:77] Creating layer relu2
I0929 17:30:49.285748 11684 net.cpp:91] Creating Layer relu2
I0929 17:30:49.285748 11684 net.cpp:425] relu2 <- scale2
I0929 17:30:49.285748 11684 net.cpp:386] relu2 -> scale2 (in-place)
I0929 17:30:49.286748 11684 net.cpp:141] Setting up relu2
I0929 17:30:49.286748 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.286748 11684 net.cpp:156] Memory required for data: 262759000
I0929 17:30:49.286748 11684 layer_factory.hpp:77] Creating layer conv2_1
I0929 17:30:49.286748 11684 net.cpp:91] Creating Layer conv2_1
I0929 17:30:49.286748 11684 net.cpp:425] conv2_1 <- scale2
I0929 17:30:49.286748 11684 net.cpp:399] conv2_1 -> conv2_1
I0929 17:30:49.291817 11684 net.cpp:141] Setting up conv2_1
I0929 17:30:49.291817 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.291817 11684 net.cpp:156] Memory required for data: 288973400
I0929 17:30:49.291817 11684 layer_factory.hpp:77] Creating layer bn2_1
I0929 17:30:49.291817 11684 net.cpp:91] Creating Layer bn2_1
I0929 17:30:49.291817 11684 net.cpp:425] bn2_1 <- conv2_1
I0929 17:30:49.291817 11684 net.cpp:399] bn2_1 -> bn2_1
I0929 17:30:49.291817 11684 net.cpp:141] Setting up bn2_1
I0929 17:30:49.291817 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.291817 11684 net.cpp:156] Memory required for data: 315187800
I0929 17:30:49.291817 11684 layer_factory.hpp:77] Creating layer scale2_1
I0929 17:30:49.291817 11684 net.cpp:91] Creating Layer scale2_1
I0929 17:30:49.291817 11684 net.cpp:425] scale2_1 <- bn2_1
I0929 17:30:49.291817 11684 net.cpp:399] scale2_1 -> scale2_1
I0929 17:30:49.291817 11684 layer_factory.hpp:77] Creating layer scale2_1
I0929 17:30:49.291817 11684 net.cpp:141] Setting up scale2_1
I0929 17:30:49.291817 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.291817 11684 net.cpp:156] Memory required for data: 341402200
I0929 17:30:49.291817 11684 layer_factory.hpp:77] Creating layer relu2_1
I0929 17:30:49.291817 11684 net.cpp:91] Creating Layer relu2_1
I0929 17:30:49.291817 11684 net.cpp:425] relu2_1 <- scale2_1
I0929 17:30:49.291817 11684 net.cpp:386] relu2_1 -> scale2_1 (in-place)
I0929 17:30:49.292819 11684 net.cpp:141] Setting up relu2_1
I0929 17:30:49.292819 11684 net.cpp:148] Top shape: 50 128 32 32 (6553600)
I0929 17:30:49.292819 11684 net.cpp:156] Memory required for data: 367616600
I0929 17:30:49.292819 11684 layer_factory.hpp:77] Creating layer pool2_1
I0929 17:30:49.292819 11684 net.cpp:91] Creating Layer pool2_1
I0929 17:30:49.292819 11684 net.cpp:425] pool2_1 <- scale2_1
I0929 17:30:49.292819 11684 net.cpp:399] pool2_1 -> pool2_1
I0929 17:30:49.292819 11684 net.cpp:141] Setting up pool2_1
I0929 17:30:49.292819 11684 net.cpp:148] Top shape: 50 128 16 16 (1638400)
I0929 17:30:49.292819 11684 net.cpp:156] Memory required for data: 374170200
I0929 17:30:49.292819 11684 layer_factory.hpp:77] Creating layer conv2_2
I0929 17:30:49.292819 11684 net.cpp:91] Creating Layer conv2_2
I0929 17:30:49.292819 11684 net.cpp:425] conv2_2 <- pool2_1
I0929 17:30:49.292819 11684 net.cpp:399] conv2_2 -> conv2_2
I0929 17:30:49.300825 11684 net.cpp:141] Setting up conv2_2
I0929 17:30:49.300825 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.300825 11684 net.cpp:156] Memory required for data: 387277400
I0929 17:30:49.300825 11684 layer_factory.hpp:77] Creating layer bn2_2
I0929 17:30:49.300825 11684 net.cpp:91] Creating Layer bn2_2
I0929 17:30:49.300825 11684 net.cpp:425] bn2_2 <- conv2_2
I0929 17:30:49.300825 11684 net.cpp:399] bn2_2 -> bn2_2
I0929 17:30:49.301826 11684 net.cpp:141] Setting up bn2_2
I0929 17:30:49.301826 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.301826 11684 net.cpp:156] Memory required for data: 400384600
I0929 17:30:49.301826 11684 layer_factory.hpp:77] Creating layer scale2_2
I0929 17:30:49.301826 11684 net.cpp:91] Creating Layer scale2_2
I0929 17:30:49.301826 11684 net.cpp:425] scale2_2 <- bn2_2
I0929 17:30:49.301826 11684 net.cpp:399] scale2_2 -> scale2_2
I0929 17:30:49.301826 11684 layer_factory.hpp:77] Creating layer scale2_2
I0929 17:30:49.301826 11684 net.cpp:141] Setting up scale2_2
I0929 17:30:49.301826 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.301826 11684 net.cpp:156] Memory required for data: 413491800
I0929 17:30:49.301826 11684 layer_factory.hpp:77] Creating layer relu2_2
I0929 17:30:49.301826 11684 net.cpp:91] Creating Layer relu2_2
I0929 17:30:49.301826 11684 net.cpp:425] relu2_2 <- scale2_2
I0929 17:30:49.301826 11684 net.cpp:386] relu2_2 -> scale2_2 (in-place)
I0929 17:30:49.301826 11684 net.cpp:141] Setting up relu2_2
I0929 17:30:49.301826 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.301826 11684 net.cpp:156] Memory required for data: 426599000
I0929 17:30:49.301826 11684 layer_factory.hpp:77] Creating layer conv3
I0929 17:30:49.301826 11684 net.cpp:91] Creating Layer conv3
I0929 17:30:49.301826 11684 net.cpp:425] conv3 <- scale2_2
I0929 17:30:49.301826 11684 net.cpp:399] conv3 -> conv3
I0929 17:30:49.309831 11684 net.cpp:141] Setting up conv3
I0929 17:30:49.309831 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.309831 11684 net.cpp:156] Memory required for data: 439706200
I0929 17:30:49.309831 11684 layer_factory.hpp:77] Creating layer bn3
I0929 17:30:49.309831 11684 net.cpp:91] Creating Layer bn3
I0929 17:30:49.309831 11684 net.cpp:425] bn3 <- conv3
I0929 17:30:49.309831 11684 net.cpp:399] bn3 -> bn3
I0929 17:30:49.309831 11684 net.cpp:141] Setting up bn3
I0929 17:30:49.309831 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.309831 11684 net.cpp:156] Memory required for data: 452813400
I0929 17:30:49.309831 11684 layer_factory.hpp:77] Creating layer scale3
I0929 17:30:49.309831 11684 net.cpp:91] Creating Layer scale3
I0929 17:30:49.309831 11684 net.cpp:425] scale3 <- bn3
I0929 17:30:49.309831 11684 net.cpp:399] scale3 -> scale3
I0929 17:30:49.309831 11684 layer_factory.hpp:77] Creating layer scale3
I0929 17:30:49.309831 11684 net.cpp:141] Setting up scale3
I0929 17:30:49.309831 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.309831 11684 net.cpp:156] Memory required for data: 465920600
I0929 17:30:49.309831 11684 layer_factory.hpp:77] Creating layer relu3
I0929 17:30:49.309831 11684 net.cpp:91] Creating Layer relu3
I0929 17:30:49.309831 11684 net.cpp:425] relu3 <- scale3
I0929 17:30:49.309831 11684 net.cpp:386] relu3 -> scale3 (in-place)
I0929 17:30:49.310832 11684 net.cpp:141] Setting up relu3
I0929 17:30:49.310832 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.310832 11684 net.cpp:156] Memory required for data: 479027800
I0929 17:30:49.310832 11684 layer_factory.hpp:77] Creating layer conv4
I0929 17:30:49.310832 11684 net.cpp:91] Creating Layer conv4
I0929 17:30:49.310832 11684 net.cpp:425] conv4 <- scale3
I0929 17:30:49.310832 11684 net.cpp:399] conv4 -> conv4
I0929 17:30:49.317879 11684 net.cpp:141] Setting up conv4
I0929 17:30:49.317879 11684 net.cpp:148] Top shape: 50 256 16 16 (3276800)
I0929 17:30:49.317879 11684 net.cpp:156] Memory required for data: 492135000
I0929 17:30:49.317879 11684 layer_factory.hpp:77] Creating layer pool4
I0929 17:30:49.317879 11684 net.cpp:91] Creating Layer pool4
I0929 17:30:49.317879 11684 net.cpp:425] pool4 <- conv4
I0929 17:30:49.317879 11684 net.cpp:399] pool4 -> pool4
I0929 17:30:49.317879 11684 net.cpp:141] Setting up pool4
I0929 17:30:49.317879 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.317879 11684 net.cpp:156] Memory required for data: 495411800
I0929 17:30:49.317879 11684 layer_factory.hpp:77] Creating layer bn4
I0929 17:30:49.317879 11684 net.cpp:91] Creating Layer bn4
I0929 17:30:49.317879 11684 net.cpp:425] bn4 <- pool4
I0929 17:30:49.317879 11684 net.cpp:399] bn4 -> bn4
I0929 17:30:49.317879 11684 net.cpp:141] Setting up bn4
I0929 17:30:49.317879 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.317879 11684 net.cpp:156] Memory required for data: 498688600
I0929 17:30:49.317879 11684 layer_factory.hpp:77] Creating layer scale4
I0929 17:30:49.317879 11684 net.cpp:91] Creating Layer scale4
I0929 17:30:49.317879 11684 net.cpp:425] scale4 <- bn4
I0929 17:30:49.317879 11684 net.cpp:399] scale4 -> scale4
I0929 17:30:49.317879 11684 layer_factory.hpp:77] Creating layer scale4
I0929 17:30:49.317879 11684 net.cpp:141] Setting up scale4
I0929 17:30:49.317879 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.317879 11684 net.cpp:156] Memory required for data: 501965400
I0929 17:30:49.317879 11684 layer_factory.hpp:77] Creating layer relu4
I0929 17:30:49.317879 11684 net.cpp:91] Creating Layer relu4
I0929 17:30:49.317879 11684 net.cpp:425] relu4 <- scale4
I0929 17:30:49.317879 11684 net.cpp:386] relu4 -> scale4 (in-place)
I0929 17:30:49.318881 11684 net.cpp:141] Setting up relu4
I0929 17:30:49.318881 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.318881 11684 net.cpp:156] Memory required for data: 505242200
I0929 17:30:49.318881 11684 layer_factory.hpp:77] Creating layer conv4_1
I0929 17:30:49.318881 11684 net.cpp:91] Creating Layer conv4_1
I0929 17:30:49.318881 11684 net.cpp:425] conv4_1 <- scale4
I0929 17:30:49.318881 11684 net.cpp:399] conv4_1 -> conv4_1
I0929 17:30:49.325314 11684 net.cpp:141] Setting up conv4_1
I0929 17:30:49.325314 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.325314 11684 net.cpp:156] Memory required for data: 508519000
I0929 17:30:49.325314 11684 layer_factory.hpp:77] Creating layer bn4_1
I0929 17:30:49.325314 11684 net.cpp:91] Creating Layer bn4_1
I0929 17:30:49.325314 11684 net.cpp:425] bn4_1 <- conv4_1
I0929 17:30:49.325314 11684 net.cpp:399] bn4_1 -> bn4_1
I0929 17:30:49.325314 11684 net.cpp:141] Setting up bn4_1
I0929 17:30:49.325314 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.325314 11684 net.cpp:156] Memory required for data: 511795800
I0929 17:30:49.325314 11684 layer_factory.hpp:77] Creating layer scale4_1
I0929 17:30:49.325314 11684 net.cpp:91] Creating Layer scale4_1
I0929 17:30:49.325314 11684 net.cpp:425] scale4_1 <- bn4_1
I0929 17:30:49.325314 11684 net.cpp:399] scale4_1 -> scale4_1
I0929 17:30:49.325314 11684 layer_factory.hpp:77] Creating layer scale4_1
I0929 17:30:49.325314 11684 net.cpp:141] Setting up scale4_1
I0929 17:30:49.325314 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.325314 11684 net.cpp:156] Memory required for data: 515072600
I0929 17:30:49.325314 11684 layer_factory.hpp:77] Creating layer relu4_1
I0929 17:30:49.325314 11684 net.cpp:91] Creating Layer relu4_1
I0929 17:30:49.325314 11684 net.cpp:425] relu4_1 <- scale4_1
I0929 17:30:49.325314 11684 net.cpp:386] relu4_1 -> scale4_1 (in-place)
I0929 17:30:49.326316 11684 net.cpp:141] Setting up relu4_1
I0929 17:30:49.326316 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.326316 11684 net.cpp:156] Memory required for data: 518349400
I0929 17:30:49.326316 11684 layer_factory.hpp:77] Creating layer conv4_2
I0929 17:30:49.326316 11684 net.cpp:91] Creating Layer conv4_2
I0929 17:30:49.326316 11684 net.cpp:425] conv4_2 <- scale4_1
I0929 17:30:49.326316 11684 net.cpp:399] conv4_2 -> conv4_2
I0929 17:30:49.335324 11684 net.cpp:141] Setting up conv4_2
I0929 17:30:49.335324 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.335324 11684 net.cpp:156] Memory required for data: 521626200
I0929 17:30:49.335324 11684 layer_factory.hpp:77] Creating layer bn4_2
I0929 17:30:49.335324 11684 net.cpp:91] Creating Layer bn4_2
I0929 17:30:49.335324 11684 net.cpp:425] bn4_2 <- conv4_2
I0929 17:30:49.335324 11684 net.cpp:399] bn4_2 -> bn4_2
I0929 17:30:49.336323 11684 net.cpp:141] Setting up bn4_2
I0929 17:30:49.336323 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.336323 11684 net.cpp:156] Memory required for data: 524903000
I0929 17:30:49.336323 11684 layer_factory.hpp:77] Creating layer scale4_2
I0929 17:30:49.336323 11684 net.cpp:91] Creating Layer scale4_2
I0929 17:30:49.336323 11684 net.cpp:425] scale4_2 <- bn4_2
I0929 17:30:49.336323 11684 net.cpp:399] scale4_2 -> scale4_2
I0929 17:30:49.336323 11684 layer_factory.hpp:77] Creating layer scale4_2
I0929 17:30:49.336323 11684 net.cpp:141] Setting up scale4_2
I0929 17:30:49.336323 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.336323 11684 net.cpp:156] Memory required for data: 528179800
I0929 17:30:49.336323 11684 layer_factory.hpp:77] Creating layer relu4_2
I0929 17:30:49.336323 11684 net.cpp:91] Creating Layer relu4_2
I0929 17:30:49.336323 11684 net.cpp:425] relu4_2 <- scale4_2
I0929 17:30:49.336323 11684 net.cpp:386] relu4_2 -> scale4_2 (in-place)
I0929 17:30:49.337324 11684 net.cpp:141] Setting up relu4_2
I0929 17:30:49.337324 11684 net.cpp:148] Top shape: 50 256 8 8 (819200)
I0929 17:30:49.337324 11684 net.cpp:156] Memory required for data: 531456600
I0929 17:30:49.337324 11684 layer_factory.hpp:77] Creating layer pool4_2
I0929 17:30:49.337324 11684 net.cpp:91] Creating Layer pool4_2
I0929 17:30:49.337324 11684 net.cpp:425] pool4_2 <- scale4_2
I0929 17:30:49.337324 11684 net.cpp:399] pool4_2 -> pool4_2
I0929 17:30:49.337324 11684 net.cpp:141] Setting up pool4_2
I0929 17:30:49.337324 11684 net.cpp:148] Top shape: 50 256 4 4 (204800)
I0929 17:30:49.337324 11684 net.cpp:156] Memory required for data: 532275800
I0929 17:30:49.337324 11684 layer_factory.hpp:77] Creating layer conv4_0
I0929 17:30:49.337324 11684 net.cpp:91] Creating Layer conv4_0
I0929 17:30:49.337324 11684 net.cpp:425] conv4_0 <- pool4_2
I0929 17:30:49.337324 11684 net.cpp:399] conv4_0 -> conv4_0
I0929 17:30:49.349334 11684 net.cpp:141] Setting up conv4_0
I0929 17:30:49.350333 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.350333 11684 net.cpp:156] Memory required for data: 533914200
I0929 17:30:49.350333 11684 layer_factory.hpp:77] Creating layer bn4_0
I0929 17:30:49.350333 11684 net.cpp:91] Creating Layer bn4_0
I0929 17:30:49.350333 11684 net.cpp:425] bn4_0 <- conv4_0
I0929 17:30:49.350333 11684 net.cpp:399] bn4_0 -> bn4_0
I0929 17:30:49.350333 11684 net.cpp:141] Setting up bn4_0
I0929 17:30:49.350333 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.350333 11684 net.cpp:156] Memory required for data: 535552600
I0929 17:30:49.350333 11684 layer_factory.hpp:77] Creating layer scale4_0
I0929 17:30:49.350333 11684 net.cpp:91] Creating Layer scale4_0
I0929 17:30:49.350333 11684 net.cpp:425] scale4_0 <- bn4_0
I0929 17:30:49.350333 11684 net.cpp:399] scale4_0 -> scale4_0
I0929 17:30:49.350333 11684 layer_factory.hpp:77] Creating layer scale4_0
I0929 17:30:49.350333 11684 net.cpp:141] Setting up scale4_0
I0929 17:30:49.350333 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.350333 11684 net.cpp:156] Memory required for data: 537191000
I0929 17:30:49.350333 11684 layer_factory.hpp:77] Creating layer relu4_0
I0929 17:30:49.350333 11684 net.cpp:91] Creating Layer relu4_0
I0929 17:30:49.350333 11684 net.cpp:425] relu4_0 <- scale4_0
I0929 17:30:49.350333 11684 net.cpp:386] relu4_0 -> scale4_0 (in-place)
I0929 17:30:49.350333 11684 net.cpp:141] Setting up relu4_0
I0929 17:30:49.350333 11684 net.cpp:148] Top shape: 50 512 4 4 (409600)
I0929 17:30:49.350333 11684 net.cpp:156] Memory required for data: 538829400
I0929 17:30:49.350333 11684 layer_factory.hpp:77] Creating layer cccp4
I0929 17:30:49.350333 11684 net.cpp:91] Creating Layer cccp4
I0929 17:30:49.350333 11684 net.cpp:425] cccp4 <- scale4_0
I0929 17:30:49.350333 11684 net.cpp:399] cccp4 -> cccp4
I0929 17:30:49.362074 11684 net.cpp:141] Setting up cccp4
I0929 17:30:49.362074 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.362074 11684 net.cpp:156] Memory required for data: 545383000
I0929 17:30:49.362074 11684 layer_factory.hpp:77] Creating layer bn_cccp4
I0929 17:30:49.362074 11684 net.cpp:91] Creating Layer bn_cccp4
I0929 17:30:49.362074 11684 net.cpp:425] bn_cccp4 <- cccp4
I0929 17:30:49.362074 11684 net.cpp:399] bn_cccp4 -> bn_cccp4
I0929 17:30:49.362074 11684 net.cpp:141] Setting up bn_cccp4
I0929 17:30:49.362074 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.362074 11684 net.cpp:156] Memory required for data: 551936600
I0929 17:30:49.362074 11684 layer_factory.hpp:77] Creating layer scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:91] Creating Layer scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:425] scale_ccp4 <- bn_cccp4
I0929 17:30:49.362074 11684 net.cpp:399] scale_ccp4 -> scale_ccp4
I0929 17:30:49.362074 11684 layer_factory.hpp:77] Creating layer scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:141] Setting up scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.362074 11684 net.cpp:156] Memory required for data: 558490200
I0929 17:30:49.362074 11684 layer_factory.hpp:77] Creating layer relu_cccp4
I0929 17:30:49.362074 11684 net.cpp:91] Creating Layer relu_cccp4
I0929 17:30:49.362074 11684 net.cpp:425] relu_cccp4 <- scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:386] relu_cccp4 -> scale_ccp4 (in-place)
I0929 17:30:49.362074 11684 net.cpp:141] Setting up relu_cccp4
I0929 17:30:49.362074 11684 net.cpp:148] Top shape: 50 2048 4 4 (1638400)
I0929 17:30:49.362074 11684 net.cpp:156] Memory required for data: 565043800
I0929 17:30:49.362074 11684 layer_factory.hpp:77] Creating layer cccp5
I0929 17:30:49.362074 11684 net.cpp:91] Creating Layer cccp5
I0929 17:30:49.362074 11684 net.cpp:425] cccp5 <- scale_ccp4
I0929 17:30:49.362074 11684 net.cpp:399] cccp5 -> cccp5
I0929 17:30:49.447134 11684 net.cpp:141] Setting up cccp5
I0929 17:30:49.447134 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.447134 11684 net.cpp:156] Memory required for data: 565453400
I0929 17:30:49.447134 11684 layer_factory.hpp:77] Creating layer bn_cccp5
I0929 17:30:49.447134 11684 net.cpp:91] Creating Layer bn_cccp5
I0929 17:30:49.447134 11684 net.cpp:425] bn_cccp5 <- cccp5
I0929 17:30:49.447134 11684 net.cpp:399] bn_cccp5 -> bn_cccp5
I0929 17:30:49.447134 11684 net.cpp:141] Setting up bn_cccp5
I0929 17:30:49.447134 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.447134 11684 net.cpp:156] Memory required for data: 565863000
I0929 17:30:49.447134 11684 layer_factory.hpp:77] Creating layer scale_ccp5
I0929 17:30:49.447134 11684 net.cpp:91] Creating Layer scale_ccp5
I0929 17:30:49.447134 11684 net.cpp:425] scale_ccp5 <- bn_cccp5
I0929 17:30:49.447134 11684 net.cpp:399] scale_ccp5 -> scale_ccp5
I0929 17:30:49.447134 11684 layer_factory.hpp:77] Creating layer scale_ccp5
I0929 17:30:49.448135 11684 net.cpp:141] Setting up scale_ccp5
I0929 17:30:49.449137 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.449137 11684 net.cpp:156] Memory required for data: 566272600
I0929 17:30:49.449137 11684 layer_factory.hpp:77] Creating layer relu_cccp5
I0929 17:30:49.449137 11684 net.cpp:91] Creating Layer relu_cccp5
I0929 17:30:49.449137 11684 net.cpp:425] relu_cccp5 <- scale_ccp5
I0929 17:30:49.449137 11684 net.cpp:386] relu_cccp5 -> scale_ccp5 (in-place)
I0929 17:30:49.449137 11684 net.cpp:141] Setting up relu_cccp5
I0929 17:30:49.449137 11684 net.cpp:148] Top shape: 50 512 2 2 (102400)
I0929 17:30:49.449137 11684 net.cpp:156] Memory required for data: 566682200
I0929 17:30:49.449137 11684 layer_factory.hpp:77] Creating layer poolcp5
I0929 17:30:49.449137 11684 net.cpp:91] Creating Layer poolcp5
I0929 17:30:49.449137 11684 net.cpp:425] poolcp5 <- scale_ccp5
I0929 17:30:49.449137 11684 net.cpp:399] poolcp5 -> poolcp5
I0929 17:30:49.449137 11684 net.cpp:141] Setting up poolcp5
I0929 17:30:49.449137 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.449137 11684 net.cpp:156] Memory required for data: 566784600
I0929 17:30:49.449137 11684 layer_factory.hpp:77] Creating layer cccp6
I0929 17:30:49.449137 11684 net.cpp:91] Creating Layer cccp6
I0929 17:30:49.449137 11684 net.cpp:425] cccp6 <- poolcp5
I0929 17:30:49.450137 11684 net.cpp:399] cccp6 -> cccp6
I0929 17:30:49.479157 11684 net.cpp:141] Setting up cccp6
I0929 17:30:49.479157 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.479157 11684 net.cpp:156] Memory required for data: 566887000
I0929 17:30:49.479157 11684 layer_factory.hpp:77] Creating layer bn_cccp6
I0929 17:30:49.479157 11684 net.cpp:91] Creating Layer bn_cccp6
I0929 17:30:49.479157 11684 net.cpp:425] bn_cccp6 <- cccp6
I0929 17:30:49.479157 11684 net.cpp:399] bn_cccp6 -> bn_cccp6
I0929 17:30:49.479157 11684 net.cpp:141] Setting up bn_cccp6
I0929 17:30:49.479157 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.479157 11684 net.cpp:156] Memory required for data: 566989400
I0929 17:30:49.479157 11684 layer_factory.hpp:77] Creating layer scale_ccp6
I0929 17:30:49.479157 11684 net.cpp:91] Creating Layer scale_ccp6
I0929 17:30:49.479157 11684 net.cpp:425] scale_ccp6 <- bn_cccp6
I0929 17:30:49.479157 11684 net.cpp:399] scale_ccp6 -> scale_ccp6
I0929 17:30:49.479157 11684 layer_factory.hpp:77] Creating layer scale_ccp6
I0929 17:30:49.479157 11684 net.cpp:141] Setting up scale_ccp6
I0929 17:30:49.479157 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.479157 11684 net.cpp:156] Memory required for data: 567091800
I0929 17:30:49.479157 11684 layer_factory.hpp:77] Creating layer relu_cccp6
I0929 17:30:49.479157 11684 net.cpp:91] Creating Layer relu_cccp6
I0929 17:30:49.479157 11684 net.cpp:425] relu_cccp6 <- scale_ccp6
I0929 17:30:49.479157 11684 net.cpp:386] relu_cccp6 -> scale_ccp6 (in-place)
I0929 17:30:49.480159 11684 net.cpp:141] Setting up relu_cccp6
I0929 17:30:49.480159 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.480159 11684 net.cpp:156] Memory required for data: 567194200
I0929 17:30:49.480159 11684 layer_factory.hpp:77] Creating layer poolcp6
I0929 17:30:49.480159 11684 net.cpp:91] Creating Layer poolcp6
I0929 17:30:49.480159 11684 net.cpp:425] poolcp6 <- scale_ccp6
I0929 17:30:49.480159 11684 net.cpp:399] poolcp6 -> poolcp6
I0929 17:30:49.483160 11684 net.cpp:141] Setting up poolcp6
I0929 17:30:49.483160 11684 net.cpp:148] Top shape: 50 512 1 1 (25600)
I0929 17:30:49.483160 11684 net.cpp:156] Memory required for data: 567296600
I0929 17:30:49.483160 11684 layer_factory.hpp:77] Creating layer fc_conv
I0929 17:30:49.483160 11684 net.cpp:91] Creating Layer fc_conv
I0929 17:30:49.483160 11684 net.cpp:425] fc_conv <- poolcp6
I0929 17:30:49.483160 11684 net.cpp:399] fc_conv -> fc_conv
I0929 17:30:49.495137 11684 net.cpp:141] Setting up fc_conv
I0929 17:30:49.495137 11684 net.cpp:148] Top shape: 50 2048 3 3 (921600)
I0929 17:30:49.495137 11684 net.cpp:156] Memory required for data: 570983000
I0929 17:30:49.495137 11684 layer_factory.hpp:77] Creating layer ipf0
I0929 17:30:49.495137 11684 net.cpp:91] Creating Layer ipf0
I0929 17:30:49.495137 11684 net.cpp:425] ipf0 <- fc_conv
I0929 17:30:49.495137 11684 net.cpp:399] ipf0 -> ipf0
I0929 17:30:49.511148 11684 net.cpp:141] Setting up ipf0
I0929 17:30:49.511148 11684 net.cpp:148] Top shape: 50 100 (5000)
I0929 17:30:49.511148 11684 net.cpp:156] Memory required for data: 571003000
I0929 17:30:49.511148 11684 layer_factory.hpp:77] Creating layer ipf0_ipf0_0_split
I0929 17:30:49.511148 11684 net.cpp:91] Creating Layer ipf0_ipf0_0_split
I0929 17:30:49.511148 11684 net.cpp:425] ipf0_ipf0_0_split <- ipf0
I0929 17:30:49.511148 11684 net.cpp:399] ipf0_ipf0_0_split -> ipf0_ipf0_0_split_0
I0929 17:30:49.511148 11684 net.cpp:399] ipf0_ipf0_0_split -> ipf0_ipf0_0_split_1
I0929 17:30:49.512150 11684 net.cpp:141] Setting up ipf0_ipf0_0_split
I0929 17:30:49.512150 11684 net.cpp:148] Top shape: 50 100 (5000)
I0929 17:30:49.512150 11684 net.cpp:148] Top shape: 50 100 (5000)
I0929 17:30:49.512150 11684 net.cpp:156] Memory required for data: 571043000
I0929 17:30:49.512150 11684 layer_factory.hpp:77] Creating layer accuracy
I0929 17:30:49.512150 11684 net.cpp:91] Creating Layer accuracy
I0929 17:30:49.512150 11684 net.cpp:425] accuracy <- ipf0_ipf0_0_split_0
I0929 17:30:49.512150 11684 net.cpp:425] accuracy <- label_fine_cifar_1_split_0
I0929 17:30:49.512150 11684 net.cpp:399] accuracy -> accuracy
I0929 17:30:49.512150 11684 net.cpp:141] Setting up accuracy
I0929 17:30:49.512150 11684 net.cpp:148] Top shape: (1)
I0929 17:30:49.512150 11684 net.cpp:156] Memory required for data: 571043004
I0929 17:30:49.512150 11684 layer_factory.hpp:77] Creating layer loss
I0929 17:30:49.512150 11684 net.cpp:91] Creating Layer loss
I0929 17:30:49.512150 11684 net.cpp:425] loss <- ipf0_ipf0_0_split_1
I0929 17:30:49.512150 11684 net.cpp:425] loss <- label_fine_cifar_1_split_1
I0929 17:30:49.512150 11684 net.cpp:399] loss -> loss
I0929 17:30:49.512150 11684 layer_factory.hpp:77] Creating layer loss
I0929 17:30:49.512938 11684 net.cpp:141] Setting up loss
I0929 17:30:49.512938 11684 net.cpp:148] Top shape: (1)
I0929 17:30:49.512938 11684 net.cpp:151]     with loss weight 1
I0929 17:30:49.512938 11684 net.cpp:156] Memory required for data: 571043008
I0929 17:30:49.512938 11684 net.cpp:217] loss needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:219] accuracy does not need backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] ipf0_ipf0_0_split needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] ipf0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] fc_conv needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] poolcp6 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu_cccp6 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale_ccp6 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn_cccp6 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] cccp6 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] poolcp5 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu_cccp5 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale_ccp5 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn_cccp5 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] cccp5 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu_cccp4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale_ccp4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn_cccp4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] cccp4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu4_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale4_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn4_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv4_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] pool4_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu4_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale4_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn4_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv4_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu4_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale4_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn4_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv4_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] pool4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv4 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu3 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale3 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn3 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv3 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu2_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale2_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn2_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv2_2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] pool2_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu2_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale2_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn2_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv2_1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv2 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu1_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale1_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn1_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv1_0 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] relu1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] scale1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] bn1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:217] conv1 needs backward computation.
I0929 17:30:49.512938 11684 net.cpp:219] label_fine_cifar_1_split does not need backward computation.
I0929 17:30:49.512938 11684 net.cpp:219] cifar does not need backward computation.
I0929 17:30:49.512938 11684 net.cpp:261] This network produces output accuracy
I0929 17:30:49.512938 11684 net.cpp:261] This network produces output loss
I0929 17:30:49.512938 11684 net.cpp:274] Network initialization done.
I0929 17:30:49.513941 11684 solver.cpp:60] Solver scaffolding done.
I0929 17:30:49.519944 11684 caffe.cpp:220] Starting Optimization
I0929 17:30:49.519944 11684 solver.cpp:279] Solving CIFAR100_full
I0929 17:30:49.519944 11684 solver.cpp:280] Learning Rate Policy: multistep
I0929 17:30:49.531955 11684 solver.cpp:337] Iteration 0, Testing net (#0)
I0929 17:30:58.418280 11684 solver.cpp:404]     Test net output #0: accuracy = 0.00999999
I0929 17:30:58.418781 11684 solver.cpp:404]     Test net output #1: loss = 86.4632 (* 1 = 86.4632 loss)
I0929 17:30:58.734498 11684 solver.cpp:228] Iteration 0, loss = 4.67389
I0929 17:30:58.734498 11684 solver.cpp:244]     Train net output #0: loss = 4.67389 (* 1 = 4.67389 loss)
I0929 17:30:58.734498 11684 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0929 17:31:18.443482 11684 solver.cpp:228] Iteration 100, loss = 4.37181
I0929 17:31:18.443982 11684 solver.cpp:244]     Train net output #0: loss = 4.37181 (* 1 = 4.37181 loss)
I0929 17:31:18.443982 11684 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0929 17:31:38.036504 11684 solver.cpp:228] Iteration 200, loss = 4.20852
I0929 17:31:38.037004 11684 solver.cpp:244]     Train net output #0: loss = 4.20852 (* 1 = 4.20852 loss)
I0929 17:31:38.037004 11684 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0929 17:31:57.660914 11684 solver.cpp:228] Iteration 300, loss = 3.92697
I0929 17:31:57.660914 11684 solver.cpp:244]     Train net output #0: loss = 3.92697 (* 1 = 3.92697 loss)
I0929 17:31:57.660914 11684 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0929 17:32:17.380606 11684 solver.cpp:228] Iteration 400, loss = 3.31605
I0929 17:32:17.380606 11684 solver.cpp:244]     Train net output #0: loss = 3.31605 (* 1 = 3.31605 loss)
I0929 17:32:17.380606 11684 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0929 17:32:37.263475 11684 solver.cpp:228] Iteration 500, loss = 3.63085
I0929 17:32:37.263475 11684 solver.cpp:244]     Train net output #0: loss = 3.63085 (* 1 = 3.63085 loss)
I0929 17:32:37.263475 11684 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0929 17:32:57.022207 11684 solver.cpp:228] Iteration 600, loss = 3.43414
I0929 17:32:57.022207 11684 solver.cpp:244]     Train net output #0: loss = 3.43414 (* 1 = 3.43414 loss)
I0929 17:32:57.022707 11684 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0929 17:33:16.791182 11684 solver.cpp:228] Iteration 700, loss = 3.60373
I0929 17:33:16.791182 11684 solver.cpp:244]     Train net output #0: loss = 3.60373 (* 1 = 3.60373 loss)
I0929 17:33:16.791682 11684 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0929 17:33:36.553611 11684 solver.cpp:228] Iteration 800, loss = 3.38081
I0929 17:33:36.554111 11684 solver.cpp:244]     Train net output #0: loss = 3.38081 (* 1 = 3.38081 loss)
I0929 17:33:36.554111 11684 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0929 17:33:56.289368 11684 solver.cpp:228] Iteration 900, loss = 2.82835
I0929 17:33:56.289368 11684 solver.cpp:244]     Train net output #0: loss = 2.82835 (* 1 = 2.82835 loss)
I0929 17:33:56.289368 11684 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0929 17:34:15.916656 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_1000.caffemodel
I0929 17:34:16.636900 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_1000.solverstate
I0929 17:34:17.034684 11684 solver.cpp:337] Iteration 1000, Testing net (#0)
I0929 17:34:25.749320 11684 solver.cpp:404]     Test net output #0: accuracy = 0.2318
I0929 17:34:25.749819 11684 solver.cpp:404]     Test net output #1: loss = 3.0668 (* 1 = 3.0668 loss)
I0929 17:34:25.800355 11684 solver.cpp:228] Iteration 1000, loss = 3.20133
I0929 17:34:25.800355 11684 solver.cpp:244]     Train net output #0: loss = 3.20133 (* 1 = 3.20133 loss)
I0929 17:34:25.800355 11684 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0929 17:34:45.591140 11684 solver.cpp:228] Iteration 1100, loss = 2.87715
I0929 17:34:45.591140 11684 solver.cpp:244]     Train net output #0: loss = 2.87715 (* 1 = 2.87715 loss)
I0929 17:34:45.591140 11684 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0929 17:35:05.266366 11684 solver.cpp:228] Iteration 1200, loss = 3.14242
I0929 17:35:05.266366 11684 solver.cpp:244]     Train net output #0: loss = 3.14242 (* 1 = 3.14242 loss)
I0929 17:35:05.266366 11684 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0929 17:35:25.006001 11684 solver.cpp:228] Iteration 1300, loss = 2.921
I0929 17:35:25.006001 11684 solver.cpp:244]     Train net output #0: loss = 2.921 (* 1 = 2.921 loss)
I0929 17:35:25.006001 11684 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0929 17:35:44.742075 11684 solver.cpp:228] Iteration 1400, loss = 2.57978
I0929 17:35:44.742075 11684 solver.cpp:244]     Train net output #0: loss = 2.57978 (* 1 = 2.57978 loss)
I0929 17:35:44.742075 11684 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0929 17:36:04.548979 11684 solver.cpp:228] Iteration 1500, loss = 2.74284
I0929 17:36:04.548979 11684 solver.cpp:244]     Train net output #0: loss = 2.74284 (* 1 = 2.74284 loss)
I0929 17:36:04.548979 11684 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0929 17:36:24.285329 11684 solver.cpp:228] Iteration 1600, loss = 2.54124
I0929 17:36:24.285329 11684 solver.cpp:244]     Train net output #0: loss = 2.54124 (* 1 = 2.54124 loss)
I0929 17:36:24.285329 11684 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0929 17:36:43.781270 11684 solver.cpp:228] Iteration 1700, loss = 2.94015
I0929 17:36:43.781270 11684 solver.cpp:244]     Train net output #0: loss = 2.94015 (* 1 = 2.94015 loss)
I0929 17:36:43.781270 11684 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0929 17:37:03.115849 11684 solver.cpp:228] Iteration 1800, loss = 2.68669
I0929 17:37:03.115849 11684 solver.cpp:244]     Train net output #0: loss = 2.68669 (* 1 = 2.68669 loss)
I0929 17:37:03.115849 11684 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0929 17:37:22.306349 11684 solver.cpp:228] Iteration 1900, loss = 2.19037
I0929 17:37:22.306349 11684 solver.cpp:244]     Train net output #0: loss = 2.19037 (* 1 = 2.19037 loss)
I0929 17:37:22.306349 11684 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0929 17:37:41.553513 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_2000.caffemodel
I0929 17:37:42.244005 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_2000.solverstate
I0929 17:37:42.624397 11684 solver.cpp:337] Iteration 2000, Testing net (#0)
I0929 17:37:50.923645 11684 solver.cpp:404]     Test net output #0: accuracy = 0.3631
I0929 17:37:50.923645 11684 solver.cpp:404]     Test net output #1: loss = 2.41746 (* 1 = 2.41746 loss)
I0929 17:37:50.975181 11684 solver.cpp:228] Iteration 2000, loss = 2.5108
I0929 17:37:50.975181 11684 solver.cpp:244]     Train net output #0: loss = 2.5108 (* 1 = 2.5108 loss)
I0929 17:37:50.975181 11684 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0929 17:38:10.374114 11684 solver.cpp:228] Iteration 2100, loss = 2.59058
I0929 17:38:10.374114 11684 solver.cpp:244]     Train net output #0: loss = 2.59058 (* 1 = 2.59058 loss)
I0929 17:38:10.374614 11684 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0929 17:38:29.706277 11684 solver.cpp:228] Iteration 2200, loss = 2.23591
I0929 17:38:29.706277 11684 solver.cpp:244]     Train net output #0: loss = 2.23591 (* 1 = 2.23591 loss)
I0929 17:38:29.706277 11684 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0929 17:38:49.104346 11684 solver.cpp:228] Iteration 2300, loss = 2.49238
I0929 17:38:49.104346 11684 solver.cpp:244]     Train net output #0: loss = 2.49238 (* 1 = 2.49238 loss)
I0929 17:38:49.104846 11684 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0929 17:39:08.959794 11684 solver.cpp:228] Iteration 2400, loss = 2.03664
I0929 17:39:08.959794 11684 solver.cpp:244]     Train net output #0: loss = 2.03664 (* 1 = 2.03664 loss)
I0929 17:39:08.959794 11684 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0929 17:39:28.726771 11684 solver.cpp:228] Iteration 2500, loss = 1.98854
I0929 17:39:28.726771 11684 solver.cpp:244]     Train net output #0: loss = 1.98854 (* 1 = 1.98854 loss)
I0929 17:39:28.726771 11684 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0929 17:39:48.484076 11684 solver.cpp:228] Iteration 2600, loss = 2.09795
I0929 17:39:48.484076 11684 solver.cpp:244]     Train net output #0: loss = 2.09795 (* 1 = 2.09795 loss)
I0929 17:39:48.484076 11684 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0929 17:40:08.434790 11684 solver.cpp:228] Iteration 2700, loss = 2.48096
I0929 17:40:08.434790 11684 solver.cpp:244]     Train net output #0: loss = 2.48096 (* 1 = 2.48096 loss)
I0929 17:40:08.434790 11684 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0929 17:40:28.279270 11684 solver.cpp:228] Iteration 2800, loss = 2.2612
I0929 17:40:28.279770 11684 solver.cpp:244]     Train net output #0: loss = 2.2612 (* 1 = 2.2612 loss)
I0929 17:40:28.279770 11684 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0929 17:40:48.121276 11684 solver.cpp:228] Iteration 2900, loss = 1.71957
I0929 17:40:48.121276 11684 solver.cpp:244]     Train net output #0: loss = 1.71957 (* 1 = 1.71957 loss)
I0929 17:40:48.121276 11684 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0929 17:41:07.998371 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_3000.caffemodel
I0929 17:41:08.680860 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_3000.solverstate
I0929 17:41:09.090150 11684 solver.cpp:337] Iteration 3000, Testing net (#0)
I0929 17:41:17.628118 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4292
I0929 17:41:17.628118 11684 solver.cpp:404]     Test net output #1: loss = 2.13702 (* 1 = 2.13702 loss)
I0929 17:41:17.680155 11684 solver.cpp:228] Iteration 3000, loss = 2.0236
I0929 17:41:17.680155 11684 solver.cpp:244]     Train net output #0: loss = 2.0236 (* 1 = 2.0236 loss)
I0929 17:41:17.680155 11684 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0929 17:41:37.542176 11684 solver.cpp:228] Iteration 3100, loss = 2.27341
I0929 17:41:37.542176 11684 solver.cpp:244]     Train net output #0: loss = 2.27341 (* 1 = 2.27341 loss)
I0929 17:41:37.542176 11684 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0929 17:41:57.385566 11684 solver.cpp:228] Iteration 3200, loss = 1.9956
I0929 17:41:57.385566 11684 solver.cpp:244]     Train net output #0: loss = 1.9956 (* 1 = 1.9956 loss)
I0929 17:41:57.385566 11684 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0929 17:42:17.267976 11684 solver.cpp:228] Iteration 3300, loss = 2.14293
I0929 17:42:17.267976 11684 solver.cpp:244]     Train net output #0: loss = 2.14293 (* 1 = 2.14293 loss)
I0929 17:42:17.267976 11684 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0929 17:42:37.206559 11684 solver.cpp:228] Iteration 3400, loss = 1.61713
I0929 17:42:37.206559 11684 solver.cpp:244]     Train net output #0: loss = 1.61713 (* 1 = 1.61713 loss)
I0929 17:42:37.206559 11684 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0929 17:42:57.051653 11684 solver.cpp:228] Iteration 3500, loss = 1.86634
I0929 17:42:57.052155 11684 solver.cpp:244]     Train net output #0: loss = 1.86634 (* 1 = 1.86634 loss)
I0929 17:42:57.052155 11684 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0929 17:43:16.990914 11684 solver.cpp:228] Iteration 3600, loss = 2.113
I0929 17:43:16.990914 11684 solver.cpp:244]     Train net output #0: loss = 2.113 (* 1 = 2.113 loss)
I0929 17:43:16.990914 11684 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0929 17:43:36.876020 11684 solver.cpp:228] Iteration 3700, loss = 2.28826
I0929 17:43:36.876520 11684 solver.cpp:244]     Train net output #0: loss = 2.28826 (* 1 = 2.28826 loss)
I0929 17:43:36.876520 11684 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0929 17:43:56.709295 11684 solver.cpp:228] Iteration 3800, loss = 2.01884
I0929 17:43:56.709295 11684 solver.cpp:244]     Train net output #0: loss = 2.01884 (* 1 = 2.01884 loss)
I0929 17:43:56.709295 11684 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0929 17:44:16.493343 11684 solver.cpp:228] Iteration 3900, loss = 1.40813
I0929 17:44:16.493343 11684 solver.cpp:244]     Train net output #0: loss = 1.40813 (* 1 = 1.40813 loss)
I0929 17:44:16.493343 11684 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0929 17:44:36.211012 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_4000.caffemodel
I0929 17:44:36.856251 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_4000.solverstate
I0929 17:44:37.259536 11684 solver.cpp:337] Iteration 4000, Testing net (#0)
I0929 17:44:45.740627 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4252
I0929 17:44:45.740627 11684 solver.cpp:404]     Test net output #1: loss = 2.11562 (* 1 = 2.11562 loss)
I0929 17:44:45.792664 11684 solver.cpp:228] Iteration 4000, loss = 1.68414
I0929 17:44:45.792664 11684 solver.cpp:244]     Train net output #0: loss = 1.68414 (* 1 = 1.68414 loss)
I0929 17:44:45.792664 11684 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0929 17:45:05.649253 11684 solver.cpp:228] Iteration 4100, loss = 1.80058
I0929 17:45:05.649253 11684 solver.cpp:244]     Train net output #0: loss = 1.80058 (* 1 = 1.80058 loss)
I0929 17:45:05.649253 11684 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0929 17:45:25.426914 11684 solver.cpp:228] Iteration 4200, loss = 1.84837
I0929 17:45:25.426914 11684 solver.cpp:244]     Train net output #0: loss = 1.84837 (* 1 = 1.84837 loss)
I0929 17:45:25.426914 11684 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0929 17:45:45.221715 11684 solver.cpp:228] Iteration 4300, loss = 1.96306
I0929 17:45:45.221715 11684 solver.cpp:244]     Train net output #0: loss = 1.96306 (* 1 = 1.96306 loss)
I0929 17:45:45.221715 11684 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0929 17:46:04.978729 11684 solver.cpp:228] Iteration 4400, loss = 1.60328
I0929 17:46:04.978729 11684 solver.cpp:244]     Train net output #0: loss = 1.60328 (* 1 = 1.60328 loss)
I0929 17:46:04.978729 11684 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0929 17:46:24.769176 11684 solver.cpp:228] Iteration 4500, loss = 1.62674
I0929 17:46:24.769176 11684 solver.cpp:244]     Train net output #0: loss = 1.62674 (* 1 = 1.62674 loss)
I0929 17:46:24.769176 11684 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0929 17:46:44.258302 11684 solver.cpp:228] Iteration 4600, loss = 2.12498
I0929 17:46:44.258302 11684 solver.cpp:244]     Train net output #0: loss = 2.12498 (* 1 = 2.12498 loss)
I0929 17:46:44.258302 11684 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0929 17:47:04.019357 11684 solver.cpp:228] Iteration 4700, loss = 2.07081
I0929 17:47:04.019357 11684 solver.cpp:244]     Train net output #0: loss = 2.07081 (* 1 = 2.07081 loss)
I0929 17:47:04.019357 11684 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0929 17:47:23.856360 11684 solver.cpp:228] Iteration 4800, loss = 1.79361
I0929 17:47:23.856360 11684 solver.cpp:244]     Train net output #0: loss = 1.79361 (* 1 = 1.79361 loss)
I0929 17:47:23.856360 11684 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0929 17:47:43.817111 11684 solver.cpp:228] Iteration 4900, loss = 1.33688
I0929 17:47:43.817610 11684 solver.cpp:244]     Train net output #0: loss = 1.33688 (* 1 = 1.33688 loss)
I0929 17:47:43.817610 11684 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0929 17:48:03.545727 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_5000.caffemodel
I0929 17:48:04.214164 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_5000.solverstate
I0929 17:48:04.628162 11684 solver.cpp:337] Iteration 5000, Testing net (#0)
I0929 17:48:13.135095 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4813
I0929 17:48:13.135095 11684 solver.cpp:404]     Test net output #1: loss = 1.86897 (* 1 = 1.86897 loss)
I0929 17:48:13.203644 11684 solver.cpp:228] Iteration 5000, loss = 1.4161
I0929 17:48:13.203644 11684 solver.cpp:244]     Train net output #0: loss = 1.4161 (* 1 = 1.4161 loss)
I0929 17:48:13.203644 11684 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0929 17:48:32.964818 11684 solver.cpp:228] Iteration 5100, loss = 1.81162
I0929 17:48:32.964818 11684 solver.cpp:244]     Train net output #0: loss = 1.81162 (* 1 = 1.81162 loss)
I0929 17:48:32.964818 11684 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0929 17:48:52.733870 11684 solver.cpp:228] Iteration 5200, loss = 1.68608
I0929 17:48:52.733870 11684 solver.cpp:244]     Train net output #0: loss = 1.68608 (* 1 = 1.68608 loss)
I0929 17:48:52.733870 11684 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0929 17:49:12.524365 11684 solver.cpp:228] Iteration 5300, loss = 1.92987
I0929 17:49:12.524365 11684 solver.cpp:244]     Train net output #0: loss = 1.92987 (* 1 = 1.92987 loss)
I0929 17:49:12.524365 11684 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0929 17:49:32.415622 11684 solver.cpp:228] Iteration 5400, loss = 1.37536
I0929 17:49:32.415622 11684 solver.cpp:244]     Train net output #0: loss = 1.37536 (* 1 = 1.37536 loss)
I0929 17:49:32.415622 11684 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0929 17:49:52.258585 11684 solver.cpp:228] Iteration 5500, loss = 1.5126
I0929 17:49:52.259086 11684 solver.cpp:244]     Train net output #0: loss = 1.5126 (* 1 = 1.5126 loss)
I0929 17:49:52.259086 11684 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0929 17:50:12.300391 11684 solver.cpp:228] Iteration 5600, loss = 1.80221
I0929 17:50:12.300391 11684 solver.cpp:244]     Train net output #0: loss = 1.80221 (* 1 = 1.80221 loss)
I0929 17:50:12.300391 11684 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0929 17:50:32.188243 11684 solver.cpp:228] Iteration 5700, loss = 1.80235
I0929 17:50:32.188743 11684 solver.cpp:244]     Train net output #0: loss = 1.80235 (* 1 = 1.80235 loss)
I0929 17:50:32.188743 11684 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0929 17:50:52.007261 11684 solver.cpp:228] Iteration 5800, loss = 1.95713
I0929 17:50:52.007261 11684 solver.cpp:244]     Train net output #0: loss = 1.95713 (* 1 = 1.95713 loss)
I0929 17:50:52.007261 11684 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0929 17:51:11.845856 11684 solver.cpp:228] Iteration 5900, loss = 1.25483
I0929 17:51:11.845856 11684 solver.cpp:244]     Train net output #0: loss = 1.25483 (* 1 = 1.25483 loss)
I0929 17:51:11.845856 11684 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0929 17:51:31.832038 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_6000.caffemodel
I0929 17:51:32.525033 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_6000.solverstate
I0929 17:51:33.065418 11684 solver.cpp:337] Iteration 6000, Testing net (#0)
I0929 17:51:42.053553 11684 solver.cpp:404]     Test net output #0: accuracy = 0.513
I0929 17:51:42.053553 11684 solver.cpp:404]     Test net output #1: loss = 1.75517 (* 1 = 1.75517 loss)
I0929 17:51:42.106591 11684 solver.cpp:228] Iteration 6000, loss = 1.57026
I0929 17:51:42.106591 11684 solver.cpp:244]     Train net output #0: loss = 1.57026 (* 1 = 1.57026 loss)
I0929 17:51:42.106591 11684 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0929 17:52:02.084756 11684 solver.cpp:228] Iteration 6100, loss = 2.10552
I0929 17:52:02.084756 11684 solver.cpp:244]     Train net output #0: loss = 2.10552 (* 1 = 2.10552 loss)
I0929 17:52:02.084756 11684 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0929 17:52:21.847177 11684 solver.cpp:228] Iteration 6200, loss = 1.64726
I0929 17:52:21.847177 11684 solver.cpp:244]     Train net output #0: loss = 1.64726 (* 1 = 1.64726 loss)
I0929 17:52:21.847177 11684 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0929 17:52:41.628900 11684 solver.cpp:228] Iteration 6300, loss = 2.08362
I0929 17:52:41.628900 11684 solver.cpp:244]     Train net output #0: loss = 2.08362 (* 1 = 2.08362 loss)
I0929 17:52:41.628900 11684 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0929 17:53:01.358762 11684 solver.cpp:228] Iteration 6400, loss = 1.3337
I0929 17:53:01.358762 11684 solver.cpp:244]     Train net output #0: loss = 1.3337 (* 1 = 1.3337 loss)
I0929 17:53:01.358762 11684 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0929 17:53:21.098197 11684 solver.cpp:228] Iteration 6500, loss = 1.38
I0929 17:53:21.098697 11684 solver.cpp:244]     Train net output #0: loss = 1.38 (* 1 = 1.38 loss)
I0929 17:53:21.098697 11684 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0929 17:53:40.851083 11684 solver.cpp:228] Iteration 6600, loss = 1.73788
I0929 17:53:40.851083 11684 solver.cpp:244]     Train net output #0: loss = 1.73788 (* 1 = 1.73788 loss)
I0929 17:53:40.851083 11684 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0929 17:54:00.649700 11684 solver.cpp:228] Iteration 6700, loss = 1.80099
I0929 17:54:00.649700 11684 solver.cpp:244]     Train net output #0: loss = 1.80099 (* 1 = 1.80099 loss)
I0929 17:54:00.649700 11684 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0929 17:54:20.433898 11684 solver.cpp:228] Iteration 6800, loss = 1.67383
I0929 17:54:20.433898 11684 solver.cpp:244]     Train net output #0: loss = 1.67383 (* 1 = 1.67383 loss)
I0929 17:54:20.433898 11684 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0929 17:54:40.198771 11684 solver.cpp:228] Iteration 6900, loss = 1.25817
I0929 17:54:40.198771 11684 solver.cpp:244]     Train net output #0: loss = 1.25817 (* 1 = 1.25817 loss)
I0929 17:54:40.198771 11684 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0929 17:54:59.899430 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_7000.caffemodel
I0929 17:55:00.567406 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_7000.solverstate
I0929 17:55:00.964687 11684 solver.cpp:337] Iteration 7000, Testing net (#0)
I0929 17:55:09.394953 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4833
I0929 17:55:09.394953 11684 solver.cpp:404]     Test net output #1: loss = 1.94963 (* 1 = 1.94963 loss)
I0929 17:55:09.445989 11684 solver.cpp:228] Iteration 7000, loss = 1.55207
I0929 17:55:09.445989 11684 solver.cpp:244]     Train net output #0: loss = 1.55207 (* 1 = 1.55207 loss)
I0929 17:55:09.445989 11684 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0929 17:55:29.207132 11684 solver.cpp:228] Iteration 7100, loss = 1.8625
I0929 17:55:29.207132 11684 solver.cpp:244]     Train net output #0: loss = 1.8625 (* 1 = 1.8625 loss)
I0929 17:55:29.207633 11684 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0929 17:55:48.973850 11684 solver.cpp:228] Iteration 7200, loss = 1.54314
I0929 17:55:48.974351 11684 solver.cpp:244]     Train net output #0: loss = 1.54314 (* 1 = 1.54314 loss)
I0929 17:55:48.974351 11684 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0929 17:56:08.690963 11684 solver.cpp:228] Iteration 7300, loss = 1.76354
I0929 17:56:08.690963 11684 solver.cpp:244]     Train net output #0: loss = 1.76354 (* 1 = 1.76354 loss)
I0929 17:56:08.690963 11684 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0929 17:56:28.482720 11684 solver.cpp:228] Iteration 7400, loss = 1.31645
I0929 17:56:28.482720 11684 solver.cpp:244]     Train net output #0: loss = 1.31645 (* 1 = 1.31645 loss)
I0929 17:56:28.482720 11684 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0929 17:56:48.241106 11684 solver.cpp:228] Iteration 7500, loss = 1.63612
I0929 17:56:48.241106 11684 solver.cpp:244]     Train net output #0: loss = 1.63612 (* 1 = 1.63612 loss)
I0929 17:56:48.241106 11684 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0929 17:57:08.278600 11684 solver.cpp:228] Iteration 7600, loss = 1.85147
I0929 17:57:08.278600 11684 solver.cpp:244]     Train net output #0: loss = 1.85147 (* 1 = 1.85147 loss)
I0929 17:57:08.278600 11684 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0929 17:57:27.686879 11684 solver.cpp:228] Iteration 7700, loss = 1.99575
I0929 17:57:27.686879 11684 solver.cpp:244]     Train net output #0: loss = 1.99575 (* 1 = 1.99575 loss)
I0929 17:57:27.686879 11684 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0929 17:57:46.965340 11684 solver.cpp:228] Iteration 7800, loss = 1.74666
I0929 17:57:46.965340 11684 solver.cpp:244]     Train net output #0: loss = 1.74666 (* 1 = 1.74666 loss)
I0929 17:57:46.965340 11684 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0929 17:58:06.264848 11684 solver.cpp:228] Iteration 7900, loss = 1.1157
I0929 17:58:06.264848 11684 solver.cpp:244]     Train net output #0: loss = 1.1157 (* 1 = 1.1157 loss)
I0929 17:58:06.264848 11684 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0929 17:58:25.540769 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_8000.caffemodel
I0929 17:58:26.123196 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_8000.solverstate
I0929 17:58:26.493445 11684 solver.cpp:337] Iteration 8000, Testing net (#0)
I0929 17:58:34.672250 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4608
I0929 17:58:34.672250 11684 solver.cpp:404]     Test net output #1: loss = 2.00177 (* 1 = 2.00177 loss)
I0929 17:58:34.722299 11684 solver.cpp:228] Iteration 8000, loss = 1.4602
I0929 17:58:34.722299 11684 solver.cpp:244]     Train net output #0: loss = 1.4602 (* 1 = 1.4602 loss)
I0929 17:58:34.722299 11684 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0929 17:58:54.356333 11684 solver.cpp:228] Iteration 8100, loss = 1.75936
I0929 17:58:54.356333 11684 solver.cpp:244]     Train net output #0: loss = 1.75936 (* 1 = 1.75936 loss)
I0929 17:58:54.356333 11684 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0929 17:59:14.264830 11684 solver.cpp:228] Iteration 8200, loss = 1.2647
I0929 17:59:14.264830 11684 solver.cpp:244]     Train net output #0: loss = 1.2647 (* 1 = 1.2647 loss)
I0929 17:59:14.264830 11684 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0929 17:59:34.259297 11684 solver.cpp:228] Iteration 8300, loss = 1.82357
I0929 17:59:34.259297 11684 solver.cpp:244]     Train net output #0: loss = 1.82357 (* 1 = 1.82357 loss)
I0929 17:59:34.259297 11684 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0929 17:59:54.482584 11684 solver.cpp:228] Iteration 8400, loss = 1.22787
I0929 17:59:54.483084 11684 solver.cpp:244]     Train net output #0: loss = 1.22787 (* 1 = 1.22787 loss)
I0929 17:59:54.483084 11684 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0929 18:00:14.940687 11684 solver.cpp:228] Iteration 8500, loss = 1.43715
I0929 18:00:14.940687 11684 solver.cpp:244]     Train net output #0: loss = 1.43715 (* 1 = 1.43715 loss)
I0929 18:00:14.940687 11684 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0929 18:00:34.790199 11684 solver.cpp:228] Iteration 8600, loss = 1.79392
I0929 18:00:34.790700 11684 solver.cpp:244]     Train net output #0: loss = 1.79392 (* 1 = 1.79392 loss)
I0929 18:00:34.790700 11684 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0929 18:00:54.529039 11684 solver.cpp:228] Iteration 8700, loss = 1.71689
I0929 18:00:54.529039 11684 solver.cpp:244]     Train net output #0: loss = 1.71689 (* 1 = 1.71689 loss)
I0929 18:00:54.529039 11684 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0929 18:01:14.333858 11684 solver.cpp:228] Iteration 8800, loss = 1.44079
I0929 18:01:14.334358 11684 solver.cpp:244]     Train net output #0: loss = 1.44079 (* 1 = 1.44079 loss)
I0929 18:01:14.334358 11684 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0929 18:01:34.134587 11684 solver.cpp:228] Iteration 8900, loss = 1.22061
I0929 18:01:34.134587 11684 solver.cpp:244]     Train net output #0: loss = 1.22061 (* 1 = 1.22061 loss)
I0929 18:01:34.134587 11684 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0929 18:01:53.852604 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_9000.caffemodel
I0929 18:01:54.541095 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_9000.solverstate
I0929 18:01:54.928370 11684 solver.cpp:337] Iteration 9000, Testing net (#0)
I0929 18:02:03.347905 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5112
I0929 18:02:03.347905 11684 solver.cpp:404]     Test net output #1: loss = 1.77 (* 1 = 1.77 loss)
I0929 18:02:03.399441 11684 solver.cpp:228] Iteration 9000, loss = 1.43795
I0929 18:02:03.399441 11684 solver.cpp:244]     Train net output #0: loss = 1.43795 (* 1 = 1.43795 loss)
I0929 18:02:03.399441 11684 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0929 18:02:22.969388 11684 solver.cpp:228] Iteration 9100, loss = 1.61421
I0929 18:02:22.969388 11684 solver.cpp:244]     Train net output #0: loss = 1.61421 (* 1 = 1.61421 loss)
I0929 18:02:22.969388 11684 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0929 18:02:42.579377 11684 solver.cpp:228] Iteration 9200, loss = 1.30813
I0929 18:02:42.579877 11684 solver.cpp:244]     Train net output #0: loss = 1.30813 (* 1 = 1.30813 loss)
I0929 18:02:42.579877 11684 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0929 18:03:02.253403 11684 solver.cpp:228] Iteration 9300, loss = 1.83594
I0929 18:03:02.253403 11684 solver.cpp:244]     Train net output #0: loss = 1.83594 (* 1 = 1.83594 loss)
I0929 18:03:02.253403 11684 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0929 18:03:21.926316 11684 solver.cpp:228] Iteration 9400, loss = 1.23317
I0929 18:03:21.926816 11684 solver.cpp:244]     Train net output #0: loss = 1.23317 (* 1 = 1.23317 loss)
I0929 18:03:21.926816 11684 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0929 18:03:41.564790 11684 solver.cpp:228] Iteration 9500, loss = 1.32323
I0929 18:03:41.564790 11684 solver.cpp:244]     Train net output #0: loss = 1.32323 (* 1 = 1.32323 loss)
I0929 18:03:41.564790 11684 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0929 18:04:01.255210 11684 solver.cpp:228] Iteration 9600, loss = 1.55019
I0929 18:04:01.255210 11684 solver.cpp:244]     Train net output #0: loss = 1.55019 (* 1 = 1.55019 loss)
I0929 18:04:01.255210 11684 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0929 18:04:20.950556 11684 solver.cpp:228] Iteration 9700, loss = 1.64399
I0929 18:04:20.950556 11684 solver.cpp:244]     Train net output #0: loss = 1.64399 (* 1 = 1.64399 loss)
I0929 18:04:20.950556 11684 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0929 18:04:40.675763 11684 solver.cpp:228] Iteration 9800, loss = 1.38478
I0929 18:04:40.675763 11684 solver.cpp:244]     Train net output #0: loss = 1.38478 (* 1 = 1.38478 loss)
I0929 18:04:40.675763 11684 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0929 18:05:00.117885 11684 solver.cpp:228] Iteration 9900, loss = 1.21923
I0929 18:05:00.117885 11684 solver.cpp:244]     Train net output #0: loss = 1.21923 (* 1 = 1.21923 loss)
I0929 18:05:00.117885 11684 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0929 18:05:19.481519 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_10000.caffemodel
I0929 18:05:20.087450 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_10000.solverstate
I0929 18:05:20.478227 11684 solver.cpp:337] Iteration 10000, Testing net (#0)
I0929 18:05:28.790676 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4852
I0929 18:05:28.790676 11684 solver.cpp:404]     Test net output #1: loss = 1.90213 (* 1 = 1.90213 loss)
I0929 18:05:28.840711 11684 solver.cpp:228] Iteration 10000, loss = 1.42106
I0929 18:05:28.841212 11684 solver.cpp:244]     Train net output #0: loss = 1.42106 (* 1 = 1.42106 loss)
I0929 18:05:28.841212 11684 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0929 18:05:48.249006 11684 solver.cpp:228] Iteration 10100, loss = 1.70521
I0929 18:05:48.249006 11684 solver.cpp:244]     Train net output #0: loss = 1.70521 (* 1 = 1.70521 loss)
I0929 18:05:48.249006 11684 sgd_solver.cpp:106] Iteration 10100, lr = 0.1
I0929 18:06:07.645524 11684 solver.cpp:228] Iteration 10200, loss = 1.52189
I0929 18:06:07.645524 11684 solver.cpp:244]     Train net output #0: loss = 1.52189 (* 1 = 1.52189 loss)
I0929 18:06:07.645524 11684 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0929 18:06:27.033903 11684 solver.cpp:228] Iteration 10300, loss = 2.00979
I0929 18:06:27.033903 11684 solver.cpp:244]     Train net output #0: loss = 2.00979 (* 1 = 2.00979 loss)
I0929 18:06:27.033903 11684 sgd_solver.cpp:106] Iteration 10300, lr = 0.1
I0929 18:06:46.451491 11684 solver.cpp:228] Iteration 10400, loss = 1.20946
I0929 18:06:46.451491 11684 solver.cpp:244]     Train net output #0: loss = 1.20946 (* 1 = 1.20946 loss)
I0929 18:06:46.451491 11684 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0929 18:07:05.848505 11684 solver.cpp:228] Iteration 10500, loss = 1.10529
I0929 18:07:05.848505 11684 solver.cpp:244]     Train net output #0: loss = 1.10529 (* 1 = 1.10529 loss)
I0929 18:07:05.848505 11684 sgd_solver.cpp:106] Iteration 10500, lr = 0.1
I0929 18:07:25.598315 11684 solver.cpp:228] Iteration 10600, loss = 1.64847
I0929 18:07:25.598315 11684 solver.cpp:244]     Train net output #0: loss = 1.64847 (* 1 = 1.64847 loss)
I0929 18:07:25.598315 11684 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0929 18:07:45.381355 11684 solver.cpp:228] Iteration 10700, loss = 1.6238
I0929 18:07:45.381855 11684 solver.cpp:244]     Train net output #0: loss = 1.6238 (* 1 = 1.6238 loss)
I0929 18:07:45.381855 11684 sgd_solver.cpp:106] Iteration 10700, lr = 0.1
I0929 18:08:04.834292 11684 solver.cpp:228] Iteration 10800, loss = 1.78182
I0929 18:08:04.834292 11684 solver.cpp:244]     Train net output #0: loss = 1.78182 (* 1 = 1.78182 loss)
I0929 18:08:04.834292 11684 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0929 18:08:24.234935 11684 solver.cpp:228] Iteration 10900, loss = 1.20446
I0929 18:08:24.234935 11684 solver.cpp:244]     Train net output #0: loss = 1.20446 (* 1 = 1.20446 loss)
I0929 18:08:24.234935 11684 sgd_solver.cpp:106] Iteration 10900, lr = 0.1
I0929 18:08:43.540643 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_11000.caffemodel
I0929 18:08:44.142069 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_11000.solverstate
I0929 18:08:44.603397 11684 solver.cpp:337] Iteration 11000, Testing net (#0)
I0929 18:08:52.887264 11684 solver.cpp:404]     Test net output #0: accuracy = 0.482
I0929 18:08:52.887264 11684 solver.cpp:404]     Test net output #1: loss = 1.991 (* 1 = 1.991 loss)
I0929 18:08:52.937299 11684 solver.cpp:228] Iteration 11000, loss = 1.28022
I0929 18:08:52.937299 11684 solver.cpp:244]     Train net output #0: loss = 1.28022 (* 1 = 1.28022 loss)
I0929 18:08:52.937299 11684 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0929 18:09:12.257520 11684 solver.cpp:228] Iteration 11100, loss = 1.65151
I0929 18:09:12.257520 11684 solver.cpp:244]     Train net output #0: loss = 1.65151 (* 1 = 1.65151 loss)
I0929 18:09:12.257520 11684 sgd_solver.cpp:106] Iteration 11100, lr = 0.1
I0929 18:09:31.559234 11684 solver.cpp:228] Iteration 11200, loss = 1.39344
I0929 18:09:31.559234 11684 solver.cpp:244]     Train net output #0: loss = 1.39344 (* 1 = 1.39344 loss)
I0929 18:09:31.559234 11684 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0929 18:09:50.921519 11684 solver.cpp:228] Iteration 11300, loss = 1.90057
I0929 18:09:50.921519 11684 solver.cpp:244]     Train net output #0: loss = 1.90057 (* 1 = 1.90057 loss)
I0929 18:09:50.921519 11684 sgd_solver.cpp:106] Iteration 11300, lr = 0.1
I0929 18:10:10.277765 11684 solver.cpp:228] Iteration 11400, loss = 1.52224
I0929 18:10:10.277765 11684 solver.cpp:244]     Train net output #0: loss = 1.52224 (* 1 = 1.52224 loss)
I0929 18:10:10.277765 11684 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0929 18:10:29.571216 11684 solver.cpp:228] Iteration 11500, loss = 1.40968
I0929 18:10:29.571216 11684 solver.cpp:244]     Train net output #0: loss = 1.40968 (* 1 = 1.40968 loss)
I0929 18:10:29.571216 11684 sgd_solver.cpp:106] Iteration 11500, lr = 0.1
I0929 18:10:49.000016 11684 solver.cpp:228] Iteration 11600, loss = 1.56606
I0929 18:10:49.000016 11684 solver.cpp:244]     Train net output #0: loss = 1.56606 (* 1 = 1.56606 loss)
I0929 18:10:49.000517 11684 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0929 18:11:08.557344 11684 solver.cpp:228] Iteration 11700, loss = 1.63346
I0929 18:11:08.557344 11684 solver.cpp:244]     Train net output #0: loss = 1.63346 (* 1 = 1.63346 loss)
I0929 18:11:08.557344 11684 sgd_solver.cpp:106] Iteration 11700, lr = 0.1
I0929 18:11:27.838502 11684 solver.cpp:228] Iteration 11800, loss = 1.62508
I0929 18:11:27.838502 11684 solver.cpp:244]     Train net output #0: loss = 1.62508 (* 1 = 1.62508 loss)
I0929 18:11:27.838502 11684 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0929 18:11:47.861670 11684 solver.cpp:228] Iteration 11900, loss = 1.08381
I0929 18:11:47.862170 11684 solver.cpp:244]     Train net output #0: loss = 1.08381 (* 1 = 1.08381 loss)
I0929 18:11:47.862170 11684 sgd_solver.cpp:106] Iteration 11900, lr = 0.1
I0929 18:12:07.629081 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_12000.caffemodel
I0929 18:12:08.302543 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_12000.solverstate
I0929 18:12:08.705329 11684 solver.cpp:337] Iteration 12000, Testing net (#0)
I0929 18:12:17.145015 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5104
I0929 18:12:17.145015 11684 solver.cpp:404]     Test net output #1: loss = 1.86014 (* 1 = 1.86014 loss)
I0929 18:12:17.214064 11684 solver.cpp:228] Iteration 12000, loss = 1.17169
I0929 18:12:17.214064 11684 solver.cpp:244]     Train net output #0: loss = 1.17169 (* 1 = 1.17169 loss)
I0929 18:12:17.214064 11684 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0929 18:12:37.059118 11684 solver.cpp:228] Iteration 12100, loss = 1.81038
I0929 18:12:37.059118 11684 solver.cpp:244]     Train net output #0: loss = 1.81038 (* 1 = 1.81038 loss)
I0929 18:12:37.059118 11684 sgd_solver.cpp:106] Iteration 12100, lr = 0.1
I0929 18:12:56.902444 11684 solver.cpp:228] Iteration 12200, loss = 1.00244
I0929 18:12:56.902444 11684 solver.cpp:244]     Train net output #0: loss = 1.00244 (* 1 = 1.00244 loss)
I0929 18:12:56.902444 11684 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0929 18:13:16.682778 11684 solver.cpp:228] Iteration 12300, loss = 1.71868
I0929 18:13:16.682778 11684 solver.cpp:244]     Train net output #0: loss = 1.71868 (* 1 = 1.71868 loss)
I0929 18:13:16.682778 11684 sgd_solver.cpp:106] Iteration 12300, lr = 0.1
I0929 18:13:36.467583 11684 solver.cpp:228] Iteration 12400, loss = 1.45413
I0929 18:13:36.468085 11684 solver.cpp:244]     Train net output #0: loss = 1.45413 (* 1 = 1.45413 loss)
I0929 18:13:36.468085 11684 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0929 18:13:56.245024 11684 solver.cpp:228] Iteration 12500, loss = 1.32736
I0929 18:13:56.245024 11684 solver.cpp:244]     Train net output #0: loss = 1.32736 (* 1 = 1.32736 loss)
I0929 18:13:56.245024 11684 sgd_solver.cpp:106] Iteration 12500, lr = 0.1
I0929 18:14:16.004706 11684 solver.cpp:228] Iteration 12600, loss = 1.40908
I0929 18:14:16.004706 11684 solver.cpp:244]     Train net output #0: loss = 1.40908 (* 1 = 1.40908 loss)
I0929 18:14:16.004706 11684 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0929 18:14:35.843061 11684 solver.cpp:228] Iteration 12700, loss = 1.80662
I0929 18:14:35.843061 11684 solver.cpp:244]     Train net output #0: loss = 1.80662 (* 1 = 1.80662 loss)
I0929 18:14:35.843061 11684 sgd_solver.cpp:106] Iteration 12700, lr = 0.1
I0929 18:14:55.652865 11684 solver.cpp:228] Iteration 12800, loss = 1.32597
I0929 18:14:55.652865 11684 solver.cpp:244]     Train net output #0: loss = 1.32597 (* 1 = 1.32597 loss)
I0929 18:14:55.652865 11684 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0929 18:15:15.553519 11684 solver.cpp:228] Iteration 12900, loss = 1.05976
I0929 18:15:15.553519 11684 solver.cpp:244]     Train net output #0: loss = 1.05976 (* 1 = 1.05976 loss)
I0929 18:15:15.553519 11684 sgd_solver.cpp:106] Iteration 12900, lr = 0.1
I0929 18:15:35.183825 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_13000.caffemodel
I0929 18:15:35.884611 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_13000.solverstate
I0929 18:15:36.301908 11684 solver.cpp:337] Iteration 13000, Testing net (#0)
I0929 18:15:44.739908 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5385
I0929 18:15:44.739908 11684 solver.cpp:404]     Test net output #1: loss = 1.71207 (* 1 = 1.71207 loss)
I0929 18:15:44.790944 11684 solver.cpp:228] Iteration 13000, loss = 1.24046
I0929 18:15:44.791445 11684 solver.cpp:244]     Train net output #0: loss = 1.24046 (* 1 = 1.24046 loss)
I0929 18:15:44.791445 11684 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0929 18:16:04.612428 11684 solver.cpp:228] Iteration 13100, loss = 1.57351
I0929 18:16:04.612428 11684 solver.cpp:244]     Train net output #0: loss = 1.57351 (* 1 = 1.57351 loss)
I0929 18:16:04.612428 11684 sgd_solver.cpp:106] Iteration 13100, lr = 0.1
I0929 18:16:24.425611 11684 solver.cpp:228] Iteration 13200, loss = 1.46823
I0929 18:16:24.425611 11684 solver.cpp:244]     Train net output #0: loss = 1.46823 (* 1 = 1.46823 loss)
I0929 18:16:24.425611 11684 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0929 18:16:44.216218 11684 solver.cpp:228] Iteration 13300, loss = 1.5603
I0929 18:16:44.216218 11684 solver.cpp:244]     Train net output #0: loss = 1.5603 (* 1 = 1.5603 loss)
I0929 18:16:44.216218 11684 sgd_solver.cpp:106] Iteration 13300, lr = 0.1
I0929 18:17:03.976256 11684 solver.cpp:228] Iteration 13400, loss = 1.40093
I0929 18:17:03.976256 11684 solver.cpp:244]     Train net output #0: loss = 1.40093 (* 1 = 1.40093 loss)
I0929 18:17:03.976757 11684 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0929 18:17:23.834720 11684 solver.cpp:228] Iteration 13500, loss = 1.37356
I0929 18:17:23.834720 11684 solver.cpp:244]     Train net output #0: loss = 1.37356 (* 1 = 1.37356 loss)
I0929 18:17:23.834720 11684 sgd_solver.cpp:106] Iteration 13500, lr = 0.1
I0929 18:17:43.633632 11684 solver.cpp:228] Iteration 13600, loss = 1.49183
I0929 18:17:43.633632 11684 solver.cpp:244]     Train net output #0: loss = 1.49183 (* 1 = 1.49183 loss)
I0929 18:17:43.633632 11684 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0929 18:18:03.448907 11684 solver.cpp:228] Iteration 13700, loss = 1.54711
I0929 18:18:03.448907 11684 solver.cpp:244]     Train net output #0: loss = 1.54711 (* 1 = 1.54711 loss)
I0929 18:18:03.448907 11684 sgd_solver.cpp:106] Iteration 13700, lr = 0.1
I0929 18:18:23.257400 11684 solver.cpp:228] Iteration 13800, loss = 1.379
I0929 18:18:23.257400 11684 solver.cpp:244]     Train net output #0: loss = 1.379 (* 1 = 1.379 loss)
I0929 18:18:23.257400 11684 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0929 18:18:43.039628 11684 solver.cpp:228] Iteration 13900, loss = 1.14071
I0929 18:18:43.039628 11684 solver.cpp:244]     Train net output #0: loss = 1.14071 (* 1 = 1.14071 loss)
I0929 18:18:43.039628 11684 sgd_solver.cpp:106] Iteration 13900, lr = 0.1
I0929 18:19:02.407105 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_14000.caffemodel
I0929 18:19:02.991022 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_14000.solverstate
I0929 18:19:03.364286 11684 solver.cpp:337] Iteration 14000, Testing net (#0)
I0929 18:19:11.583605 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4976
I0929 18:19:11.583605 11684 solver.cpp:404]     Test net output #1: loss = 1.99353 (* 1 = 1.99353 loss)
I0929 18:19:11.633638 11684 solver.cpp:228] Iteration 14000, loss = 1.34827
I0929 18:19:11.633638 11684 solver.cpp:244]     Train net output #0: loss = 1.34827 (* 1 = 1.34827 loss)
I0929 18:19:11.633638 11684 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0929 18:19:31.431329 11684 solver.cpp:228] Iteration 14100, loss = 1.76417
I0929 18:19:31.431329 11684 solver.cpp:244]     Train net output #0: loss = 1.76417 (* 1 = 1.76417 loss)
I0929 18:19:31.431329 11684 sgd_solver.cpp:106] Iteration 14100, lr = 0.1
I0929 18:19:50.862445 11684 solver.cpp:228] Iteration 14200, loss = 1.07927
I0929 18:19:50.862445 11684 solver.cpp:244]     Train net output #0: loss = 1.07927 (* 1 = 1.07927 loss)
I0929 18:19:50.862445 11684 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0929 18:20:10.166143 11684 solver.cpp:228] Iteration 14300, loss = 1.59396
I0929 18:20:10.166143 11684 solver.cpp:244]     Train net output #0: loss = 1.59396 (* 1 = 1.59396 loss)
I0929 18:20:10.166143 11684 sgd_solver.cpp:106] Iteration 14300, lr = 0.1
I0929 18:20:29.429934 11684 solver.cpp:228] Iteration 14400, loss = 1.26518
I0929 18:20:29.429934 11684 solver.cpp:244]     Train net output #0: loss = 1.26518 (* 1 = 1.26518 loss)
I0929 18:20:29.429934 11684 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0929 18:20:48.914286 11684 solver.cpp:228] Iteration 14500, loss = 1.14894
I0929 18:20:48.914286 11684 solver.cpp:244]     Train net output #0: loss = 1.14894 (* 1 = 1.14894 loss)
I0929 18:20:48.914286 11684 sgd_solver.cpp:106] Iteration 14500, lr = 0.1
I0929 18:21:08.323348 11684 solver.cpp:228] Iteration 14600, loss = 1.39637
I0929 18:21:08.323848 11684 solver.cpp:244]     Train net output #0: loss = 1.39637 (* 1 = 1.39637 loss)
I0929 18:21:08.323848 11684 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0929 18:21:27.819769 11684 solver.cpp:228] Iteration 14700, loss = 1.63238
I0929 18:21:27.819769 11684 solver.cpp:244]     Train net output #0: loss = 1.63238 (* 1 = 1.63238 loss)
I0929 18:21:27.819769 11684 sgd_solver.cpp:106] Iteration 14700, lr = 0.1
I0929 18:21:47.394490 11684 solver.cpp:228] Iteration 14800, loss = 1.23576
I0929 18:21:47.394490 11684 solver.cpp:244]     Train net output #0: loss = 1.23576 (* 1 = 1.23576 loss)
I0929 18:21:47.394490 11684 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0929 18:22:06.983265 11684 solver.cpp:228] Iteration 14900, loss = 1.12211
I0929 18:22:06.983265 11684 solver.cpp:244]     Train net output #0: loss = 1.12211 (* 1 = 1.12211 loss)
I0929 18:22:06.983265 11684 sgd_solver.cpp:106] Iteration 14900, lr = 0.1
I0929 18:22:26.402969 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_15000.caffemodel
I0929 18:22:27.011894 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_15000.solverstate
I0929 18:22:27.394165 11684 solver.cpp:337] Iteration 15000, Testing net (#0)
I0929 18:22:35.671468 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5145
I0929 18:22:35.671468 11684 solver.cpp:404]     Test net output #1: loss = 1.87283 (* 1 = 1.87283 loss)
I0929 18:22:35.722004 11684 solver.cpp:228] Iteration 15000, loss = 1.26854
I0929 18:22:35.722004 11684 solver.cpp:244]     Train net output #0: loss = 1.26854 (* 1 = 1.26854 loss)
I0929 18:22:35.722004 11684 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0929 18:22:55.008668 11684 solver.cpp:228] Iteration 15100, loss = 1.71292
I0929 18:22:55.008668 11684 solver.cpp:244]     Train net output #0: loss = 1.71292 (* 1 = 1.71292 loss)
I0929 18:22:55.008668 11684 sgd_solver.cpp:106] Iteration 15100, lr = 0.1
I0929 18:23:14.268748 11684 solver.cpp:228] Iteration 15200, loss = 1.09842
I0929 18:23:14.269748 11684 solver.cpp:244]     Train net output #0: loss = 1.09842 (* 1 = 1.09842 loss)
I0929 18:23:14.269748 11684 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0929 18:23:33.549940 11684 solver.cpp:228] Iteration 15300, loss = 1.90851
I0929 18:23:33.549940 11684 solver.cpp:244]     Train net output #0: loss = 1.90851 (* 1 = 1.90851 loss)
I0929 18:23:33.549940 11684 sgd_solver.cpp:106] Iteration 15300, lr = 0.1
I0929 18:23:52.853593 11684 solver.cpp:228] Iteration 15400, loss = 1.32672
I0929 18:23:52.853593 11684 solver.cpp:244]     Train net output #0: loss = 1.32672 (* 1 = 1.32672 loss)
I0929 18:23:52.853593 11684 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0929 18:24:12.101277 11684 solver.cpp:228] Iteration 15500, loss = 1.3353
I0929 18:24:12.101277 11684 solver.cpp:244]     Train net output #0: loss = 1.3353 (* 1 = 1.3353 loss)
I0929 18:24:12.101277 11684 sgd_solver.cpp:106] Iteration 15500, lr = 0.1
I0929 18:24:31.399978 11684 solver.cpp:228] Iteration 15600, loss = 1.46656
I0929 18:24:31.400979 11684 solver.cpp:244]     Train net output #0: loss = 1.46656 (* 1 = 1.46656 loss)
I0929 18:24:31.400979 11684 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0929 18:24:50.665397 11684 solver.cpp:228] Iteration 15700, loss = 1.79734
I0929 18:24:50.665397 11684 solver.cpp:244]     Train net output #0: loss = 1.79734 (* 1 = 1.79734 loss)
I0929 18:24:50.665397 11684 sgd_solver.cpp:106] Iteration 15700, lr = 0.1
I0929 18:25:10.257796 11684 solver.cpp:228] Iteration 15800, loss = 1.26748
I0929 18:25:10.258795 11684 solver.cpp:244]     Train net output #0: loss = 1.26748 (* 1 = 1.26748 loss)
I0929 18:25:10.258795 11684 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0929 18:25:29.559403 11684 solver.cpp:228] Iteration 15900, loss = 0.911775
I0929 18:25:29.559403 11684 solver.cpp:244]     Train net output #0: loss = 0.911775 (* 1 = 0.911775 loss)
I0929 18:25:29.559403 11684 sgd_solver.cpp:106] Iteration 15900, lr = 0.1
I0929 18:25:48.769158 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_16000.caffemodel
I0929 18:25:49.369071 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_16000.solverstate
I0929 18:25:49.725324 11684 solver.cpp:337] Iteration 16000, Testing net (#0)
I0929 18:25:57.961112 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5258
I0929 18:25:57.961112 11684 solver.cpp:404]     Test net output #1: loss = 1.78594 (* 1 = 1.78594 loss)
I0929 18:25:58.011147 11684 solver.cpp:228] Iteration 16000, loss = 1.24187
I0929 18:25:58.011147 11684 solver.cpp:244]     Train net output #0: loss = 1.24187 (* 1 = 1.24187 loss)
I0929 18:25:58.011147 11684 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0929 18:26:17.296877 11684 solver.cpp:228] Iteration 16100, loss = 1.82088
I0929 18:26:17.296877 11684 solver.cpp:244]     Train net output #0: loss = 1.82088 (* 1 = 1.82088 loss)
I0929 18:26:17.296877 11684 sgd_solver.cpp:106] Iteration 16100, lr = 0.1
I0929 18:26:36.540572 11684 solver.cpp:228] Iteration 16200, loss = 1.13987
I0929 18:26:36.540572 11684 solver.cpp:244]     Train net output #0: loss = 1.13987 (* 1 = 1.13987 loss)
I0929 18:26:36.540572 11684 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0929 18:26:55.835345 11684 solver.cpp:228] Iteration 16300, loss = 1.60719
I0929 18:26:55.835345 11684 solver.cpp:244]     Train net output #0: loss = 1.60719 (* 1 = 1.60719 loss)
I0929 18:26:55.835345 11684 sgd_solver.cpp:106] Iteration 16300, lr = 0.1
I0929 18:27:15.193775 11684 solver.cpp:228] Iteration 16400, loss = 1.05453
I0929 18:27:15.193775 11684 solver.cpp:244]     Train net output #0: loss = 1.05453 (* 1 = 1.05453 loss)
I0929 18:27:15.193775 11684 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0929 18:27:35.054093 11684 solver.cpp:228] Iteration 16500, loss = 1.29777
I0929 18:27:35.054093 11684 solver.cpp:244]     Train net output #0: loss = 1.29777 (* 1 = 1.29777 loss)
I0929 18:27:35.054093 11684 sgd_solver.cpp:106] Iteration 16500, lr = 0.1
I0929 18:27:55.078275 11684 solver.cpp:228] Iteration 16600, loss = 1.33965
I0929 18:27:55.079777 11684 solver.cpp:244]     Train net output #0: loss = 1.33965 (* 1 = 1.33965 loss)
I0929 18:27:55.080276 11684 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0929 18:28:15.004283 11684 solver.cpp:228] Iteration 16700, loss = 1.44804
I0929 18:28:15.004283 11684 solver.cpp:244]     Train net output #0: loss = 1.44804 (* 1 = 1.44804 loss)
I0929 18:28:15.004283 11684 sgd_solver.cpp:106] Iteration 16700, lr = 0.1
I0929 18:28:34.881839 11684 solver.cpp:228] Iteration 16800, loss = 1.50505
I0929 18:28:34.881839 11684 solver.cpp:244]     Train net output #0: loss = 1.50505 (* 1 = 1.50505 loss)
I0929 18:28:34.881839 11684 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0929 18:28:54.861225 11684 solver.cpp:228] Iteration 16900, loss = 0.865347
I0929 18:28:54.861225 11684 solver.cpp:244]     Train net output #0: loss = 0.865347 (* 1 = 0.865347 loss)
I0929 18:28:54.861225 11684 sgd_solver.cpp:106] Iteration 16900, lr = 0.1
I0929 18:29:14.852402 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_17000.caffemodel
I0929 18:29:15.590812 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_17000.solverstate
I0929 18:29:15.998100 11684 solver.cpp:337] Iteration 17000, Testing net (#0)
I0929 18:29:24.723436 11684 solver.cpp:404]     Test net output #0: accuracy = 0.4937
I0929 18:29:24.723436 11684 solver.cpp:404]     Test net output #1: loss = 1.98191 (* 1 = 1.98191 loss)
I0929 18:29:24.776974 11684 solver.cpp:228] Iteration 17000, loss = 1.20834
I0929 18:29:24.776974 11684 solver.cpp:244]     Train net output #0: loss = 1.20834 (* 1 = 1.20834 loss)
I0929 18:29:24.777475 11684 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0929 18:29:44.641098 11684 solver.cpp:228] Iteration 17100, loss = 1.71231
I0929 18:29:44.641599 11684 solver.cpp:244]     Train net output #0: loss = 1.71231 (* 1 = 1.71231 loss)
I0929 18:29:44.641599 11684 sgd_solver.cpp:106] Iteration 17100, lr = 0.1
I0929 18:30:04.524070 11684 solver.cpp:228] Iteration 17200, loss = 1.0696
I0929 18:30:04.524070 11684 solver.cpp:244]     Train net output #0: loss = 1.0696 (* 1 = 1.0696 loss)
I0929 18:30:04.524070 11684 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0929 18:30:24.412191 11684 solver.cpp:228] Iteration 17300, loss = 1.55161
I0929 18:30:24.412191 11684 solver.cpp:244]     Train net output #0: loss = 1.55161 (* 1 = 1.55161 loss)
I0929 18:30:24.412691 11684 sgd_solver.cpp:106] Iteration 17300, lr = 0.1
I0929 18:30:44.278856 11684 solver.cpp:228] Iteration 17400, loss = 1.01278
I0929 18:30:44.278856 11684 solver.cpp:244]     Train net output #0: loss = 1.01278 (* 1 = 1.01278 loss)
I0929 18:30:44.278856 11684 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0929 18:31:04.262686 11684 solver.cpp:228] Iteration 17500, loss = 1.32089
I0929 18:31:04.263185 11684 solver.cpp:244]     Train net output #0: loss = 1.32089 (* 1 = 1.32089 loss)
I0929 18:31:04.263185 11684 sgd_solver.cpp:106] Iteration 17500, lr = 0.1
I0929 18:31:24.255532 11684 solver.cpp:228] Iteration 17600, loss = 1.53757
I0929 18:31:24.255532 11684 solver.cpp:244]     Train net output #0: loss = 1.53757 (* 1 = 1.53757 loss)
I0929 18:31:24.255532 11684 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0929 18:31:44.092569 11684 solver.cpp:228] Iteration 17700, loss = 1.51569
I0929 18:31:44.092569 11684 solver.cpp:244]     Train net output #0: loss = 1.51569 (* 1 = 1.51569 loss)
I0929 18:31:44.092569 11684 sgd_solver.cpp:106] Iteration 17700, lr = 0.1
I0929 18:32:04.000493 11684 solver.cpp:228] Iteration 17800, loss = 1.20157
I0929 18:32:04.000493 11684 solver.cpp:244]     Train net output #0: loss = 1.20157 (* 1 = 1.20157 loss)
I0929 18:32:04.000493 11684 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0929 18:32:23.848899 11684 solver.cpp:228] Iteration 17900, loss = 0.807739
I0929 18:32:23.849400 11684 solver.cpp:244]     Train net output #0: loss = 0.807738 (* 1 = 0.807738 loss)
I0929 18:32:23.849400 11684 sgd_solver.cpp:106] Iteration 17900, lr = 0.1
I0929 18:32:43.865423 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_18000.caffemodel
I0929 18:32:44.544083 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_18000.solverstate
I0929 18:32:44.948370 11684 solver.cpp:337] Iteration 18000, Testing net (#0)
I0929 18:32:53.602308 11684 solver.cpp:404]     Test net output #0: accuracy = 0.5033
I0929 18:32:53.602308 11684 solver.cpp:404]     Test net output #1: loss = 1.9232 (* 1 = 1.9232 loss)
I0929 18:32:53.653344 11684 solver.cpp:228] Iteration 18000, loss = 1.11691
I0929 18:32:53.653344 11684 solver.cpp:244]     Train net output #0: loss = 1.11691 (* 1 = 1.11691 loss)
I0929 18:32:53.653344 11684 sgd_solver.cpp:46] MultiStep Status: Iteration 18000, step = 1
I0929 18:32:53.653344 11684 sgd_solver.cpp:106] Iteration 18000, lr = 0.01
I0929 18:33:13.233528 11684 solver.cpp:228] Iteration 18100, loss = 1.23756
I0929 18:33:13.233528 11684 solver.cpp:244]     Train net output #0: loss = 1.23756 (* 1 = 1.23756 loss)
I0929 18:33:13.233528 11684 sgd_solver.cpp:106] Iteration 18100, lr = 0.01
I0929 18:33:32.999410 11684 solver.cpp:228] Iteration 18200, loss = 0.922952
I0929 18:33:32.999410 11684 solver.cpp:244]     Train net output #0: loss = 0.922952 (* 1 = 0.922952 loss)
I0929 18:33:32.999410 11684 sgd_solver.cpp:106] Iteration 18200, lr = 0.01
I0929 18:33:52.897922 11684 solver.cpp:228] Iteration 18300, loss = 1.29294
I0929 18:33:52.897922 11684 solver.cpp:244]     Train net output #0: loss = 1.29294 (* 1 = 1.29294 loss)
I0929 18:33:52.897922 11684 sgd_solver.cpp:106] Iteration 18300, lr = 0.01
I0929 18:34:13.093147 11684 solver.cpp:228] Iteration 18400, loss = 0.804488
I0929 18:34:13.093147 11684 solver.cpp:244]     Train net output #0: loss = 0.804488 (* 1 = 0.804488 loss)
I0929 18:34:13.093147 11684 sgd_solver.cpp:106] Iteration 18400, lr = 0.01
I0929 18:34:33.146311 11684 solver.cpp:228] Iteration 18500, loss = 0.628058
I0929 18:34:33.146311 11684 solver.cpp:244]     Train net output #0: loss = 0.628057 (* 1 = 0.628057 loss)
I0929 18:34:33.146311 11684 sgd_solver.cpp:106] Iteration 18500, lr = 0.01
I0929 18:34:52.827992 11684 solver.cpp:228] Iteration 18600, loss = 0.691695
I0929 18:34:52.827992 11684 solver.cpp:244]     Train net output #0: loss = 0.691695 (* 1 = 0.691695 loss)
I0929 18:34:52.827992 11684 sgd_solver.cpp:106] Iteration 18600, lr = 0.01
I0929 18:35:12.503041 11684 solver.cpp:228] Iteration 18700, loss = 0.778676
I0929 18:35:12.503041 11684 solver.cpp:244]     Train net output #0: loss = 0.778675 (* 1 = 0.778675 loss)
I0929 18:35:12.503041 11684 sgd_solver.cpp:106] Iteration 18700, lr = 0.01
I0929 18:35:32.154168 11684 solver.cpp:228] Iteration 18800, loss = 0.780496
I0929 18:35:32.154670 11684 solver.cpp:244]     Train net output #0: loss = 0.780496 (* 1 = 0.780496 loss)
I0929 18:35:32.154670 11684 sgd_solver.cpp:106] Iteration 18800, lr = 0.01
I0929 18:35:51.848660 11684 solver.cpp:228] Iteration 18900, loss = 0.410392
I0929 18:35:51.848660 11684 solver.cpp:244]     Train net output #0: loss = 0.410392 (* 1 = 0.410392 loss)
I0929 18:35:51.848660 11684 sgd_solver.cpp:106] Iteration 18900, lr = 0.01
I0929 18:36:11.657568 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_19000.caffemodel
I0929 18:36:12.308532 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_19000.solverstate
I0929 18:36:12.692325 11684 solver.cpp:337] Iteration 19000, Testing net (#0)
I0929 18:36:21.107275 11684 solver.cpp:404]     Test net output #0: accuracy = 0.696
I0929 18:36:21.107275 11684 solver.cpp:404]     Test net output #1: loss = 1.05117 (* 1 = 1.05117 loss)
I0929 18:36:21.158812 11684 solver.cpp:228] Iteration 19000, loss = 0.66451
I0929 18:36:21.158812 11684 solver.cpp:244]     Train net output #0: loss = 0.66451 (* 1 = 0.66451 loss)
I0929 18:36:21.158812 11684 sgd_solver.cpp:106] Iteration 19000, lr = 0.01
I0929 18:36:40.774955 11684 solver.cpp:228] Iteration 19100, loss = 1.00622
I0929 18:36:40.774955 11684 solver.cpp:244]     Train net output #0: loss = 1.00622 (* 1 = 1.00622 loss)
I0929 18:36:40.774955 11684 sgd_solver.cpp:106] Iteration 19100, lr = 0.01
I0929 18:37:00.461488 11684 solver.cpp:228] Iteration 19200, loss = 0.683209
I0929 18:37:00.461488 11684 solver.cpp:244]     Train net output #0: loss = 0.683209 (* 1 = 0.683209 loss)
I0929 18:37:00.461488 11684 sgd_solver.cpp:106] Iteration 19200, lr = 0.01
I0929 18:37:20.141715 11684 solver.cpp:228] Iteration 19300, loss = 1.01758
I0929 18:37:20.141715 11684 solver.cpp:244]     Train net output #0: loss = 1.01758 (* 1 = 1.01758 loss)
I0929 18:37:20.141715 11684 sgd_solver.cpp:106] Iteration 19300, lr = 0.01
I0929 18:37:40.326009 11684 solver.cpp:228] Iteration 19400, loss = 0.575551
I0929 18:37:40.326009 11684 solver.cpp:244]     Train net output #0: loss = 0.575551 (* 1 = 0.575551 loss)
I0929 18:37:40.326509 11684 sgd_solver.cpp:106] Iteration 19400, lr = 0.01
I0929 18:38:00.411458 11684 solver.cpp:228] Iteration 19500, loss = 0.535016
I0929 18:38:00.411458 11684 solver.cpp:244]     Train net output #0: loss = 0.535016 (* 1 = 0.535016 loss)
I0929 18:38:00.411458 11684 sgd_solver.cpp:106] Iteration 19500, lr = 0.01
I0929 18:38:20.581600 11684 solver.cpp:228] Iteration 19600, loss = 0.652911
I0929 18:38:20.581600 11684 solver.cpp:244]     Train net output #0: loss = 0.652911 (* 1 = 0.652911 loss)
I0929 18:38:20.582100 11684 sgd_solver.cpp:106] Iteration 19600, lr = 0.01
I0929 18:38:40.128732 11684 solver.cpp:228] Iteration 19700, loss = 0.644185
I0929 18:38:40.128732 11684 solver.cpp:244]     Train net output #0: loss = 0.644185 (* 1 = 0.644185 loss)
I0929 18:38:40.128732 11684 sgd_solver.cpp:106] Iteration 19700, lr = 0.01
I0929 18:38:59.378680 11684 solver.cpp:228] Iteration 19800, loss = 0.672242
I0929 18:38:59.378680 11684 solver.cpp:244]     Train net output #0: loss = 0.672242 (* 1 = 0.672242 loss)
I0929 18:38:59.378680 11684 sgd_solver.cpp:106] Iteration 19800, lr = 0.01
I0929 18:39:18.611754 11684 solver.cpp:228] Iteration 19900, loss = 0.403417
I0929 18:39:18.611754 11684 solver.cpp:244]     Train net output #0: loss = 0.403417 (* 1 = 0.403417 loss)
I0929 18:39:18.611754 11684 sgd_solver.cpp:106] Iteration 19900, lr = 0.01
I0929 18:39:37.797371 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_20000.caffemodel
I0929 18:39:38.395426 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_20000.solverstate
I0929 18:39:38.752677 11684 solver.cpp:337] Iteration 20000, Testing net (#0)
I0929 18:39:46.938596 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7058
I0929 18:39:46.938596 11684 solver.cpp:404]     Test net output #1: loss = 1.02572 (* 1 = 1.02572 loss)
I0929 18:39:46.988631 11684 solver.cpp:228] Iteration 20000, loss = 0.471127
I0929 18:39:46.988631 11684 solver.cpp:244]     Train net output #0: loss = 0.471127 (* 1 = 0.471127 loss)
I0929 18:39:46.988631 11684 sgd_solver.cpp:106] Iteration 20000, lr = 0.01
I0929 18:40:06.315893 11684 solver.cpp:228] Iteration 20100, loss = 0.733602
I0929 18:40:06.315893 11684 solver.cpp:244]     Train net output #0: loss = 0.733602 (* 1 = 0.733602 loss)
I0929 18:40:06.315893 11684 sgd_solver.cpp:106] Iteration 20100, lr = 0.01
I0929 18:40:25.556643 11684 solver.cpp:228] Iteration 20200, loss = 0.602899
I0929 18:40:25.556643 11684 solver.cpp:244]     Train net output #0: loss = 0.602899 (* 1 = 0.602899 loss)
I0929 18:40:25.556643 11684 sgd_solver.cpp:106] Iteration 20200, lr = 0.01
I0929 18:40:44.788305 11684 solver.cpp:228] Iteration 20300, loss = 0.978338
I0929 18:40:44.788305 11684 solver.cpp:244]     Train net output #0: loss = 0.978338 (* 1 = 0.978338 loss)
I0929 18:40:44.788305 11684 sgd_solver.cpp:106] Iteration 20300, lr = 0.01
I0929 18:41:04.017972 11684 solver.cpp:228] Iteration 20400, loss = 0.536153
I0929 18:41:04.017972 11684 solver.cpp:244]     Train net output #0: loss = 0.536152 (* 1 = 0.536152 loss)
I0929 18:41:04.017972 11684 sgd_solver.cpp:106] Iteration 20400, lr = 0.01
I0929 18:41:23.253654 11684 solver.cpp:228] Iteration 20500, loss = 0.553767
I0929 18:41:23.253654 11684 solver.cpp:244]     Train net output #0: loss = 0.553767 (* 1 = 0.553767 loss)
I0929 18:41:23.253654 11684 sgd_solver.cpp:106] Iteration 20500, lr = 0.01
I0929 18:41:42.477478 11684 solver.cpp:228] Iteration 20600, loss = 0.65477
I0929 18:41:42.477478 11684 solver.cpp:244]     Train net output #0: loss = 0.65477 (* 1 = 0.65477 loss)
I0929 18:41:42.477478 11684 sgd_solver.cpp:106] Iteration 20600, lr = 0.01
I0929 18:42:01.718688 11684 solver.cpp:228] Iteration 20700, loss = 0.614768
I0929 18:42:01.718688 11684 solver.cpp:244]     Train net output #0: loss = 0.614768 (* 1 = 0.614768 loss)
I0929 18:42:01.718688 11684 sgd_solver.cpp:106] Iteration 20700, lr = 0.01
I0929 18:42:20.954339 11684 solver.cpp:228] Iteration 20800, loss = 0.497081
I0929 18:42:20.954339 11684 solver.cpp:244]     Train net output #0: loss = 0.497081 (* 1 = 0.497081 loss)
I0929 18:42:20.954339 11684 sgd_solver.cpp:106] Iteration 20800, lr = 0.01
I0929 18:42:40.186990 11684 solver.cpp:228] Iteration 20900, loss = 0.387809
I0929 18:42:40.186990 11684 solver.cpp:244]     Train net output #0: loss = 0.387809 (* 1 = 0.387809 loss)
I0929 18:42:40.186990 11684 sgd_solver.cpp:106] Iteration 20900, lr = 0.01
I0929 18:42:59.355595 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_21000.caffemodel
I0929 18:42:59.941025 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_21000.solverstate
I0929 18:43:00.325284 11684 solver.cpp:337] Iteration 21000, Testing net (#0)
I0929 18:43:08.529108 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7067
I0929 18:43:08.529108 11684 solver.cpp:404]     Test net output #1: loss = 1.02232 (* 1 = 1.02232 loss)
I0929 18:43:08.579155 11684 solver.cpp:228] Iteration 21000, loss = 0.513178
I0929 18:43:08.579155 11684 solver.cpp:244]     Train net output #0: loss = 0.513178 (* 1 = 0.513178 loss)
I0929 18:43:08.579155 11684 sgd_solver.cpp:106] Iteration 21000, lr = 0.01
I0929 18:43:27.798782 11684 solver.cpp:228] Iteration 21100, loss = 0.819878
I0929 18:43:27.798782 11684 solver.cpp:244]     Train net output #0: loss = 0.819878 (* 1 = 0.819878 loss)
I0929 18:43:27.798782 11684 sgd_solver.cpp:106] Iteration 21100, lr = 0.01
I0929 18:43:47.027431 11684 solver.cpp:228] Iteration 21200, loss = 0.367943
I0929 18:43:47.027431 11684 solver.cpp:244]     Train net output #0: loss = 0.367943 (* 1 = 0.367943 loss)
I0929 18:43:47.027431 11684 sgd_solver.cpp:106] Iteration 21200, lr = 0.01
I0929 18:44:06.254825 11684 solver.cpp:228] Iteration 21300, loss = 0.807373
I0929 18:44:06.254825 11684 solver.cpp:244]     Train net output #0: loss = 0.807373 (* 1 = 0.807373 loss)
I0929 18:44:06.254825 11684 sgd_solver.cpp:106] Iteration 21300, lr = 0.01
I0929 18:44:25.493270 11684 solver.cpp:228] Iteration 21400, loss = 0.431279
I0929 18:44:25.493270 11684 solver.cpp:244]     Train net output #0: loss = 0.431279 (* 1 = 0.431279 loss)
I0929 18:44:25.493270 11684 sgd_solver.cpp:106] Iteration 21400, lr = 0.01
I0929 18:44:45.001312 11684 solver.cpp:228] Iteration 21500, loss = 0.435412
I0929 18:44:45.001312 11684 solver.cpp:244]     Train net output #0: loss = 0.435412 (* 1 = 0.435412 loss)
I0929 18:44:45.001312 11684 sgd_solver.cpp:106] Iteration 21500, lr = 0.01
I0929 18:45:05.064973 11684 solver.cpp:228] Iteration 21600, loss = 0.595997
I0929 18:45:05.064973 11684 solver.cpp:244]     Train net output #0: loss = 0.595996 (* 1 = 0.595996 loss)
I0929 18:45:05.064973 11684 sgd_solver.cpp:106] Iteration 21600, lr = 0.01
I0929 18:45:25.118963 11684 solver.cpp:228] Iteration 21700, loss = 0.504771
I0929 18:45:25.118963 11684 solver.cpp:244]     Train net output #0: loss = 0.50477 (* 1 = 0.50477 loss)
I0929 18:45:25.118963 11684 sgd_solver.cpp:106] Iteration 21700, lr = 0.01
I0929 18:45:45.141855 11684 solver.cpp:228] Iteration 21800, loss = 0.455595
I0929 18:45:45.141855 11684 solver.cpp:244]     Train net output #0: loss = 0.455594 (* 1 = 0.455594 loss)
I0929 18:45:45.141855 11684 sgd_solver.cpp:106] Iteration 21800, lr = 0.01
I0929 18:46:05.075562 11684 solver.cpp:228] Iteration 21900, loss = 0.380801
I0929 18:46:05.075562 11684 solver.cpp:244]     Train net output #0: loss = 0.380801 (* 1 = 0.380801 loss)
I0929 18:46:05.075562 11684 sgd_solver.cpp:106] Iteration 21900, lr = 0.01
I0929 18:46:24.858180 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_22000.caffemodel
I0929 18:46:25.537858 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_22000.solverstate
I0929 18:46:25.905102 11684 solver.cpp:337] Iteration 22000, Testing net (#0)
I0929 18:46:34.138849 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7107
I0929 18:46:34.138849 11684 solver.cpp:404]     Test net output #1: loss = 1.01773 (* 1 = 1.01773 loss)
I0929 18:46:34.210901 11684 solver.cpp:228] Iteration 22000, loss = 0.543025
I0929 18:46:34.210901 11684 solver.cpp:244]     Train net output #0: loss = 0.543025 (* 1 = 0.543025 loss)
I0929 18:46:34.210901 11684 sgd_solver.cpp:106] Iteration 22000, lr = 0.01
I0929 18:46:53.507714 11684 solver.cpp:228] Iteration 22100, loss = 0.623715
I0929 18:46:53.507714 11684 solver.cpp:244]     Train net output #0: loss = 0.623715 (* 1 = 0.623715 loss)
I0929 18:46:53.507714 11684 sgd_solver.cpp:106] Iteration 22100, lr = 0.01
I0929 18:47:12.817281 11684 solver.cpp:228] Iteration 22200, loss = 0.425784
I0929 18:47:12.817281 11684 solver.cpp:244]     Train net output #0: loss = 0.425784 (* 1 = 0.425784 loss)
I0929 18:47:12.817281 11684 sgd_solver.cpp:106] Iteration 22200, lr = 0.01
I0929 18:47:32.743005 11684 solver.cpp:228] Iteration 22300, loss = 0.799375
I0929 18:47:32.743005 11684 solver.cpp:244]     Train net output #0: loss = 0.799375 (* 1 = 0.799375 loss)
I0929 18:47:32.743505 11684 sgd_solver.cpp:106] Iteration 22300, lr = 0.01
I0929 18:47:52.660563 11684 solver.cpp:228] Iteration 22400, loss = 0.379665
I0929 18:47:52.660563 11684 solver.cpp:244]     Train net output #0: loss = 0.379665 (* 1 = 0.379665 loss)
I0929 18:47:52.660563 11684 sgd_solver.cpp:106] Iteration 22400, lr = 0.01
I0929 18:48:12.637101 11684 solver.cpp:228] Iteration 22500, loss = 0.312067
I0929 18:48:12.637101 11684 solver.cpp:244]     Train net output #0: loss = 0.312067 (* 1 = 0.312067 loss)
I0929 18:48:12.637101 11684 sgd_solver.cpp:106] Iteration 22500, lr = 0.01
I0929 18:48:32.414106 11684 solver.cpp:228] Iteration 22600, loss = 0.483892
I0929 18:48:32.414106 11684 solver.cpp:244]     Train net output #0: loss = 0.483891 (* 1 = 0.483891 loss)
I0929 18:48:32.414106 11684 sgd_solver.cpp:106] Iteration 22600, lr = 0.01
I0929 18:48:52.238745 11684 solver.cpp:228] Iteration 22700, loss = 0.407098
I0929 18:48:52.238745 11684 solver.cpp:244]     Train net output #0: loss = 0.407098 (* 1 = 0.407098 loss)
I0929 18:48:52.238745 11684 sgd_solver.cpp:106] Iteration 22700, lr = 0.01
I0929 18:49:12.045768 11684 solver.cpp:228] Iteration 22800, loss = 0.550136
I0929 18:49:12.045768 11684 solver.cpp:244]     Train net output #0: loss = 0.550136 (* 1 = 0.550136 loss)
I0929 18:49:12.045768 11684 sgd_solver.cpp:106] Iteration 22800, lr = 0.01
I0929 18:49:32.001595 11684 solver.cpp:228] Iteration 22900, loss = 0.224618
I0929 18:49:32.001595 11684 solver.cpp:244]     Train net output #0: loss = 0.224618 (* 1 = 0.224618 loss)
I0929 18:49:32.001595 11684 sgd_solver.cpp:106] Iteration 22900, lr = 0.01
I0929 18:49:51.790504 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_23000.caffemodel
I0929 18:49:52.460984 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_23000.solverstate
I0929 18:49:52.862267 11684 solver.cpp:337] Iteration 23000, Testing net (#0)
I0929 18:50:01.490838 11684 solver.cpp:404]     Test net output #0: accuracy = 0.717
I0929 18:50:01.490838 11684 solver.cpp:404]     Test net output #1: loss = 1.01019 (* 1 = 1.01019 loss)
I0929 18:50:01.542373 11684 solver.cpp:228] Iteration 23000, loss = 0.373698
I0929 18:50:01.542873 11684 solver.cpp:244]     Train net output #0: loss = 0.373698 (* 1 = 0.373698 loss)
I0929 18:50:01.542873 11684 sgd_solver.cpp:106] Iteration 23000, lr = 0.01
I0929 18:50:21.486475 11684 solver.cpp:228] Iteration 23100, loss = 0.59247
I0929 18:50:21.486475 11684 solver.cpp:244]     Train net output #0: loss = 0.59247 (* 1 = 0.59247 loss)
I0929 18:50:21.486475 11684 sgd_solver.cpp:106] Iteration 23100, lr = 0.01
I0929 18:50:41.347744 11684 solver.cpp:228] Iteration 23200, loss = 0.351458
I0929 18:50:41.348245 11684 solver.cpp:244]     Train net output #0: loss = 0.351458 (* 1 = 0.351458 loss)
I0929 18:50:41.348245 11684 sgd_solver.cpp:106] Iteration 23200, lr = 0.01
I0929 18:51:01.206599 11684 solver.cpp:228] Iteration 23300, loss = 0.632829
I0929 18:51:01.206599 11684 solver.cpp:244]     Train net output #0: loss = 0.632829 (* 1 = 0.632829 loss)
I0929 18:51:01.206599 11684 sgd_solver.cpp:106] Iteration 23300, lr = 0.01
I0929 18:51:21.163789 11684 solver.cpp:228] Iteration 23400, loss = 0.445274
I0929 18:51:21.163789 11684 solver.cpp:244]     Train net output #0: loss = 0.445274 (* 1 = 0.445274 loss)
I0929 18:51:21.163789 11684 sgd_solver.cpp:106] Iteration 23400, lr = 0.01
I0929 18:51:40.994813 11684 solver.cpp:228] Iteration 23500, loss = 0.408672
I0929 18:51:40.995313 11684 solver.cpp:244]     Train net output #0: loss = 0.408672 (* 1 = 0.408672 loss)
I0929 18:51:40.995313 11684 sgd_solver.cpp:106] Iteration 23500, lr = 0.01
I0929 18:52:00.819578 11684 solver.cpp:228] Iteration 23600, loss = 0.373835
I0929 18:52:00.819578 11684 solver.cpp:244]     Train net output #0: loss = 0.373835 (* 1 = 0.373835 loss)
I0929 18:52:00.819578 11684 sgd_solver.cpp:106] Iteration 23600, lr = 0.01
I0929 18:52:20.649883 11684 solver.cpp:228] Iteration 23700, loss = 0.33141
I0929 18:52:20.649883 11684 solver.cpp:244]     Train net output #0: loss = 0.33141 (* 1 = 0.33141 loss)
I0929 18:52:20.649883 11684 sgd_solver.cpp:106] Iteration 23700, lr = 0.01
I0929 18:52:40.511450 11684 solver.cpp:228] Iteration 23800, loss = 0.509942
I0929 18:52:40.511450 11684 solver.cpp:244]     Train net output #0: loss = 0.509942 (* 1 = 0.509942 loss)
I0929 18:52:40.511450 11684 sgd_solver.cpp:106] Iteration 23800, lr = 0.01
I0929 18:53:00.365473 11684 solver.cpp:228] Iteration 23900, loss = 0.251597
I0929 18:53:00.365473 11684 solver.cpp:244]     Train net output #0: loss = 0.251597 (* 1 = 0.251597 loss)
I0929 18:53:00.365473 11684 sgd_solver.cpp:106] Iteration 23900, lr = 0.01
I0929 18:53:20.109545 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_24000.caffemodel
I0929 18:53:20.814100 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_24000.solverstate
I0929 18:53:21.243007 11684 solver.cpp:337] Iteration 24000, Testing net (#0)
I0929 18:53:29.746042 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7116
I0929 18:53:29.746042 11684 solver.cpp:404]     Test net output #1: loss = 1.04085 (* 1 = 1.04085 loss)
I0929 18:53:29.797579 11684 solver.cpp:228] Iteration 24000, loss = 0.422951
I0929 18:53:29.797579 11684 solver.cpp:244]     Train net output #0: loss = 0.422951 (* 1 = 0.422951 loss)
I0929 18:53:29.797579 11684 sgd_solver.cpp:106] Iteration 24000, lr = 0.01
I0929 18:53:49.449590 11684 solver.cpp:228] Iteration 24100, loss = 0.664686
I0929 18:53:49.449590 11684 solver.cpp:244]     Train net output #0: loss = 0.664686 (* 1 = 0.664686 loss)
I0929 18:53:49.449590 11684 sgd_solver.cpp:106] Iteration 24100, lr = 0.01
I0929 18:54:09.257668 11684 solver.cpp:228] Iteration 24200, loss = 0.341707
I0929 18:54:09.257668 11684 solver.cpp:244]     Train net output #0: loss = 0.341707 (* 1 = 0.341707 loss)
I0929 18:54:09.257668 11684 sgd_solver.cpp:106] Iteration 24200, lr = 0.01
I0929 18:54:29.292179 11684 solver.cpp:228] Iteration 24300, loss = 0.608898
I0929 18:54:29.292179 11684 solver.cpp:244]     Train net output #0: loss = 0.608898 (* 1 = 0.608898 loss)
I0929 18:54:29.292179 11684 sgd_solver.cpp:106] Iteration 24300, lr = 0.01
I0929 18:54:49.180070 11684 solver.cpp:228] Iteration 24400, loss = 0.260115
I0929 18:54:49.180070 11684 solver.cpp:244]     Train net output #0: loss = 0.260115 (* 1 = 0.260115 loss)
I0929 18:54:49.180070 11684 sgd_solver.cpp:106] Iteration 24400, lr = 0.01
I0929 18:55:09.466992 11684 solver.cpp:228] Iteration 24500, loss = 0.338398
I0929 18:55:09.466992 11684 solver.cpp:244]     Train net output #0: loss = 0.338398 (* 1 = 0.338398 loss)
I0929 18:55:09.466992 11684 sgd_solver.cpp:106] Iteration 24500, lr = 0.01
I0929 18:55:29.541211 11684 solver.cpp:228] Iteration 24600, loss = 0.371789
I0929 18:55:29.541211 11684 solver.cpp:244]     Train net output #0: loss = 0.371789 (* 1 = 0.371789 loss)
I0929 18:55:29.541211 11684 sgd_solver.cpp:106] Iteration 24600, lr = 0.01
I0929 18:55:49.764598 11684 solver.cpp:228] Iteration 24700, loss = 0.212504
I0929 18:55:49.764598 11684 solver.cpp:244]     Train net output #0: loss = 0.212504 (* 1 = 0.212504 loss)
I0929 18:55:49.764598 11684 sgd_solver.cpp:106] Iteration 24700, lr = 0.01
I0929 18:56:09.808297 11684 solver.cpp:228] Iteration 24800, loss = 0.300421
I0929 18:56:09.808297 11684 solver.cpp:244]     Train net output #0: loss = 0.300421 (* 1 = 0.300421 loss)
I0929 18:56:09.808297 11684 sgd_solver.cpp:106] Iteration 24800, lr = 0.01
I0929 18:56:29.660966 11684 solver.cpp:228] Iteration 24900, loss = 0.165072
I0929 18:56:29.660966 11684 solver.cpp:244]     Train net output #0: loss = 0.165072 (* 1 = 0.165072 loss)
I0929 18:56:29.660966 11684 sgd_solver.cpp:106] Iteration 24900, lr = 0.01
I0929 18:56:49.792037 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_25000.caffemodel
I0929 18:56:50.476495 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_25000.solverstate
I0929 18:56:50.852672 11684 solver.cpp:337] Iteration 25000, Testing net (#0)
I0929 18:56:59.478893 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7124
I0929 18:56:59.478893 11684 solver.cpp:404]     Test net output #1: loss = 1.05932 (* 1 = 1.05932 loss)
I0929 18:56:59.528928 11684 solver.cpp:228] Iteration 25000, loss = 0.254566
I0929 18:56:59.528928 11684 solver.cpp:244]     Train net output #0: loss = 0.254566 (* 1 = 0.254566 loss)
I0929 18:56:59.528928 11684 sgd_solver.cpp:106] Iteration 25000, lr = 0.01
I0929 18:57:18.930002 11684 solver.cpp:228] Iteration 25100, loss = 0.349518
I0929 18:57:18.930002 11684 solver.cpp:244]     Train net output #0: loss = 0.349518 (* 1 = 0.349518 loss)
I0929 18:57:18.930002 11684 sgd_solver.cpp:106] Iteration 25100, lr = 0.01
I0929 18:57:38.409447 11684 solver.cpp:228] Iteration 25200, loss = 0.275826
I0929 18:57:38.409447 11684 solver.cpp:244]     Train net output #0: loss = 0.275826 (* 1 = 0.275826 loss)
I0929 18:57:38.409447 11684 sgd_solver.cpp:106] Iteration 25200, lr = 0.01
I0929 18:57:58.726409 11684 solver.cpp:228] Iteration 25300, loss = 0.434779
I0929 18:57:58.726409 11684 solver.cpp:244]     Train net output #0: loss = 0.434779 (* 1 = 0.434779 loss)
I0929 18:57:58.726409 11684 sgd_solver.cpp:106] Iteration 25300, lr = 0.01
I0929 18:58:18.778910 11684 solver.cpp:228] Iteration 25400, loss = 0.291605
I0929 18:58:18.778910 11684 solver.cpp:244]     Train net output #0: loss = 0.291605 (* 1 = 0.291605 loss)
I0929 18:58:18.778910 11684 sgd_solver.cpp:106] Iteration 25400, lr = 0.01
I0929 18:58:38.615059 11684 solver.cpp:228] Iteration 25500, loss = 0.285004
I0929 18:58:38.615059 11684 solver.cpp:244]     Train net output #0: loss = 0.285004 (* 1 = 0.285004 loss)
I0929 18:58:38.615059 11684 sgd_solver.cpp:106] Iteration 25500, lr = 0.01
I0929 18:58:58.628491 11684 solver.cpp:228] Iteration 25600, loss = 0.302519
I0929 18:58:58.628491 11684 solver.cpp:244]     Train net output #0: loss = 0.302519 (* 1 = 0.302519 loss)
I0929 18:58:58.628491 11684 sgd_solver.cpp:106] Iteration 25600, lr = 0.01
I0929 18:59:18.242374 11684 solver.cpp:228] Iteration 25700, loss = 0.258416
I0929 18:59:18.242374 11684 solver.cpp:244]     Train net output #0: loss = 0.258416 (* 1 = 0.258416 loss)
I0929 18:59:18.242374 11684 sgd_solver.cpp:106] Iteration 25700, lr = 0.01
I0929 18:59:38.058207 11684 solver.cpp:228] Iteration 25800, loss = 0.408925
I0929 18:59:38.058207 11684 solver.cpp:244]     Train net output #0: loss = 0.408925 (* 1 = 0.408925 loss)
I0929 18:59:38.058207 11684 sgd_solver.cpp:106] Iteration 25800, lr = 0.01
I0929 18:59:57.907853 11684 solver.cpp:228] Iteration 25900, loss = 0.234683
I0929 18:59:57.907853 11684 solver.cpp:244]     Train net output #0: loss = 0.234683 (* 1 = 0.234683 loss)
I0929 18:59:57.907853 11684 sgd_solver.cpp:106] Iteration 25900, lr = 0.01
I0929 19:00:17.791992 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_26000.caffemodel
I0929 19:00:18.488929 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_26000.solverstate
I0929 19:00:18.891214 11684 solver.cpp:337] Iteration 26000, Testing net (#0)
I0929 19:00:27.417567 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7134
I0929 19:00:27.417567 11684 solver.cpp:404]     Test net output #1: loss = 1.07345 (* 1 = 1.07345 loss)
I0929 19:00:27.469604 11684 solver.cpp:228] Iteration 26000, loss = 0.239182
I0929 19:00:27.469604 11684 solver.cpp:244]     Train net output #0: loss = 0.239182 (* 1 = 0.239182 loss)
I0929 19:00:27.469604 11684 sgd_solver.cpp:106] Iteration 26000, lr = 0.01
I0929 19:00:47.366494 11684 solver.cpp:228] Iteration 26100, loss = 0.345516
I0929 19:00:47.366494 11684 solver.cpp:244]     Train net output #0: loss = 0.345516 (* 1 = 0.345516 loss)
I0929 19:00:47.366494 11684 sgd_solver.cpp:106] Iteration 26100, lr = 0.01
I0929 19:01:07.253350 11684 solver.cpp:228] Iteration 26200, loss = 0.206843
I0929 19:01:07.253350 11684 solver.cpp:244]     Train net output #0: loss = 0.206843 (* 1 = 0.206843 loss)
I0929 19:01:07.253350 11684 sgd_solver.cpp:106] Iteration 26200, lr = 0.01
I0929 19:01:27.257580 11684 solver.cpp:228] Iteration 26300, loss = 0.335817
I0929 19:01:27.257580 11684 solver.cpp:244]     Train net output #0: loss = 0.335817 (* 1 = 0.335817 loss)
I0929 19:01:27.257580 11684 sgd_solver.cpp:106] Iteration 26300, lr = 0.01
I0929 19:01:47.175264 11684 solver.cpp:228] Iteration 26400, loss = 0.34418
I0929 19:01:47.175264 11684 solver.cpp:244]     Train net output #0: loss = 0.34418 (* 1 = 0.34418 loss)
I0929 19:01:47.175264 11684 sgd_solver.cpp:106] Iteration 26400, lr = 0.01
I0929 19:02:07.204030 11684 solver.cpp:228] Iteration 26500, loss = 0.286337
I0929 19:02:07.204030 11684 solver.cpp:244]     Train net output #0: loss = 0.286338 (* 1 = 0.286338 loss)
I0929 19:02:07.204030 11684 sgd_solver.cpp:106] Iteration 26500, lr = 0.01
I0929 19:02:27.299489 11684 solver.cpp:228] Iteration 26600, loss = 0.240283
I0929 19:02:27.299489 11684 solver.cpp:244]     Train net output #0: loss = 0.240283 (* 1 = 0.240283 loss)
I0929 19:02:27.299489 11684 sgd_solver.cpp:106] Iteration 26600, lr = 0.01
I0929 19:02:47.337393 11684 solver.cpp:228] Iteration 26700, loss = 0.166423
I0929 19:02:47.337393 11684 solver.cpp:244]     Train net output #0: loss = 0.166423 (* 1 = 0.166423 loss)
I0929 19:02:47.337393 11684 sgd_solver.cpp:106] Iteration 26700, lr = 0.01
I0929 19:03:07.357980 11684 solver.cpp:228] Iteration 26800, loss = 0.252321
I0929 19:03:07.357980 11684 solver.cpp:244]     Train net output #0: loss = 0.252321 (* 1 = 0.252321 loss)
I0929 19:03:07.357980 11684 sgd_solver.cpp:106] Iteration 26800, lr = 0.01
I0929 19:03:27.410281 11684 solver.cpp:228] Iteration 26900, loss = 0.158143
I0929 19:03:27.410281 11684 solver.cpp:244]     Train net output #0: loss = 0.158143 (* 1 = 0.158143 loss)
I0929 19:03:27.410281 11684 sgd_solver.cpp:106] Iteration 26900, lr = 0.01
I0929 19:03:47.462249 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_27000.caffemodel
I0929 19:03:48.248809 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_27000.solverstate
I0929 19:03:48.737207 11684 solver.cpp:337] Iteration 27000, Testing net (#0)
I0929 19:03:57.684020 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7072
I0929 19:03:57.684020 11684 solver.cpp:404]     Test net output #1: loss = 1.10686 (* 1 = 1.10686 loss)
I0929 19:03:57.740061 11684 solver.cpp:228] Iteration 27000, loss = 0.137734
I0929 19:03:57.740061 11684 solver.cpp:244]     Train net output #0: loss = 0.137734 (* 1 = 0.137734 loss)
I0929 19:03:57.740061 11684 sgd_solver.cpp:106] Iteration 27000, lr = 0.01
I0929 19:04:17.782004 11684 solver.cpp:228] Iteration 27100, loss = 0.306687
I0929 19:04:17.782004 11684 solver.cpp:244]     Train net output #0: loss = 0.306687 (* 1 = 0.306687 loss)
I0929 19:04:17.782004 11684 sgd_solver.cpp:106] Iteration 27100, lr = 0.01
I0929 19:04:37.853993 11684 solver.cpp:228] Iteration 27200, loss = 0.236252
I0929 19:04:37.853993 11684 solver.cpp:244]     Train net output #0: loss = 0.236252 (* 1 = 0.236252 loss)
I0929 19:04:37.853993 11684 sgd_solver.cpp:106] Iteration 27200, lr = 0.01
I0929 19:04:57.660343 11684 solver.cpp:228] Iteration 27300, loss = 0.355473
I0929 19:04:57.660343 11684 solver.cpp:244]     Train net output #0: loss = 0.355473 (* 1 = 0.355473 loss)
I0929 19:04:57.660343 11684 sgd_solver.cpp:106] Iteration 27300, lr = 0.01
I0929 19:05:17.463232 11684 solver.cpp:228] Iteration 27400, loss = 0.190637
I0929 19:05:17.463731 11684 solver.cpp:244]     Train net output #0: loss = 0.190637 (* 1 = 0.190637 loss)
I0929 19:05:17.463731 11684 sgd_solver.cpp:106] Iteration 27400, lr = 0.01
I0929 19:05:37.254015 11684 solver.cpp:228] Iteration 27500, loss = 0.24104
I0929 19:05:37.254015 11684 solver.cpp:244]     Train net output #0: loss = 0.24104 (* 1 = 0.24104 loss)
I0929 19:05:37.254015 11684 sgd_solver.cpp:106] Iteration 27500, lr = 0.01
I0929 19:05:57.040417 11684 solver.cpp:228] Iteration 27600, loss = 0.244064
I0929 19:05:57.040417 11684 solver.cpp:244]     Train net output #0: loss = 0.244064 (* 1 = 0.244064 loss)
I0929 19:05:57.040417 11684 sgd_solver.cpp:106] Iteration 27600, lr = 0.01
I0929 19:06:16.921300 11684 solver.cpp:228] Iteration 27700, loss = 0.228677
I0929 19:06:16.921300 11684 solver.cpp:244]     Train net output #0: loss = 0.228677 (* 1 = 0.228677 loss)
I0929 19:06:16.921300 11684 sgd_solver.cpp:106] Iteration 27700, lr = 0.01
I0929 19:06:36.726259 11684 solver.cpp:228] Iteration 27800, loss = 0.213907
I0929 19:06:36.726259 11684 solver.cpp:244]     Train net output #0: loss = 0.213907 (* 1 = 0.213907 loss)
I0929 19:06:36.726259 11684 sgd_solver.cpp:106] Iteration 27800, lr = 0.01
I0929 19:06:56.486402 11684 solver.cpp:228] Iteration 27900, loss = 0.257096
I0929 19:06:56.486402 11684 solver.cpp:244]     Train net output #0: loss = 0.257096 (* 1 = 0.257096 loss)
I0929 19:06:56.486402 11684 sgd_solver.cpp:106] Iteration 27900, lr = 0.01
I0929 19:07:16.211745 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_28000.caffemodel
I0929 19:07:16.879221 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_28000.solverstate
I0929 19:07:17.316531 11684 solver.cpp:337] Iteration 28000, Testing net (#0)
I0929 19:07:25.779831 11684 solver.cpp:404]     Test net output #0: accuracy = 0.715
I0929 19:07:25.779831 11684 solver.cpp:404]     Test net output #1: loss = 1.11214 (* 1 = 1.11214 loss)
I0929 19:07:25.834370 11684 solver.cpp:228] Iteration 28000, loss = 0.201004
I0929 19:07:25.834370 11684 solver.cpp:244]     Train net output #0: loss = 0.201004 (* 1 = 0.201004 loss)
I0929 19:07:25.834370 11684 sgd_solver.cpp:106] Iteration 28000, lr = 0.01
I0929 19:07:45.636672 11684 solver.cpp:228] Iteration 28100, loss = 0.278713
I0929 19:07:45.637172 11684 solver.cpp:244]     Train net output #0: loss = 0.278713 (* 1 = 0.278713 loss)
I0929 19:07:45.637172 11684 sgd_solver.cpp:106] Iteration 28100, lr = 0.01
I0929 19:08:05.487643 11684 solver.cpp:228] Iteration 28200, loss = 0.168356
I0929 19:08:05.487643 11684 solver.cpp:244]     Train net output #0: loss = 0.168356 (* 1 = 0.168356 loss)
I0929 19:08:05.487643 11684 sgd_solver.cpp:106] Iteration 28200, lr = 0.01
I0929 19:08:25.620414 11684 solver.cpp:228] Iteration 28300, loss = 0.358903
I0929 19:08:25.620414 11684 solver.cpp:244]     Train net output #0: loss = 0.358903 (* 1 = 0.358903 loss)
I0929 19:08:25.620414 11684 sgd_solver.cpp:106] Iteration 28300, lr = 0.01
I0929 19:08:45.496165 11684 solver.cpp:228] Iteration 28400, loss = 0.164639
I0929 19:08:45.496165 11684 solver.cpp:244]     Train net output #0: loss = 0.164639 (* 1 = 0.164639 loss)
I0929 19:08:45.496165 11684 sgd_solver.cpp:106] Iteration 28400, lr = 0.01
I0929 19:09:05.424180 11684 solver.cpp:228] Iteration 28500, loss = 0.16142
I0929 19:09:05.424180 11684 solver.cpp:244]     Train net output #0: loss = 0.16142 (* 1 = 0.16142 loss)
I0929 19:09:05.424180 11684 sgd_solver.cpp:106] Iteration 28500, lr = 0.01
I0929 19:09:25.640753 11684 solver.cpp:228] Iteration 28600, loss = 0.208339
I0929 19:09:25.641253 11684 solver.cpp:244]     Train net output #0: loss = 0.208339 (* 1 = 0.208339 loss)
I0929 19:09:25.641253 11684 sgd_solver.cpp:106] Iteration 28600, lr = 0.01
I0929 19:09:45.710928 11684 solver.cpp:228] Iteration 28700, loss = 0.255005
I0929 19:09:45.710928 11684 solver.cpp:244]     Train net output #0: loss = 0.255005 (* 1 = 0.255005 loss)
I0929 19:09:45.710928 11684 sgd_solver.cpp:106] Iteration 28700, lr = 0.01
I0929 19:10:05.750823 11684 solver.cpp:228] Iteration 28800, loss = 0.261541
I0929 19:10:05.750823 11684 solver.cpp:244]     Train net output #0: loss = 0.261541 (* 1 = 0.261541 loss)
I0929 19:10:05.750823 11684 sgd_solver.cpp:106] Iteration 28800, lr = 0.01
I0929 19:10:25.706073 11684 solver.cpp:228] Iteration 28900, loss = 0.102531
I0929 19:10:25.706073 11684 solver.cpp:244]     Train net output #0: loss = 0.102532 (* 1 = 0.102532 loss)
I0929 19:10:25.706073 11684 sgd_solver.cpp:106] Iteration 28900, lr = 0.01
I0929 19:10:45.631325 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_29000.caffemodel
I0929 19:10:46.372927 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_29000.solverstate
I0929 19:10:46.793226 11684 solver.cpp:337] Iteration 29000, Testing net (#0)
I0929 19:10:55.493805 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7145
I0929 19:10:55.493805 11684 solver.cpp:404]     Test net output #1: loss = 1.11929 (* 1 = 1.11929 loss)
I0929 19:10:55.550345 11684 solver.cpp:228] Iteration 29000, loss = 0.147827
I0929 19:10:55.550345 11684 solver.cpp:244]     Train net output #0: loss = 0.147827 (* 1 = 0.147827 loss)
I0929 19:10:55.550345 11684 sgd_solver.cpp:106] Iteration 29000, lr = 0.01
I0929 19:11:15.471451 11684 solver.cpp:228] Iteration 29100, loss = 0.352591
I0929 19:11:15.471451 11684 solver.cpp:244]     Train net output #0: loss = 0.352591 (* 1 = 0.352591 loss)
I0929 19:11:15.471451 11684 sgd_solver.cpp:106] Iteration 29100, lr = 0.01
I0929 19:11:35.298868 11684 solver.cpp:228] Iteration 29200, loss = 0.149529
I0929 19:11:35.298868 11684 solver.cpp:244]     Train net output #0: loss = 0.149529 (* 1 = 0.149529 loss)
I0929 19:11:35.298868 11684 sgd_solver.cpp:106] Iteration 29200, lr = 0.01
I0929 19:11:55.344705 11684 solver.cpp:228] Iteration 29300, loss = 0.151402
I0929 19:11:55.344705 11684 solver.cpp:244]     Train net output #0: loss = 0.151403 (* 1 = 0.151403 loss)
I0929 19:11:55.344705 11684 sgd_solver.cpp:106] Iteration 29300, lr = 0.01
I0929 19:12:15.298049 11684 solver.cpp:228] Iteration 29400, loss = 0.123241
I0929 19:12:15.298049 11684 solver.cpp:244]     Train net output #0: loss = 0.123241 (* 1 = 0.123241 loss)
I0929 19:12:15.298550 11684 sgd_solver.cpp:106] Iteration 29400, lr = 0.01
I0929 19:12:35.087297 11684 solver.cpp:228] Iteration 29500, loss = 0.191864
I0929 19:12:35.087297 11684 solver.cpp:244]     Train net output #0: loss = 0.191864 (* 1 = 0.191864 loss)
I0929 19:12:35.087297 11684 sgd_solver.cpp:106] Iteration 29500, lr = 0.01
I0929 19:12:55.084456 11684 solver.cpp:228] Iteration 29600, loss = 0.176475
I0929 19:12:55.084956 11684 solver.cpp:244]     Train net output #0: loss = 0.176475 (* 1 = 0.176475 loss)
I0929 19:12:55.085458 11684 sgd_solver.cpp:106] Iteration 29600, lr = 0.01
I0929 19:13:15.146908 11684 solver.cpp:228] Iteration 29700, loss = 0.193874
I0929 19:13:15.146908 11684 solver.cpp:244]     Train net output #0: loss = 0.193874 (* 1 = 0.193874 loss)
I0929 19:13:15.146908 11684 sgd_solver.cpp:106] Iteration 29700, lr = 0.01
I0929 19:13:35.074820 11684 solver.cpp:228] Iteration 29800, loss = 0.147539
I0929 19:13:35.074820 11684 solver.cpp:244]     Train net output #0: loss = 0.147539 (* 1 = 0.147539 loss)
I0929 19:13:35.074820 11684 sgd_solver.cpp:106] Iteration 29800, lr = 0.01
I0929 19:13:55.052882 11684 solver.cpp:228] Iteration 29900, loss = 0.0885868
I0929 19:13:55.053382 11684 solver.cpp:244]     Train net output #0: loss = 0.0885871 (* 1 = 0.0885871 loss)
I0929 19:13:55.053382 11684 sgd_solver.cpp:106] Iteration 29900, lr = 0.01
I0929 19:14:14.931020 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_30000.caffemodel
I0929 19:14:15.623013 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_30000.solverstate
I0929 19:14:16.065328 11684 solver.cpp:337] Iteration 30000, Testing net (#0)
I0929 19:14:24.623056 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7082
I0929 19:14:24.623556 11684 solver.cpp:404]     Test net output #1: loss = 1.15498 (* 1 = 1.15498 loss)
I0929 19:14:24.676093 11684 solver.cpp:228] Iteration 30000, loss = 0.128107
I0929 19:14:24.676093 11684 solver.cpp:244]     Train net output #0: loss = 0.128107 (* 1 = 0.128107 loss)
I0929 19:14:24.676093 11684 sgd_solver.cpp:106] Iteration 30000, lr = 0.01
I0929 19:14:44.601219 11684 solver.cpp:228] Iteration 30100, loss = 0.250591
I0929 19:14:44.601219 11684 solver.cpp:244]     Train net output #0: loss = 0.250591 (* 1 = 0.250591 loss)
I0929 19:14:44.601219 11684 sgd_solver.cpp:106] Iteration 30100, lr = 0.01
I0929 19:15:04.403826 11684 solver.cpp:228] Iteration 30200, loss = 0.180274
I0929 19:15:04.403826 11684 solver.cpp:244]     Train net output #0: loss = 0.180274 (* 1 = 0.180274 loss)
I0929 19:15:04.403826 11684 sgd_solver.cpp:106] Iteration 30200, lr = 0.01
I0929 19:15:24.518093 11684 solver.cpp:228] Iteration 30300, loss = 0.334145
I0929 19:15:24.518093 11684 solver.cpp:244]     Train net output #0: loss = 0.334145 (* 1 = 0.334145 loss)
I0929 19:15:24.518093 11684 sgd_solver.cpp:106] Iteration 30300, lr = 0.01
I0929 19:15:44.137761 11684 solver.cpp:228] Iteration 30400, loss = 0.171242
I0929 19:15:44.137761 11684 solver.cpp:244]     Train net output #0: loss = 0.171242 (* 1 = 0.171242 loss)
I0929 19:15:44.137761 11684 sgd_solver.cpp:106] Iteration 30400, lr = 0.01
I0929 19:16:04.085842 11684 solver.cpp:228] Iteration 30500, loss = 0.311946
I0929 19:16:04.085842 11684 solver.cpp:244]     Train net output #0: loss = 0.311946 (* 1 = 0.311946 loss)
I0929 19:16:04.085842 11684 sgd_solver.cpp:106] Iteration 30500, lr = 0.01
I0929 19:16:24.089167 11684 solver.cpp:228] Iteration 30600, loss = 0.27065
I0929 19:16:24.089167 11684 solver.cpp:244]     Train net output #0: loss = 0.27065 (* 1 = 0.27065 loss)
I0929 19:16:24.089167 11684 sgd_solver.cpp:106] Iteration 30600, lr = 0.01
I0929 19:16:43.612279 11684 solver.cpp:228] Iteration 30700, loss = 0.103934
I0929 19:16:43.612279 11684 solver.cpp:244]     Train net output #0: loss = 0.103934 (* 1 = 0.103934 loss)
I0929 19:16:43.612279 11684 sgd_solver.cpp:106] Iteration 30700, lr = 0.01
I0929 19:17:03.478988 11684 solver.cpp:228] Iteration 30800, loss = 0.129255
I0929 19:17:03.478988 11684 solver.cpp:244]     Train net output #0: loss = 0.129255 (* 1 = 0.129255 loss)
I0929 19:17:03.479488 11684 sgd_solver.cpp:106] Iteration 30800, lr = 0.01
I0929 19:17:23.442253 11684 solver.cpp:228] Iteration 30900, loss = 0.0980805
I0929 19:17:23.442253 11684 solver.cpp:244]     Train net output #0: loss = 0.0980807 (* 1 = 0.0980807 loss)
I0929 19:17:23.442253 11684 sgd_solver.cpp:106] Iteration 30900, lr = 0.01
I0929 19:17:43.298115 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_31000.caffemodel
I0929 19:17:44.057657 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_31000.solverstate
I0929 19:17:44.521986 11684 solver.cpp:337] Iteration 31000, Testing net (#0)
I0929 19:17:53.307798 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7095
I0929 19:17:53.307798 11684 solver.cpp:404]     Test net output #1: loss = 1.16898 (* 1 = 1.16898 loss)
I0929 19:17:53.359335 11684 solver.cpp:228] Iteration 31000, loss = 0.0937241
I0929 19:17:53.359335 11684 solver.cpp:244]     Train net output #0: loss = 0.0937243 (* 1 = 0.0937243 loss)
I0929 19:17:53.359335 11684 sgd_solver.cpp:106] Iteration 31000, lr = 0.01
I0929 19:18:13.125548 11684 solver.cpp:228] Iteration 31100, loss = 0.176322
I0929 19:18:13.125548 11684 solver.cpp:244]     Train net output #0: loss = 0.176323 (* 1 = 0.176323 loss)
I0929 19:18:13.125548 11684 sgd_solver.cpp:106] Iteration 31100, lr = 0.01
I0929 19:18:33.027690 11684 solver.cpp:228] Iteration 31200, loss = 0.232188
I0929 19:18:33.027690 11684 solver.cpp:244]     Train net output #0: loss = 0.232188 (* 1 = 0.232188 loss)
I0929 19:18:33.027690 11684 sgd_solver.cpp:106] Iteration 31200, lr = 0.01
I0929 19:18:52.494747 11684 solver.cpp:228] Iteration 31300, loss = 0.172762
I0929 19:18:52.494747 11684 solver.cpp:244]     Train net output #0: loss = 0.172762 (* 1 = 0.172762 loss)
I0929 19:18:52.494747 11684 sgd_solver.cpp:106] Iteration 31300, lr = 0.01
I0929 19:19:12.278265 11684 solver.cpp:228] Iteration 31400, loss = 0.13113
I0929 19:19:12.278265 11684 solver.cpp:244]     Train net output #0: loss = 0.13113 (* 1 = 0.13113 loss)
I0929 19:19:12.278265 11684 sgd_solver.cpp:106] Iteration 31400, lr = 0.01
I0929 19:19:32.805251 11684 solver.cpp:228] Iteration 31500, loss = 0.0960141
I0929 19:19:32.805752 11684 solver.cpp:244]     Train net output #0: loss = 0.0960144 (* 1 = 0.0960144 loss)
I0929 19:19:32.805752 11684 sgd_solver.cpp:106] Iteration 31500, lr = 0.01
I0929 19:19:53.006882 11684 solver.cpp:228] Iteration 31600, loss = 0.114775
I0929 19:19:53.006882 11684 solver.cpp:244]     Train net output #0: loss = 0.114775 (* 1 = 0.114775 loss)
I0929 19:19:53.006882 11684 sgd_solver.cpp:106] Iteration 31600, lr = 0.01
I0929 19:20:13.503422 11684 solver.cpp:228] Iteration 31700, loss = 0.126442
I0929 19:20:13.503422 11684 solver.cpp:244]     Train net output #0: loss = 0.126442 (* 1 = 0.126442 loss)
I0929 19:20:13.503922 11684 sgd_solver.cpp:106] Iteration 31700, lr = 0.01
I0929 19:20:33.499919 11684 solver.cpp:228] Iteration 31800, loss = 0.123998
I0929 19:20:33.499919 11684 solver.cpp:244]     Train net output #0: loss = 0.123999 (* 1 = 0.123999 loss)
I0929 19:20:33.500419 11684 sgd_solver.cpp:106] Iteration 31800, lr = 0.01
I0929 19:20:53.635804 11684 solver.cpp:228] Iteration 31900, loss = 0.08907
I0929 19:20:53.636306 11684 solver.cpp:244]     Train net output #0: loss = 0.0890703 (* 1 = 0.0890703 loss)
I0929 19:20:53.636306 11684 sgd_solver.cpp:106] Iteration 31900, lr = 0.01
I0929 19:21:13.773442 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_32000.caffemodel
I0929 19:21:14.514974 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_32000.solverstate
I0929 19:21:14.941273 11684 solver.cpp:337] Iteration 32000, Testing net (#0)
I0929 19:21:23.648834 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7097
I0929 19:21:23.648834 11684 solver.cpp:404]     Test net output #1: loss = 1.18502 (* 1 = 1.18502 loss)
I0929 19:21:23.701372 11684 solver.cpp:228] Iteration 32000, loss = 0.167467
I0929 19:21:23.701872 11684 solver.cpp:244]     Train net output #0: loss = 0.167467 (* 1 = 0.167467 loss)
I0929 19:21:23.701872 11684 sgd_solver.cpp:106] Iteration 32000, lr = 0.01
I0929 19:21:43.734642 11684 solver.cpp:228] Iteration 32100, loss = 0.174444
I0929 19:21:43.734642 11684 solver.cpp:244]     Train net output #0: loss = 0.174444 (* 1 = 0.174444 loss)
I0929 19:21:43.734642 11684 sgd_solver.cpp:106] Iteration 32100, lr = 0.01
I0929 19:22:03.417384 11684 solver.cpp:228] Iteration 32200, loss = 0.131606
I0929 19:22:03.417384 11684 solver.cpp:244]     Train net output #0: loss = 0.131607 (* 1 = 0.131607 loss)
I0929 19:22:03.417384 11684 sgd_solver.cpp:106] Iteration 32200, lr = 0.01
I0929 19:22:23.040711 11684 solver.cpp:228] Iteration 32300, loss = 0.219394
I0929 19:22:23.040711 11684 solver.cpp:244]     Train net output #0: loss = 0.219394 (* 1 = 0.219394 loss)
I0929 19:22:23.040711 11684 sgd_solver.cpp:106] Iteration 32300, lr = 0.01
I0929 19:22:42.686332 11684 solver.cpp:228] Iteration 32400, loss = 0.0900484
I0929 19:22:42.686832 11684 solver.cpp:244]     Train net output #0: loss = 0.0900487 (* 1 = 0.0900487 loss)
I0929 19:22:42.686832 11684 sgd_solver.cpp:106] Iteration 32400, lr = 0.01
I0929 19:23:02.326606 11684 solver.cpp:228] Iteration 32500, loss = 0.187908
I0929 19:23:02.326606 11684 solver.cpp:244]     Train net output #0: loss = 0.187908 (* 1 = 0.187908 loss)
I0929 19:23:02.326606 11684 sgd_solver.cpp:106] Iteration 32500, lr = 0.01
I0929 19:23:21.880748 11684 solver.cpp:228] Iteration 32600, loss = 0.116733
I0929 19:23:21.881248 11684 solver.cpp:244]     Train net output #0: loss = 0.116733 (* 1 = 0.116733 loss)
I0929 19:23:21.881248 11684 sgd_solver.cpp:106] Iteration 32600, lr = 0.01
I0929 19:23:41.489004 11684 solver.cpp:228] Iteration 32700, loss = 0.105946
I0929 19:23:41.489004 11684 solver.cpp:244]     Train net output #0: loss = 0.105946 (* 1 = 0.105946 loss)
I0929 19:23:41.489004 11684 sgd_solver.cpp:106] Iteration 32700, lr = 0.01
I0929 19:24:01.145812 11684 solver.cpp:228] Iteration 32800, loss = 0.143661
I0929 19:24:01.145812 11684 solver.cpp:244]     Train net output #0: loss = 0.143661 (* 1 = 0.143661 loss)
I0929 19:24:01.145812 11684 sgd_solver.cpp:106] Iteration 32800, lr = 0.01
I0929 19:24:20.744490 11684 solver.cpp:228] Iteration 32900, loss = 0.127011
I0929 19:24:20.744490 11684 solver.cpp:244]     Train net output #0: loss = 0.127012 (* 1 = 0.127012 loss)
I0929 19:24:20.744490 11684 sgd_solver.cpp:106] Iteration 32900, lr = 0.01
I0929 19:24:40.371583 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_33000.caffemodel
I0929 19:24:41.036558 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_33000.solverstate
I0929 19:24:41.427835 11684 solver.cpp:337] Iteration 33000, Testing net (#0)
I0929 19:24:49.862543 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7033
I0929 19:24:49.862543 11684 solver.cpp:404]     Test net output #1: loss = 1.20389 (* 1 = 1.20389 loss)
I0929 19:24:49.914579 11684 solver.cpp:228] Iteration 33000, loss = 0.0820781
I0929 19:24:49.914579 11684 solver.cpp:244]     Train net output #0: loss = 0.0820785 (* 1 = 0.0820785 loss)
I0929 19:24:49.914579 11684 sgd_solver.cpp:106] Iteration 33000, lr = 0.01
I0929 19:25:09.502691 11684 solver.cpp:228] Iteration 33100, loss = 0.209707
I0929 19:25:09.502691 11684 solver.cpp:244]     Train net output #0: loss = 0.209708 (* 1 = 0.209708 loss)
I0929 19:25:09.502691 11684 sgd_solver.cpp:106] Iteration 33100, lr = 0.01
I0929 19:25:29.197554 11684 solver.cpp:228] Iteration 33200, loss = 0.105035
I0929 19:25:29.197554 11684 solver.cpp:244]     Train net output #0: loss = 0.105035 (* 1 = 0.105035 loss)
I0929 19:25:29.197554 11684 sgd_solver.cpp:106] Iteration 33200, lr = 0.01
I0929 19:25:48.766319 11684 solver.cpp:228] Iteration 33300, loss = 0.176958
I0929 19:25:48.766319 11684 solver.cpp:244]     Train net output #0: loss = 0.176959 (* 1 = 0.176959 loss)
I0929 19:25:48.766319 11684 sgd_solver.cpp:106] Iteration 33300, lr = 0.01
I0929 19:26:08.443562 11684 solver.cpp:228] Iteration 33400, loss = 0.0943264
I0929 19:26:08.443562 11684 solver.cpp:244]     Train net output #0: loss = 0.0943267 (* 1 = 0.0943267 loss)
I0929 19:26:08.443562 11684 sgd_solver.cpp:106] Iteration 33400, lr = 0.01
I0929 19:26:28.000146 11684 solver.cpp:228] Iteration 33500, loss = 0.0682076
I0929 19:26:28.000146 11684 solver.cpp:244]     Train net output #0: loss = 0.0682079 (* 1 = 0.0682079 loss)
I0929 19:26:28.000648 11684 sgd_solver.cpp:106] Iteration 33500, lr = 0.01
I0929 19:26:47.612938 11684 solver.cpp:228] Iteration 33600, loss = 0.208994
I0929 19:26:47.612938 11684 solver.cpp:244]     Train net output #0: loss = 0.208995 (* 1 = 0.208995 loss)
I0929 19:26:47.612938 11684 sgd_solver.cpp:106] Iteration 33600, lr = 0.01
I0929 19:27:07.252225 11684 solver.cpp:228] Iteration 33700, loss = 0.0901411
I0929 19:27:07.252225 11684 solver.cpp:244]     Train net output #0: loss = 0.0901414 (* 1 = 0.0901414 loss)
I0929 19:27:07.252225 11684 sgd_solver.cpp:106] Iteration 33700, lr = 0.01
I0929 19:27:27.117074 11684 solver.cpp:228] Iteration 33800, loss = 0.181015
I0929 19:27:27.117074 11684 solver.cpp:244]     Train net output #0: loss = 0.181016 (* 1 = 0.181016 loss)
I0929 19:27:27.117074 11684 sgd_solver.cpp:106] Iteration 33800, lr = 0.01
I0929 19:27:47.022042 11684 solver.cpp:228] Iteration 33900, loss = 0.0680196
I0929 19:27:47.022042 11684 solver.cpp:244]     Train net output #0: loss = 0.06802 (* 1 = 0.06802 loss)
I0929 19:27:47.022042 11684 sgd_solver.cpp:106] Iteration 33900, lr = 0.01
I0929 19:28:06.716675 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_34000.caffemodel
I0929 19:28:07.392156 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_34000.solverstate
I0929 19:28:07.781432 11684 solver.cpp:337] Iteration 34000, Testing net (#0)
I0929 19:28:16.163239 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7112
I0929 19:28:16.163239 11684 solver.cpp:404]     Test net output #1: loss = 1.19238 (* 1 = 1.19238 loss)
I0929 19:28:16.215775 11684 solver.cpp:228] Iteration 34000, loss = 0.106055
I0929 19:28:16.215775 11684 solver.cpp:244]     Train net output #0: loss = 0.106055 (* 1 = 0.106055 loss)
I0929 19:28:16.215775 11684 sgd_solver.cpp:106] Iteration 34000, lr = 0.01
I0929 19:28:35.772064 11684 solver.cpp:228] Iteration 34100, loss = 0.0973717
I0929 19:28:35.772064 11684 solver.cpp:244]     Train net output #0: loss = 0.0973721 (* 1 = 0.0973721 loss)
I0929 19:28:35.772064 11684 sgd_solver.cpp:106] Iteration 34100, lr = 0.01
I0929 19:28:55.240702 11684 solver.cpp:228] Iteration 34200, loss = 0.10431
I0929 19:28:55.240702 11684 solver.cpp:244]     Train net output #0: loss = 0.10431 (* 1 = 0.10431 loss)
I0929 19:28:55.240702 11684 sgd_solver.cpp:106] Iteration 34200, lr = 0.01
I0929 19:29:14.633631 11684 solver.cpp:228] Iteration 34300, loss = 0.241759
I0929 19:29:14.633631 11684 solver.cpp:244]     Train net output #0: loss = 0.24176 (* 1 = 0.24176 loss)
I0929 19:29:14.633631 11684 sgd_solver.cpp:106] Iteration 34300, lr = 0.01
I0929 19:29:33.999336 11684 solver.cpp:228] Iteration 34400, loss = 0.0870982
I0929 19:29:33.999336 11684 solver.cpp:244]     Train net output #0: loss = 0.0870986 (* 1 = 0.0870986 loss)
I0929 19:29:33.999336 11684 sgd_solver.cpp:106] Iteration 34400, lr = 0.01
I0929 19:29:53.336601 11684 solver.cpp:228] Iteration 34500, loss = 0.0950804
I0929 19:29:53.336601 11684 solver.cpp:244]     Train net output #0: loss = 0.0950807 (* 1 = 0.0950807 loss)
I0929 19:29:53.336601 11684 sgd_solver.cpp:106] Iteration 34500, lr = 0.01
I0929 19:30:13.351433 11684 solver.cpp:228] Iteration 34600, loss = 0.136994
I0929 19:30:13.351433 11684 solver.cpp:244]     Train net output #0: loss = 0.136995 (* 1 = 0.136995 loss)
I0929 19:30:13.351433 11684 sgd_solver.cpp:106] Iteration 34600, lr = 0.01
I0929 19:30:33.015890 11684 solver.cpp:228] Iteration 34700, loss = 0.136026
I0929 19:30:33.015890 11684 solver.cpp:244]     Train net output #0: loss = 0.136027 (* 1 = 0.136027 loss)
I0929 19:30:33.015890 11684 sgd_solver.cpp:106] Iteration 34700, lr = 0.01
I0929 19:30:52.836050 11684 solver.cpp:228] Iteration 34800, loss = 0.120339
I0929 19:30:52.836050 11684 solver.cpp:244]     Train net output #0: loss = 0.120339 (* 1 = 0.120339 loss)
I0929 19:30:52.836549 11684 sgd_solver.cpp:106] Iteration 34800, lr = 0.01
I0929 19:31:12.800072 11684 solver.cpp:228] Iteration 34900, loss = 0.0864739
I0929 19:31:12.800072 11684 solver.cpp:244]     Train net output #0: loss = 0.0864742 (* 1 = 0.0864742 loss)
I0929 19:31:12.800072 11684 sgd_solver.cpp:106] Iteration 34900, lr = 0.01
I0929 19:31:32.484663 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_35000.caffemodel
I0929 19:31:33.131624 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_35000.solverstate
I0929 19:31:33.527905 11684 solver.cpp:337] Iteration 35000, Testing net (#0)
I0929 19:31:41.893663 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7076
I0929 19:31:41.894163 11684 solver.cpp:404]     Test net output #1: loss = 1.22879 (* 1 = 1.22879 loss)
I0929 19:31:41.944700 11684 solver.cpp:228] Iteration 35000, loss = 0.105807
I0929 19:31:41.944700 11684 solver.cpp:244]     Train net output #0: loss = 0.105808 (* 1 = 0.105808 loss)
I0929 19:31:41.944700 11684 sgd_solver.cpp:106] Iteration 35000, lr = 0.01
I0929 19:32:01.397292 11684 solver.cpp:228] Iteration 35100, loss = 0.161018
I0929 19:32:01.397792 11684 solver.cpp:244]     Train net output #0: loss = 0.161018 (* 1 = 0.161018 loss)
I0929 19:32:01.397792 11684 sgd_solver.cpp:106] Iteration 35100, lr = 0.01
I0929 19:32:20.822144 11684 solver.cpp:228] Iteration 35200, loss = 0.155889
I0929 19:32:20.822144 11684 solver.cpp:244]     Train net output #0: loss = 0.155889 (* 1 = 0.155889 loss)
I0929 19:32:20.822144 11684 sgd_solver.cpp:106] Iteration 35200, lr = 0.01
I0929 19:32:40.225965 11684 solver.cpp:228] Iteration 35300, loss = 0.174695
I0929 19:32:40.225965 11684 solver.cpp:244]     Train net output #0: loss = 0.174695 (* 1 = 0.174695 loss)
I0929 19:32:40.225965 11684 sgd_solver.cpp:106] Iteration 35300, lr = 0.01
I0929 19:33:00.117020 11684 solver.cpp:228] Iteration 35400, loss = 0.105647
I0929 19:33:00.117020 11684 solver.cpp:244]     Train net output #0: loss = 0.105647 (* 1 = 0.105647 loss)
I0929 19:33:00.117020 11684 sgd_solver.cpp:106] Iteration 35400, lr = 0.01
I0929 19:33:19.599021 11684 solver.cpp:228] Iteration 35500, loss = 0.15429
I0929 19:33:19.599021 11684 solver.cpp:244]     Train net output #0: loss = 0.15429 (* 1 = 0.15429 loss)
I0929 19:33:19.599021 11684 sgd_solver.cpp:106] Iteration 35500, lr = 0.01
I0929 19:33:39.019315 11684 solver.cpp:228] Iteration 35600, loss = 0.077071
I0929 19:33:39.019315 11684 solver.cpp:244]     Train net output #0: loss = 0.0770713 (* 1 = 0.0770713 loss)
I0929 19:33:39.019315 11684 sgd_solver.cpp:106] Iteration 35600, lr = 0.01
I0929 19:33:58.836573 11684 solver.cpp:228] Iteration 35700, loss = 0.0672262
I0929 19:33:58.837074 11684 solver.cpp:244]     Train net output #0: loss = 0.0672265 (* 1 = 0.0672265 loss)
I0929 19:33:58.837074 11684 sgd_solver.cpp:106] Iteration 35700, lr = 0.01
I0929 19:34:18.454762 11684 solver.cpp:228] Iteration 35800, loss = 0.0843211
I0929 19:34:18.454762 11684 solver.cpp:244]     Train net output #0: loss = 0.0843214 (* 1 = 0.0843214 loss)
I0929 19:34:18.455262 11684 sgd_solver.cpp:106] Iteration 35800, lr = 0.01
I0929 19:34:38.495666 11684 solver.cpp:228] Iteration 35900, loss = 0.0730255
I0929 19:34:38.495666 11684 solver.cpp:244]     Train net output #0: loss = 0.0730259 (* 1 = 0.0730259 loss)
I0929 19:34:38.495666 11684 sgd_solver.cpp:106] Iteration 35900, lr = 0.01
I0929 19:34:58.491858 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_36000.caffemodel
I0929 19:34:59.128798 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_36000.solverstate
I0929 19:34:59.565106 11684 solver.cpp:337] Iteration 36000, Testing net (#0)
I0929 19:35:07.994879 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7081
I0929 19:35:07.994879 11684 solver.cpp:404]     Test net output #1: loss = 1.21967 (* 1 = 1.21967 loss)
I0929 19:35:08.045413 11684 solver.cpp:228] Iteration 36000, loss = 0.084661
I0929 19:35:08.045413 11684 solver.cpp:244]     Train net output #0: loss = 0.0846614 (* 1 = 0.0846614 loss)
I0929 19:35:08.045413 11684 sgd_solver.cpp:106] Iteration 36000, lr = 0.01
I0929 19:35:27.513628 11684 solver.cpp:228] Iteration 36100, loss = 0.120518
I0929 19:35:27.513628 11684 solver.cpp:244]     Train net output #0: loss = 0.120519 (* 1 = 0.120519 loss)
I0929 19:35:27.513628 11684 sgd_solver.cpp:106] Iteration 36100, lr = 0.01
I0929 19:35:46.931903 11684 solver.cpp:228] Iteration 36200, loss = 0.120542
I0929 19:35:46.932404 11684 solver.cpp:244]     Train net output #0: loss = 0.120543 (* 1 = 0.120543 loss)
I0929 19:35:46.932404 11684 sgd_solver.cpp:106] Iteration 36200, lr = 0.01
I0929 19:36:06.998174 11684 solver.cpp:228] Iteration 36300, loss = 0.173676
I0929 19:36:06.998174 11684 solver.cpp:244]     Train net output #0: loss = 0.173676 (* 1 = 0.173676 loss)
I0929 19:36:06.998675 11684 sgd_solver.cpp:106] Iteration 36300, lr = 0.01
I0929 19:36:26.920748 11684 solver.cpp:228] Iteration 36400, loss = 0.0927838
I0929 19:36:26.920748 11684 solver.cpp:244]     Train net output #0: loss = 0.0927842 (* 1 = 0.0927842 loss)
I0929 19:36:26.920748 11684 sgd_solver.cpp:106] Iteration 36400, lr = 0.01
I0929 19:36:46.235326 11684 solver.cpp:228] Iteration 36500, loss = 0.150761
I0929 19:36:46.235326 11684 solver.cpp:244]     Train net output #0: loss = 0.150761 (* 1 = 0.150761 loss)
I0929 19:36:46.235326 11684 sgd_solver.cpp:106] Iteration 36500, lr = 0.01
I0929 19:37:05.657863 11684 solver.cpp:228] Iteration 36600, loss = 0.0916153
I0929 19:37:05.657863 11684 solver.cpp:244]     Train net output #0: loss = 0.0916156 (* 1 = 0.0916156 loss)
I0929 19:37:05.657863 11684 sgd_solver.cpp:106] Iteration 36600, lr = 0.01
I0929 19:37:24.994730 11684 solver.cpp:228] Iteration 36700, loss = 0.154685
I0929 19:37:24.994730 11684 solver.cpp:244]     Train net output #0: loss = 0.154685 (* 1 = 0.154685 loss)
I0929 19:37:24.994730 11684 sgd_solver.cpp:106] Iteration 36700, lr = 0.01
I0929 19:37:44.402174 11684 solver.cpp:228] Iteration 36800, loss = 0.114723
I0929 19:37:44.402174 11684 solver.cpp:244]     Train net output #0: loss = 0.114723 (* 1 = 0.114723 loss)
I0929 19:37:44.402174 11684 sgd_solver.cpp:106] Iteration 36800, lr = 0.01
I0929 19:38:04.418066 11684 solver.cpp:228] Iteration 36900, loss = 0.143344
I0929 19:38:04.418066 11684 solver.cpp:244]     Train net output #0: loss = 0.143344 (* 1 = 0.143344 loss)
I0929 19:38:04.418066 11684 sgd_solver.cpp:106] Iteration 36900, lr = 0.01
I0929 19:38:23.962452 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_37000.caffemodel
I0929 19:38:24.614416 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_37000.solverstate
I0929 19:38:25.104367 11684 solver.cpp:337] Iteration 37000, Testing net (#0)
I0929 19:38:33.384112 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7101
I0929 19:38:33.385113 11684 solver.cpp:404]     Test net output #1: loss = 1.22647 (* 1 = 1.22647 loss)
I0929 19:38:33.436149 11684 solver.cpp:228] Iteration 37000, loss = 0.131805
I0929 19:38:33.436149 11684 solver.cpp:244]     Train net output #0: loss = 0.131805 (* 1 = 0.131805 loss)
I0929 19:38:33.436149 11684 sgd_solver.cpp:106] Iteration 37000, lr = 0.01
I0929 19:38:52.768934 11684 solver.cpp:228] Iteration 37100, loss = 0.0859429
I0929 19:38:52.768934 11684 solver.cpp:244]     Train net output #0: loss = 0.0859434 (* 1 = 0.0859434 loss)
I0929 19:38:52.768934 11684 sgd_solver.cpp:106] Iteration 37100, lr = 0.01
I0929 19:39:12.258090 11684 solver.cpp:228] Iteration 37200, loss = 0.0592171
I0929 19:39:12.258090 11684 solver.cpp:244]     Train net output #0: loss = 0.0592175 (* 1 = 0.0592175 loss)
I0929 19:39:12.258090 11684 sgd_solver.cpp:106] Iteration 37200, lr = 0.01
I0929 19:39:31.776948 11684 solver.cpp:228] Iteration 37300, loss = 0.168107
I0929 19:39:31.776948 11684 solver.cpp:244]     Train net output #0: loss = 0.168107 (* 1 = 0.168107 loss)
I0929 19:39:31.776948 11684 sgd_solver.cpp:106] Iteration 37300, lr = 0.01
I0929 19:39:51.100569 11684 solver.cpp:228] Iteration 37400, loss = 0.0509631
I0929 19:39:51.100569 11684 solver.cpp:244]     Train net output #0: loss = 0.0509635 (* 1 = 0.0509635 loss)
I0929 19:39:51.100569 11684 sgd_solver.cpp:106] Iteration 37400, lr = 0.01
I0929 19:40:10.680680 11684 solver.cpp:228] Iteration 37500, loss = 0.103744
I0929 19:40:10.680680 11684 solver.cpp:244]     Train net output #0: loss = 0.103745 (* 1 = 0.103745 loss)
I0929 19:40:10.680680 11684 sgd_solver.cpp:106] Iteration 37500, lr = 0.01
I0929 19:40:30.061825 11684 solver.cpp:228] Iteration 37600, loss = 0.0807438
I0929 19:40:30.061825 11684 solver.cpp:244]     Train net output #0: loss = 0.0807443 (* 1 = 0.0807443 loss)
I0929 19:40:30.061825 11684 sgd_solver.cpp:106] Iteration 37600, lr = 0.01
I0929 19:40:49.693584 11684 solver.cpp:228] Iteration 37700, loss = 0.0669281
I0929 19:40:49.693584 11684 solver.cpp:244]     Train net output #0: loss = 0.0669285 (* 1 = 0.0669285 loss)
I0929 19:40:49.693584 11684 sgd_solver.cpp:106] Iteration 37700, lr = 0.01
I0929 19:41:09.101429 11684 solver.cpp:228] Iteration 37800, loss = 0.0769655
I0929 19:41:09.101429 11684 solver.cpp:244]     Train net output #0: loss = 0.0769659 (* 1 = 0.0769659 loss)
I0929 19:41:09.101429 11684 sgd_solver.cpp:106] Iteration 37800, lr = 0.01
I0929 19:41:28.455826 11684 solver.cpp:228] Iteration 37900, loss = 0.0830998
I0929 19:41:28.455826 11684 solver.cpp:244]     Train net output #0: loss = 0.0831003 (* 1 = 0.0831003 loss)
I0929 19:41:28.455826 11684 sgd_solver.cpp:106] Iteration 37900, lr = 0.01
I0929 19:41:47.748783 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_38000.caffemodel
I0929 19:41:48.403261 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_38000.solverstate
I0929 19:41:48.814014 11684 solver.cpp:337] Iteration 38000, Testing net (#0)
I0929 19:41:57.036137 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7099
I0929 19:41:57.036137 11684 solver.cpp:404]     Test net output #1: loss = 1.22647 (* 1 = 1.22647 loss)
I0929 19:41:57.086174 11684 solver.cpp:228] Iteration 38000, loss = 0.0904195
I0929 19:41:57.086174 11684 solver.cpp:244]     Train net output #0: loss = 0.09042 (* 1 = 0.09042 loss)
I0929 19:41:57.086174 11684 sgd_solver.cpp:106] Iteration 38000, lr = 0.01
I0929 19:42:16.384763 11684 solver.cpp:228] Iteration 38100, loss = 0.102525
I0929 19:42:16.384763 11684 solver.cpp:244]     Train net output #0: loss = 0.102525 (* 1 = 0.102525 loss)
I0929 19:42:16.384763 11684 sgd_solver.cpp:106] Iteration 38100, lr = 0.01
I0929 19:42:35.857944 11684 solver.cpp:228] Iteration 38200, loss = 0.07442
I0929 19:42:35.857944 11684 solver.cpp:244]     Train net output #0: loss = 0.0744205 (* 1 = 0.0744205 loss)
I0929 19:42:35.857944 11684 sgd_solver.cpp:106] Iteration 38200, lr = 0.01
I0929 19:42:55.087011 11684 solver.cpp:228] Iteration 38300, loss = 0.126165
I0929 19:42:55.087011 11684 solver.cpp:244]     Train net output #0: loss = 0.126166 (* 1 = 0.126166 loss)
I0929 19:42:55.087011 11684 sgd_solver.cpp:106] Iteration 38300, lr = 0.01
I0929 19:43:14.320919 11684 solver.cpp:228] Iteration 38400, loss = 0.0417573
I0929 19:43:14.320919 11684 solver.cpp:244]     Train net output #0: loss = 0.0417578 (* 1 = 0.0417578 loss)
I0929 19:43:14.320919 11684 sgd_solver.cpp:106] Iteration 38400, lr = 0.01
I0929 19:43:33.548617 11684 solver.cpp:228] Iteration 38500, loss = 0.0511395
I0929 19:43:33.548617 11684 solver.cpp:244]     Train net output #0: loss = 0.05114 (* 1 = 0.05114 loss)
I0929 19:43:33.548617 11684 sgd_solver.cpp:106] Iteration 38500, lr = 0.01
I0929 19:43:52.784895 11684 solver.cpp:228] Iteration 38600, loss = 0.0568753
I0929 19:43:52.784895 11684 solver.cpp:244]     Train net output #0: loss = 0.0568758 (* 1 = 0.0568758 loss)
I0929 19:43:52.784895 11684 sgd_solver.cpp:106] Iteration 38600, lr = 0.01
I0929 19:44:12.047921 11684 solver.cpp:228] Iteration 38700, loss = 0.0830876
I0929 19:44:12.047921 11684 solver.cpp:244]     Train net output #0: loss = 0.0830881 (* 1 = 0.0830881 loss)
I0929 19:44:12.047921 11684 sgd_solver.cpp:106] Iteration 38700, lr = 0.01
I0929 19:44:31.287915 11684 solver.cpp:228] Iteration 38800, loss = 0.0792292
I0929 19:44:31.287915 11684 solver.cpp:244]     Train net output #0: loss = 0.0792297 (* 1 = 0.0792297 loss)
I0929 19:44:31.287915 11684 sgd_solver.cpp:106] Iteration 38800, lr = 0.01
I0929 19:44:50.551587 11684 solver.cpp:228] Iteration 38900, loss = 0.0438554
I0929 19:44:50.551587 11684 solver.cpp:244]     Train net output #0: loss = 0.043856 (* 1 = 0.043856 loss)
I0929 19:44:50.551587 11684 sgd_solver.cpp:106] Iteration 38900, lr = 0.01
I0929 19:45:09.865295 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_39000.caffemodel
I0929 19:45:10.485252 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_39000.solverstate
I0929 19:45:10.840651 11684 solver.cpp:337] Iteration 39000, Testing net (#0)
I0929 19:45:19.060484 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7081
I0929 19:45:19.061486 11684 solver.cpp:404]     Test net output #1: loss = 1.21719 (* 1 = 1.21719 loss)
I0929 19:45:19.111521 11684 solver.cpp:228] Iteration 39000, loss = 0.119518
I0929 19:45:19.111521 11684 solver.cpp:244]     Train net output #0: loss = 0.119518 (* 1 = 0.119518 loss)
I0929 19:45:19.111521 11684 sgd_solver.cpp:106] Iteration 39000, lr = 0.01
I0929 19:45:38.355669 11684 solver.cpp:228] Iteration 39100, loss = 0.0908333
I0929 19:45:38.355669 11684 solver.cpp:244]     Train net output #0: loss = 0.0908338 (* 1 = 0.0908338 loss)
I0929 19:45:38.355669 11684 sgd_solver.cpp:106] Iteration 39100, lr = 0.01
I0929 19:45:57.589061 11684 solver.cpp:228] Iteration 39200, loss = 0.0616165
I0929 19:45:57.590065 11684 solver.cpp:244]     Train net output #0: loss = 0.061617 (* 1 = 0.061617 loss)
I0929 19:45:57.590065 11684 sgd_solver.cpp:106] Iteration 39200, lr = 0.01
I0929 19:46:16.833410 11684 solver.cpp:228] Iteration 39300, loss = 0.163227
I0929 19:46:16.833410 11684 solver.cpp:244]     Train net output #0: loss = 0.163227 (* 1 = 0.163227 loss)
I0929 19:46:16.833410 11684 sgd_solver.cpp:106] Iteration 39300, lr = 0.01
I0929 19:46:36.090318 11684 solver.cpp:228] Iteration 39400, loss = 0.0827772
I0929 19:46:36.090318 11684 solver.cpp:244]     Train net output #0: loss = 0.0827777 (* 1 = 0.0827777 loss)
I0929 19:46:36.090318 11684 sgd_solver.cpp:106] Iteration 39400, lr = 0.01
I0929 19:46:55.328356 11684 solver.cpp:228] Iteration 39500, loss = 0.084677
I0929 19:46:55.328356 11684 solver.cpp:244]     Train net output #0: loss = 0.0846775 (* 1 = 0.0846775 loss)
I0929 19:46:55.328356 11684 sgd_solver.cpp:106] Iteration 39500, lr = 0.01
I0929 19:47:14.558003 11684 solver.cpp:228] Iteration 39600, loss = 0.249751
I0929 19:47:14.558003 11684 solver.cpp:244]     Train net output #0: loss = 0.249751 (* 1 = 0.249751 loss)
I0929 19:47:14.558003 11684 sgd_solver.cpp:106] Iteration 39600, lr = 0.01
I0929 19:47:33.816671 11684 solver.cpp:228] Iteration 39700, loss = 0.112795
I0929 19:47:33.816671 11684 solver.cpp:244]     Train net output #0: loss = 0.112795 (* 1 = 0.112795 loss)
I0929 19:47:33.816671 11684 sgd_solver.cpp:106] Iteration 39700, lr = 0.01
I0929 19:47:53.050771 11684 solver.cpp:228] Iteration 39800, loss = 0.0783372
I0929 19:47:53.050771 11684 solver.cpp:244]     Train net output #0: loss = 0.0783377 (* 1 = 0.0783377 loss)
I0929 19:47:53.050771 11684 sgd_solver.cpp:106] Iteration 39800, lr = 0.01
I0929 19:48:12.281347 11684 solver.cpp:228] Iteration 39900, loss = 0.0465188
I0929 19:48:12.281347 11684 solver.cpp:244]     Train net output #0: loss = 0.0465193 (* 1 = 0.0465193 loss)
I0929 19:48:12.281347 11684 sgd_solver.cpp:106] Iteration 39900, lr = 0.01
I0929 19:48:31.459483 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_40000.caffemodel
I0929 19:48:32.070942 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_40000.solverstate
I0929 19:48:32.436200 11684 solver.cpp:337] Iteration 40000, Testing net (#0)
I0929 19:48:40.628015 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7107
I0929 19:48:40.628015 11684 solver.cpp:404]     Test net output #1: loss = 1.2401 (* 1 = 1.2401 loss)
I0929 19:48:40.678050 11684 solver.cpp:228] Iteration 40000, loss = 0.0811003
I0929 19:48:40.678050 11684 solver.cpp:244]     Train net output #0: loss = 0.0811008 (* 1 = 0.0811008 loss)
I0929 19:48:40.678050 11684 sgd_solver.cpp:106] Iteration 40000, lr = 0.01
I0929 19:48:59.928732 11684 solver.cpp:228] Iteration 40100, loss = 0.207514
I0929 19:48:59.928732 11684 solver.cpp:244]     Train net output #0: loss = 0.207514 (* 1 = 0.207514 loss)
I0929 19:48:59.928732 11684 sgd_solver.cpp:106] Iteration 40100, lr = 0.01
I0929 19:49:19.155550 11684 solver.cpp:228] Iteration 40200, loss = 0.142327
I0929 19:49:19.155550 11684 solver.cpp:244]     Train net output #0: loss = 0.142328 (* 1 = 0.142328 loss)
I0929 19:49:19.155550 11684 sgd_solver.cpp:106] Iteration 40200, lr = 0.01
I0929 19:49:38.400326 11684 solver.cpp:228] Iteration 40300, loss = 0.128137
I0929 19:49:38.400326 11684 solver.cpp:244]     Train net output #0: loss = 0.128137 (* 1 = 0.128137 loss)
I0929 19:49:38.400326 11684 sgd_solver.cpp:106] Iteration 40300, lr = 0.01
I0929 19:49:57.652004 11684 solver.cpp:228] Iteration 40400, loss = 0.0619781
I0929 19:49:57.652004 11684 solver.cpp:244]     Train net output #0: loss = 0.0619785 (* 1 = 0.0619785 loss)
I0929 19:49:57.652004 11684 sgd_solver.cpp:106] Iteration 40400, lr = 0.01
I0929 19:50:16.910336 11684 solver.cpp:228] Iteration 40500, loss = 0.109154
I0929 19:50:16.910336 11684 solver.cpp:244]     Train net output #0: loss = 0.109154 (* 1 = 0.109154 loss)
I0929 19:50:16.910336 11684 sgd_solver.cpp:106] Iteration 40500, lr = 0.01
I0929 19:50:36.130977 11684 solver.cpp:228] Iteration 40600, loss = 0.0483002
I0929 19:50:36.130977 11684 solver.cpp:244]     Train net output #0: loss = 0.0483007 (* 1 = 0.0483007 loss)
I0929 19:50:36.130977 11684 sgd_solver.cpp:106] Iteration 40600, lr = 0.01
I0929 19:50:55.354557 11684 solver.cpp:228] Iteration 40700, loss = 0.0436099
I0929 19:50:55.354557 11684 solver.cpp:244]     Train net output #0: loss = 0.0436104 (* 1 = 0.0436104 loss)
I0929 19:50:55.354557 11684 sgd_solver.cpp:106] Iteration 40700, lr = 0.01
I0929 19:51:14.592211 11684 solver.cpp:228] Iteration 40800, loss = 0.0553001
I0929 19:51:14.592211 11684 solver.cpp:244]     Train net output #0: loss = 0.0553005 (* 1 = 0.0553005 loss)
I0929 19:51:14.592211 11684 sgd_solver.cpp:106] Iteration 40800, lr = 0.01
I0929 19:51:33.812665 11684 solver.cpp:228] Iteration 40900, loss = 0.0747826
I0929 19:51:33.813666 11684 solver.cpp:244]     Train net output #0: loss = 0.0747831 (* 1 = 0.0747831 loss)
I0929 19:51:33.813666 11684 sgd_solver.cpp:106] Iteration 40900, lr = 0.01
I0929 19:51:53.002285 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_41000.caffemodel
I0929 19:51:53.645571 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_41000.solverstate
I0929 19:51:53.992758 11684 solver.cpp:337] Iteration 41000, Testing net (#0)
I0929 19:52:02.184573 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7092
I0929 19:52:02.184573 11684 solver.cpp:404]     Test net output #1: loss = 1.23951 (* 1 = 1.23951 loss)
I0929 19:52:02.235608 11684 solver.cpp:228] Iteration 41000, loss = 0.0935377
I0929 19:52:02.235608 11684 solver.cpp:244]     Train net output #0: loss = 0.0935382 (* 1 = 0.0935382 loss)
I0929 19:52:02.235608 11684 sgd_solver.cpp:106] Iteration 41000, lr = 0.01
I0929 19:52:21.471302 11684 solver.cpp:228] Iteration 41100, loss = 0.04977
I0929 19:52:21.471302 11684 solver.cpp:244]     Train net output #0: loss = 0.0497705 (* 1 = 0.0497705 loss)
I0929 19:52:21.471302 11684 sgd_solver.cpp:106] Iteration 41100, lr = 0.01
I0929 19:52:40.769495 11684 solver.cpp:228] Iteration 41200, loss = 0.0248913
I0929 19:52:40.769495 11684 solver.cpp:244]     Train net output #0: loss = 0.0248918 (* 1 = 0.0248918 loss)
I0929 19:52:40.769495 11684 sgd_solver.cpp:106] Iteration 41200, lr = 0.01
I0929 19:52:59.979346 11684 solver.cpp:228] Iteration 41300, loss = 0.0657855
I0929 19:52:59.979346 11684 solver.cpp:244]     Train net output #0: loss = 0.065786 (* 1 = 0.065786 loss)
I0929 19:52:59.979346 11684 sgd_solver.cpp:106] Iteration 41300, lr = 0.01
I0929 19:53:19.157958 11684 solver.cpp:228] Iteration 41400, loss = 0.0519286
I0929 19:53:19.157958 11684 solver.cpp:244]     Train net output #0: loss = 0.0519291 (* 1 = 0.0519291 loss)
I0929 19:53:19.157958 11684 sgd_solver.cpp:106] Iteration 41400, lr = 0.01
I0929 19:53:38.349200 11684 solver.cpp:228] Iteration 41500, loss = 0.0428032
I0929 19:53:38.349200 11684 solver.cpp:244]     Train net output #0: loss = 0.0428038 (* 1 = 0.0428038 loss)
I0929 19:53:38.349200 11684 sgd_solver.cpp:106] Iteration 41500, lr = 0.01
I0929 19:53:57.542330 11684 solver.cpp:228] Iteration 41600, loss = 0.0477592
I0929 19:53:57.542330 11684 solver.cpp:244]     Train net output #0: loss = 0.0477598 (* 1 = 0.0477598 loss)
I0929 19:53:57.542330 11684 sgd_solver.cpp:106] Iteration 41600, lr = 0.01
I0929 19:54:16.728947 11684 solver.cpp:228] Iteration 41700, loss = 0.0437691
I0929 19:54:16.728947 11684 solver.cpp:244]     Train net output #0: loss = 0.0437696 (* 1 = 0.0437696 loss)
I0929 19:54:16.728947 11684 sgd_solver.cpp:106] Iteration 41700, lr = 0.01
I0929 19:54:35.922157 11684 solver.cpp:228] Iteration 41800, loss = 0.0960279
I0929 19:54:35.922157 11684 solver.cpp:244]     Train net output #0: loss = 0.0960284 (* 1 = 0.0960284 loss)
I0929 19:54:35.922157 11684 sgd_solver.cpp:106] Iteration 41800, lr = 0.01
I0929 19:54:55.107486 11684 solver.cpp:228] Iteration 41900, loss = 0.0808671
I0929 19:54:55.107486 11684 solver.cpp:244]     Train net output #0: loss = 0.0808676 (* 1 = 0.0808676 loss)
I0929 19:54:55.107486 11684 sgd_solver.cpp:106] Iteration 41900, lr = 0.01
I0929 19:55:14.228109 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_42000.caffemodel
I0929 19:55:14.815527 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_42000.solverstate
I0929 19:55:15.159771 11684 solver.cpp:337] Iteration 42000, Testing net (#0)
I0929 19:55:23.356398 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7034
I0929 19:55:23.356398 11684 solver.cpp:404]     Test net output #1: loss = 1.28191 (* 1 = 1.28191 loss)
I0929 19:55:23.406435 11684 solver.cpp:228] Iteration 42000, loss = 0.0240788
I0929 19:55:23.406435 11684 solver.cpp:244]     Train net output #0: loss = 0.0240793 (* 1 = 0.0240793 loss)
I0929 19:55:23.406435 11684 sgd_solver.cpp:106] Iteration 42000, lr = 0.01
I0929 19:55:42.589092 11684 solver.cpp:228] Iteration 42100, loss = 0.09104
I0929 19:55:42.589092 11684 solver.cpp:244]     Train net output #0: loss = 0.0910404 (* 1 = 0.0910404 loss)
I0929 19:55:42.589092 11684 sgd_solver.cpp:106] Iteration 42100, lr = 0.01
I0929 19:56:01.777712 11684 solver.cpp:228] Iteration 42200, loss = 0.0401732
I0929 19:56:01.777712 11684 solver.cpp:244]     Train net output #0: loss = 0.0401737 (* 1 = 0.0401737 loss)
I0929 19:56:01.777712 11684 sgd_solver.cpp:106] Iteration 42200, lr = 0.01
I0929 19:56:20.949744 11684 solver.cpp:228] Iteration 42300, loss = 0.0713637
I0929 19:56:20.949744 11684 solver.cpp:244]     Train net output #0: loss = 0.0713642 (* 1 = 0.0713642 loss)
I0929 19:56:20.949744 11684 sgd_solver.cpp:106] Iteration 42300, lr = 0.01
I0929 19:56:40.123173 11684 solver.cpp:228] Iteration 42400, loss = 0.0710308
I0929 19:56:40.123173 11684 solver.cpp:244]     Train net output #0: loss = 0.0710313 (* 1 = 0.0710313 loss)
I0929 19:56:40.123173 11684 sgd_solver.cpp:106] Iteration 42400, lr = 0.01
I0929 19:56:59.309262 11684 solver.cpp:228] Iteration 42500, loss = 0.0817977
I0929 19:56:59.309262 11684 solver.cpp:244]     Train net output #0: loss = 0.0817982 (* 1 = 0.0817982 loss)
I0929 19:56:59.309262 11684 sgd_solver.cpp:106] Iteration 42500, lr = 0.01
I0929 19:57:18.490164 11684 solver.cpp:228] Iteration 42600, loss = 0.0555892
I0929 19:57:18.491165 11684 solver.cpp:244]     Train net output #0: loss = 0.0555897 (* 1 = 0.0555897 loss)
I0929 19:57:18.491165 11684 sgd_solver.cpp:106] Iteration 42600, lr = 0.01
I0929 19:57:37.651806 11684 solver.cpp:228] Iteration 42700, loss = 0.0791698
I0929 19:57:37.651806 11684 solver.cpp:244]     Train net output #0: loss = 0.0791703 (* 1 = 0.0791703 loss)
I0929 19:57:37.651806 11684 sgd_solver.cpp:106] Iteration 42700, lr = 0.01
I0929 19:57:56.820397 11684 solver.cpp:228] Iteration 42800, loss = 0.0999457
I0929 19:57:56.820397 11684 solver.cpp:244]     Train net output #0: loss = 0.0999463 (* 1 = 0.0999463 loss)
I0929 19:57:56.820397 11684 sgd_solver.cpp:106] Iteration 42800, lr = 0.01
I0929 19:58:15.998008 11684 solver.cpp:228] Iteration 42900, loss = 0.052733
I0929 19:58:15.998008 11684 solver.cpp:244]     Train net output #0: loss = 0.0527335 (* 1 = 0.0527335 loss)
I0929 19:58:15.998008 11684 sgd_solver.cpp:106] Iteration 42900, lr = 0.01
I0929 19:58:35.122328 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_43000.caffemodel
I0929 19:58:35.747648 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_43000.solverstate
I0929 19:58:36.090889 11684 solver.cpp:337] Iteration 43000, Testing net (#0)
I0929 19:58:44.254684 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7071
I0929 19:58:44.254684 11684 solver.cpp:404]     Test net output #1: loss = 1.24059 (* 1 = 1.24059 loss)
I0929 19:58:44.304719 11684 solver.cpp:228] Iteration 43000, loss = 0.042351
I0929 19:58:44.304719 11684 solver.cpp:244]     Train net output #0: loss = 0.0423516 (* 1 = 0.0423516 loss)
I0929 19:58:44.304719 11684 sgd_solver.cpp:106] Iteration 43000, lr = 0.01
I0929 19:59:03.474356 11684 solver.cpp:228] Iteration 43100, loss = 0.111738
I0929 19:59:03.474356 11684 solver.cpp:244]     Train net output #0: loss = 0.111738 (* 1 = 0.111738 loss)
I0929 19:59:03.474356 11684 sgd_solver.cpp:106] Iteration 43100, lr = 0.01
I0929 19:59:23.038131 11684 solver.cpp:228] Iteration 43200, loss = 0.0403716
I0929 19:59:23.038131 11684 solver.cpp:244]     Train net output #0: loss = 0.0403721 (* 1 = 0.0403721 loss)
I0929 19:59:23.038131 11684 sgd_solver.cpp:106] Iteration 43200, lr = 0.01
I0929 19:59:42.292044 11684 solver.cpp:228] Iteration 43300, loss = 0.0922125
I0929 19:59:42.292044 11684 solver.cpp:244]     Train net output #0: loss = 0.0922131 (* 1 = 0.0922131 loss)
I0929 19:59:42.292044 11684 sgd_solver.cpp:106] Iteration 43300, lr = 0.01
I0929 20:00:01.831745 11684 solver.cpp:228] Iteration 43400, loss = 0.0608503
I0929 20:00:01.831745 11684 solver.cpp:244]     Train net output #0: loss = 0.0608508 (* 1 = 0.0608508 loss)
I0929 20:00:01.831745 11684 sgd_solver.cpp:106] Iteration 43400, lr = 0.01
I0929 20:00:21.676223 11684 solver.cpp:228] Iteration 43500, loss = 0.183447
I0929 20:00:21.676223 11684 solver.cpp:244]     Train net output #0: loss = 0.183448 (* 1 = 0.183448 loss)
I0929 20:00:21.676223 11684 sgd_solver.cpp:106] Iteration 43500, lr = 0.01
I0929 20:00:41.591076 11684 solver.cpp:228] Iteration 43600, loss = 0.0790982
I0929 20:00:41.591076 11684 solver.cpp:244]     Train net output #0: loss = 0.0790987 (* 1 = 0.0790987 loss)
I0929 20:00:41.591076 11684 sgd_solver.cpp:106] Iteration 43600, lr = 0.01
I0929 20:01:01.392478 11684 solver.cpp:228] Iteration 43700, loss = 0.0347662
I0929 20:01:01.392979 11684 solver.cpp:244]     Train net output #0: loss = 0.0347666 (* 1 = 0.0347666 loss)
I0929 20:01:01.392979 11684 sgd_solver.cpp:106] Iteration 43700, lr = 0.01
I0929 20:01:21.199514 11684 solver.cpp:228] Iteration 43800, loss = 0.0349677
I0929 20:01:21.199514 11684 solver.cpp:244]     Train net output #0: loss = 0.0349682 (* 1 = 0.0349682 loss)
I0929 20:01:21.199514 11684 sgd_solver.cpp:106] Iteration 43800, lr = 0.01
I0929 20:01:41.010007 11684 solver.cpp:228] Iteration 43900, loss = 0.0802472
I0929 20:01:41.010007 11684 solver.cpp:244]     Train net output #0: loss = 0.0802476 (* 1 = 0.0802476 loss)
I0929 20:01:41.010007 11684 sgd_solver.cpp:106] Iteration 43900, lr = 0.01
I0929 20:02:00.788686 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_44000.caffemodel
I0929 20:02:01.489684 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_44000.solverstate
I0929 20:02:01.924006 11684 solver.cpp:337] Iteration 44000, Testing net (#0)
I0929 20:02:10.418062 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7104
I0929 20:02:10.418062 11684 solver.cpp:404]     Test net output #1: loss = 1.24573 (* 1 = 1.24573 loss)
I0929 20:02:10.470599 11684 solver.cpp:228] Iteration 44000, loss = 0.157391
I0929 20:02:10.470599 11684 solver.cpp:244]     Train net output #0: loss = 0.157391 (* 1 = 0.157391 loss)
I0929 20:02:10.470599 11684 sgd_solver.cpp:106] Iteration 44000, lr = 0.01
I0929 20:02:30.280247 11684 solver.cpp:228] Iteration 44100, loss = 0.0471725
I0929 20:02:30.280247 11684 solver.cpp:244]     Train net output #0: loss = 0.0471729 (* 1 = 0.0471729 loss)
I0929 20:02:30.280247 11684 sgd_solver.cpp:106] Iteration 44100, lr = 0.01
I0929 20:02:50.100245 11684 solver.cpp:228] Iteration 44200, loss = 0.0638402
I0929 20:02:50.100746 11684 solver.cpp:244]     Train net output #0: loss = 0.0638405 (* 1 = 0.0638405 loss)
I0929 20:02:50.100746 11684 sgd_solver.cpp:106] Iteration 44200, lr = 0.01
I0929 20:03:09.930141 11684 solver.cpp:228] Iteration 44300, loss = 0.122148
I0929 20:03:09.930141 11684 solver.cpp:244]     Train net output #0: loss = 0.122149 (* 1 = 0.122149 loss)
I0929 20:03:09.930141 11684 sgd_solver.cpp:106] Iteration 44300, lr = 0.01
I0929 20:03:29.699784 11684 solver.cpp:228] Iteration 44400, loss = 0.0585437
I0929 20:03:29.699784 11684 solver.cpp:244]     Train net output #0: loss = 0.0585441 (* 1 = 0.0585441 loss)
I0929 20:03:29.699784 11684 sgd_solver.cpp:106] Iteration 44400, lr = 0.01
I0929 20:03:49.442836 11684 solver.cpp:228] Iteration 44500, loss = 0.0718647
I0929 20:03:49.443336 11684 solver.cpp:244]     Train net output #0: loss = 0.071865 (* 1 = 0.071865 loss)
I0929 20:03:49.443336 11684 sgd_solver.cpp:106] Iteration 44500, lr = 0.01
I0929 20:04:09.230664 11684 solver.cpp:228] Iteration 44600, loss = 0.0588109
I0929 20:04:09.230664 11684 solver.cpp:244]     Train net output #0: loss = 0.0588112 (* 1 = 0.0588112 loss)
I0929 20:04:09.230664 11684 sgd_solver.cpp:106] Iteration 44600, lr = 0.01
I0929 20:04:29.235153 11684 solver.cpp:228] Iteration 44700, loss = 0.131022
I0929 20:04:29.235153 11684 solver.cpp:244]     Train net output #0: loss = 0.131022 (* 1 = 0.131022 loss)
I0929 20:04:29.235153 11684 sgd_solver.cpp:106] Iteration 44700, lr = 0.01
I0929 20:04:49.138437 11684 solver.cpp:228] Iteration 44800, loss = 0.0814978
I0929 20:04:49.138936 11684 solver.cpp:244]     Train net output #0: loss = 0.0814981 (* 1 = 0.0814981 loss)
I0929 20:04:49.138936 11684 sgd_solver.cpp:106] Iteration 44800, lr = 0.01
I0929 20:05:08.924600 11684 solver.cpp:228] Iteration 44900, loss = 0.0727418
I0929 20:05:08.924600 11684 solver.cpp:244]     Train net output #0: loss = 0.0727422 (* 1 = 0.0727422 loss)
I0929 20:05:08.924600 11684 sgd_solver.cpp:106] Iteration 44900, lr = 0.01
I0929 20:05:29.059311 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_45000.caffemodel
I0929 20:05:29.923082 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_45000.solverstate
I0929 20:05:30.447934 11684 solver.cpp:337] Iteration 45000, Testing net (#0)
I0929 20:05:39.555033 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6981
I0929 20:05:39.555033 11684 solver.cpp:404]     Test net output #1: loss = 1.28634 (* 1 = 1.28634 loss)
I0929 20:05:39.607069 11684 solver.cpp:228] Iteration 45000, loss = 0.0799104
I0929 20:05:39.607570 11684 solver.cpp:244]     Train net output #0: loss = 0.0799108 (* 1 = 0.0799108 loss)
I0929 20:05:39.607570 11684 sgd_solver.cpp:106] Iteration 45000, lr = 0.01
I0929 20:05:59.762423 11684 solver.cpp:228] Iteration 45100, loss = 0.139407
I0929 20:05:59.762423 11684 solver.cpp:244]     Train net output #0: loss = 0.139408 (* 1 = 0.139408 loss)
I0929 20:05:59.762423 11684 sgd_solver.cpp:106] Iteration 45100, lr = 0.01
I0929 20:06:19.863291 11684 solver.cpp:228] Iteration 45200, loss = 0.114507
I0929 20:06:19.863291 11684 solver.cpp:244]     Train net output #0: loss = 0.114508 (* 1 = 0.114508 loss)
I0929 20:06:19.863291 11684 sgd_solver.cpp:106] Iteration 45200, lr = 0.01
I0929 20:06:39.583693 11684 solver.cpp:228] Iteration 45300, loss = 0.0650848
I0929 20:06:39.583693 11684 solver.cpp:244]     Train net output #0: loss = 0.0650853 (* 1 = 0.0650853 loss)
I0929 20:06:39.583693 11684 sgd_solver.cpp:106] Iteration 45300, lr = 0.01
I0929 20:06:59.443850 11684 solver.cpp:228] Iteration 45400, loss = 0.0763366
I0929 20:06:59.443850 11684 solver.cpp:244]     Train net output #0: loss = 0.076337 (* 1 = 0.076337 loss)
I0929 20:06:59.443850 11684 sgd_solver.cpp:106] Iteration 45400, lr = 0.01
I0929 20:07:19.492009 11684 solver.cpp:228] Iteration 45500, loss = 0.120044
I0929 20:07:19.492009 11684 solver.cpp:244]     Train net output #0: loss = 0.120044 (* 1 = 0.120044 loss)
I0929 20:07:19.492009 11684 sgd_solver.cpp:106] Iteration 45500, lr = 0.01
I0929 20:07:39.529132 11684 solver.cpp:228] Iteration 45600, loss = 0.13027
I0929 20:07:39.529132 11684 solver.cpp:244]     Train net output #0: loss = 0.13027 (* 1 = 0.13027 loss)
I0929 20:07:39.529132 11684 sgd_solver.cpp:106] Iteration 45600, lr = 0.01
I0929 20:07:59.701025 11684 solver.cpp:228] Iteration 45700, loss = 0.0941386
I0929 20:07:59.701025 11684 solver.cpp:244]     Train net output #0: loss = 0.094139 (* 1 = 0.094139 loss)
I0929 20:07:59.701025 11684 sgd_solver.cpp:106] Iteration 45700, lr = 0.01
I0929 20:08:19.719928 11684 solver.cpp:228] Iteration 45800, loss = 0.0564004
I0929 20:08:19.719928 11684 solver.cpp:244]     Train net output #0: loss = 0.0564008 (* 1 = 0.0564008 loss)
I0929 20:08:19.719928 11684 sgd_solver.cpp:106] Iteration 45800, lr = 0.01
I0929 20:08:39.558995 11684 solver.cpp:228] Iteration 45900, loss = 0.0651857
I0929 20:08:39.558995 11684 solver.cpp:244]     Train net output #0: loss = 0.0651861 (* 1 = 0.0651861 loss)
I0929 20:08:39.558995 11684 sgd_solver.cpp:106] Iteration 45900, lr = 0.01
I0929 20:08:58.834043 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_46000.caffemodel
I0929 20:08:59.469496 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_46000.solverstate
I0929 20:08:59.823745 11684 solver.cpp:337] Iteration 46000, Testing net (#0)
I0929 20:09:08.041080 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7055
I0929 20:09:08.041080 11684 solver.cpp:404]     Test net output #1: loss = 1.26805 (* 1 = 1.26805 loss)
I0929 20:09:08.091116 11684 solver.cpp:228] Iteration 46000, loss = 0.0494165
I0929 20:09:08.091116 11684 solver.cpp:244]     Train net output #0: loss = 0.049417 (* 1 = 0.049417 loss)
I0929 20:09:08.091116 11684 sgd_solver.cpp:106] Iteration 46000, lr = 0.01
I0929 20:09:27.315762 11684 solver.cpp:228] Iteration 46100, loss = 0.101713
I0929 20:09:27.315762 11684 solver.cpp:244]     Train net output #0: loss = 0.101713 (* 1 = 0.101713 loss)
I0929 20:09:27.315762 11684 sgd_solver.cpp:106] Iteration 46100, lr = 0.01
I0929 20:09:46.548411 11684 solver.cpp:228] Iteration 46200, loss = 0.0766499
I0929 20:09:46.548411 11684 solver.cpp:244]     Train net output #0: loss = 0.0766503 (* 1 = 0.0766503 loss)
I0929 20:09:46.548411 11684 sgd_solver.cpp:106] Iteration 46200, lr = 0.01
I0929 20:10:06.102121 11684 solver.cpp:228] Iteration 46300, loss = 0.0745052
I0929 20:10:06.102121 11684 solver.cpp:244]     Train net output #0: loss = 0.0745056 (* 1 = 0.0745056 loss)
I0929 20:10:06.102121 11684 sgd_solver.cpp:106] Iteration 46300, lr = 0.01
I0929 20:10:25.393373 11684 solver.cpp:228] Iteration 46400, loss = 0.0715508
I0929 20:10:25.393373 11684 solver.cpp:244]     Train net output #0: loss = 0.0715512 (* 1 = 0.0715512 loss)
I0929 20:10:25.393373 11684 sgd_solver.cpp:106] Iteration 46400, lr = 0.01
I0929 20:10:45.169033 11684 solver.cpp:228] Iteration 46500, loss = 0.0657138
I0929 20:10:45.169033 11684 solver.cpp:244]     Train net output #0: loss = 0.0657142 (* 1 = 0.0657142 loss)
I0929 20:10:45.169033 11684 sgd_solver.cpp:106] Iteration 46500, lr = 0.01
I0929 20:11:05.032107 11684 solver.cpp:228] Iteration 46600, loss = 0.0856818
I0929 20:11:05.032107 11684 solver.cpp:244]     Train net output #0: loss = 0.0856822 (* 1 = 0.0856822 loss)
I0929 20:11:05.032107 11684 sgd_solver.cpp:106] Iteration 46600, lr = 0.01
I0929 20:11:24.855481 11684 solver.cpp:228] Iteration 46700, loss = 0.0732107
I0929 20:11:24.855481 11684 solver.cpp:244]     Train net output #0: loss = 0.0732112 (* 1 = 0.0732112 loss)
I0929 20:11:24.855481 11684 sgd_solver.cpp:106] Iteration 46700, lr = 0.01
I0929 20:11:44.874263 11684 solver.cpp:228] Iteration 46800, loss = 0.0671934
I0929 20:11:44.874263 11684 solver.cpp:244]     Train net output #0: loss = 0.0671939 (* 1 = 0.0671939 loss)
I0929 20:11:44.874263 11684 sgd_solver.cpp:106] Iteration 46800, lr = 0.01
I0929 20:12:04.845291 11684 solver.cpp:228] Iteration 46900, loss = 0.0769911
I0929 20:12:04.845291 11684 solver.cpp:244]     Train net output #0: loss = 0.0769916 (* 1 = 0.0769916 loss)
I0929 20:12:04.845291 11684 sgd_solver.cpp:106] Iteration 46900, lr = 0.01
I0929 20:12:24.801403 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_47000.caffemodel
I0929 20:12:25.624488 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_47000.solverstate
I0929 20:12:26.184886 11684 solver.cpp:337] Iteration 47000, Testing net (#0)
I0929 20:12:34.696043 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6976
I0929 20:12:34.696043 11684 solver.cpp:404]     Test net output #1: loss = 1.27963 (* 1 = 1.27963 loss)
I0929 20:12:34.747081 11684 solver.cpp:228] Iteration 47000, loss = 0.0378997
I0929 20:12:34.747081 11684 solver.cpp:244]     Train net output #0: loss = 0.0379001 (* 1 = 0.0379001 loss)
I0929 20:12:34.747081 11684 sgd_solver.cpp:106] Iteration 47000, lr = 0.01
I0929 20:12:54.611402 11684 solver.cpp:228] Iteration 47100, loss = 0.0522533
I0929 20:12:54.612402 11684 solver.cpp:244]     Train net output #0: loss = 0.0522537 (* 1 = 0.0522537 loss)
I0929 20:12:54.612402 11684 sgd_solver.cpp:106] Iteration 47100, lr = 0.01
I0929 20:13:14.401177 11684 solver.cpp:228] Iteration 47200, loss = 0.0408213
I0929 20:13:14.401679 11684 solver.cpp:244]     Train net output #0: loss = 0.0408217 (* 1 = 0.0408217 loss)
I0929 20:13:14.401679 11684 sgd_solver.cpp:106] Iteration 47200, lr = 0.01
I0929 20:13:34.190956 11684 solver.cpp:228] Iteration 47300, loss = 0.045385
I0929 20:13:34.190956 11684 solver.cpp:244]     Train net output #0: loss = 0.0453855 (* 1 = 0.0453855 loss)
I0929 20:13:34.190956 11684 sgd_solver.cpp:106] Iteration 47300, lr = 0.01
I0929 20:13:53.527503 11684 solver.cpp:228] Iteration 47400, loss = 0.076513
I0929 20:13:53.527503 11684 solver.cpp:244]     Train net output #0: loss = 0.0765134 (* 1 = 0.0765134 loss)
I0929 20:13:53.527503 11684 sgd_solver.cpp:106] Iteration 47400, lr = 0.01
I0929 20:14:12.909857 11684 solver.cpp:228] Iteration 47500, loss = 0.0670125
I0929 20:14:12.909857 11684 solver.cpp:244]     Train net output #0: loss = 0.067013 (* 1 = 0.067013 loss)
I0929 20:14:12.909857 11684 sgd_solver.cpp:106] Iteration 47500, lr = 0.01
I0929 20:14:32.204424 11684 solver.cpp:228] Iteration 47600, loss = 0.0479882
I0929 20:14:32.204424 11684 solver.cpp:244]     Train net output #0: loss = 0.0479887 (* 1 = 0.0479887 loss)
I0929 20:14:32.204424 11684 sgd_solver.cpp:106] Iteration 47600, lr = 0.01
I0929 20:14:51.543169 11684 solver.cpp:228] Iteration 47700, loss = 0.055871
I0929 20:14:51.543169 11684 solver.cpp:244]     Train net output #0: loss = 0.0558715 (* 1 = 0.0558715 loss)
I0929 20:14:51.543169 11684 sgd_solver.cpp:106] Iteration 47700, lr = 0.01
I0929 20:15:11.123139 11684 solver.cpp:228] Iteration 47800, loss = 0.046196
I0929 20:15:11.123139 11684 solver.cpp:244]     Train net output #0: loss = 0.0461964 (* 1 = 0.0461964 loss)
I0929 20:15:11.123139 11684 sgd_solver.cpp:106] Iteration 47800, lr = 0.01
I0929 20:15:31.344691 11684 solver.cpp:228] Iteration 47900, loss = 0.0761872
I0929 20:15:31.344691 11684 solver.cpp:244]     Train net output #0: loss = 0.0761877 (* 1 = 0.0761877 loss)
I0929 20:15:31.344691 11684 sgd_solver.cpp:106] Iteration 47900, lr = 0.01
I0929 20:15:50.944380 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_48000.caffemodel
I0929 20:15:51.731942 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_48000.solverstate
I0929 20:15:52.226965 11684 solver.cpp:337] Iteration 48000, Testing net (#0)
I0929 20:16:00.917273 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7002
I0929 20:16:00.917773 11684 solver.cpp:404]     Test net output #1: loss = 1.28877 (* 1 = 1.28877 loss)
I0929 20:16:00.972811 11684 solver.cpp:228] Iteration 48000, loss = 0.0937598
I0929 20:16:00.972811 11684 solver.cpp:244]     Train net output #0: loss = 0.0937603 (* 1 = 0.0937603 loss)
I0929 20:16:00.972811 11684 sgd_solver.cpp:106] Iteration 48000, lr = 0.01
I0929 20:16:20.879612 11684 solver.cpp:228] Iteration 48100, loss = 0.109256
I0929 20:16:20.879612 11684 solver.cpp:244]     Train net output #0: loss = 0.109257 (* 1 = 0.109257 loss)
I0929 20:16:20.879612 11684 sgd_solver.cpp:106] Iteration 48100, lr = 0.01
I0929 20:16:40.685355 11684 solver.cpp:228] Iteration 48200, loss = 0.0439026
I0929 20:16:40.685355 11684 solver.cpp:244]     Train net output #0: loss = 0.0439031 (* 1 = 0.0439031 loss)
I0929 20:16:40.685355 11684 sgd_solver.cpp:106] Iteration 48200, lr = 0.01
I0929 20:17:00.723330 11684 solver.cpp:228] Iteration 48300, loss = 0.0622146
I0929 20:17:00.723330 11684 solver.cpp:244]     Train net output #0: loss = 0.0622151 (* 1 = 0.0622151 loss)
I0929 20:17:00.723330 11684 sgd_solver.cpp:106] Iteration 48300, lr = 0.01
I0929 20:17:20.711398 11684 solver.cpp:228] Iteration 48400, loss = 0.0523115
I0929 20:17:20.711398 11684 solver.cpp:244]     Train net output #0: loss = 0.0523119 (* 1 = 0.0523119 loss)
I0929 20:17:20.711398 11684 sgd_solver.cpp:106] Iteration 48400, lr = 0.01
I0929 20:17:40.608492 11684 solver.cpp:228] Iteration 48500, loss = 0.0714023
I0929 20:17:40.608492 11684 solver.cpp:244]     Train net output #0: loss = 0.0714028 (* 1 = 0.0714028 loss)
I0929 20:17:40.608492 11684 sgd_solver.cpp:106] Iteration 48500, lr = 0.01
I0929 20:18:00.424916 11684 solver.cpp:228] Iteration 48600, loss = 0.0801208
I0929 20:18:00.424916 11684 solver.cpp:244]     Train net output #0: loss = 0.0801213 (* 1 = 0.0801213 loss)
I0929 20:18:00.424916 11684 sgd_solver.cpp:106] Iteration 48600, lr = 0.01
I0929 20:18:20.259702 11684 solver.cpp:228] Iteration 48700, loss = 0.0558007
I0929 20:18:20.259702 11684 solver.cpp:244]     Train net output #0: loss = 0.0558012 (* 1 = 0.0558012 loss)
I0929 20:18:20.259702 11684 sgd_solver.cpp:106] Iteration 48700, lr = 0.01
I0929 20:18:39.844650 11684 solver.cpp:228] Iteration 48800, loss = 0.085329
I0929 20:18:39.844650 11684 solver.cpp:244]     Train net output #0: loss = 0.0853295 (* 1 = 0.0853295 loss)
I0929 20:18:39.844650 11684 sgd_solver.cpp:106] Iteration 48800, lr = 0.01
I0929 20:18:59.237963 11684 solver.cpp:228] Iteration 48900, loss = 0.0576623
I0929 20:18:59.237963 11684 solver.cpp:244]     Train net output #0: loss = 0.0576628 (* 1 = 0.0576628 loss)
I0929 20:18:59.237963 11684 sgd_solver.cpp:106] Iteration 48900, lr = 0.01
I0929 20:19:18.712254 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_49000.caffemodel
I0929 20:19:19.359715 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_49000.solverstate
I0929 20:19:19.718969 11684 solver.cpp:337] Iteration 49000, Testing net (#0)
I0929 20:19:28.295552 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6979
I0929 20:19:28.295552 11684 solver.cpp:404]     Test net output #1: loss = 1.32021 (* 1 = 1.32021 loss)
I0929 20:19:28.346087 11684 solver.cpp:228] Iteration 49000, loss = 0.0782158
I0929 20:19:28.346087 11684 solver.cpp:244]     Train net output #0: loss = 0.0782164 (* 1 = 0.0782164 loss)
I0929 20:19:28.346087 11684 sgd_solver.cpp:106] Iteration 49000, lr = 0.01
I0929 20:19:47.668274 11684 solver.cpp:228] Iteration 49100, loss = 0.123725
I0929 20:19:47.668274 11684 solver.cpp:244]     Train net output #0: loss = 0.123726 (* 1 = 0.123726 loss)
I0929 20:19:47.668274 11684 sgd_solver.cpp:106] Iteration 49100, lr = 0.01
I0929 20:20:06.905740 11684 solver.cpp:228] Iteration 49200, loss = 0.127919
I0929 20:20:06.905740 11684 solver.cpp:244]     Train net output #0: loss = 0.127919 (* 1 = 0.127919 loss)
I0929 20:20:06.905740 11684 sgd_solver.cpp:106] Iteration 49200, lr = 0.01
I0929 20:20:26.166483 11684 solver.cpp:228] Iteration 49300, loss = 0.0957651
I0929 20:20:26.166483 11684 solver.cpp:244]     Train net output #0: loss = 0.0957656 (* 1 = 0.0957656 loss)
I0929 20:20:26.166483 11684 sgd_solver.cpp:106] Iteration 49300, lr = 0.01
I0929 20:20:45.448010 11684 solver.cpp:228] Iteration 49400, loss = 0.044758
I0929 20:20:45.448010 11684 solver.cpp:244]     Train net output #0: loss = 0.0447586 (* 1 = 0.0447586 loss)
I0929 20:20:45.448010 11684 sgd_solver.cpp:106] Iteration 49400, lr = 0.01
I0929 20:21:04.719570 11684 solver.cpp:228] Iteration 49500, loss = 0.0868137
I0929 20:21:04.720072 11684 solver.cpp:244]     Train net output #0: loss = 0.0868142 (* 1 = 0.0868142 loss)
I0929 20:21:04.720072 11684 sgd_solver.cpp:106] Iteration 49500, lr = 0.01
I0929 20:21:24.001783 11684 solver.cpp:228] Iteration 49600, loss = 0.11601
I0929 20:21:24.001783 11684 solver.cpp:244]     Train net output #0: loss = 0.116011 (* 1 = 0.116011 loss)
I0929 20:21:24.001783 11684 sgd_solver.cpp:106] Iteration 49600, lr = 0.01
I0929 20:21:43.280448 11684 solver.cpp:228] Iteration 49700, loss = 0.0452962
I0929 20:21:43.280448 11684 solver.cpp:244]     Train net output #0: loss = 0.0452968 (* 1 = 0.0452968 loss)
I0929 20:21:43.280448 11684 sgd_solver.cpp:106] Iteration 49700, lr = 0.01
I0929 20:22:02.588953 11684 solver.cpp:228] Iteration 49800, loss = 0.197504
I0929 20:22:02.588953 11684 solver.cpp:244]     Train net output #0: loss = 0.197505 (* 1 = 0.197505 loss)
I0929 20:22:02.588953 11684 sgd_solver.cpp:106] Iteration 49800, lr = 0.01
I0929 20:22:21.844682 11684 solver.cpp:228] Iteration 49900, loss = 0.11796
I0929 20:22:21.844682 11684 solver.cpp:244]     Train net output #0: loss = 0.117961 (* 1 = 0.117961 loss)
I0929 20:22:21.844682 11684 sgd_solver.cpp:106] Iteration 49900, lr = 0.01
I0929 20:22:41.083487 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_50000.caffemodel
I0929 20:22:41.697929 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_50000.solverstate
I0929 20:22:42.054671 11684 solver.cpp:337] Iteration 50000, Testing net (#0)
I0929 20:22:50.272735 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6988
I0929 20:22:50.272735 11684 solver.cpp:404]     Test net output #1: loss = 1.28018 (* 1 = 1.28018 loss)
I0929 20:22:50.322772 11684 solver.cpp:228] Iteration 50000, loss = 0.0681034
I0929 20:22:50.322772 11684 solver.cpp:244]     Train net output #0: loss = 0.068104 (* 1 = 0.068104 loss)
I0929 20:22:50.322772 11684 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0929 20:23:09.676870 11684 solver.cpp:228] Iteration 50100, loss = 0.148593
I0929 20:23:09.676870 11684 solver.cpp:244]     Train net output #0: loss = 0.148593 (* 1 = 0.148593 loss)
I0929 20:23:09.676870 11684 sgd_solver.cpp:106] Iteration 50100, lr = 0.01
I0929 20:23:28.990170 11684 solver.cpp:228] Iteration 50200, loss = 0.116614
I0929 20:23:28.990170 11684 solver.cpp:244]     Train net output #0: loss = 0.116615 (* 1 = 0.116615 loss)
I0929 20:23:28.990170 11684 sgd_solver.cpp:106] Iteration 50200, lr = 0.01
I0929 20:23:48.286478 11684 solver.cpp:228] Iteration 50300, loss = 0.14524
I0929 20:23:48.286478 11684 solver.cpp:244]     Train net output #0: loss = 0.145241 (* 1 = 0.145241 loss)
I0929 20:23:48.286478 11684 sgd_solver.cpp:106] Iteration 50300, lr = 0.01
I0929 20:24:07.591171 11684 solver.cpp:228] Iteration 50400, loss = 0.0531163
I0929 20:24:07.591171 11684 solver.cpp:244]     Train net output #0: loss = 0.0531169 (* 1 = 0.0531169 loss)
I0929 20:24:07.591171 11684 sgd_solver.cpp:106] Iteration 50400, lr = 0.01
I0929 20:24:26.900554 11684 solver.cpp:228] Iteration 50500, loss = 0.0885541
I0929 20:24:26.901556 11684 solver.cpp:244]     Train net output #0: loss = 0.0885547 (* 1 = 0.0885547 loss)
I0929 20:24:26.901556 11684 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0929 20:24:46.172575 11684 solver.cpp:228] Iteration 50600, loss = 0.0776053
I0929 20:24:46.172575 11684 solver.cpp:244]     Train net output #0: loss = 0.0776059 (* 1 = 0.0776059 loss)
I0929 20:24:46.172575 11684 sgd_solver.cpp:106] Iteration 50600, lr = 0.01
I0929 20:25:05.441632 11684 solver.cpp:228] Iteration 50700, loss = 0.0655517
I0929 20:25:05.441632 11684 solver.cpp:244]     Train net output #0: loss = 0.0655523 (* 1 = 0.0655523 loss)
I0929 20:25:05.441632 11684 sgd_solver.cpp:106] Iteration 50700, lr = 0.01
I0929 20:25:24.723157 11684 solver.cpp:228] Iteration 50800, loss = 0.0379922
I0929 20:25:24.723157 11684 solver.cpp:244]     Train net output #0: loss = 0.0379928 (* 1 = 0.0379928 loss)
I0929 20:25:24.723157 11684 sgd_solver.cpp:106] Iteration 50800, lr = 0.01
I0929 20:25:44.002274 11684 solver.cpp:228] Iteration 50900, loss = 0.0503933
I0929 20:25:44.002774 11684 solver.cpp:244]     Train net output #0: loss = 0.0503939 (* 1 = 0.0503939 loss)
I0929 20:25:44.002774 11684 sgd_solver.cpp:106] Iteration 50900, lr = 0.01
I0929 20:26:03.213042 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_51000.caffemodel
I0929 20:26:03.810607 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_51000.solverstate
I0929 20:26:04.167078 11684 solver.cpp:337] Iteration 51000, Testing net (#0)
I0929 20:26:12.422837 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7023
I0929 20:26:12.422837 11684 solver.cpp:404]     Test net output #1: loss = 1.28413 (* 1 = 1.28413 loss)
I0929 20:26:12.472872 11684 solver.cpp:228] Iteration 51000, loss = 0.0904738
I0929 20:26:12.472872 11684 solver.cpp:244]     Train net output #0: loss = 0.0904743 (* 1 = 0.0904743 loss)
I0929 20:26:12.472872 11684 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0929 20:26:31.789216 11684 solver.cpp:228] Iteration 51100, loss = 0.102996
I0929 20:26:31.789216 11684 solver.cpp:244]     Train net output #0: loss = 0.102997 (* 1 = 0.102997 loss)
I0929 20:26:31.790217 11684 sgd_solver.cpp:106] Iteration 51100, lr = 0.01
I0929 20:26:51.051060 11684 solver.cpp:228] Iteration 51200, loss = 0.166678
I0929 20:26:51.051060 11684 solver.cpp:244]     Train net output #0: loss = 0.166678 (* 1 = 0.166678 loss)
I0929 20:26:51.051060 11684 sgd_solver.cpp:106] Iteration 51200, lr = 0.01
I0929 20:27:10.286639 11684 solver.cpp:228] Iteration 51300, loss = 0.101831
I0929 20:27:10.286639 11684 solver.cpp:244]     Train net output #0: loss = 0.101832 (* 1 = 0.101832 loss)
I0929 20:27:10.286639 11684 sgd_solver.cpp:106] Iteration 51300, lr = 0.01
I0929 20:27:29.694118 11684 solver.cpp:228] Iteration 51400, loss = 0.065829
I0929 20:27:29.694118 11684 solver.cpp:244]     Train net output #0: loss = 0.0658296 (* 1 = 0.0658296 loss)
I0929 20:27:29.694118 11684 sgd_solver.cpp:106] Iteration 51400, lr = 0.01
I0929 20:27:49.162858 11684 solver.cpp:228] Iteration 51500, loss = 0.0618266
I0929 20:27:49.163858 11684 solver.cpp:244]     Train net output #0: loss = 0.0618272 (* 1 = 0.0618272 loss)
I0929 20:27:49.163858 11684 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0929 20:28:08.581126 11684 solver.cpp:228] Iteration 51600, loss = 0.0675549
I0929 20:28:08.581126 11684 solver.cpp:244]     Train net output #0: loss = 0.0675555 (* 1 = 0.0675555 loss)
I0929 20:28:08.581627 11684 sgd_solver.cpp:106] Iteration 51600, lr = 0.01
I0929 20:28:28.105190 11684 solver.cpp:228] Iteration 51700, loss = 0.127216
I0929 20:28:28.105690 11684 solver.cpp:244]     Train net output #0: loss = 0.127216 (* 1 = 0.127216 loss)
I0929 20:28:28.105690 11684 sgd_solver.cpp:106] Iteration 51700, lr = 0.01
I0929 20:28:47.710664 11684 solver.cpp:228] Iteration 51800, loss = 0.0920254
I0929 20:28:47.710664 11684 solver.cpp:244]     Train net output #0: loss = 0.092026 (* 1 = 0.092026 loss)
I0929 20:28:47.710664 11684 sgd_solver.cpp:106] Iteration 51800, lr = 0.01
I0929 20:29:06.994982 11684 solver.cpp:228] Iteration 51900, loss = 0.084241
I0929 20:29:06.994982 11684 solver.cpp:244]     Train net output #0: loss = 0.0842415 (* 1 = 0.0842415 loss)
I0929 20:29:06.994982 11684 sgd_solver.cpp:106] Iteration 51900, lr = 0.01
I0929 20:29:26.188966 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_52000.caffemodel
I0929 20:29:26.797399 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_52000.solverstate
I0929 20:29:27.159656 11684 solver.cpp:337] Iteration 52000, Testing net (#0)
I0929 20:29:35.354471 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6886
I0929 20:29:35.354471 11684 solver.cpp:404]     Test net output #1: loss = 1.32926 (* 1 = 1.32926 loss)
I0929 20:29:35.404506 11684 solver.cpp:228] Iteration 52000, loss = 0.131181
I0929 20:29:35.404506 11684 solver.cpp:244]     Train net output #0: loss = 0.131182 (* 1 = 0.131182 loss)
I0929 20:29:35.404506 11684 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0929 20:29:54.643162 11684 solver.cpp:228] Iteration 52100, loss = 0.110688
I0929 20:29:54.643162 11684 solver.cpp:244]     Train net output #0: loss = 0.110689 (* 1 = 0.110689 loss)
I0929 20:29:54.643162 11684 sgd_solver.cpp:106] Iteration 52100, lr = 0.01
I0929 20:30:13.863802 11684 solver.cpp:228] Iteration 52200, loss = 0.190314
I0929 20:30:13.863802 11684 solver.cpp:244]     Train net output #0: loss = 0.190314 (* 1 = 0.190314 loss)
I0929 20:30:13.863802 11684 sgd_solver.cpp:106] Iteration 52200, lr = 0.01
I0929 20:30:33.094838 11684 solver.cpp:228] Iteration 52300, loss = 0.119161
I0929 20:30:33.094838 11684 solver.cpp:244]     Train net output #0: loss = 0.119162 (* 1 = 0.119162 loss)
I0929 20:30:33.094838 11684 sgd_solver.cpp:106] Iteration 52300, lr = 0.01
I0929 20:30:52.332464 11684 solver.cpp:228] Iteration 52400, loss = 0.115487
I0929 20:30:52.332464 11684 solver.cpp:244]     Train net output #0: loss = 0.115488 (* 1 = 0.115488 loss)
I0929 20:30:52.332464 11684 sgd_solver.cpp:106] Iteration 52400, lr = 0.01
I0929 20:31:11.554780 11684 solver.cpp:228] Iteration 52500, loss = 0.0674366
I0929 20:31:11.554780 11684 solver.cpp:244]     Train net output #0: loss = 0.0674372 (* 1 = 0.0674372 loss)
I0929 20:31:11.554780 11684 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0929 20:31:30.779412 11684 solver.cpp:228] Iteration 52600, loss = 0.182312
I0929 20:31:30.779412 11684 solver.cpp:244]     Train net output #0: loss = 0.182313 (* 1 = 0.182313 loss)
I0929 20:31:30.779412 11684 sgd_solver.cpp:106] Iteration 52600, lr = 0.01
I0929 20:31:50.004189 11684 solver.cpp:228] Iteration 52700, loss = 0.0509086
I0929 20:31:50.004189 11684 solver.cpp:244]     Train net output #0: loss = 0.0509091 (* 1 = 0.0509091 loss)
I0929 20:31:50.004189 11684 sgd_solver.cpp:106] Iteration 52700, lr = 0.01
I0929 20:32:09.240872 11684 solver.cpp:228] Iteration 52800, loss = 0.145207
I0929 20:32:09.240872 11684 solver.cpp:244]     Train net output #0: loss = 0.145208 (* 1 = 0.145208 loss)
I0929 20:32:09.240872 11684 sgd_solver.cpp:106] Iteration 52800, lr = 0.01
I0929 20:32:28.463515 11684 solver.cpp:228] Iteration 52900, loss = 0.136587
I0929 20:32:28.463515 11684 solver.cpp:244]     Train net output #0: loss = 0.136587 (* 1 = 0.136587 loss)
I0929 20:32:28.463515 11684 sgd_solver.cpp:106] Iteration 52900, lr = 0.01
I0929 20:32:47.656149 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_53000.caffemodel
I0929 20:32:48.275650 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_53000.solverstate
I0929 20:32:48.649915 11684 solver.cpp:337] Iteration 53000, Testing net (#0)
I0929 20:32:56.828521 11684 solver.cpp:404]     Test net output #0: accuracy = 0.69
I0929 20:32:56.828521 11684 solver.cpp:404]     Test net output #1: loss = 1.35254 (* 1 = 1.35254 loss)
I0929 20:32:56.878556 11684 solver.cpp:228] Iteration 53000, loss = 0.0704763
I0929 20:32:56.878556 11684 solver.cpp:244]     Train net output #0: loss = 0.0704769 (* 1 = 0.0704769 loss)
I0929 20:32:56.878556 11684 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0929 20:33:16.117862 11684 solver.cpp:228] Iteration 53100, loss = 0.129649
I0929 20:33:16.117862 11684 solver.cpp:244]     Train net output #0: loss = 0.12965 (* 1 = 0.12965 loss)
I0929 20:33:16.117862 11684 sgd_solver.cpp:106] Iteration 53100, lr = 0.01
I0929 20:33:35.356555 11684 solver.cpp:228] Iteration 53200, loss = 0.0807244
I0929 20:33:35.356555 11684 solver.cpp:244]     Train net output #0: loss = 0.0807251 (* 1 = 0.0807251 loss)
I0929 20:33:35.356555 11684 sgd_solver.cpp:106] Iteration 53200, lr = 0.01
I0929 20:33:54.596465 11684 solver.cpp:228] Iteration 53300, loss = 0.349398
I0929 20:33:54.596465 11684 solver.cpp:244]     Train net output #0: loss = 0.349399 (* 1 = 0.349399 loss)
I0929 20:33:54.597465 11684 sgd_solver.cpp:106] Iteration 53300, lr = 0.01
I0929 20:34:13.824326 11684 solver.cpp:228] Iteration 53400, loss = 0.0769833
I0929 20:34:13.824326 11684 solver.cpp:244]     Train net output #0: loss = 0.076984 (* 1 = 0.076984 loss)
I0929 20:34:13.824326 11684 sgd_solver.cpp:106] Iteration 53400, lr = 0.01
I0929 20:34:33.057039 11684 solver.cpp:228] Iteration 53500, loss = 0.210025
I0929 20:34:33.057039 11684 solver.cpp:244]     Train net output #0: loss = 0.210026 (* 1 = 0.210026 loss)
I0929 20:34:33.057039 11684 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0929 20:34:52.288259 11684 solver.cpp:228] Iteration 53600, loss = 0.129349
I0929 20:34:52.288259 11684 solver.cpp:244]     Train net output #0: loss = 0.12935 (* 1 = 0.12935 loss)
I0929 20:34:52.288259 11684 sgd_solver.cpp:106] Iteration 53600, lr = 0.01
I0929 20:35:11.542965 11684 solver.cpp:228] Iteration 53700, loss = 0.287077
I0929 20:35:11.542965 11684 solver.cpp:244]     Train net output #0: loss = 0.287078 (* 1 = 0.287078 loss)
I0929 20:35:11.542965 11684 sgd_solver.cpp:106] Iteration 53700, lr = 0.01
I0929 20:35:30.785622 11684 solver.cpp:228] Iteration 53800, loss = 0.128167
I0929 20:35:30.785622 11684 solver.cpp:244]     Train net output #0: loss = 0.128168 (* 1 = 0.128168 loss)
I0929 20:35:30.785622 11684 sgd_solver.cpp:106] Iteration 53800, lr = 0.01
I0929 20:35:50.032094 11684 solver.cpp:228] Iteration 53900, loss = 0.0981422
I0929 20:35:50.032094 11684 solver.cpp:244]     Train net output #0: loss = 0.0981429 (* 1 = 0.0981429 loss)
I0929 20:35:50.032094 11684 sgd_solver.cpp:106] Iteration 53900, lr = 0.01
I0929 20:36:09.423347 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_54000.caffemodel
I0929 20:36:10.053727 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_54000.solverstate
I0929 20:36:10.444003 11684 solver.cpp:337] Iteration 54000, Testing net (#0)
I0929 20:36:18.718809 11684 solver.cpp:404]     Test net output #0: accuracy = 0.6904
I0929 20:36:18.718809 11684 solver.cpp:404]     Test net output #1: loss = 1.32991 (* 1 = 1.32991 loss)
I0929 20:36:18.769845 11684 solver.cpp:228] Iteration 54000, loss = 0.10001
I0929 20:36:18.769845 11684 solver.cpp:244]     Train net output #0: loss = 0.100011 (* 1 = 0.100011 loss)
I0929 20:36:18.769845 11684 sgd_solver.cpp:46] MultiStep Status: Iteration 54000, step = 2
I0929 20:36:18.769845 11684 sgd_solver.cpp:106] Iteration 54000, lr = 0.001
I0929 20:36:38.101800 11684 solver.cpp:228] Iteration 54100, loss = 0.0620832
I0929 20:36:38.102301 11684 solver.cpp:244]     Train net output #0: loss = 0.0620839 (* 1 = 0.0620839 loss)
I0929 20:36:38.102301 11684 sgd_solver.cpp:106] Iteration 54100, lr = 0.001
I0929 20:36:57.521600 11684 solver.cpp:228] Iteration 54200, loss = 0.0811233
I0929 20:36:57.521600 11684 solver.cpp:244]     Train net output #0: loss = 0.081124 (* 1 = 0.081124 loss)
I0929 20:36:57.522601 11684 sgd_solver.cpp:106] Iteration 54200, lr = 0.001
I0929 20:37:16.949959 11684 solver.cpp:228] Iteration 54300, loss = 0.0606916
I0929 20:37:16.949959 11684 solver.cpp:244]     Train net output #0: loss = 0.0606923 (* 1 = 0.0606923 loss)
I0929 20:37:16.949959 11684 sgd_solver.cpp:106] Iteration 54300, lr = 0.001
I0929 20:37:36.431949 11684 solver.cpp:228] Iteration 54400, loss = 0.0650928
I0929 20:37:36.431949 11684 solver.cpp:244]     Train net output #0: loss = 0.0650935 (* 1 = 0.0650935 loss)
I0929 20:37:36.431949 11684 sgd_solver.cpp:106] Iteration 54400, lr = 0.001
I0929 20:37:55.925770 11684 solver.cpp:228] Iteration 54500, loss = 0.0959145
I0929 20:37:55.926270 11684 solver.cpp:244]     Train net output #0: loss = 0.0959152 (* 1 = 0.0959152 loss)
I0929 20:37:55.926270 11684 sgd_solver.cpp:106] Iteration 54500, lr = 0.001
I0929 20:38:15.346869 11684 solver.cpp:228] Iteration 54600, loss = 0.0497856
I0929 20:38:15.346869 11684 solver.cpp:244]     Train net output #0: loss = 0.0497863 (* 1 = 0.0497863 loss)
I0929 20:38:15.346869 11684 sgd_solver.cpp:106] Iteration 54600, lr = 0.001
I0929 20:38:34.743433 11684 solver.cpp:228] Iteration 54700, loss = 0.0441872
I0929 20:38:34.743433 11684 solver.cpp:244]     Train net output #0: loss = 0.0441879 (* 1 = 0.0441879 loss)
I0929 20:38:34.743433 11684 sgd_solver.cpp:106] Iteration 54700, lr = 0.001
I0929 20:38:54.271492 11684 solver.cpp:228] Iteration 54800, loss = 0.0487457
I0929 20:38:54.271492 11684 solver.cpp:244]     Train net output #0: loss = 0.0487464 (* 1 = 0.0487464 loss)
I0929 20:38:54.271492 11684 sgd_solver.cpp:106] Iteration 54800, lr = 0.001
I0929 20:39:13.763175 11684 solver.cpp:228] Iteration 54900, loss = 0.0480773
I0929 20:39:13.763175 11684 solver.cpp:244]     Train net output #0: loss = 0.048078 (* 1 = 0.048078 loss)
I0929 20:39:13.763175 11684 sgd_solver.cpp:106] Iteration 54900, lr = 0.001
I0929 20:39:33.089397 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_55000.caffemodel
I0929 20:39:33.692325 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_55000.solverstate
I0929 20:39:34.046577 11684 solver.cpp:337] Iteration 55000, Testing net (#0)
I0929 20:39:42.267879 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7236
I0929 20:39:42.267879 11684 solver.cpp:404]     Test net output #1: loss = 1.14761 (* 1 = 1.14761 loss)
I0929 20:39:42.318914 11684 solver.cpp:228] Iteration 55000, loss = 0.10832
I0929 20:39:42.318914 11684 solver.cpp:244]     Train net output #0: loss = 0.10832 (* 1 = 0.10832 loss)
I0929 20:39:42.318914 11684 sgd_solver.cpp:106] Iteration 55000, lr = 0.001
I0929 20:40:01.712326 11684 solver.cpp:228] Iteration 55100, loss = 0.0198926
I0929 20:40:01.712826 11684 solver.cpp:244]     Train net output #0: loss = 0.0198933 (* 1 = 0.0198933 loss)
I0929 20:40:01.712826 11684 sgd_solver.cpp:106] Iteration 55100, lr = 0.001
I0929 20:40:21.097393 11684 solver.cpp:228] Iteration 55200, loss = 0.0674807
I0929 20:40:21.097393 11684 solver.cpp:244]     Train net output #0: loss = 0.0674814 (* 1 = 0.0674814 loss)
I0929 20:40:21.097393 11684 sgd_solver.cpp:106] Iteration 55200, lr = 0.001
I0929 20:40:40.466135 11684 solver.cpp:228] Iteration 55300, loss = 0.0571296
I0929 20:40:40.466135 11684 solver.cpp:244]     Train net output #0: loss = 0.0571303 (* 1 = 0.0571303 loss)
I0929 20:40:40.466135 11684 sgd_solver.cpp:106] Iteration 55300, lr = 0.001
I0929 20:40:59.946326 11684 solver.cpp:228] Iteration 55400, loss = 0.0504571
I0929 20:40:59.946326 11684 solver.cpp:244]     Train net output #0: loss = 0.0504578 (* 1 = 0.0504578 loss)
I0929 20:40:59.946326 11684 sgd_solver.cpp:106] Iteration 55400, lr = 0.001
I0929 20:41:19.328280 11684 solver.cpp:228] Iteration 55500, loss = 0.0515261
I0929 20:41:19.328280 11684 solver.cpp:244]     Train net output #0: loss = 0.0515268 (* 1 = 0.0515268 loss)
I0929 20:41:19.328280 11684 sgd_solver.cpp:106] Iteration 55500, lr = 0.001
I0929 20:41:38.655114 11684 solver.cpp:228] Iteration 55600, loss = 0.032104
I0929 20:41:38.655114 11684 solver.cpp:244]     Train net output #0: loss = 0.0321047 (* 1 = 0.0321047 loss)
I0929 20:41:38.655114 11684 sgd_solver.cpp:106] Iteration 55600, lr = 0.001
I0929 20:41:58.052270 11684 solver.cpp:228] Iteration 55700, loss = 0.0259721
I0929 20:41:58.052270 11684 solver.cpp:244]     Train net output #0: loss = 0.0259728 (* 1 = 0.0259728 loss)
I0929 20:41:58.052270 11684 sgd_solver.cpp:106] Iteration 55700, lr = 0.001
I0929 20:42:17.390846 11684 solver.cpp:228] Iteration 55800, loss = 0.0279517
I0929 20:42:17.390846 11684 solver.cpp:244]     Train net output #0: loss = 0.0279525 (* 1 = 0.0279525 loss)
I0929 20:42:17.390846 11684 sgd_solver.cpp:106] Iteration 55800, lr = 0.001
I0929 20:42:36.642439 11684 solver.cpp:228] Iteration 55900, loss = 0.0258089
I0929 20:42:36.642439 11684 solver.cpp:244]     Train net output #0: loss = 0.0258096 (* 1 = 0.0258096 loss)
I0929 20:42:36.642439 11684 sgd_solver.cpp:106] Iteration 55900, lr = 0.001
I0929 20:42:55.974896 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_56000.caffemodel
I0929 20:42:56.622040 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_56000.solverstate
I0929 20:42:56.991300 11684 solver.cpp:337] Iteration 56000, Testing net (#0)
I0929 20:43:05.211139 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7276
I0929 20:43:05.211139 11684 solver.cpp:404]     Test net output #1: loss = 1.13261 (* 1 = 1.13261 loss)
I0929 20:43:05.261188 11684 solver.cpp:228] Iteration 56000, loss = 0.0503999
I0929 20:43:05.261188 11684 solver.cpp:244]     Train net output #0: loss = 0.0504006 (* 1 = 0.0504006 loss)
I0929 20:43:05.261188 11684 sgd_solver.cpp:106] Iteration 56000, lr = 0.001
I0929 20:43:24.640763 11684 solver.cpp:228] Iteration 56100, loss = 0.0305533
I0929 20:43:24.640763 11684 solver.cpp:244]     Train net output #0: loss = 0.030554 (* 1 = 0.030554 loss)
I0929 20:43:24.640763 11684 sgd_solver.cpp:106] Iteration 56100, lr = 0.001
I0929 20:43:44.190244 11684 solver.cpp:228] Iteration 56200, loss = 0.0361553
I0929 20:43:44.190244 11684 solver.cpp:244]     Train net output #0: loss = 0.0361561 (* 1 = 0.0361561 loss)
I0929 20:43:44.190244 11684 sgd_solver.cpp:106] Iteration 56200, lr = 0.001
I0929 20:44:03.683100 11684 solver.cpp:228] Iteration 56300, loss = 0.0416968
I0929 20:44:03.683100 11684 solver.cpp:244]     Train net output #0: loss = 0.0416975 (* 1 = 0.0416975 loss)
I0929 20:44:03.683100 11684 sgd_solver.cpp:106] Iteration 56300, lr = 0.001
I0929 20:44:23.217211 11684 solver.cpp:228] Iteration 56400, loss = 0.0204953
I0929 20:44:23.218211 11684 solver.cpp:244]     Train net output #0: loss = 0.020496 (* 1 = 0.020496 loss)
I0929 20:44:23.218211 11684 sgd_solver.cpp:106] Iteration 56400, lr = 0.001
I0929 20:44:42.826154 11684 solver.cpp:228] Iteration 56500, loss = 0.021716
I0929 20:44:42.826154 11684 solver.cpp:244]     Train net output #0: loss = 0.0217167 (* 1 = 0.0217167 loss)
I0929 20:44:42.826154 11684 sgd_solver.cpp:106] Iteration 56500, lr = 0.001
I0929 20:45:02.316120 11684 solver.cpp:228] Iteration 56600, loss = 0.0519527
I0929 20:45:02.316120 11684 solver.cpp:244]     Train net output #0: loss = 0.0519534 (* 1 = 0.0519534 loss)
I0929 20:45:02.316120 11684 sgd_solver.cpp:106] Iteration 56600, lr = 0.001
I0929 20:45:21.835960 11684 solver.cpp:228] Iteration 56700, loss = 0.0280584
I0929 20:45:21.835960 11684 solver.cpp:244]     Train net output #0: loss = 0.028059 (* 1 = 0.028059 loss)
I0929 20:45:21.835960 11684 sgd_solver.cpp:106] Iteration 56700, lr = 0.001
I0929 20:45:41.370712 11684 solver.cpp:228] Iteration 56800, loss = 0.0263232
I0929 20:45:41.370712 11684 solver.cpp:244]     Train net output #0: loss = 0.0263239 (* 1 = 0.0263239 loss)
I0929 20:45:41.370712 11684 sgd_solver.cpp:106] Iteration 56800, lr = 0.001
I0929 20:46:00.826900 11684 solver.cpp:228] Iteration 56900, loss = 0.0156737
I0929 20:46:00.826900 11684 solver.cpp:244]     Train net output #0: loss = 0.0156744 (* 1 = 0.0156744 loss)
I0929 20:46:00.826900 11684 sgd_solver.cpp:106] Iteration 56900, lr = 0.001
I0929 20:46:20.080979 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_57000.caffemodel
I0929 20:46:20.709429 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_57000.solverstate
I0929 20:46:21.075687 11684 solver.cpp:337] Iteration 57000, Testing net (#0)
I0929 20:46:29.507535 11684 solver.cpp:404]     Test net output #0: accuracy = 0.728
I0929 20:46:29.507535 11684 solver.cpp:404]     Test net output #1: loss = 1.13053 (* 1 = 1.13053 loss)
I0929 20:46:29.557570 11684 solver.cpp:228] Iteration 57000, loss = 0.0261152
I0929 20:46:29.557570 11684 solver.cpp:244]     Train net output #0: loss = 0.0261159 (* 1 = 0.0261159 loss)
I0929 20:46:29.557570 11684 sgd_solver.cpp:106] Iteration 57000, lr = 0.001
I0929 20:46:48.996732 11684 solver.cpp:228] Iteration 57100, loss = 0.0276136
I0929 20:46:48.997233 11684 solver.cpp:244]     Train net output #0: loss = 0.0276143 (* 1 = 0.0276143 loss)
I0929 20:46:48.997233 11684 sgd_solver.cpp:106] Iteration 57100, lr = 0.001
I0929 20:47:08.491376 11684 solver.cpp:228] Iteration 57200, loss = 0.0198478
I0929 20:47:08.491376 11684 solver.cpp:244]     Train net output #0: loss = 0.0198485 (* 1 = 0.0198485 loss)
I0929 20:47:08.491376 11684 sgd_solver.cpp:106] Iteration 57200, lr = 0.001
I0929 20:47:27.844563 11684 solver.cpp:228] Iteration 57300, loss = 0.0420228
I0929 20:47:27.844563 11684 solver.cpp:244]     Train net output #0: loss = 0.0420235 (* 1 = 0.0420235 loss)
I0929 20:47:27.844563 11684 sgd_solver.cpp:106] Iteration 57300, lr = 0.001
I0929 20:47:47.147034 11684 solver.cpp:228] Iteration 57400, loss = 0.0140858
I0929 20:47:47.147034 11684 solver.cpp:244]     Train net output #0: loss = 0.0140865 (* 1 = 0.0140865 loss)
I0929 20:47:47.147034 11684 sgd_solver.cpp:106] Iteration 57400, lr = 0.001
I0929 20:48:06.502746 11684 solver.cpp:228] Iteration 57500, loss = 0.0337333
I0929 20:48:06.502746 11684 solver.cpp:244]     Train net output #0: loss = 0.033734 (* 1 = 0.033734 loss)
I0929 20:48:06.502746 11684 sgd_solver.cpp:106] Iteration 57500, lr = 0.001
I0929 20:48:26.004290 11684 solver.cpp:228] Iteration 57600, loss = 0.0290617
I0929 20:48:26.004290 11684 solver.cpp:244]     Train net output #0: loss = 0.0290624 (* 1 = 0.0290624 loss)
I0929 20:48:26.004290 11684 sgd_solver.cpp:106] Iteration 57600, lr = 0.001
I0929 20:48:45.361969 11684 solver.cpp:228] Iteration 57700, loss = 0.0114924
I0929 20:48:45.361969 11684 solver.cpp:244]     Train net output #0: loss = 0.0114931 (* 1 = 0.0114931 loss)
I0929 20:48:45.361969 11684 sgd_solver.cpp:106] Iteration 57700, lr = 0.001
I0929 20:49:04.683720 11684 solver.cpp:228] Iteration 57800, loss = 0.0572904
I0929 20:49:04.683720 11684 solver.cpp:244]     Train net output #0: loss = 0.0572911 (* 1 = 0.0572911 loss)
I0929 20:49:04.683720 11684 sgd_solver.cpp:106] Iteration 57800, lr = 0.001
I0929 20:49:23.985376 11684 solver.cpp:228] Iteration 57900, loss = 0.0267073
I0929 20:49:23.985376 11684 solver.cpp:244]     Train net output #0: loss = 0.026708 (* 1 = 0.026708 loss)
I0929 20:49:23.985376 11684 sgd_solver.cpp:106] Iteration 57900, lr = 0.001
I0929 20:49:43.327693 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_58000.caffemodel
I0929 20:49:43.914110 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_58000.solverstate
I0929 20:49:44.289207 11684 solver.cpp:337] Iteration 58000, Testing net (#0)
I0929 20:49:52.475016 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7304
I0929 20:49:52.475016 11684 solver.cpp:404]     Test net output #1: loss = 1.12096 (* 1 = 1.12096 loss)
I0929 20:49:52.528054 11684 solver.cpp:228] Iteration 58000, loss = 0.0192181
I0929 20:49:52.528054 11684 solver.cpp:244]     Train net output #0: loss = 0.0192188 (* 1 = 0.0192188 loss)
I0929 20:49:52.528054 11684 sgd_solver.cpp:106] Iteration 58000, lr = 0.001
I0929 20:50:11.925686 11684 solver.cpp:228] Iteration 58100, loss = 0.028511
I0929 20:50:11.926687 11684 solver.cpp:244]     Train net output #0: loss = 0.0285117 (* 1 = 0.0285117 loss)
I0929 20:50:11.926687 11684 sgd_solver.cpp:106] Iteration 58100, lr = 0.001
I0929 20:50:31.372575 11684 solver.cpp:228] Iteration 58200, loss = 0.0410655
I0929 20:50:31.372575 11684 solver.cpp:244]     Train net output #0: loss = 0.0410662 (* 1 = 0.0410662 loss)
I0929 20:50:31.372575 11684 sgd_solver.cpp:106] Iteration 58200, lr = 0.001
I0929 20:50:50.682150 11684 solver.cpp:228] Iteration 58300, loss = 0.0358813
I0929 20:50:50.682150 11684 solver.cpp:244]     Train net output #0: loss = 0.035882 (* 1 = 0.035882 loss)
I0929 20:50:50.682150 11684 sgd_solver.cpp:106] Iteration 58300, lr = 0.001
I0929 20:51:10.082613 11684 solver.cpp:228] Iteration 58400, loss = 0.040433
I0929 20:51:10.082613 11684 solver.cpp:244]     Train net output #0: loss = 0.0404337 (* 1 = 0.0404337 loss)
I0929 20:51:10.082613 11684 sgd_solver.cpp:106] Iteration 58400, lr = 0.001
I0929 20:51:29.604681 11684 solver.cpp:228] Iteration 58500, loss = 0.0211755
I0929 20:51:29.605180 11684 solver.cpp:244]     Train net output #0: loss = 0.0211762 (* 1 = 0.0211762 loss)
I0929 20:51:29.605180 11684 sgd_solver.cpp:106] Iteration 58500, lr = 0.001
I0929 20:51:49.120450 11684 solver.cpp:228] Iteration 58600, loss = 0.0182606
I0929 20:51:49.120450 11684 solver.cpp:244]     Train net output #0: loss = 0.0182613 (* 1 = 0.0182613 loss)
I0929 20:51:49.120450 11684 sgd_solver.cpp:106] Iteration 58600, lr = 0.001
I0929 20:52:08.467314 11684 solver.cpp:228] Iteration 58700, loss = 0.0397291
I0929 20:52:08.467314 11684 solver.cpp:244]     Train net output #0: loss = 0.0397297 (* 1 = 0.0397297 loss)
I0929 20:52:08.467314 11684 sgd_solver.cpp:106] Iteration 58700, lr = 0.001
I0929 20:52:27.696949 11684 solver.cpp:228] Iteration 58800, loss = 0.0358676
I0929 20:52:27.696949 11684 solver.cpp:244]     Train net output #0: loss = 0.0358683 (* 1 = 0.0358683 loss)
I0929 20:52:27.696949 11684 sgd_solver.cpp:106] Iteration 58800, lr = 0.001
I0929 20:52:46.950403 11684 solver.cpp:228] Iteration 58900, loss = 0.0169428
I0929 20:52:46.950403 11684 solver.cpp:244]     Train net output #0: loss = 0.0169435 (* 1 = 0.0169435 loss)
I0929 20:52:46.950403 11684 sgd_solver.cpp:106] Iteration 58900, lr = 0.001
I0929 20:53:06.231719 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_59000.caffemodel
I0929 20:53:06.857434 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_59000.solverstate
I0929 20:53:07.214687 11684 solver.cpp:337] Iteration 59000, Testing net (#0)
I0929 20:53:15.463026 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7269
I0929 20:53:15.463526 11684 solver.cpp:404]     Test net output #1: loss = 1.14173 (* 1 = 1.14173 loss)
I0929 20:53:15.513561 11684 solver.cpp:228] Iteration 59000, loss = 0.0173412
I0929 20:53:15.514062 11684 solver.cpp:244]     Train net output #0: loss = 0.0173419 (* 1 = 0.0173419 loss)
I0929 20:53:15.514062 11684 sgd_solver.cpp:106] Iteration 59000, lr = 0.001
I0929 20:53:34.858160 11684 solver.cpp:228] Iteration 59100, loss = 0.0149631
I0929 20:53:34.858160 11684 solver.cpp:244]     Train net output #0: loss = 0.0149638 (* 1 = 0.0149638 loss)
I0929 20:53:34.858160 11684 sgd_solver.cpp:106] Iteration 59100, lr = 0.001
I0929 20:53:54.265451 11684 solver.cpp:228] Iteration 59200, loss = 0.020925
I0929 20:53:54.265451 11684 solver.cpp:244]     Train net output #0: loss = 0.0209257 (* 1 = 0.0209257 loss)
I0929 20:53:54.265451 11684 sgd_solver.cpp:106] Iteration 59200, lr = 0.001
I0929 20:54:14.024760 11684 solver.cpp:228] Iteration 59300, loss = 0.0341617
I0929 20:54:14.024760 11684 solver.cpp:244]     Train net output #0: loss = 0.0341624 (* 1 = 0.0341624 loss)
I0929 20:54:14.024760 11684 sgd_solver.cpp:106] Iteration 59300, lr = 0.001
I0929 20:54:33.948199 11684 solver.cpp:228] Iteration 59400, loss = 0.0178002
I0929 20:54:33.948199 11684 solver.cpp:244]     Train net output #0: loss = 0.0178009 (* 1 = 0.0178009 loss)
I0929 20:54:33.948199 11684 sgd_solver.cpp:106] Iteration 59400, lr = 0.001
I0929 20:54:53.733007 11684 solver.cpp:228] Iteration 59500, loss = 0.013825
I0929 20:54:53.733007 11684 solver.cpp:244]     Train net output #0: loss = 0.0138257 (* 1 = 0.0138257 loss)
I0929 20:54:53.733007 11684 sgd_solver.cpp:106] Iteration 59500, lr = 0.001
I0929 20:55:13.511288 11684 solver.cpp:228] Iteration 59600, loss = 0.0206185
I0929 20:55:13.511787 11684 solver.cpp:244]     Train net output #0: loss = 0.0206192 (* 1 = 0.0206192 loss)
I0929 20:55:13.511787 11684 sgd_solver.cpp:106] Iteration 59600, lr = 0.001
I0929 20:55:33.386914 11684 solver.cpp:228] Iteration 59700, loss = 0.0234408
I0929 20:55:33.386914 11684 solver.cpp:244]     Train net output #0: loss = 0.0234415 (* 1 = 0.0234415 loss)
I0929 20:55:33.386914 11684 sgd_solver.cpp:106] Iteration 59700, lr = 0.001
I0929 20:55:53.206673 11684 solver.cpp:228] Iteration 59800, loss = 0.00877814
I0929 20:55:53.206673 11684 solver.cpp:244]     Train net output #0: loss = 0.00877885 (* 1 = 0.00877885 loss)
I0929 20:55:53.206673 11684 sgd_solver.cpp:106] Iteration 59800, lr = 0.001
I0929 20:56:13.159139 11684 solver.cpp:228] Iteration 59900, loss = 0.0197912
I0929 20:56:13.159139 11684 solver.cpp:244]     Train net output #0: loss = 0.0197919 (* 1 = 0.0197919 loss)
I0929 20:56:13.159139 11684 sgd_solver.cpp:106] Iteration 59900, lr = 0.001
I0929 20:56:32.914440 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_60000.caffemodel
I0929 20:56:33.611938 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_60000.solverstate
I0929 20:56:34.005216 11684 solver.cpp:337] Iteration 60000, Testing net (#0)
I0929 20:56:43.054788 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7317
I0929 20:56:43.054788 11684 solver.cpp:404]     Test net output #1: loss = 1.11746 (* 1 = 1.11746 loss)
I0929 20:56:43.113329 11684 solver.cpp:228] Iteration 60000, loss = 0.0222259
I0929 20:56:43.113329 11684 solver.cpp:244]     Train net output #0: loss = 0.0222266 (* 1 = 0.0222266 loss)
I0929 20:56:43.113329 11684 sgd_solver.cpp:106] Iteration 60000, lr = 0.001
I0929 20:57:03.146347 11684 solver.cpp:228] Iteration 60100, loss = 0.0162663
I0929 20:57:03.146347 11684 solver.cpp:244]     Train net output #0: loss = 0.0162671 (* 1 = 0.0162671 loss)
I0929 20:57:03.146347 11684 sgd_solver.cpp:106] Iteration 60100, lr = 0.001
I0929 20:57:22.948746 11684 solver.cpp:228] Iteration 60200, loss = 0.030566
I0929 20:57:22.948746 11684 solver.cpp:244]     Train net output #0: loss = 0.0305667 (* 1 = 0.0305667 loss)
I0929 20:57:22.948746 11684 sgd_solver.cpp:106] Iteration 60200, lr = 0.001
I0929 20:57:42.737077 11684 solver.cpp:228] Iteration 60300, loss = 0.0341941
I0929 20:57:42.737077 11684 solver.cpp:244]     Train net output #0: loss = 0.0341948 (* 1 = 0.0341948 loss)
I0929 20:57:42.737077 11684 sgd_solver.cpp:106] Iteration 60300, lr = 0.001
I0929 20:58:02.413822 11684 solver.cpp:228] Iteration 60400, loss = 0.0405205
I0929 20:58:02.413822 11684 solver.cpp:244]     Train net output #0: loss = 0.0405212 (* 1 = 0.0405212 loss)
I0929 20:58:02.413822 11684 sgd_solver.cpp:106] Iteration 60400, lr = 0.001
I0929 20:58:21.813792 11684 solver.cpp:228] Iteration 60500, loss = 0.0225904
I0929 20:58:21.813792 11684 solver.cpp:244]     Train net output #0: loss = 0.0225911 (* 1 = 0.0225911 loss)
I0929 20:58:21.813792 11684 sgd_solver.cpp:106] Iteration 60500, lr = 0.001
I0929 20:58:41.395620 11684 solver.cpp:228] Iteration 60600, loss = 0.0164591
I0929 20:58:41.395620 11684 solver.cpp:244]     Train net output #0: loss = 0.0164598 (* 1 = 0.0164598 loss)
I0929 20:58:41.395620 11684 sgd_solver.cpp:106] Iteration 60600, lr = 0.001
I0929 20:59:01.378882 11684 solver.cpp:228] Iteration 60700, loss = 0.0184266
I0929 20:59:01.378882 11684 solver.cpp:244]     Train net output #0: loss = 0.0184273 (* 1 = 0.0184273 loss)
I0929 20:59:01.378882 11684 sgd_solver.cpp:106] Iteration 60700, lr = 0.001
I0929 20:59:21.252795 11684 solver.cpp:228] Iteration 60800, loss = 0.0199936
I0929 20:59:21.252795 11684 solver.cpp:244]     Train net output #0: loss = 0.0199943 (* 1 = 0.0199943 loss)
I0929 20:59:21.252795 11684 sgd_solver.cpp:106] Iteration 60800, lr = 0.001
I0929 20:59:41.023458 11684 solver.cpp:228] Iteration 60900, loss = 0.014529
I0929 20:59:41.023458 11684 solver.cpp:244]     Train net output #0: loss = 0.0145298 (* 1 = 0.0145298 loss)
I0929 20:59:41.023458 11684 sgd_solver.cpp:106] Iteration 60900, lr = 0.001
I0929 21:00:00.814373 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_61000.caffemodel
I0929 21:00:01.627049 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_61000.solverstate
I0929 21:00:02.101387 11684 solver.cpp:337] Iteration 61000, Testing net (#0)
I0929 21:00:10.678513 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7337
I0929 21:00:10.678513 11684 solver.cpp:404]     Test net output #1: loss = 1.12389 (* 1 = 1.12389 loss)
I0929 21:00:10.730548 11684 solver.cpp:228] Iteration 61000, loss = 0.0281002
I0929 21:00:10.730548 11684 solver.cpp:244]     Train net output #0: loss = 0.0281009 (* 1 = 0.0281009 loss)
I0929 21:00:10.730548 11684 sgd_solver.cpp:106] Iteration 61000, lr = 0.001
I0929 21:00:30.699404 11684 solver.cpp:228] Iteration 61100, loss = 0.0194417
I0929 21:00:30.699404 11684 solver.cpp:244]     Train net output #0: loss = 0.0194424 (* 1 = 0.0194424 loss)
I0929 21:00:30.699404 11684 sgd_solver.cpp:106] Iteration 61100, lr = 0.001
I0929 21:00:50.494048 11684 solver.cpp:228] Iteration 61200, loss = 0.0329328
I0929 21:00:50.494048 11684 solver.cpp:244]     Train net output #0: loss = 0.0329335 (* 1 = 0.0329335 loss)
I0929 21:00:50.494048 11684 sgd_solver.cpp:106] Iteration 61200, lr = 0.001
I0929 21:01:10.356447 11684 solver.cpp:228] Iteration 61300, loss = 0.0314923
I0929 21:01:10.356447 11684 solver.cpp:244]     Train net output #0: loss = 0.031493 (* 1 = 0.031493 loss)
I0929 21:01:10.356447 11684 sgd_solver.cpp:106] Iteration 61300, lr = 0.001
I0929 21:01:30.102263 11684 solver.cpp:228] Iteration 61400, loss = 0.0410525
I0929 21:01:30.102263 11684 solver.cpp:244]     Train net output #0: loss = 0.0410533 (* 1 = 0.0410533 loss)
I0929 21:01:30.102763 11684 sgd_solver.cpp:106] Iteration 61400, lr = 0.001
I0929 21:01:49.866550 11684 solver.cpp:228] Iteration 61500, loss = 0.0175384
I0929 21:01:49.866550 11684 solver.cpp:244]     Train net output #0: loss = 0.0175392 (* 1 = 0.0175392 loss)
I0929 21:01:49.866550 11684 sgd_solver.cpp:106] Iteration 61500, lr = 0.001
I0929 21:02:09.667047 11684 solver.cpp:228] Iteration 61600, loss = 0.0160484
I0929 21:02:09.667047 11684 solver.cpp:244]     Train net output #0: loss = 0.0160491 (* 1 = 0.0160491 loss)
I0929 21:02:09.667047 11684 sgd_solver.cpp:106] Iteration 61600, lr = 0.001
I0929 21:02:29.798555 11684 solver.cpp:228] Iteration 61700, loss = 0.0194388
I0929 21:02:29.798555 11684 solver.cpp:244]     Train net output #0: loss = 0.0194396 (* 1 = 0.0194396 loss)
I0929 21:02:29.799055 11684 sgd_solver.cpp:106] Iteration 61700, lr = 0.001
I0929 21:02:49.655493 11684 solver.cpp:228] Iteration 61800, loss = 0.0159607
I0929 21:02:49.655493 11684 solver.cpp:244]     Train net output #0: loss = 0.0159614 (* 1 = 0.0159614 loss)
I0929 21:02:49.655493 11684 sgd_solver.cpp:106] Iteration 61800, lr = 0.001
I0929 21:03:09.436969 11684 solver.cpp:228] Iteration 61900, loss = 0.00977561
I0929 21:03:09.436969 11684 solver.cpp:244]     Train net output #0: loss = 0.00977634 (* 1 = 0.00977634 loss)
I0929 21:03:09.436969 11684 sgd_solver.cpp:106] Iteration 61900, lr = 0.001
I0929 21:03:29.164567 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_62000.caffemodel
I0929 21:03:29.844066 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_62000.solverstate
I0929 21:03:30.251199 11684 solver.cpp:337] Iteration 62000, Testing net (#0)
I0929 21:03:38.750797 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7348
I0929 21:03:38.750797 11684 solver.cpp:404]     Test net output #1: loss = 1.12265 (* 1 = 1.12265 loss)
I0929 21:03:38.802834 11684 solver.cpp:228] Iteration 62000, loss = 0.0125389
I0929 21:03:38.802834 11684 solver.cpp:244]     Train net output #0: loss = 0.0125397 (* 1 = 0.0125397 loss)
I0929 21:03:38.802834 11684 sgd_solver.cpp:106] Iteration 62000, lr = 0.001
I0929 21:03:58.596014 11684 solver.cpp:228] Iteration 62100, loss = 0.0331547
I0929 21:03:58.596514 11684 solver.cpp:244]     Train net output #0: loss = 0.0331554 (* 1 = 0.0331554 loss)
I0929 21:03:58.596514 11684 sgd_solver.cpp:106] Iteration 62100, lr = 0.001
I0929 21:04:18.400629 11684 solver.cpp:228] Iteration 62200, loss = 0.0179813
I0929 21:04:18.400629 11684 solver.cpp:244]     Train net output #0: loss = 0.017982 (* 1 = 0.017982 loss)
I0929 21:04:18.400629 11684 sgd_solver.cpp:106] Iteration 62200, lr = 0.001
I0929 21:04:38.196982 11684 solver.cpp:228] Iteration 62300, loss = 0.0276737
I0929 21:04:38.196982 11684 solver.cpp:244]     Train net output #0: loss = 0.0276744 (* 1 = 0.0276744 loss)
I0929 21:04:38.196982 11684 sgd_solver.cpp:106] Iteration 62300, lr = 0.001
I0929 21:04:57.997618 11684 solver.cpp:228] Iteration 62400, loss = 0.0317751
I0929 21:04:57.997618 11684 solver.cpp:244]     Train net output #0: loss = 0.0317758 (* 1 = 0.0317758 loss)
I0929 21:04:57.997618 11684 sgd_solver.cpp:106] Iteration 62400, lr = 0.001
I0929 21:05:17.789366 11684 solver.cpp:228] Iteration 62500, loss = 0.0189309
I0929 21:05:17.789865 11684 solver.cpp:244]     Train net output #0: loss = 0.0189316 (* 1 = 0.0189316 loss)
I0929 21:05:17.789865 11684 sgd_solver.cpp:106] Iteration 62500, lr = 0.001
I0929 21:05:37.631706 11684 solver.cpp:228] Iteration 62600, loss = 0.0192073
I0929 21:05:37.631706 11684 solver.cpp:244]     Train net output #0: loss = 0.019208 (* 1 = 0.019208 loss)
I0929 21:05:37.631706 11684 sgd_solver.cpp:106] Iteration 62600, lr = 0.001
I0929 21:05:57.484243 11684 solver.cpp:228] Iteration 62700, loss = 0.0216132
I0929 21:05:57.484243 11684 solver.cpp:244]     Train net output #0: loss = 0.0216139 (* 1 = 0.0216139 loss)
I0929 21:05:57.484243 11684 sgd_solver.cpp:106] Iteration 62700, lr = 0.001
I0929 21:06:17.212285 11684 solver.cpp:228] Iteration 62800, loss = 0.018218
I0929 21:06:17.212285 11684 solver.cpp:244]     Train net output #0: loss = 0.0182187 (* 1 = 0.0182187 loss)
I0929 21:06:17.212285 11684 sgd_solver.cpp:106] Iteration 62800, lr = 0.001
I0929 21:06:36.607508 11684 solver.cpp:228] Iteration 62900, loss = 0.017709
I0929 21:06:36.607508 11684 solver.cpp:244]     Train net output #0: loss = 0.0177098 (* 1 = 0.0177098 loss)
I0929 21:06:36.607508 11684 sgd_solver.cpp:106] Iteration 62900, lr = 0.001
I0929 21:06:55.914645 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_63000.caffemodel
I0929 21:06:56.513069 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_63000.solverstate
I0929 21:06:56.872324 11684 solver.cpp:337] Iteration 63000, Testing net (#0)
I0929 21:07:05.054898 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7332
I0929 21:07:05.054898 11684 solver.cpp:404]     Test net output #1: loss = 1.12914 (* 1 = 1.12914 loss)
I0929 21:07:05.106434 11684 solver.cpp:228] Iteration 63000, loss = 0.0189782
I0929 21:07:05.106434 11684 solver.cpp:244]     Train net output #0: loss = 0.0189789 (* 1 = 0.0189789 loss)
I0929 21:07:05.106434 11684 sgd_solver.cpp:106] Iteration 63000, lr = 0.001
I0929 21:07:25.199385 11684 solver.cpp:228] Iteration 63100, loss = 0.0151142
I0929 21:07:25.199385 11684 solver.cpp:244]     Train net output #0: loss = 0.0151149 (* 1 = 0.0151149 loss)
I0929 21:07:25.199385 11684 sgd_solver.cpp:106] Iteration 63100, lr = 0.001
I0929 21:07:45.087426 11684 solver.cpp:228] Iteration 63200, loss = 0.0128843
I0929 21:07:45.087426 11684 solver.cpp:244]     Train net output #0: loss = 0.012885 (* 1 = 0.012885 loss)
I0929 21:07:45.087426 11684 sgd_solver.cpp:106] Iteration 63200, lr = 0.001
I0929 21:08:04.911842 11684 solver.cpp:228] Iteration 63300, loss = 0.0203804
I0929 21:08:04.911842 11684 solver.cpp:244]     Train net output #0: loss = 0.0203811 (* 1 = 0.0203811 loss)
I0929 21:08:04.911842 11684 sgd_solver.cpp:106] Iteration 63300, lr = 0.001
I0929 21:08:24.741468 11684 solver.cpp:228] Iteration 63400, loss = 0.0336318
I0929 21:08:24.741468 11684 solver.cpp:244]     Train net output #0: loss = 0.0336325 (* 1 = 0.0336325 loss)
I0929 21:08:24.741468 11684 sgd_solver.cpp:106] Iteration 63400, lr = 0.001
I0929 21:08:44.618685 11684 solver.cpp:228] Iteration 63500, loss = 0.0161854
I0929 21:08:44.618685 11684 solver.cpp:244]     Train net output #0: loss = 0.0161861 (* 1 = 0.0161861 loss)
I0929 21:08:44.618685 11684 sgd_solver.cpp:106] Iteration 63500, lr = 0.001
I0929 21:09:04.491897 11684 solver.cpp:228] Iteration 63600, loss = 0.0110723
I0929 21:09:04.491897 11684 solver.cpp:244]     Train net output #0: loss = 0.011073 (* 1 = 0.011073 loss)
I0929 21:09:04.491897 11684 sgd_solver.cpp:106] Iteration 63600, lr = 0.001
I0929 21:09:24.345613 11684 solver.cpp:228] Iteration 63700, loss = 0.00925209
I0929 21:09:24.346114 11684 solver.cpp:244]     Train net output #0: loss = 0.00925278 (* 1 = 0.00925278 loss)
I0929 21:09:24.346114 11684 sgd_solver.cpp:106] Iteration 63700, lr = 0.001
I0929 21:09:44.211992 11684 solver.cpp:228] Iteration 63800, loss = 0.0289049
I0929 21:09:44.211992 11684 solver.cpp:244]     Train net output #0: loss = 0.0289056 (* 1 = 0.0289056 loss)
I0929 21:09:44.211992 11684 sgd_solver.cpp:106] Iteration 63800, lr = 0.001
I0929 21:10:04.111747 11684 solver.cpp:228] Iteration 63900, loss = 0.0102673
I0929 21:10:04.111747 11684 solver.cpp:244]     Train net output #0: loss = 0.010268 (* 1 = 0.010268 loss)
I0929 21:10:04.111747 11684 sgd_solver.cpp:106] Iteration 63900, lr = 0.001
I0929 21:10:23.918856 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_64000.caffemodel
I0929 21:10:24.665388 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_64000.solverstate
I0929 21:10:25.103699 11684 solver.cpp:337] Iteration 64000, Testing net (#0)
I0929 21:10:33.955231 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7335
I0929 21:10:33.955231 11684 solver.cpp:404]     Test net output #1: loss = 1.12437 (* 1 = 1.12437 loss)
I0929 21:10:34.012773 11684 solver.cpp:228] Iteration 64000, loss = 0.0184538
I0929 21:10:34.012773 11684 solver.cpp:244]     Train net output #0: loss = 0.0184545 (* 1 = 0.0184545 loss)
I0929 21:10:34.012773 11684 sgd_solver.cpp:106] Iteration 64000, lr = 0.001
I0929 21:10:53.833542 11684 solver.cpp:228] Iteration 64100, loss = 0.0236945
I0929 21:10:53.833542 11684 solver.cpp:244]     Train net output #0: loss = 0.0236952 (* 1 = 0.0236952 loss)
I0929 21:10:53.833542 11684 sgd_solver.cpp:106] Iteration 64100, lr = 0.001
I0929 21:11:13.735930 11684 solver.cpp:228] Iteration 64200, loss = 0.019702
I0929 21:11:13.735930 11684 solver.cpp:244]     Train net output #0: loss = 0.0197027 (* 1 = 0.0197027 loss)
I0929 21:11:13.735930 11684 sgd_solver.cpp:106] Iteration 64200, lr = 0.001
I0929 21:11:33.646543 11684 solver.cpp:228] Iteration 64300, loss = 0.0156146
I0929 21:11:33.647043 11684 solver.cpp:244]     Train net output #0: loss = 0.0156153 (* 1 = 0.0156153 loss)
I0929 21:11:33.647043 11684 sgd_solver.cpp:106] Iteration 64300, lr = 0.001
I0929 21:11:53.460440 11684 solver.cpp:228] Iteration 64400, loss = 0.0162555
I0929 21:11:53.460440 11684 solver.cpp:244]     Train net output #0: loss = 0.0162562 (* 1 = 0.0162562 loss)
I0929 21:11:53.460440 11684 sgd_solver.cpp:106] Iteration 64400, lr = 0.001
I0929 21:12:13.261402 11684 solver.cpp:228] Iteration 64500, loss = 0.012827
I0929 21:12:13.261402 11684 solver.cpp:244]     Train net output #0: loss = 0.0128277 (* 1 = 0.0128277 loss)
I0929 21:12:13.261402 11684 sgd_solver.cpp:106] Iteration 64500, lr = 0.001
I0929 21:12:33.036155 11684 solver.cpp:228] Iteration 64600, loss = 0.0210257
I0929 21:12:33.036655 11684 solver.cpp:244]     Train net output #0: loss = 0.0210263 (* 1 = 0.0210263 loss)
I0929 21:12:33.036655 11684 sgd_solver.cpp:106] Iteration 64600, lr = 0.001
I0929 21:12:52.803828 11684 solver.cpp:228] Iteration 64700, loss = 0.0116846
I0929 21:12:52.803828 11684 solver.cpp:244]     Train net output #0: loss = 0.0116853 (* 1 = 0.0116853 loss)
I0929 21:12:52.803828 11684 sgd_solver.cpp:106] Iteration 64700, lr = 0.001
I0929 21:13:12.608191 11684 solver.cpp:228] Iteration 64800, loss = 0.0200658
I0929 21:13:12.608191 11684 solver.cpp:244]     Train net output #0: loss = 0.0200665 (* 1 = 0.0200665 loss)
I0929 21:13:12.608191 11684 sgd_solver.cpp:106] Iteration 64800, lr = 0.001
I0929 21:13:32.515868 11684 solver.cpp:228] Iteration 64900, loss = 0.0130827
I0929 21:13:32.515868 11684 solver.cpp:244]     Train net output #0: loss = 0.0130834 (* 1 = 0.0130834 loss)
I0929 21:13:32.515868 11684 sgd_solver.cpp:106] Iteration 64900, lr = 0.001
I0929 21:13:52.383254 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_65000.caffemodel
I0929 21:13:53.057734 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_65000.solverstate
I0929 21:13:53.487038 11684 solver.cpp:337] Iteration 65000, Testing net (#0)
I0929 21:14:02.112699 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7341
I0929 21:14:02.112699 11684 solver.cpp:404]     Test net output #1: loss = 1.13329 (* 1 = 1.13329 loss)
I0929 21:14:02.164734 11684 solver.cpp:228] Iteration 65000, loss = 0.0159847
I0929 21:14:02.164734 11684 solver.cpp:244]     Train net output #0: loss = 0.0159854 (* 1 = 0.0159854 loss)
I0929 21:14:02.164734 11684 sgd_solver.cpp:106] Iteration 65000, lr = 0.001
I0929 21:14:21.845053 11684 solver.cpp:228] Iteration 65100, loss = 0.0128996
I0929 21:14:21.845053 11684 solver.cpp:244]     Train net output #0: loss = 0.0129003 (* 1 = 0.0129003 loss)
I0929 21:14:21.845053 11684 sgd_solver.cpp:106] Iteration 65100, lr = 0.001
I0929 21:14:41.638538 11684 solver.cpp:228] Iteration 65200, loss = 0.0155729
I0929 21:14:41.638538 11684 solver.cpp:244]     Train net output #0: loss = 0.0155736 (* 1 = 0.0155736 loss)
I0929 21:14:41.638538 11684 sgd_solver.cpp:106] Iteration 65200, lr = 0.001
I0929 21:15:01.423194 11684 solver.cpp:228] Iteration 65300, loss = 0.0269371
I0929 21:15:01.423194 11684 solver.cpp:244]     Train net output #0: loss = 0.0269378 (* 1 = 0.0269378 loss)
I0929 21:15:01.423194 11684 sgd_solver.cpp:106] Iteration 65300, lr = 0.001
I0929 21:15:21.223374 11684 solver.cpp:228] Iteration 65400, loss = 0.0339717
I0929 21:15:21.223374 11684 solver.cpp:244]     Train net output #0: loss = 0.0339724 (* 1 = 0.0339724 loss)
I0929 21:15:21.223374 11684 sgd_solver.cpp:106] Iteration 65400, lr = 0.001
I0929 21:15:41.009160 11684 solver.cpp:228] Iteration 65500, loss = 0.0194109
I0929 21:15:41.009660 11684 solver.cpp:244]     Train net output #0: loss = 0.0194115 (* 1 = 0.0194115 loss)
I0929 21:15:41.009660 11684 sgd_solver.cpp:106] Iteration 65500, lr = 0.001
I0929 21:16:00.795099 11684 solver.cpp:228] Iteration 65600, loss = 0.0130672
I0929 21:16:00.795099 11684 solver.cpp:244]     Train net output #0: loss = 0.0130679 (* 1 = 0.0130679 loss)
I0929 21:16:00.795099 11684 sgd_solver.cpp:106] Iteration 65600, lr = 0.001
I0929 21:16:20.597582 11684 solver.cpp:228] Iteration 65700, loss = 0.0338671
I0929 21:16:20.597582 11684 solver.cpp:244]     Train net output #0: loss = 0.0338678 (* 1 = 0.0338678 loss)
I0929 21:16:20.597582 11684 sgd_solver.cpp:106] Iteration 65700, lr = 0.001
I0929 21:16:40.387159 11684 solver.cpp:228] Iteration 65800, loss = 0.0132957
I0929 21:16:40.387660 11684 solver.cpp:244]     Train net output #0: loss = 0.0132964 (* 1 = 0.0132964 loss)
I0929 21:16:40.387660 11684 sgd_solver.cpp:106] Iteration 65800, lr = 0.001
I0929 21:17:00.176909 11684 solver.cpp:228] Iteration 65900, loss = 0.0129978
I0929 21:17:00.176909 11684 solver.cpp:244]     Train net output #0: loss = 0.0129985 (* 1 = 0.0129985 loss)
I0929 21:17:00.176909 11684 sgd_solver.cpp:106] Iteration 65900, lr = 0.001
I0929 21:17:19.889791 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_66000.caffemodel
I0929 21:17:20.489217 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_66000.solverstate
I0929 21:17:20.848472 11684 solver.cpp:337] Iteration 66000, Testing net (#0)
I0929 21:17:29.046828 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7343
I0929 21:17:29.046828 11684 solver.cpp:404]     Test net output #1: loss = 1.1144 (* 1 = 1.1144 loss)
I0929 21:17:29.097863 11684 solver.cpp:228] Iteration 66000, loss = 0.0233143
I0929 21:17:29.098865 11684 solver.cpp:244]     Train net output #0: loss = 0.023315 (* 1 = 0.023315 loss)
I0929 21:17:29.098865 11684 sgd_solver.cpp:106] Iteration 66000, lr = 0.001
I0929 21:17:48.664758 11684 solver.cpp:228] Iteration 66100, loss = 0.0256278
I0929 21:17:48.664758 11684 solver.cpp:244]     Train net output #0: loss = 0.0256284 (* 1 = 0.0256284 loss)
I0929 21:17:48.664758 11684 sgd_solver.cpp:106] Iteration 66100, lr = 0.001
I0929 21:18:08.012199 11684 solver.cpp:228] Iteration 66200, loss = 0.00949796
I0929 21:18:08.012199 11684 solver.cpp:244]     Train net output #0: loss = 0.00949864 (* 1 = 0.00949864 loss)
I0929 21:18:08.012199 11684 sgd_solver.cpp:106] Iteration 66200, lr = 0.001
I0929 21:18:27.276505 11684 solver.cpp:228] Iteration 66300, loss = 0.0174604
I0929 21:18:27.276505 11684 solver.cpp:244]     Train net output #0: loss = 0.0174611 (* 1 = 0.0174611 loss)
I0929 21:18:27.276505 11684 sgd_solver.cpp:106] Iteration 66300, lr = 0.001
I0929 21:18:46.498148 11684 solver.cpp:228] Iteration 66400, loss = 0.00838889
I0929 21:18:46.498148 11684 solver.cpp:244]     Train net output #0: loss = 0.00838957 (* 1 = 0.00838957 loss)
I0929 21:18:46.498148 11684 sgd_solver.cpp:106] Iteration 66400, lr = 0.001
I0929 21:19:05.718969 11684 solver.cpp:228] Iteration 66500, loss = 0.0115154
I0929 21:19:05.718969 11684 solver.cpp:244]     Train net output #0: loss = 0.0115161 (* 1 = 0.0115161 loss)
I0929 21:19:05.718969 11684 sgd_solver.cpp:106] Iteration 66500, lr = 0.001
I0929 21:19:24.950193 11684 solver.cpp:228] Iteration 66600, loss = 0.0159114
I0929 21:19:24.950193 11684 solver.cpp:244]     Train net output #0: loss = 0.0159121 (* 1 = 0.0159121 loss)
I0929 21:19:24.950193 11684 sgd_solver.cpp:106] Iteration 66600, lr = 0.001
I0929 21:19:44.182560 11684 solver.cpp:228] Iteration 66700, loss = 0.0160991
I0929 21:19:44.183560 11684 solver.cpp:244]     Train net output #0: loss = 0.0160998 (* 1 = 0.0160998 loss)
I0929 21:19:44.183560 11684 sgd_solver.cpp:106] Iteration 66700, lr = 0.001
I0929 21:20:03.428774 11684 solver.cpp:228] Iteration 66800, loss = 0.0138251
I0929 21:20:03.428774 11684 solver.cpp:244]     Train net output #0: loss = 0.0138258 (* 1 = 0.0138258 loss)
I0929 21:20:03.428774 11684 sgd_solver.cpp:106] Iteration 66800, lr = 0.001
I0929 21:20:22.660424 11684 solver.cpp:228] Iteration 66900, loss = 0.0122099
I0929 21:20:22.660424 11684 solver.cpp:244]     Train net output #0: loss = 0.0122106 (* 1 = 0.0122106 loss)
I0929 21:20:22.660424 11684 sgd_solver.cpp:106] Iteration 66900, lr = 0.001
I0929 21:20:41.835072 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_67000.caffemodel
I0929 21:20:42.463510 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_67000.solverstate
I0929 21:20:42.827769 11684 solver.cpp:337] Iteration 67000, Testing net (#0)
I0929 21:20:51.025475 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7303
I0929 21:20:51.025475 11684 solver.cpp:404]     Test net output #1: loss = 1.12986 (* 1 = 1.12986 loss)
I0929 21:20:51.075511 11684 solver.cpp:228] Iteration 67000, loss = 0.0167246
I0929 21:20:51.075511 11684 solver.cpp:244]     Train net output #0: loss = 0.0167253 (* 1 = 0.0167253 loss)
I0929 21:20:51.075511 11684 sgd_solver.cpp:106] Iteration 67000, lr = 0.001
I0929 21:21:10.312327 11684 solver.cpp:228] Iteration 67100, loss = 0.0114935
I0929 21:21:10.312327 11684 solver.cpp:244]     Train net output #0: loss = 0.0114942 (* 1 = 0.0114942 loss)
I0929 21:21:10.312327 11684 sgd_solver.cpp:106] Iteration 67100, lr = 0.001
I0929 21:21:29.543601 11684 solver.cpp:228] Iteration 67200, loss = 0.0264452
I0929 21:21:29.543601 11684 solver.cpp:244]     Train net output #0: loss = 0.0264458 (* 1 = 0.0264458 loss)
I0929 21:21:29.543601 11684 sgd_solver.cpp:106] Iteration 67200, lr = 0.001
I0929 21:21:48.769975 11684 solver.cpp:228] Iteration 67300, loss = 0.0220037
I0929 21:21:48.769975 11684 solver.cpp:244]     Train net output #0: loss = 0.0220044 (* 1 = 0.0220044 loss)
I0929 21:21:48.769975 11684 sgd_solver.cpp:106] Iteration 67300, lr = 0.001
I0929 21:22:07.985613 11684 solver.cpp:228] Iteration 67400, loss = 0.0108423
I0929 21:22:07.985613 11684 solver.cpp:244]     Train net output #0: loss = 0.010843 (* 1 = 0.010843 loss)
I0929 21:22:07.985613 11684 sgd_solver.cpp:106] Iteration 67400, lr = 0.001
I0929 21:22:27.233778 11684 solver.cpp:228] Iteration 67500, loss = 0.0141955
I0929 21:22:27.233778 11684 solver.cpp:244]     Train net output #0: loss = 0.0141962 (* 1 = 0.0141962 loss)
I0929 21:22:27.233778 11684 sgd_solver.cpp:106] Iteration 67500, lr = 0.001
I0929 21:22:46.461426 11684 solver.cpp:228] Iteration 67600, loss = 0.02451
I0929 21:22:46.461426 11684 solver.cpp:244]     Train net output #0: loss = 0.0245106 (* 1 = 0.0245106 loss)
I0929 21:22:46.461426 11684 sgd_solver.cpp:106] Iteration 67600, lr = 0.001
I0929 21:23:05.696409 11684 solver.cpp:228] Iteration 67700, loss = 0.0152452
I0929 21:23:05.696409 11684 solver.cpp:244]     Train net output #0: loss = 0.0152459 (* 1 = 0.0152459 loss)
I0929 21:23:05.697410 11684 sgd_solver.cpp:106] Iteration 67700, lr = 0.001
I0929 21:23:24.924057 11684 solver.cpp:228] Iteration 67800, loss = 0.0118929
I0929 21:23:24.924057 11684 solver.cpp:244]     Train net output #0: loss = 0.0118936 (* 1 = 0.0118936 loss)
I0929 21:23:24.925057 11684 sgd_solver.cpp:106] Iteration 67800, lr = 0.001
I0929 21:23:44.165324 11684 solver.cpp:228] Iteration 67900, loss = 0.0207226
I0929 21:23:44.165324 11684 solver.cpp:244]     Train net output #0: loss = 0.0207232 (* 1 = 0.0207232 loss)
I0929 21:23:44.165324 11684 sgd_solver.cpp:106] Iteration 67900, lr = 0.001
I0929 21:24:03.347406 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_68000.caffemodel
I0929 21:24:03.938827 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_68000.solverstate
I0929 21:24:04.309089 11684 solver.cpp:337] Iteration 68000, Testing net (#0)
I0929 21:24:12.489462 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7327
I0929 21:24:12.489462 11684 solver.cpp:404]     Test net output #1: loss = 1.11867 (* 1 = 1.11867 loss)
I0929 21:24:12.539497 11684 solver.cpp:228] Iteration 68000, loss = 0.0311741
I0929 21:24:12.539497 11684 solver.cpp:244]     Train net output #0: loss = 0.0311748 (* 1 = 0.0311748 loss)
I0929 21:24:12.539497 11684 sgd_solver.cpp:106] Iteration 68000, lr = 0.001
I0929 21:24:31.780165 11684 solver.cpp:228] Iteration 68100, loss = 0.013692
I0929 21:24:31.780165 11684 solver.cpp:244]     Train net output #0: loss = 0.0136927 (* 1 = 0.0136927 loss)
I0929 21:24:31.780165 11684 sgd_solver.cpp:106] Iteration 68100, lr = 0.001
I0929 21:24:51.016116 11684 solver.cpp:228] Iteration 68200, loss = 0.0125304
I0929 21:24:51.016116 11684 solver.cpp:244]     Train net output #0: loss = 0.0125311 (* 1 = 0.0125311 loss)
I0929 21:24:51.016116 11684 sgd_solver.cpp:106] Iteration 68200, lr = 0.001
I0929 21:25:10.238778 11684 solver.cpp:228] Iteration 68300, loss = 0.0250612
I0929 21:25:10.238778 11684 solver.cpp:244]     Train net output #0: loss = 0.0250618 (* 1 = 0.0250618 loss)
I0929 21:25:10.238778 11684 sgd_solver.cpp:106] Iteration 68300, lr = 0.001
I0929 21:25:29.474604 11684 solver.cpp:228] Iteration 68400, loss = 0.041277
I0929 21:25:29.474604 11684 solver.cpp:244]     Train net output #0: loss = 0.0412776 (* 1 = 0.0412776 loss)
I0929 21:25:29.474604 11684 sgd_solver.cpp:106] Iteration 68400, lr = 0.001
I0929 21:25:48.718044 11684 solver.cpp:228] Iteration 68500, loss = 0.0138126
I0929 21:25:48.718044 11684 solver.cpp:244]     Train net output #0: loss = 0.0138132 (* 1 = 0.0138132 loss)
I0929 21:25:48.718044 11684 sgd_solver.cpp:106] Iteration 68500, lr = 0.001
I0929 21:26:07.940590 11684 solver.cpp:228] Iteration 68600, loss = 0.0104943
I0929 21:26:07.940590 11684 solver.cpp:244]     Train net output #0: loss = 0.010495 (* 1 = 0.010495 loss)
I0929 21:26:07.940590 11684 sgd_solver.cpp:106] Iteration 68600, lr = 0.001
I0929 21:26:27.172611 11684 solver.cpp:228] Iteration 68700, loss = 0.0210127
I0929 21:26:27.172611 11684 solver.cpp:244]     Train net output #0: loss = 0.0210133 (* 1 = 0.0210133 loss)
I0929 21:26:27.172611 11684 sgd_solver.cpp:106] Iteration 68700, lr = 0.001
I0929 21:26:46.408264 11684 solver.cpp:228] Iteration 68800, loss = 0.0295047
I0929 21:26:46.408264 11684 solver.cpp:244]     Train net output #0: loss = 0.0295054 (* 1 = 0.0295054 loss)
I0929 21:26:46.408264 11684 sgd_solver.cpp:106] Iteration 68800, lr = 0.001
I0929 21:27:05.634937 11684 solver.cpp:228] Iteration 68900, loss = 0.0141585
I0929 21:27:05.634937 11684 solver.cpp:244]     Train net output #0: loss = 0.0141591 (* 1 = 0.0141591 loss)
I0929 21:27:05.634937 11684 sgd_solver.cpp:106] Iteration 68900, lr = 0.001
I0929 21:27:24.819605 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_69000.caffemodel
I0929 21:27:25.418031 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_69000.solverstate
I0929 21:27:25.782289 11684 solver.cpp:337] Iteration 69000, Testing net (#0)
I0929 21:27:33.970449 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7345
I0929 21:27:33.970449 11684 solver.cpp:404]     Test net output #1: loss = 1.12657 (* 1 = 1.12657 loss)
I0929 21:27:34.021472 11684 solver.cpp:228] Iteration 69000, loss = 0.0138794
I0929 21:27:34.021472 11684 solver.cpp:244]     Train net output #0: loss = 0.0138801 (* 1 = 0.0138801 loss)
I0929 21:27:34.021472 11684 sgd_solver.cpp:106] Iteration 69000, lr = 0.001
I0929 21:27:53.279155 11684 solver.cpp:228] Iteration 69100, loss = 0.00814085
I0929 21:27:53.279155 11684 solver.cpp:244]     Train net output #0: loss = 0.00814151 (* 1 = 0.00814151 loss)
I0929 21:27:53.279155 11684 sgd_solver.cpp:106] Iteration 69100, lr = 0.001
I0929 21:28:12.564431 11684 solver.cpp:228] Iteration 69200, loss = 0.00859844
I0929 21:28:12.564431 11684 solver.cpp:244]     Train net output #0: loss = 0.0085991 (* 1 = 0.0085991 loss)
I0929 21:28:12.564431 11684 sgd_solver.cpp:106] Iteration 69200, lr = 0.001
I0929 21:28:31.760406 11684 solver.cpp:228] Iteration 69300, loss = 0.00972304
I0929 21:28:31.760406 11684 solver.cpp:244]     Train net output #0: loss = 0.0097237 (* 1 = 0.0097237 loss)
I0929 21:28:31.760406 11684 sgd_solver.cpp:106] Iteration 69300, lr = 0.001
I0929 21:28:50.955018 11684 solver.cpp:228] Iteration 69400, loss = 0.013303
I0929 21:28:50.955018 11684 solver.cpp:244]     Train net output #0: loss = 0.0133037 (* 1 = 0.0133037 loss)
I0929 21:28:50.955018 11684 sgd_solver.cpp:106] Iteration 69400, lr = 0.001
I0929 21:29:10.128221 11684 solver.cpp:228] Iteration 69500, loss = 0.0121266
I0929 21:29:10.128221 11684 solver.cpp:244]     Train net output #0: loss = 0.0121272 (* 1 = 0.0121272 loss)
I0929 21:29:10.128221 11684 sgd_solver.cpp:106] Iteration 69500, lr = 0.001
I0929 21:29:29.308835 11684 solver.cpp:228] Iteration 69600, loss = 0.0492544
I0929 21:29:29.308835 11684 solver.cpp:244]     Train net output #0: loss = 0.049255 (* 1 = 0.049255 loss)
I0929 21:29:29.308835 11684 sgd_solver.cpp:106] Iteration 69600, lr = 0.001
I0929 21:29:48.488447 11684 solver.cpp:228] Iteration 69700, loss = 0.0121102
I0929 21:29:48.488447 11684 solver.cpp:244]     Train net output #0: loss = 0.0121109 (* 1 = 0.0121109 loss)
I0929 21:29:48.488447 11684 sgd_solver.cpp:106] Iteration 69700, lr = 0.001
I0929 21:30:07.668113 11684 solver.cpp:228] Iteration 69800, loss = 0.014617
I0929 21:30:07.668113 11684 solver.cpp:244]     Train net output #0: loss = 0.0146177 (* 1 = 0.0146177 loss)
I0929 21:30:07.668113 11684 sgd_solver.cpp:106] Iteration 69800, lr = 0.001
I0929 21:30:26.844806 11684 solver.cpp:228] Iteration 69900, loss = 0.0106239
I0929 21:30:26.844806 11684 solver.cpp:244]     Train net output #0: loss = 0.0106245 (* 1 = 0.0106245 loss)
I0929 21:30:26.844806 11684 sgd_solver.cpp:106] Iteration 69900, lr = 0.001
I0929 21:30:45.992454 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_70000.caffemodel
I0929 21:30:46.587877 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_70000.solverstate
I0929 21:30:46.949132 11684 solver.cpp:337] Iteration 70000, Testing net (#0)
I0929 21:30:55.126549 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7359
I0929 21:30:55.126549 11684 solver.cpp:404]     Test net output #1: loss = 1.11345 (* 1 = 1.11345 loss)
I0929 21:30:55.184590 11684 solver.cpp:228] Iteration 70000, loss = 0.0143504
I0929 21:30:55.184590 11684 solver.cpp:244]     Train net output #0: loss = 0.0143511 (* 1 = 0.0143511 loss)
I0929 21:30:55.184590 11684 sgd_solver.cpp:106] Iteration 70000, lr = 0.001
I0929 21:31:14.369915 11684 solver.cpp:228] Iteration 70100, loss = 0.0177978
I0929 21:31:14.369915 11684 solver.cpp:244]     Train net output #0: loss = 0.0177985 (* 1 = 0.0177985 loss)
I0929 21:31:14.369915 11684 sgd_solver.cpp:106] Iteration 70100, lr = 0.001
I0929 21:31:33.553014 11684 solver.cpp:228] Iteration 70200, loss = 0.0106729
I0929 21:31:33.553014 11684 solver.cpp:244]     Train net output #0: loss = 0.0106735 (* 1 = 0.0106735 loss)
I0929 21:31:33.553014 11684 sgd_solver.cpp:106] Iteration 70200, lr = 0.001
I0929 21:31:52.747288 11684 solver.cpp:228] Iteration 70300, loss = 0.0135496
I0929 21:31:52.747288 11684 solver.cpp:244]     Train net output #0: loss = 0.0135502 (* 1 = 0.0135502 loss)
I0929 21:31:52.747288 11684 sgd_solver.cpp:106] Iteration 70300, lr = 0.001
I0929 21:32:11.931934 11684 solver.cpp:228] Iteration 70400, loss = 0.0171534
I0929 21:32:11.931934 11684 solver.cpp:244]     Train net output #0: loss = 0.0171541 (* 1 = 0.0171541 loss)
I0929 21:32:11.931934 11684 sgd_solver.cpp:106] Iteration 70400, lr = 0.001
I0929 21:32:31.129559 11684 solver.cpp:228] Iteration 70500, loss = 0.00880463
I0929 21:32:31.129559 11684 solver.cpp:244]     Train net output #0: loss = 0.00880531 (* 1 = 0.00880531 loss)
I0929 21:32:31.129559 11684 sgd_solver.cpp:106] Iteration 70500, lr = 0.001
I0929 21:32:50.303498 11684 solver.cpp:228] Iteration 70600, loss = 0.0231399
I0929 21:32:50.303498 11684 solver.cpp:244]     Train net output #0: loss = 0.0231405 (* 1 = 0.0231405 loss)
I0929 21:32:50.303498 11684 sgd_solver.cpp:106] Iteration 70600, lr = 0.001
I0929 21:33:09.492116 11684 solver.cpp:228] Iteration 70700, loss = 0.00995129
I0929 21:33:09.492116 11684 solver.cpp:244]     Train net output #0: loss = 0.00995197 (* 1 = 0.00995197 loss)
I0929 21:33:09.492116 11684 sgd_solver.cpp:106] Iteration 70700, lr = 0.001
I0929 21:33:28.662545 11684 solver.cpp:228] Iteration 70800, loss = 0.0162127
I0929 21:33:28.662545 11684 solver.cpp:244]     Train net output #0: loss = 0.0162133 (* 1 = 0.0162133 loss)
I0929 21:33:28.662545 11684 sgd_solver.cpp:106] Iteration 70800, lr = 0.001
I0929 21:33:47.847162 11684 solver.cpp:228] Iteration 70900, loss = 0.0232955
I0929 21:33:47.847162 11684 solver.cpp:244]     Train net output #0: loss = 0.0232962 (* 1 = 0.0232962 loss)
I0929 21:33:47.847162 11684 sgd_solver.cpp:106] Iteration 70900, lr = 0.001
I0929 21:34:06.971592 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_71000.caffemodel
I0929 21:34:07.565014 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_71000.solverstate
I0929 21:34:07.931274 11684 solver.cpp:337] Iteration 71000, Testing net (#0)
I0929 21:34:16.102072 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7351
I0929 21:34:16.102072 11684 solver.cpp:404]     Test net output #1: loss = 1.12421 (* 1 = 1.12421 loss)
I0929 21:34:16.151108 11684 solver.cpp:228] Iteration 71000, loss = 0.0123194
I0929 21:34:16.151108 11684 solver.cpp:244]     Train net output #0: loss = 0.0123201 (* 1 = 0.0123201 loss)
I0929 21:34:16.151108 11684 sgd_solver.cpp:106] Iteration 71000, lr = 0.001
I0929 21:34:35.321213 11684 solver.cpp:228] Iteration 71100, loss = 0.0161395
I0929 21:34:35.321213 11684 solver.cpp:244]     Train net output #0: loss = 0.0161402 (* 1 = 0.0161402 loss)
I0929 21:34:35.321213 11684 sgd_solver.cpp:106] Iteration 71100, lr = 0.001
I0929 21:34:54.492820 11684 solver.cpp:228] Iteration 71200, loss = 0.0103468
I0929 21:34:54.492820 11684 solver.cpp:244]     Train net output #0: loss = 0.0103474 (* 1 = 0.0103474 loss)
I0929 21:34:54.492820 11684 sgd_solver.cpp:106] Iteration 71200, lr = 0.001
I0929 21:35:13.665199 11684 solver.cpp:228] Iteration 71300, loss = 0.0144751
I0929 21:35:13.665199 11684 solver.cpp:244]     Train net output #0: loss = 0.0144758 (* 1 = 0.0144758 loss)
I0929 21:35:13.665199 11684 sgd_solver.cpp:106] Iteration 71300, lr = 0.001
I0929 21:35:32.839807 11684 solver.cpp:228] Iteration 71400, loss = 0.0212144
I0929 21:35:32.839807 11684 solver.cpp:244]     Train net output #0: loss = 0.0212151 (* 1 = 0.0212151 loss)
I0929 21:35:32.839807 11684 sgd_solver.cpp:106] Iteration 71400, lr = 0.001
I0929 21:35:52.017189 11684 solver.cpp:228] Iteration 71500, loss = 0.0419422
I0929 21:35:52.017189 11684 solver.cpp:244]     Train net output #0: loss = 0.0419429 (* 1 = 0.0419429 loss)
I0929 21:35:52.017189 11684 sgd_solver.cpp:106] Iteration 71500, lr = 0.001
I0929 21:36:11.189795 11684 solver.cpp:228] Iteration 71600, loss = 0.0106572
I0929 21:36:11.189795 11684 solver.cpp:244]     Train net output #0: loss = 0.0106578 (* 1 = 0.0106578 loss)
I0929 21:36:11.189795 11684 sgd_solver.cpp:106] Iteration 71600, lr = 0.001
I0929 21:36:30.370409 11684 solver.cpp:228] Iteration 71700, loss = 0.0100141
I0929 21:36:30.370409 11684 solver.cpp:244]     Train net output #0: loss = 0.0100148 (* 1 = 0.0100148 loss)
I0929 21:36:30.370409 11684 sgd_solver.cpp:106] Iteration 71700, lr = 0.001
I0929 21:36:49.544018 11684 solver.cpp:228] Iteration 71800, loss = 0.0104687
I0929 21:36:49.544018 11684 solver.cpp:244]     Train net output #0: loss = 0.0104694 (* 1 = 0.0104694 loss)
I0929 21:36:49.544018 11684 sgd_solver.cpp:106] Iteration 71800, lr = 0.001
I0929 21:37:08.720834 11684 solver.cpp:228] Iteration 71900, loss = 0.0155048
I0929 21:37:08.721834 11684 solver.cpp:244]     Train net output #0: loss = 0.0155055 (* 1 = 0.0155055 loss)
I0929 21:37:08.721834 11684 sgd_solver.cpp:106] Iteration 71900, lr = 0.001
I0929 21:37:27.867422 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_72000.caffemodel
I0929 21:37:28.518885 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_72000.solverstate
I0929 21:37:28.897153 11684 solver.cpp:337] Iteration 72000, Testing net (#0)
I0929 21:37:37.312330 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7346
I0929 21:37:37.312330 11684 solver.cpp:404]     Test net output #1: loss = 1.1117 (* 1 = 1.1117 loss)
I0929 21:37:37.362365 11684 solver.cpp:228] Iteration 72000, loss = 0.0092183
I0929 21:37:37.362365 11684 solver.cpp:244]     Train net output #0: loss = 0.00921897 (* 1 = 0.00921897 loss)
I0929 21:37:37.362365 11684 sgd_solver.cpp:106] Iteration 72000, lr = 0.001
I0929 21:37:56.822182 11684 solver.cpp:228] Iteration 72100, loss = 0.00915791
I0929 21:37:56.822182 11684 solver.cpp:244]     Train net output #0: loss = 0.00915858 (* 1 = 0.00915858 loss)
I0929 21:37:56.822182 11684 sgd_solver.cpp:106] Iteration 72100, lr = 0.001
I0929 21:38:16.171439 11684 solver.cpp:228] Iteration 72200, loss = 0.00852962
I0929 21:38:16.171439 11684 solver.cpp:244]     Train net output #0: loss = 0.00853028 (* 1 = 0.00853028 loss)
I0929 21:38:16.171439 11684 sgd_solver.cpp:106] Iteration 72200, lr = 0.001
I0929 21:38:35.466493 11684 solver.cpp:228] Iteration 72300, loss = 0.0129653
I0929 21:38:35.466995 11684 solver.cpp:244]     Train net output #0: loss = 0.012966 (* 1 = 0.012966 loss)
I0929 21:38:35.466995 11684 sgd_solver.cpp:106] Iteration 72300, lr = 0.001
I0929 21:38:54.905050 11684 solver.cpp:228] Iteration 72400, loss = 0.0129667
I0929 21:38:54.905050 11684 solver.cpp:244]     Train net output #0: loss = 0.0129673 (* 1 = 0.0129673 loss)
I0929 21:38:54.905050 11684 sgd_solver.cpp:106] Iteration 72400, lr = 0.001
I0929 21:39:14.309389 11684 solver.cpp:228] Iteration 72500, loss = 0.0154942
I0929 21:39:14.309389 11684 solver.cpp:244]     Train net output #0: loss = 0.0154949 (* 1 = 0.0154949 loss)
I0929 21:39:14.309389 11684 sgd_solver.cpp:106] Iteration 72500, lr = 0.001
I0929 21:39:33.555125 11684 solver.cpp:228] Iteration 72600, loss = 0.00973226
I0929 21:39:33.555125 11684 solver.cpp:244]     Train net output #0: loss = 0.00973293 (* 1 = 0.00973293 loss)
I0929 21:39:33.555125 11684 sgd_solver.cpp:106] Iteration 72600, lr = 0.001
I0929 21:39:52.818506 11684 solver.cpp:228] Iteration 72700, loss = 0.0226717
I0929 21:39:52.818506 11684 solver.cpp:244]     Train net output #0: loss = 0.0226723 (* 1 = 0.0226723 loss)
I0929 21:39:52.818506 11684 sgd_solver.cpp:106] Iteration 72700, lr = 0.001
I0929 21:40:12.080356 11684 solver.cpp:228] Iteration 72800, loss = 0.0149474
I0929 21:40:12.080356 11684 solver.cpp:244]     Train net output #0: loss = 0.014948 (* 1 = 0.014948 loss)
I0929 21:40:12.080356 11684 sgd_solver.cpp:106] Iteration 72800, lr = 0.001
I0929 21:40:31.319692 11684 solver.cpp:228] Iteration 72900, loss = 0.00982236
I0929 21:40:31.319692 11684 solver.cpp:244]     Train net output #0: loss = 0.00982303 (* 1 = 0.00982303 loss)
I0929 21:40:31.319692 11684 sgd_solver.cpp:106] Iteration 72900, lr = 0.001
I0929 21:40:50.541220 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_73000.caffemodel
I0929 21:40:51.150653 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_73000.solverstate
I0929 21:40:51.532924 11684 solver.cpp:337] Iteration 73000, Testing net (#0)
I0929 21:40:59.733119 11684 solver.cpp:404]     Test net output #0: accuracy = 0.733
I0929 21:40:59.733119 11684 solver.cpp:404]     Test net output #1: loss = 1.10943 (* 1 = 1.10943 loss)
I0929 21:40:59.784155 11684 solver.cpp:228] Iteration 73000, loss = 0.0466757
I0929 21:40:59.784155 11684 solver.cpp:244]     Train net output #0: loss = 0.0466763 (* 1 = 0.0466763 loss)
I0929 21:40:59.784155 11684 sgd_solver.cpp:106] Iteration 73000, lr = 0.001
I0929 21:41:19.063946 11684 solver.cpp:228] Iteration 73100, loss = 0.0103067
I0929 21:41:19.063946 11684 solver.cpp:244]     Train net output #0: loss = 0.0103074 (* 1 = 0.0103074 loss)
I0929 21:41:19.063946 11684 sgd_solver.cpp:106] Iteration 73100, lr = 0.001
I0929 21:41:38.352620 11684 solver.cpp:228] Iteration 73200, loss = 0.0350122
I0929 21:41:38.352620 11684 solver.cpp:244]     Train net output #0: loss = 0.0350128 (* 1 = 0.0350128 loss)
I0929 21:41:38.352620 11684 sgd_solver.cpp:106] Iteration 73200, lr = 0.001
I0929 21:41:57.781136 11684 solver.cpp:228] Iteration 73300, loss = 0.0147507
I0929 21:41:57.781136 11684 solver.cpp:244]     Train net output #0: loss = 0.0147513 (* 1 = 0.0147513 loss)
I0929 21:41:57.781136 11684 sgd_solver.cpp:106] Iteration 73300, lr = 0.001
I0929 21:42:17.198667 11684 solver.cpp:228] Iteration 73400, loss = 0.00991081
I0929 21:42:17.198667 11684 solver.cpp:244]     Train net output #0: loss = 0.00991147 (* 1 = 0.00991147 loss)
I0929 21:42:17.198667 11684 sgd_solver.cpp:106] Iteration 73400, lr = 0.001
I0929 21:42:36.440966 11684 solver.cpp:228] Iteration 73500, loss = 0.017664
I0929 21:42:36.440966 11684 solver.cpp:244]     Train net output #0: loss = 0.0176647 (* 1 = 0.0176647 loss)
I0929 21:42:36.440966 11684 sgd_solver.cpp:106] Iteration 73500, lr = 0.001
I0929 21:42:55.685874 11684 solver.cpp:228] Iteration 73600, loss = 0.0189715
I0929 21:42:55.685874 11684 solver.cpp:244]     Train net output #0: loss = 0.0189722 (* 1 = 0.0189722 loss)
I0929 21:42:55.685874 11684 sgd_solver.cpp:106] Iteration 73600, lr = 0.001
I0929 21:43:14.916517 11684 solver.cpp:228] Iteration 73700, loss = 0.011904
I0929 21:43:14.916517 11684 solver.cpp:244]     Train net output #0: loss = 0.0119047 (* 1 = 0.0119047 loss)
I0929 21:43:14.916517 11684 sgd_solver.cpp:106] Iteration 73700, lr = 0.001
I0929 21:43:34.142189 11684 solver.cpp:228] Iteration 73800, loss = 0.0103723
I0929 21:43:34.142189 11684 solver.cpp:244]     Train net output #0: loss = 0.010373 (* 1 = 0.010373 loss)
I0929 21:43:34.142189 11684 sgd_solver.cpp:106] Iteration 73800, lr = 0.001
I0929 21:43:53.384845 11684 solver.cpp:228] Iteration 73900, loss = 0.0235408
I0929 21:43:53.384845 11684 solver.cpp:244]     Train net output #0: loss = 0.0235415 (* 1 = 0.0235415 loss)
I0929 21:43:53.384845 11684 sgd_solver.cpp:106] Iteration 73900, lr = 0.001
I0929 21:44:12.635717 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_74000.caffemodel
I0929 21:44:13.241163 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_74000.solverstate
I0929 21:44:13.606353 11684 solver.cpp:337] Iteration 74000, Testing net (#0)
I0929 21:44:21.794452 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7353
I0929 21:44:21.794452 11684 solver.cpp:404]     Test net output #1: loss = 1.11045 (* 1 = 1.11045 loss)
I0929 21:44:21.844487 11684 solver.cpp:228] Iteration 74000, loss = 0.0174001
I0929 21:44:21.844487 11684 solver.cpp:244]     Train net output #0: loss = 0.0174008 (* 1 = 0.0174008 loss)
I0929 21:44:21.844487 11684 sgd_solver.cpp:106] Iteration 74000, lr = 0.001
I0929 21:44:41.098157 11684 solver.cpp:228] Iteration 74100, loss = 0.020563
I0929 21:44:41.098157 11684 solver.cpp:244]     Train net output #0: loss = 0.0205637 (* 1 = 0.0205637 loss)
I0929 21:44:41.098157 11684 sgd_solver.cpp:106] Iteration 74100, lr = 0.001
I0929 21:45:00.433933 11684 solver.cpp:228] Iteration 74200, loss = 0.00983696
I0929 21:45:00.433933 11684 solver.cpp:244]     Train net output #0: loss = 0.00983762 (* 1 = 0.00983762 loss)
I0929 21:45:00.433933 11684 sgd_solver.cpp:106] Iteration 74200, lr = 0.001
I0929 21:45:19.755837 11684 solver.cpp:228] Iteration 74300, loss = 0.0153118
I0929 21:45:19.755837 11684 solver.cpp:244]     Train net output #0: loss = 0.0153125 (* 1 = 0.0153125 loss)
I0929 21:45:19.755837 11684 sgd_solver.cpp:106] Iteration 74300, lr = 0.001
I0929 21:45:39.973816 11684 solver.cpp:228] Iteration 74400, loss = 0.0110921
I0929 21:45:39.973816 11684 solver.cpp:244]     Train net output #0: loss = 0.0110928 (* 1 = 0.0110928 loss)
I0929 21:45:39.973816 11684 sgd_solver.cpp:106] Iteration 74400, lr = 0.001
I0929 21:45:59.942101 11684 solver.cpp:228] Iteration 74500, loss = 0.0112769
I0929 21:45:59.942101 11684 solver.cpp:244]     Train net output #0: loss = 0.0112776 (* 1 = 0.0112776 loss)
I0929 21:45:59.942101 11684 sgd_solver.cpp:106] Iteration 74500, lr = 0.001
I0929 21:46:19.898789 11684 solver.cpp:228] Iteration 74600, loss = 0.0165257
I0929 21:46:19.898789 11684 solver.cpp:244]     Train net output #0: loss = 0.0165263 (* 1 = 0.0165263 loss)
I0929 21:46:19.898789 11684 sgd_solver.cpp:106] Iteration 74600, lr = 0.001
I0929 21:46:39.914705 11684 solver.cpp:228] Iteration 74700, loss = 0.0110302
I0929 21:46:39.914705 11684 solver.cpp:244]     Train net output #0: loss = 0.0110309 (* 1 = 0.0110309 loss)
I0929 21:46:39.914705 11684 sgd_solver.cpp:106] Iteration 74700, lr = 0.001
I0929 21:46:59.886667 11684 solver.cpp:228] Iteration 74800, loss = 0.00997835
I0929 21:46:59.886667 11684 solver.cpp:244]     Train net output #0: loss = 0.00997901 (* 1 = 0.00997901 loss)
I0929 21:46:59.886667 11684 sgd_solver.cpp:106] Iteration 74800, lr = 0.001
I0929 21:47:19.820178 11684 solver.cpp:228] Iteration 74900, loss = 0.00850704
I0929 21:47:19.820677 11684 solver.cpp:244]     Train net output #0: loss = 0.0085077 (* 1 = 0.0085077 loss)
I0929 21:47:19.820677 11684 sgd_solver.cpp:106] Iteration 74900, lr = 0.001
I0929 21:47:39.643018 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_75000.caffemodel
I0929 21:47:40.296697 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_75000.solverstate
I0929 21:47:40.691977 11684 solver.cpp:337] Iteration 75000, Testing net (#0)
I0929 21:47:49.472964 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0929 21:47:49.472964 11684 solver.cpp:404]     Test net output #1: loss = 1.11523 (* 1 = 1.11523 loss)
I0929 21:47:49.525001 11684 solver.cpp:228] Iteration 75000, loss = 0.00862553
I0929 21:47:49.525001 11684 solver.cpp:244]     Train net output #0: loss = 0.00862619 (* 1 = 0.00862619 loss)
I0929 21:47:49.525001 11684 sgd_solver.cpp:106] Iteration 75000, lr = 0.001
I0929 21:48:09.550757 11684 solver.cpp:228] Iteration 75100, loss = 0.0152839
I0929 21:48:09.550757 11684 solver.cpp:244]     Train net output #0: loss = 0.0152846 (* 1 = 0.0152846 loss)
I0929 21:48:09.550757 11684 sgd_solver.cpp:106] Iteration 75100, lr = 0.001
I0929 21:48:29.476137 11684 solver.cpp:228] Iteration 75200, loss = 0.0132581
I0929 21:48:29.476137 11684 solver.cpp:244]     Train net output #0: loss = 0.0132588 (* 1 = 0.0132588 loss)
I0929 21:48:29.476137 11684 sgd_solver.cpp:106] Iteration 75200, lr = 0.001
I0929 21:48:49.378907 11684 solver.cpp:228] Iteration 75300, loss = 0.0221609
I0929 21:48:49.378907 11684 solver.cpp:244]     Train net output #0: loss = 0.0221615 (* 1 = 0.0221615 loss)
I0929 21:48:49.378907 11684 sgd_solver.cpp:106] Iteration 75300, lr = 0.001
I0929 21:49:09.388051 11684 solver.cpp:228] Iteration 75400, loss = 0.0167623
I0929 21:49:09.388552 11684 solver.cpp:244]     Train net output #0: loss = 0.0167629 (* 1 = 0.0167629 loss)
I0929 21:49:09.388552 11684 sgd_solver.cpp:106] Iteration 75400, lr = 0.001
I0929 21:49:29.376837 11684 solver.cpp:228] Iteration 75500, loss = 0.0101174
I0929 21:49:29.376837 11684 solver.cpp:244]     Train net output #0: loss = 0.010118 (* 1 = 0.010118 loss)
I0929 21:49:29.377338 11684 sgd_solver.cpp:106] Iteration 75500, lr = 0.001
I0929 21:49:49.318414 11684 solver.cpp:228] Iteration 75600, loss = 0.00834323
I0929 21:49:49.318414 11684 solver.cpp:244]     Train net output #0: loss = 0.00834389 (* 1 = 0.00834389 loss)
I0929 21:49:49.318414 11684 sgd_solver.cpp:106] Iteration 75600, lr = 0.001
I0929 21:50:09.314316 11684 solver.cpp:228] Iteration 75700, loss = 0.0110836
I0929 21:50:09.314316 11684 solver.cpp:244]     Train net output #0: loss = 0.0110843 (* 1 = 0.0110843 loss)
I0929 21:50:09.314316 11684 sgd_solver.cpp:106] Iteration 75700, lr = 0.001
I0929 21:50:29.358470 11684 solver.cpp:228] Iteration 75800, loss = 0.00829579
I0929 21:50:29.358470 11684 solver.cpp:244]     Train net output #0: loss = 0.00829645 (* 1 = 0.00829645 loss)
I0929 21:50:29.358470 11684 sgd_solver.cpp:106] Iteration 75800, lr = 0.001
I0929 21:50:49.429407 11684 solver.cpp:228] Iteration 75900, loss = 0.0112095
I0929 21:50:49.429407 11684 solver.cpp:244]     Train net output #0: loss = 0.0112101 (* 1 = 0.0112101 loss)
I0929 21:50:49.429407 11684 sgd_solver.cpp:106] Iteration 75900, lr = 0.001
I0929 21:51:09.175360 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_76000.caffemodel
I0929 21:51:10.067662 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_76000.solverstate
I0929 21:51:10.553676 11684 solver.cpp:337] Iteration 76000, Testing net (#0)
I0929 21:51:19.561079 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7349
I0929 21:51:19.561579 11684 solver.cpp:404]     Test net output #1: loss = 1.11325 (* 1 = 1.11325 loss)
I0929 21:51:19.616619 11684 solver.cpp:228] Iteration 76000, loss = 0.0253091
I0929 21:51:19.617120 11684 solver.cpp:244]     Train net output #0: loss = 0.0253097 (* 1 = 0.0253097 loss)
I0929 21:51:19.617120 11684 sgd_solver.cpp:106] Iteration 76000, lr = 0.001
I0929 21:51:39.681674 11684 solver.cpp:228] Iteration 76100, loss = 0.0101207
I0929 21:51:39.681674 11684 solver.cpp:244]     Train net output #0: loss = 0.0101214 (* 1 = 0.0101214 loss)
I0929 21:51:39.681674 11684 sgd_solver.cpp:106] Iteration 76100, lr = 0.001
I0929 21:51:59.736222 11684 solver.cpp:228] Iteration 76200, loss = 0.0114242
I0929 21:51:59.736222 11684 solver.cpp:244]     Train net output #0: loss = 0.0114248 (* 1 = 0.0114248 loss)
I0929 21:51:59.736222 11684 sgd_solver.cpp:106] Iteration 76200, lr = 0.001
I0929 21:52:19.754815 11684 solver.cpp:228] Iteration 76300, loss = 0.0111294
I0929 21:52:19.754815 11684 solver.cpp:244]     Train net output #0: loss = 0.0111301 (* 1 = 0.0111301 loss)
I0929 21:52:19.754815 11684 sgd_solver.cpp:106] Iteration 76300, lr = 0.001
I0929 21:52:39.776171 11684 solver.cpp:228] Iteration 76400, loss = 0.0129767
I0929 21:52:39.776171 11684 solver.cpp:244]     Train net output #0: loss = 0.0129774 (* 1 = 0.0129774 loss)
I0929 21:52:39.776171 11684 sgd_solver.cpp:106] Iteration 76400, lr = 0.001
I0929 21:52:59.879290 11684 solver.cpp:228] Iteration 76500, loss = 0.0125492
I0929 21:52:59.879290 11684 solver.cpp:244]     Train net output #0: loss = 0.0125499 (* 1 = 0.0125499 loss)
I0929 21:52:59.879290 11684 sgd_solver.cpp:106] Iteration 76500, lr = 0.001
I0929 21:53:19.953670 11684 solver.cpp:228] Iteration 76600, loss = 0.0114334
I0929 21:53:19.953670 11684 solver.cpp:244]     Train net output #0: loss = 0.0114341 (* 1 = 0.0114341 loss)
I0929 21:53:19.953670 11684 sgd_solver.cpp:106] Iteration 76600, lr = 0.001
I0929 21:53:40.071151 11684 solver.cpp:228] Iteration 76700, loss = 0.00849925
I0929 21:53:40.071151 11684 solver.cpp:244]     Train net output #0: loss = 0.00849992 (* 1 = 0.00849992 loss)
I0929 21:53:40.071151 11684 sgd_solver.cpp:106] Iteration 76700, lr = 0.001
I0929 21:54:00.142303 11684 solver.cpp:228] Iteration 76800, loss = 0.0111654
I0929 21:54:00.142303 11684 solver.cpp:244]     Train net output #0: loss = 0.011166 (* 1 = 0.011166 loss)
I0929 21:54:00.142303 11684 sgd_solver.cpp:106] Iteration 76800, lr = 0.001
I0929 21:54:20.164118 11684 solver.cpp:228] Iteration 76900, loss = 0.00773291
I0929 21:54:20.164118 11684 solver.cpp:244]     Train net output #0: loss = 0.00773358 (* 1 = 0.00773358 loss)
I0929 21:54:20.164118 11684 sgd_solver.cpp:106] Iteration 76900, lr = 0.001
I0929 21:54:39.509163 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_77000.caffemodel
I0929 21:54:40.097581 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_77000.solverstate
I0929 21:54:40.548537 11684 solver.cpp:337] Iteration 77000, Testing net (#0)
I0929 21:54:48.762557 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7355
I0929 21:54:48.762557 11684 solver.cpp:404]     Test net output #1: loss = 1.10864 (* 1 = 1.10864 loss)
I0929 21:54:48.813592 11684 solver.cpp:228] Iteration 77000, loss = 0.0101999
I0929 21:54:48.813592 11684 solver.cpp:244]     Train net output #0: loss = 0.0102006 (* 1 = 0.0102006 loss)
I0929 21:54:48.813592 11684 sgd_solver.cpp:106] Iteration 77000, lr = 0.001
I0929 21:55:08.730746 11684 solver.cpp:228] Iteration 77100, loss = 0.0108647
I0929 21:55:08.731246 11684 solver.cpp:244]     Train net output #0: loss = 0.0108654 (* 1 = 0.0108654 loss)
I0929 21:55:08.731246 11684 sgd_solver.cpp:106] Iteration 77100, lr = 0.001
I0929 21:55:28.733556 11684 solver.cpp:228] Iteration 77200, loss = 0.0134901
I0929 21:55:28.733556 11684 solver.cpp:244]     Train net output #0: loss = 0.0134908 (* 1 = 0.0134908 loss)
I0929 21:55:28.733556 11684 sgd_solver.cpp:106] Iteration 77200, lr = 0.001
I0929 21:55:48.522920 11684 solver.cpp:228] Iteration 77300, loss = 0.0101175
I0929 21:55:48.522920 11684 solver.cpp:244]     Train net output #0: loss = 0.0101182 (* 1 = 0.0101182 loss)
I0929 21:55:48.522920 11684 sgd_solver.cpp:106] Iteration 77300, lr = 0.001
I0929 21:56:08.301123 11684 solver.cpp:228] Iteration 77400, loss = 0.0189248
I0929 21:56:08.301123 11684 solver.cpp:244]     Train net output #0: loss = 0.0189255 (* 1 = 0.0189255 loss)
I0929 21:56:08.301123 11684 sgd_solver.cpp:106] Iteration 77400, lr = 0.001
I0929 21:56:28.089591 11684 solver.cpp:228] Iteration 77500, loss = 0.0128696
I0929 21:56:28.089591 11684 solver.cpp:244]     Train net output #0: loss = 0.0128702 (* 1 = 0.0128702 loss)
I0929 21:56:28.089591 11684 sgd_solver.cpp:106] Iteration 77500, lr = 0.001
I0929 21:56:47.884281 11684 solver.cpp:228] Iteration 77600, loss = 0.0158355
I0929 21:56:47.884281 11684 solver.cpp:244]     Train net output #0: loss = 0.0158362 (* 1 = 0.0158362 loss)
I0929 21:56:47.884281 11684 sgd_solver.cpp:106] Iteration 77600, lr = 0.001
I0929 21:57:07.670817 11684 solver.cpp:228] Iteration 77700, loss = 0.00619303
I0929 21:57:07.670817 11684 solver.cpp:244]     Train net output #0: loss = 0.0061937 (* 1 = 0.0061937 loss)
I0929 21:57:07.670817 11684 sgd_solver.cpp:106] Iteration 77700, lr = 0.001
I0929 21:57:27.419277 11684 solver.cpp:228] Iteration 77800, loss = 0.00781635
I0929 21:57:27.419777 11684 solver.cpp:244]     Train net output #0: loss = 0.00781702 (* 1 = 0.00781702 loss)
I0929 21:57:27.419777 11684 sgd_solver.cpp:106] Iteration 77800, lr = 0.001
I0929 21:57:47.201159 11684 solver.cpp:228] Iteration 77900, loss = 0.00836293
I0929 21:57:47.201159 11684 solver.cpp:244]     Train net output #0: loss = 0.0083636 (* 1 = 0.0083636 loss)
I0929 21:57:47.201159 11684 sgd_solver.cpp:106] Iteration 77900, lr = 0.001
I0929 21:58:06.930048 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_78000.caffemodel
I0929 21:58:07.650861 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_78000.solverstate
I0929 21:58:08.124197 11684 solver.cpp:337] Iteration 78000, Testing net (#0)
I0929 21:58:16.504828 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7376
I0929 21:58:16.504828 11684 solver.cpp:404]     Test net output #1: loss = 1.10937 (* 1 = 1.10937 loss)
I0929 21:58:16.556365 11684 solver.cpp:228] Iteration 78000, loss = 0.012503
I0929 21:58:16.556365 11684 solver.cpp:244]     Train net output #0: loss = 0.0125036 (* 1 = 0.0125036 loss)
I0929 21:58:16.556365 11684 sgd_solver.cpp:106] Iteration 78000, lr = 0.001
I0929 21:58:36.328253 11684 solver.cpp:228] Iteration 78100, loss = 0.0179243
I0929 21:58:36.328253 11684 solver.cpp:244]     Train net output #0: loss = 0.0179249 (* 1 = 0.0179249 loss)
I0929 21:58:36.328253 11684 sgd_solver.cpp:106] Iteration 78100, lr = 0.001
I0929 21:58:56.156705 11684 solver.cpp:228] Iteration 78200, loss = 0.010138
I0929 21:58:56.156705 11684 solver.cpp:244]     Train net output #0: loss = 0.0101387 (* 1 = 0.0101387 loss)
I0929 21:58:56.156705 11684 sgd_solver.cpp:106] Iteration 78200, lr = 0.001
I0929 21:59:15.892252 11684 solver.cpp:228] Iteration 78300, loss = 0.0117821
I0929 21:59:15.892752 11684 solver.cpp:244]     Train net output #0: loss = 0.0117827 (* 1 = 0.0117827 loss)
I0929 21:59:15.892752 11684 sgd_solver.cpp:106] Iteration 78300, lr = 0.001
I0929 21:59:35.694658 11684 solver.cpp:228] Iteration 78400, loss = 0.009029
I0929 21:59:35.694658 11684 solver.cpp:244]     Train net output #0: loss = 0.00902967 (* 1 = 0.00902967 loss)
I0929 21:59:35.694658 11684 sgd_solver.cpp:106] Iteration 78400, lr = 0.001
I0929 21:59:55.620081 11684 solver.cpp:228] Iteration 78500, loss = 0.0158828
I0929 21:59:55.620081 11684 solver.cpp:244]     Train net output #0: loss = 0.0158835 (* 1 = 0.0158835 loss)
I0929 21:59:55.620081 11684 sgd_solver.cpp:106] Iteration 78500, lr = 0.001
I0929 22:00:15.596092 11684 solver.cpp:228] Iteration 78600, loss = 0.0138286
I0929 22:00:15.596092 11684 solver.cpp:244]     Train net output #0: loss = 0.0138292 (* 1 = 0.0138292 loss)
I0929 22:00:15.596092 11684 sgd_solver.cpp:106] Iteration 78600, lr = 0.001
I0929 22:00:35.428390 11684 solver.cpp:228] Iteration 78700, loss = 0.0122356
I0929 22:00:35.428390 11684 solver.cpp:244]     Train net output #0: loss = 0.0122363 (* 1 = 0.0122363 loss)
I0929 22:00:35.428390 11684 sgd_solver.cpp:106] Iteration 78700, lr = 0.001
I0929 22:00:55.173892 11684 solver.cpp:228] Iteration 78800, loss = 0.0186953
I0929 22:00:55.173892 11684 solver.cpp:244]     Train net output #0: loss = 0.018696 (* 1 = 0.018696 loss)
I0929 22:00:55.173892 11684 sgd_solver.cpp:106] Iteration 78800, lr = 0.001
I0929 22:01:14.906502 11684 solver.cpp:228] Iteration 78900, loss = 0.0184507
I0929 22:01:14.907002 11684 solver.cpp:244]     Train net output #0: loss = 0.0184514 (* 1 = 0.0184514 loss)
I0929 22:01:14.907002 11684 sgd_solver.cpp:106] Iteration 78900, lr = 0.001
I0929 22:01:34.653064 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_79000.caffemodel
I0929 22:01:35.324559 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_79000.solverstate
I0929 22:01:35.726346 11684 solver.cpp:337] Iteration 79000, Testing net (#0)
I0929 22:01:44.182642 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7397
I0929 22:01:44.182642 11684 solver.cpp:404]     Test net output #1: loss = 1.10923 (* 1 = 1.10923 loss)
I0929 22:01:44.235680 11684 solver.cpp:228] Iteration 79000, loss = 0.00762136
I0929 22:01:44.235680 11684 solver.cpp:244]     Train net output #0: loss = 0.00762203 (* 1 = 0.00762203 loss)
I0929 22:01:44.235680 11684 sgd_solver.cpp:106] Iteration 79000, lr = 0.001
I0929 22:02:03.977860 11684 solver.cpp:228] Iteration 79100, loss = 0.0129676
I0929 22:02:03.977860 11684 solver.cpp:244]     Train net output #0: loss = 0.0129683 (* 1 = 0.0129683 loss)
I0929 22:02:03.977860 11684 sgd_solver.cpp:106] Iteration 79100, lr = 0.001
I0929 22:02:23.719054 11684 solver.cpp:228] Iteration 79200, loss = 0.0139505
I0929 22:02:23.719555 11684 solver.cpp:244]     Train net output #0: loss = 0.0139512 (* 1 = 0.0139512 loss)
I0929 22:02:23.719555 11684 sgd_solver.cpp:106] Iteration 79200, lr = 0.001
I0929 22:02:43.492015 11684 solver.cpp:228] Iteration 79300, loss = 0.00862237
I0929 22:02:43.492015 11684 solver.cpp:244]     Train net output #0: loss = 0.00862304 (* 1 = 0.00862304 loss)
I0929 22:02:43.492015 11684 sgd_solver.cpp:106] Iteration 79300, lr = 0.001
I0929 22:03:03.431877 11684 solver.cpp:228] Iteration 79400, loss = 0.00941909
I0929 22:03:03.431877 11684 solver.cpp:244]     Train net output #0: loss = 0.00941977 (* 1 = 0.00941977 loss)
I0929 22:03:03.431877 11684 sgd_solver.cpp:106] Iteration 79400, lr = 0.001
I0929 22:03:23.399171 11684 solver.cpp:228] Iteration 79500, loss = 0.0108438
I0929 22:03:23.399171 11684 solver.cpp:244]     Train net output #0: loss = 0.0108445 (* 1 = 0.0108445 loss)
I0929 22:03:23.399171 11684 sgd_solver.cpp:106] Iteration 79500, lr = 0.001
I0929 22:03:43.165477 11684 solver.cpp:228] Iteration 79600, loss = 0.0108634
I0929 22:03:43.165477 11684 solver.cpp:244]     Train net output #0: loss = 0.0108641 (* 1 = 0.0108641 loss)
I0929 22:03:43.165477 11684 sgd_solver.cpp:106] Iteration 79600, lr = 0.001
I0929 22:04:02.920667 11684 solver.cpp:228] Iteration 79700, loss = 0.0141809
I0929 22:04:02.920667 11684 solver.cpp:244]     Train net output #0: loss = 0.0141816 (* 1 = 0.0141816 loss)
I0929 22:04:02.920667 11684 sgd_solver.cpp:106] Iteration 79700, lr = 0.001
I0929 22:04:22.690711 11684 solver.cpp:228] Iteration 79800, loss = 0.0121387
I0929 22:04:22.690711 11684 solver.cpp:244]     Train net output #0: loss = 0.0121394 (* 1 = 0.0121394 loss)
I0929 22:04:22.690711 11684 sgd_solver.cpp:106] Iteration 79800, lr = 0.001
I0929 22:04:42.515769 11684 solver.cpp:228] Iteration 79900, loss = 0.0109097
I0929 22:04:42.515769 11684 solver.cpp:244]     Train net output #0: loss = 0.0109104 (* 1 = 0.0109104 loss)
I0929 22:04:42.515769 11684 sgd_solver.cpp:106] Iteration 79900, lr = 0.001
I0929 22:05:02.323257 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_80000.caffemodel
I0929 22:05:02.976223 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_80000.solverstate
I0929 22:05:03.474179 11684 solver.cpp:337] Iteration 80000, Testing net (#0)
I0929 22:05:11.902880 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7348
I0929 22:05:11.902880 11684 solver.cpp:404]     Test net output #1: loss = 1.10505 (* 1 = 1.10505 loss)
I0929 22:05:11.957919 11684 solver.cpp:228] Iteration 80000, loss = 0.0110062
I0929 22:05:11.958420 11684 solver.cpp:244]     Train net output #0: loss = 0.0110068 (* 1 = 0.0110068 loss)
I0929 22:05:11.958420 11684 sgd_solver.cpp:106] Iteration 80000, lr = 0.001
I0929 22:05:31.957551 11684 solver.cpp:228] Iteration 80100, loss = 0.0188619
I0929 22:05:31.958051 11684 solver.cpp:244]     Train net output #0: loss = 0.0188626 (* 1 = 0.0188626 loss)
I0929 22:05:31.958051 11684 sgd_solver.cpp:106] Iteration 80100, lr = 0.001
I0929 22:05:51.753108 11684 solver.cpp:228] Iteration 80200, loss = 0.0123301
I0929 22:05:51.753108 11684 solver.cpp:244]     Train net output #0: loss = 0.0123308 (* 1 = 0.0123308 loss)
I0929 22:05:51.753108 11684 sgd_solver.cpp:106] Iteration 80200, lr = 0.001
I0929 22:06:11.490753 11684 solver.cpp:228] Iteration 80300, loss = 0.0136755
I0929 22:06:11.490753 11684 solver.cpp:244]     Train net output #0: loss = 0.0136762 (* 1 = 0.0136762 loss)
I0929 22:06:11.490753 11684 sgd_solver.cpp:106] Iteration 80300, lr = 0.001
I0929 22:06:31.262859 11684 solver.cpp:228] Iteration 80400, loss = 0.0117223
I0929 22:06:31.262859 11684 solver.cpp:244]     Train net output #0: loss = 0.011723 (* 1 = 0.011723 loss)
I0929 22:06:31.263361 11684 sgd_solver.cpp:106] Iteration 80400, lr = 0.001
I0929 22:06:51.190461 11684 solver.cpp:228] Iteration 80500, loss = 0.00667567
I0929 22:06:51.190461 11684 solver.cpp:244]     Train net output #0: loss = 0.00667634 (* 1 = 0.00667634 loss)
I0929 22:06:51.190461 11684 sgd_solver.cpp:106] Iteration 80500, lr = 0.001
I0929 22:07:10.978220 11684 solver.cpp:228] Iteration 80600, loss = 0.00934637
I0929 22:07:10.978220 11684 solver.cpp:244]     Train net output #0: loss = 0.00934703 (* 1 = 0.00934703 loss)
I0929 22:07:10.978220 11684 sgd_solver.cpp:106] Iteration 80600, lr = 0.001
I0929 22:07:30.768656 11684 solver.cpp:228] Iteration 80700, loss = 0.0152378
I0929 22:07:30.768656 11684 solver.cpp:244]     Train net output #0: loss = 0.0152384 (* 1 = 0.0152384 loss)
I0929 22:07:30.768656 11684 sgd_solver.cpp:106] Iteration 80700, lr = 0.001
I0929 22:07:50.404531 11684 solver.cpp:228] Iteration 80800, loss = 0.0129977
I0929 22:07:50.404531 11684 solver.cpp:244]     Train net output #0: loss = 0.0129984 (* 1 = 0.0129984 loss)
I0929 22:07:50.404531 11684 sgd_solver.cpp:106] Iteration 80800, lr = 0.001
I0929 22:08:10.259999 11684 solver.cpp:228] Iteration 80900, loss = 0.0119468
I0929 22:08:10.259999 11684 solver.cpp:244]     Train net output #0: loss = 0.0119475 (* 1 = 0.0119475 loss)
I0929 22:08:10.259999 11684 sgd_solver.cpp:106] Iteration 80900, lr = 0.001
I0929 22:08:30.099491 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_81000.caffemodel
I0929 22:08:30.807019 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_81000.solverstate
I0929 22:08:31.204803 11684 solver.cpp:337] Iteration 81000, Testing net (#0)
I0929 22:08:39.560510 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7345
I0929 22:08:39.560510 11684 solver.cpp:404]     Test net output #1: loss = 1.10182 (* 1 = 1.10182 loss)
I0929 22:08:39.613046 11684 solver.cpp:228] Iteration 81000, loss = 0.014783
I0929 22:08:39.613046 11684 solver.cpp:244]     Train net output #0: loss = 0.0147837 (* 1 = 0.0147837 loss)
I0929 22:08:39.613046 11684 sgd_solver.cpp:106] Iteration 81000, lr = 0.001
I0929 22:08:59.039590 11684 solver.cpp:228] Iteration 81100, loss = 0.0137875
I0929 22:08:59.039590 11684 solver.cpp:244]     Train net output #0: loss = 0.0137882 (* 1 = 0.0137882 loss)
I0929 22:08:59.039590 11684 sgd_solver.cpp:106] Iteration 81100, lr = 0.001
I0929 22:09:18.463645 11684 solver.cpp:228] Iteration 81200, loss = 0.0102793
I0929 22:09:18.463645 11684 solver.cpp:244]     Train net output #0: loss = 0.01028 (* 1 = 0.01028 loss)
I0929 22:09:18.463645 11684 sgd_solver.cpp:106] Iteration 81200, lr = 0.001
I0930 01:39:36.629128 11684 solver.cpp:228] Iteration 81300, loss = 0.0156125
I0930 01:39:36.629128 11684 solver.cpp:244]     Train net output #0: loss = 0.0156131 (* 1 = 0.0156131 loss)
I0930 01:39:36.629128 11684 sgd_solver.cpp:106] Iteration 81300, lr = 0.001
I0930 01:39:55.946581 11684 solver.cpp:228] Iteration 81400, loss = 0.0136937
I0930 01:39:55.946581 11684 solver.cpp:244]     Train net output #0: loss = 0.0136943 (* 1 = 0.0136943 loss)
I0930 01:39:55.946581 11684 sgd_solver.cpp:106] Iteration 81400, lr = 0.001
I0930 01:40:15.368613 11684 solver.cpp:228] Iteration 81500, loss = 0.0121967
I0930 01:40:15.368613 11684 solver.cpp:244]     Train net output #0: loss = 0.0121974 (* 1 = 0.0121974 loss)
I0930 01:40:15.368613 11684 sgd_solver.cpp:106] Iteration 81500, lr = 0.001
I0930 01:40:34.807000 11684 solver.cpp:228] Iteration 81600, loss = 0.0107116
I0930 01:40:34.807500 11684 solver.cpp:244]     Train net output #0: loss = 0.0107122 (* 1 = 0.0107122 loss)
I0930 01:40:34.807500 11684 sgd_solver.cpp:106] Iteration 81600, lr = 0.001
I0930 01:40:54.364742 11684 solver.cpp:228] Iteration 81700, loss = 0.0138739
I0930 01:40:54.364742 11684 solver.cpp:244]     Train net output #0: loss = 0.0138746 (* 1 = 0.0138746 loss)
I0930 01:40:54.365242 11684 sgd_solver.cpp:106] Iteration 81700, lr = 0.001
I0930 01:41:13.637094 11684 solver.cpp:228] Iteration 81800, loss = 0.0190296
I0930 01:41:13.637094 11684 solver.cpp:244]     Train net output #0: loss = 0.0190303 (* 1 = 0.0190303 loss)
I0930 01:41:13.637094 11684 sgd_solver.cpp:106] Iteration 81800, lr = 0.001
I0930 01:41:33.020030 11684 solver.cpp:228] Iteration 81900, loss = 0.0100617
I0930 01:41:33.020030 11684 solver.cpp:244]     Train net output #0: loss = 0.0100624 (* 1 = 0.0100624 loss)
I0930 01:41:33.020030 11684 sgd_solver.cpp:106] Iteration 81900, lr = 0.001
I0930 01:41:52.268573 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_82000.caffemodel
I0930 01:41:52.855989 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_82000.solverstate
I0930 01:41:53.234257 11684 solver.cpp:337] Iteration 82000, Testing net (#0)
I0930 01:42:01.441856 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7365
I0930 01:42:01.441856 11684 solver.cpp:404]     Test net output #1: loss = 1.10519 (* 1 = 1.10519 loss)
I0930 01:42:01.491891 11684 solver.cpp:228] Iteration 82000, loss = 0.0182005
I0930 01:42:01.491891 11684 solver.cpp:244]     Train net output #0: loss = 0.0182011 (* 1 = 0.0182011 loss)
I0930 01:42:01.491891 11684 sgd_solver.cpp:106] Iteration 82000, lr = 0.001
I0930 01:42:20.858084 11684 solver.cpp:228] Iteration 82100, loss = 0.0106414
I0930 01:42:20.858084 11684 solver.cpp:244]     Train net output #0: loss = 0.010642 (* 1 = 0.010642 loss)
I0930 01:42:20.858084 11684 sgd_solver.cpp:106] Iteration 82100, lr = 0.001
I0930 01:42:40.143580 11684 solver.cpp:228] Iteration 82200, loss = 0.0170957
I0930 01:42:40.143580 11684 solver.cpp:244]     Train net output #0: loss = 0.0170964 (* 1 = 0.0170964 loss)
I0930 01:42:40.143580 11684 sgd_solver.cpp:106] Iteration 82200, lr = 0.001
I0930 01:42:59.419390 11684 solver.cpp:228] Iteration 82300, loss = 0.0162748
I0930 01:42:59.419390 11684 solver.cpp:244]     Train net output #0: loss = 0.0162755 (* 1 = 0.0162755 loss)
I0930 01:42:59.419390 11684 sgd_solver.cpp:106] Iteration 82300, lr = 0.001
I0930 01:43:18.700366 11684 solver.cpp:228] Iteration 82400, loss = 0.0108083
I0930 01:43:18.700366 11684 solver.cpp:244]     Train net output #0: loss = 0.010809 (* 1 = 0.010809 loss)
I0930 01:43:18.701365 11684 sgd_solver.cpp:106] Iteration 82400, lr = 0.001
I0930 01:43:37.983813 11684 solver.cpp:228] Iteration 82500, loss = 0.00854398
I0930 01:43:37.983813 11684 solver.cpp:244]     Train net output #0: loss = 0.00854464 (* 1 = 0.00854464 loss)
I0930 01:43:37.983813 11684 sgd_solver.cpp:106] Iteration 82500, lr = 0.001
I0930 01:43:57.247622 11684 solver.cpp:228] Iteration 82600, loss = 0.0114524
I0930 01:43:57.247622 11684 solver.cpp:244]     Train net output #0: loss = 0.011453 (* 1 = 0.011453 loss)
I0930 01:43:57.247622 11684 sgd_solver.cpp:106] Iteration 82600, lr = 0.001
I0930 01:44:16.539137 11684 solver.cpp:228] Iteration 82700, loss = 0.0130381
I0930 01:44:16.539137 11684 solver.cpp:244]     Train net output #0: loss = 0.0130388 (* 1 = 0.0130388 loss)
I0930 01:44:16.539137 11684 sgd_solver.cpp:106] Iteration 82700, lr = 0.001
I0930 01:44:35.823091 11684 solver.cpp:228] Iteration 82800, loss = 0.00826329
I0930 01:44:35.823091 11684 solver.cpp:244]     Train net output #0: loss = 0.00826394 (* 1 = 0.00826394 loss)
I0930 01:44:35.823091 11684 sgd_solver.cpp:106] Iteration 82800, lr = 0.001
I0930 01:44:55.107167 11684 solver.cpp:228] Iteration 82900, loss = 0.0118787
I0930 01:44:55.107167 11684 solver.cpp:244]     Train net output #0: loss = 0.0118794 (* 1 = 0.0118794 loss)
I0930 01:44:55.107167 11684 sgd_solver.cpp:106] Iteration 82900, lr = 0.001
I0930 01:45:14.352309 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_83000.caffemodel
I0930 01:45:14.950736 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_83000.solverstate
I0930 01:45:15.325002 11684 solver.cpp:337] Iteration 83000, Testing net (#0)
I0930 01:45:23.513768 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7383
I0930 01:45:23.513768 11684 solver.cpp:404]     Test net output #1: loss = 1.10269 (* 1 = 1.10269 loss)
I0930 01:45:23.564791 11684 solver.cpp:228] Iteration 83000, loss = 0.00922903
I0930 01:45:23.564791 11684 solver.cpp:244]     Train net output #0: loss = 0.00922969 (* 1 = 0.00922969 loss)
I0930 01:45:23.564791 11684 sgd_solver.cpp:106] Iteration 83000, lr = 0.001
I0930 01:45:42.809775 11684 solver.cpp:228] Iteration 83100, loss = 0.0139625
I0930 01:45:42.809775 11684 solver.cpp:244]     Train net output #0: loss = 0.0139631 (* 1 = 0.0139631 loss)
I0930 01:45:42.809775 11684 sgd_solver.cpp:106] Iteration 83100, lr = 0.001
I0930 01:46:02.059201 11684 solver.cpp:228] Iteration 83200, loss = 0.011771
I0930 01:46:02.059201 11684 solver.cpp:244]     Train net output #0: loss = 0.0117717 (* 1 = 0.0117717 loss)
I0930 01:46:02.059201 11684 sgd_solver.cpp:106] Iteration 83200, lr = 0.001
I0930 01:46:21.334898 11684 solver.cpp:228] Iteration 83300, loss = 0.0154705
I0930 01:46:21.334898 11684 solver.cpp:244]     Train net output #0: loss = 0.0154712 (* 1 = 0.0154712 loss)
I0930 01:46:21.334898 11684 sgd_solver.cpp:106] Iteration 83300, lr = 0.001
I0930 01:46:40.642732 11684 solver.cpp:228] Iteration 83400, loss = 0.0135653
I0930 01:46:40.642732 11684 solver.cpp:244]     Train net output #0: loss = 0.0135659 (* 1 = 0.0135659 loss)
I0930 01:46:40.642732 11684 sgd_solver.cpp:106] Iteration 83400, lr = 0.001
I0930 01:46:59.977560 11684 solver.cpp:228] Iteration 83500, loss = 0.0114076
I0930 01:46:59.977560 11684 solver.cpp:244]     Train net output #0: loss = 0.0114083 (* 1 = 0.0114083 loss)
I0930 01:46:59.977560 11684 sgd_solver.cpp:106] Iteration 83500, lr = 0.001
I0930 01:47:19.269812 11684 solver.cpp:228] Iteration 83600, loss = 0.0102411
I0930 01:47:19.269812 11684 solver.cpp:244]     Train net output #0: loss = 0.0102418 (* 1 = 0.0102418 loss)
I0930 01:47:19.269812 11684 sgd_solver.cpp:106] Iteration 83600, lr = 0.001
I0930 01:47:38.587867 11684 solver.cpp:228] Iteration 83700, loss = 0.0125971
I0930 01:47:38.587867 11684 solver.cpp:244]     Train net output #0: loss = 0.0125977 (* 1 = 0.0125977 loss)
I0930 01:47:38.587867 11684 sgd_solver.cpp:106] Iteration 83700, lr = 0.001
I0930 01:47:57.971017 11684 solver.cpp:228] Iteration 83800, loss = 0.0105808
I0930 01:47:57.971017 11684 solver.cpp:244]     Train net output #0: loss = 0.0105815 (* 1 = 0.0105815 loss)
I0930 01:47:57.971017 11684 sgd_solver.cpp:106] Iteration 83800, lr = 0.001
I0930 01:48:17.390748 11684 solver.cpp:228] Iteration 83900, loss = 0.00781256
I0930 01:48:17.390748 11684 solver.cpp:244]     Train net output #0: loss = 0.00781323 (* 1 = 0.00781323 loss)
I0930 01:48:17.390748 11684 sgd_solver.cpp:106] Iteration 83900, lr = 0.001
I0930 01:48:36.612889 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_84000.caffemodel
I0930 01:48:37.223321 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_84000.solverstate
I0930 01:48:37.571569 11684 solver.cpp:337] Iteration 84000, Testing net (#0)
I0930 01:48:45.780140 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7347
I0930 01:48:45.780140 11684 solver.cpp:404]     Test net output #1: loss = 1.10529 (* 1 = 1.10529 loss)
I0930 01:48:45.830173 11684 solver.cpp:228] Iteration 84000, loss = 0.00759912
I0930 01:48:45.830173 11684 solver.cpp:244]     Train net output #0: loss = 0.00759978 (* 1 = 0.00759978 loss)
I0930 01:48:45.830173 11684 sgd_solver.cpp:106] Iteration 84000, lr = 0.001
I0930 01:49:05.155055 11684 solver.cpp:228] Iteration 84100, loss = 0.0109378
I0930 01:49:05.155556 11684 solver.cpp:244]     Train net output #0: loss = 0.0109385 (* 1 = 0.0109385 loss)
I0930 01:49:05.155556 11684 sgd_solver.cpp:106] Iteration 84100, lr = 0.001
I0930 01:49:24.445957 11684 solver.cpp:228] Iteration 84200, loss = 0.00779504
I0930 01:49:24.445957 11684 solver.cpp:244]     Train net output #0: loss = 0.0077957 (* 1 = 0.0077957 loss)
I0930 01:49:24.445957 11684 sgd_solver.cpp:106] Iteration 84200, lr = 0.001
I0930 01:49:43.707180 11684 solver.cpp:228] Iteration 84300, loss = 0.00995695
I0930 01:49:43.707180 11684 solver.cpp:244]     Train net output #0: loss = 0.00995761 (* 1 = 0.00995761 loss)
I0930 01:49:43.707180 11684 sgd_solver.cpp:106] Iteration 84300, lr = 0.001
I0930 01:50:03.007019 11684 solver.cpp:228] Iteration 84400, loss = 0.013194
I0930 01:50:03.007019 11684 solver.cpp:244]     Train net output #0: loss = 0.0131946 (* 1 = 0.0131946 loss)
I0930 01:50:03.007019 11684 sgd_solver.cpp:106] Iteration 84400, lr = 0.001
I0930 01:50:22.279719 11684 solver.cpp:228] Iteration 84500, loss = 0.00767759
I0930 01:50:22.279719 11684 solver.cpp:244]     Train net output #0: loss = 0.00767825 (* 1 = 0.00767825 loss)
I0930 01:50:22.279719 11684 sgd_solver.cpp:106] Iteration 84500, lr = 0.001
I0930 01:50:41.574653 11684 solver.cpp:228] Iteration 84600, loss = 0.0142936
I0930 01:50:41.574653 11684 solver.cpp:244]     Train net output #0: loss = 0.0142942 (* 1 = 0.0142942 loss)
I0930 01:50:41.574653 11684 sgd_solver.cpp:106] Iteration 84600, lr = 0.001
I0930 01:51:00.894469 11684 solver.cpp:228] Iteration 84700, loss = 0.00752629
I0930 01:51:00.894970 11684 solver.cpp:244]     Train net output #0: loss = 0.00752695 (* 1 = 0.00752695 loss)
I0930 01:51:00.894970 11684 sgd_solver.cpp:106] Iteration 84700, lr = 0.001
I0930 01:51:20.328011 11684 solver.cpp:228] Iteration 84800, loss = 0.0128586
I0930 01:51:20.328011 11684 solver.cpp:244]     Train net output #0: loss = 0.0128593 (* 1 = 0.0128593 loss)
I0930 01:51:20.328011 11684 sgd_solver.cpp:106] Iteration 84800, lr = 0.001
I0930 01:51:39.564057 11684 solver.cpp:228] Iteration 84900, loss = 0.0114483
I0930 01:51:39.564057 11684 solver.cpp:244]     Train net output #0: loss = 0.011449 (* 1 = 0.011449 loss)
I0930 01:51:39.564057 11684 sgd_solver.cpp:106] Iteration 84900, lr = 0.001
I0930 01:51:58.753437 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_85000.caffemodel
I0930 01:51:59.355855 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_85000.solverstate
I0930 01:51:59.702100 11684 solver.cpp:337] Iteration 85000, Testing net (#0)
I0930 01:52:07.885601 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7363
I0930 01:52:07.885601 11684 solver.cpp:404]     Test net output #1: loss = 1.10036 (* 1 = 1.10036 loss)
I0930 01:52:07.935636 11684 solver.cpp:228] Iteration 85000, loss = 0.0102931
I0930 01:52:07.935636 11684 solver.cpp:244]     Train net output #0: loss = 0.0102938 (* 1 = 0.0102938 loss)
I0930 01:52:07.935636 11684 sgd_solver.cpp:106] Iteration 85000, lr = 0.001
I0930 01:52:27.167304 11684 solver.cpp:228] Iteration 85100, loss = 0.010629
I0930 01:52:27.167304 11684 solver.cpp:244]     Train net output #0: loss = 0.0106296 (* 1 = 0.0106296 loss)
I0930 01:52:27.167304 11684 sgd_solver.cpp:106] Iteration 85100, lr = 0.001
I0930 01:52:46.397953 11684 solver.cpp:228] Iteration 85200, loss = 0.0114116
I0930 01:52:46.397953 11684 solver.cpp:244]     Train net output #0: loss = 0.0114123 (* 1 = 0.0114123 loss)
I0930 01:52:46.397953 11684 sgd_solver.cpp:106] Iteration 85200, lr = 0.001
I0930 01:53:05.640610 11684 solver.cpp:228] Iteration 85300, loss = 0.0117959
I0930 01:53:05.640610 11684 solver.cpp:244]     Train net output #0: loss = 0.0117966 (* 1 = 0.0117966 loss)
I0930 01:53:05.640610 11684 sgd_solver.cpp:106] Iteration 85300, lr = 0.001
I0930 01:53:24.889272 11684 solver.cpp:228] Iteration 85400, loss = 0.0106347
I0930 01:53:24.889272 11684 solver.cpp:244]     Train net output #0: loss = 0.0106353 (* 1 = 0.0106353 loss)
I0930 01:53:24.889272 11684 sgd_solver.cpp:106] Iteration 85400, lr = 0.001
I0930 01:53:44.129103 11684 solver.cpp:228] Iteration 85500, loss = 0.00932648
I0930 01:53:44.129103 11684 solver.cpp:244]     Train net output #0: loss = 0.00932715 (* 1 = 0.00932715 loss)
I0930 01:53:44.129103 11684 sgd_solver.cpp:106] Iteration 85500, lr = 0.001
I0930 01:54:03.362284 11684 solver.cpp:228] Iteration 85600, loss = 0.0133395
I0930 01:54:03.362284 11684 solver.cpp:244]     Train net output #0: loss = 0.0133402 (* 1 = 0.0133402 loss)
I0930 01:54:03.362284 11684 sgd_solver.cpp:106] Iteration 85600, lr = 0.001
I0930 01:54:22.589917 11684 solver.cpp:228] Iteration 85700, loss = 0.00692932
I0930 01:54:22.589917 11684 solver.cpp:244]     Train net output #0: loss = 0.00692998 (* 1 = 0.00692998 loss)
I0930 01:54:22.589917 11684 sgd_solver.cpp:106] Iteration 85700, lr = 0.001
I0930 01:54:41.824569 11684 solver.cpp:228] Iteration 85800, loss = 0.0128859
I0930 01:54:41.824569 11684 solver.cpp:244]     Train net output #0: loss = 0.0128866 (* 1 = 0.0128866 loss)
I0930 01:54:41.824569 11684 sgd_solver.cpp:106] Iteration 85800, lr = 0.001
I0930 01:55:01.054261 11684 solver.cpp:228] Iteration 85900, loss = 0.00947532
I0930 01:55:01.054261 11684 solver.cpp:244]     Train net output #0: loss = 0.00947598 (* 1 = 0.00947598 loss)
I0930 01:55:01.054261 11684 sgd_solver.cpp:106] Iteration 85900, lr = 0.001
I0930 01:55:20.237452 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_86000.caffemodel
I0930 01:55:20.818866 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_86000.solverstate
I0930 01:55:21.184124 11684 solver.cpp:337] Iteration 86000, Testing net (#0)
I0930 01:55:29.410976 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7363
I0930 01:55:29.411976 11684 solver.cpp:404]     Test net output #1: loss = 1.10432 (* 1 = 1.10432 loss)
I0930 01:55:29.461999 11684 solver.cpp:228] Iteration 86000, loss = 0.0090375
I0930 01:55:29.461999 11684 solver.cpp:244]     Train net output #0: loss = 0.00903817 (* 1 = 0.00903817 loss)
I0930 01:55:29.461999 11684 sgd_solver.cpp:106] Iteration 86000, lr = 0.001
I0930 01:55:48.700726 11684 solver.cpp:228] Iteration 86100, loss = 0.00999247
I0930 01:55:48.700726 11684 solver.cpp:244]     Train net output #0: loss = 0.00999314 (* 1 = 0.00999314 loss)
I0930 01:55:48.700726 11684 sgd_solver.cpp:106] Iteration 86100, lr = 0.001
I0930 01:56:07.934377 11684 solver.cpp:228] Iteration 86200, loss = 0.0148698
I0930 01:56:07.934377 11684 solver.cpp:244]     Train net output #0: loss = 0.0148705 (* 1 = 0.0148705 loss)
I0930 01:56:07.934377 11684 sgd_solver.cpp:106] Iteration 86200, lr = 0.001
I0930 01:56:27.166388 11684 solver.cpp:228] Iteration 86300, loss = 0.0113306
I0930 01:56:27.166388 11684 solver.cpp:244]     Train net output #0: loss = 0.0113313 (* 1 = 0.0113313 loss)
I0930 01:56:27.166388 11684 sgd_solver.cpp:106] Iteration 86300, lr = 0.001
I0930 01:56:46.407004 11684 solver.cpp:228] Iteration 86400, loss = 0.0217661
I0930 01:56:46.407004 11684 solver.cpp:244]     Train net output #0: loss = 0.0217668 (* 1 = 0.0217668 loss)
I0930 01:56:46.407004 11684 sgd_solver.cpp:106] Iteration 86400, lr = 0.001
I0930 01:57:05.640715 11684 solver.cpp:228] Iteration 86500, loss = 0.0123347
I0930 01:57:05.640715 11684 solver.cpp:244]     Train net output #0: loss = 0.0123354 (* 1 = 0.0123354 loss)
I0930 01:57:05.640715 11684 sgd_solver.cpp:106] Iteration 86500, lr = 0.001
I0930 01:57:24.871364 11684 solver.cpp:228] Iteration 86600, loss = 0.0266994
I0930 01:57:24.871364 11684 solver.cpp:244]     Train net output #0: loss = 0.0267001 (* 1 = 0.0267001 loss)
I0930 01:57:24.871364 11684 sgd_solver.cpp:106] Iteration 86600, lr = 0.001
I0930 01:57:44.105013 11684 solver.cpp:228] Iteration 86700, loss = 0.010554
I0930 01:57:44.105013 11684 solver.cpp:244]     Train net output #0: loss = 0.0105547 (* 1 = 0.0105547 loss)
I0930 01:57:44.105013 11684 sgd_solver.cpp:106] Iteration 86700, lr = 0.001
I0930 01:58:03.362668 11684 solver.cpp:228] Iteration 86800, loss = 0.00689414
I0930 01:58:03.362668 11684 solver.cpp:244]     Train net output #0: loss = 0.00689481 (* 1 = 0.00689481 loss)
I0930 01:58:03.362668 11684 sgd_solver.cpp:106] Iteration 86800, lr = 0.001
I0930 01:58:22.594318 11684 solver.cpp:228] Iteration 86900, loss = 0.00888539
I0930 01:58:22.594318 11684 solver.cpp:244]     Train net output #0: loss = 0.00888606 (* 1 = 0.00888606 loss)
I0930 01:58:22.594318 11684 sgd_solver.cpp:106] Iteration 86900, lr = 0.001
I0930 01:58:41.773931 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_87000.caffemodel
I0930 01:58:42.372355 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_87000.solverstate
I0930 01:58:42.726606 11684 solver.cpp:337] Iteration 87000, Testing net (#0)
I0930 01:58:50.919422 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7334
I0930 01:58:50.919422 11684 solver.cpp:404]     Test net output #1: loss = 1.11124 (* 1 = 1.11124 loss)
I0930 01:58:50.969471 11684 solver.cpp:228] Iteration 87000, loss = 0.0121375
I0930 01:58:50.970469 11684 solver.cpp:244]     Train net output #0: loss = 0.0121382 (* 1 = 0.0121382 loss)
I0930 01:58:50.970469 11684 sgd_solver.cpp:106] Iteration 87000, lr = 0.001
I0930 01:59:10.217280 11684 solver.cpp:228] Iteration 87100, loss = 0.0105109
I0930 01:59:10.217280 11684 solver.cpp:244]     Train net output #0: loss = 0.0105116 (* 1 = 0.0105116 loss)
I0930 01:59:10.217280 11684 sgd_solver.cpp:106] Iteration 87100, lr = 0.001
I0930 01:59:29.450776 11684 solver.cpp:228] Iteration 87200, loss = 0.0117665
I0930 01:59:29.450776 11684 solver.cpp:244]     Train net output #0: loss = 0.0117671 (* 1 = 0.0117671 loss)
I0930 01:59:29.450776 11684 sgd_solver.cpp:106] Iteration 87200, lr = 0.001
I0930 01:59:48.686429 11684 solver.cpp:228] Iteration 87300, loss = 0.0162415
I0930 01:59:48.686429 11684 solver.cpp:244]     Train net output #0: loss = 0.0162422 (* 1 = 0.0162422 loss)
I0930 01:59:48.686429 11684 sgd_solver.cpp:106] Iteration 87300, lr = 0.001
I0930 02:00:07.977365 11684 solver.cpp:228] Iteration 87400, loss = 0.00727442
I0930 02:00:07.977365 11684 solver.cpp:244]     Train net output #0: loss = 0.00727509 (* 1 = 0.00727509 loss)
I0930 02:00:07.977365 11684 sgd_solver.cpp:106] Iteration 87400, lr = 0.001
I0930 02:00:27.232044 11684 solver.cpp:228] Iteration 87500, loss = 0.0112035
I0930 02:00:27.232044 11684 solver.cpp:244]     Train net output #0: loss = 0.0112041 (* 1 = 0.0112041 loss)
I0930 02:00:27.232044 11684 sgd_solver.cpp:106] Iteration 87500, lr = 0.001
I0930 02:00:46.468744 11684 solver.cpp:228] Iteration 87600, loss = 0.029002
I0930 02:00:46.468744 11684 solver.cpp:244]     Train net output #0: loss = 0.0290027 (* 1 = 0.0290027 loss)
I0930 02:00:46.468744 11684 sgd_solver.cpp:106] Iteration 87600, lr = 0.001
I0930 02:01:05.712959 11684 solver.cpp:228] Iteration 87700, loss = 0.00951079
I0930 02:01:05.712959 11684 solver.cpp:244]     Train net output #0: loss = 0.00951146 (* 1 = 0.00951146 loss)
I0930 02:01:05.712959 11684 sgd_solver.cpp:106] Iteration 87700, lr = 0.001
I0930 02:01:24.975523 11684 solver.cpp:228] Iteration 87800, loss = 0.00818334
I0930 02:01:24.975523 11684 solver.cpp:244]     Train net output #0: loss = 0.00818401 (* 1 = 0.00818401 loss)
I0930 02:01:24.975523 11684 sgd_solver.cpp:106] Iteration 87800, lr = 0.001
I0930 02:01:44.157137 11684 solver.cpp:228] Iteration 87900, loss = 0.00874004
I0930 02:01:44.157137 11684 solver.cpp:244]     Train net output #0: loss = 0.00874071 (* 1 = 0.00874071 loss)
I0930 02:01:44.157137 11684 sgd_solver.cpp:106] Iteration 87900, lr = 0.001
I0930 02:02:03.285713 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_88000.caffemodel
I0930 02:02:03.872130 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_88000.solverstate
I0930 02:02:04.244810 11684 solver.cpp:337] Iteration 88000, Testing net (#0)
I0930 02:02:12.424893 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7378
I0930 02:02:12.424893 11684 solver.cpp:404]     Test net output #1: loss = 1.0928 (* 1 = 1.0928 loss)
I0930 02:02:12.474942 11684 solver.cpp:228] Iteration 88000, loss = 0.0111166
I0930 02:02:12.474942 11684 solver.cpp:244]     Train net output #0: loss = 0.0111173 (* 1 = 0.0111173 loss)
I0930 02:02:12.474942 11684 sgd_solver.cpp:106] Iteration 88000, lr = 0.001
I0930 02:02:31.654606 11684 solver.cpp:228] Iteration 88100, loss = 0.00965645
I0930 02:02:31.654606 11684 solver.cpp:244]     Train net output #0: loss = 0.00965711 (* 1 = 0.00965711 loss)
I0930 02:02:31.654606 11684 sgd_solver.cpp:106] Iteration 88100, lr = 0.001
I0930 02:02:50.848217 11684 solver.cpp:228] Iteration 88200, loss = 0.0159924
I0930 02:02:50.848217 11684 solver.cpp:244]     Train net output #0: loss = 0.0159931 (* 1 = 0.0159931 loss)
I0930 02:02:50.848217 11684 sgd_solver.cpp:106] Iteration 88200, lr = 0.001
I0930 02:03:10.027829 11684 solver.cpp:228] Iteration 88300, loss = 0.010091
I0930 02:03:10.027829 11684 solver.cpp:244]     Train net output #0: loss = 0.0100917 (* 1 = 0.0100917 loss)
I0930 02:03:10.027829 11684 sgd_solver.cpp:106] Iteration 88300, lr = 0.001
I0930 02:03:29.223844 11684 solver.cpp:228] Iteration 88400, loss = 0.0161154
I0930 02:03:29.223844 11684 solver.cpp:244]     Train net output #0: loss = 0.0161161 (* 1 = 0.0161161 loss)
I0930 02:03:29.223844 11684 sgd_solver.cpp:106] Iteration 88400, lr = 0.001
I0930 02:03:48.401247 11684 solver.cpp:228] Iteration 88500, loss = 0.0104006
I0930 02:03:48.401247 11684 solver.cpp:244]     Train net output #0: loss = 0.0104013 (* 1 = 0.0104013 loss)
I0930 02:03:48.401247 11684 sgd_solver.cpp:106] Iteration 88500, lr = 0.001
I0930 02:04:07.587198 11684 solver.cpp:228] Iteration 88600, loss = 0.0125566
I0930 02:04:07.587198 11684 solver.cpp:244]     Train net output #0: loss = 0.0125572 (* 1 = 0.0125572 loss)
I0930 02:04:07.587198 11684 sgd_solver.cpp:106] Iteration 88600, lr = 0.001
I0930 02:04:26.770862 11684 solver.cpp:228] Iteration 88700, loss = 0.00815782
I0930 02:04:26.770862 11684 solver.cpp:244]     Train net output #0: loss = 0.00815848 (* 1 = 0.00815848 loss)
I0930 02:04:26.770862 11684 sgd_solver.cpp:106] Iteration 88700, lr = 0.001
I0930 02:04:45.957473 11684 solver.cpp:228] Iteration 88800, loss = 0.00902774
I0930 02:04:45.957473 11684 solver.cpp:244]     Train net output #0: loss = 0.0090284 (* 1 = 0.0090284 loss)
I0930 02:04:45.957473 11684 sgd_solver.cpp:106] Iteration 88800, lr = 0.001
I0930 02:05:05.138087 11684 solver.cpp:228] Iteration 88900, loss = 0.0148393
I0930 02:05:05.138087 11684 solver.cpp:244]     Train net output #0: loss = 0.01484 (* 1 = 0.01484 loss)
I0930 02:05:05.138087 11684 sgd_solver.cpp:106] Iteration 88900, lr = 0.001
I0930 02:05:24.270665 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_89000.caffemodel
I0930 02:05:24.893107 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_89000.solverstate
I0930 02:05:25.256364 11684 solver.cpp:337] Iteration 89000, Testing net (#0)
I0930 02:05:33.433617 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7348
I0930 02:05:33.433617 11684 solver.cpp:404]     Test net output #1: loss = 1.10348 (* 1 = 1.10348 loss)
I0930 02:05:33.483652 11684 solver.cpp:228] Iteration 89000, loss = 0.00767679
I0930 02:05:33.483652 11684 solver.cpp:244]     Train net output #0: loss = 0.00767745 (* 1 = 0.00767745 loss)
I0930 02:05:33.483652 11684 sgd_solver.cpp:106] Iteration 89000, lr = 0.001
I0930 02:05:52.655405 11684 solver.cpp:228] Iteration 89100, loss = 0.00989277
I0930 02:05:52.655405 11684 solver.cpp:244]     Train net output #0: loss = 0.00989343 (* 1 = 0.00989343 loss)
I0930 02:05:52.655405 11684 sgd_solver.cpp:106] Iteration 89100, lr = 0.001
I0930 02:06:11.841810 11684 solver.cpp:228] Iteration 89200, loss = 0.0163729
I0930 02:06:11.841810 11684 solver.cpp:244]     Train net output #0: loss = 0.0163736 (* 1 = 0.0163736 loss)
I0930 02:06:11.841810 11684 sgd_solver.cpp:106] Iteration 89200, lr = 0.001
I0930 02:06:31.025219 11684 solver.cpp:228] Iteration 89300, loss = 0.00898654
I0930 02:06:31.025219 11684 solver.cpp:244]     Train net output #0: loss = 0.0089872 (* 1 = 0.0089872 loss)
I0930 02:06:31.025219 11684 sgd_solver.cpp:106] Iteration 89300, lr = 0.001
I0930 02:06:50.209836 11684 solver.cpp:228] Iteration 89400, loss = 0.00938288
I0930 02:06:50.209836 11684 solver.cpp:244]     Train net output #0: loss = 0.00938354 (* 1 = 0.00938354 loss)
I0930 02:06:50.209836 11684 sgd_solver.cpp:106] Iteration 89400, lr = 0.001
I0930 02:07:09.380192 11684 solver.cpp:228] Iteration 89500, loss = 0.0147194
I0930 02:07:09.380192 11684 solver.cpp:244]     Train net output #0: loss = 0.01472 (* 1 = 0.01472 loss)
I0930 02:07:09.380192 11684 sgd_solver.cpp:106] Iteration 89500, lr = 0.001
I0930 02:07:28.582820 11684 solver.cpp:228] Iteration 89600, loss = 0.0152166
I0930 02:07:28.582820 11684 solver.cpp:244]     Train net output #0: loss = 0.0152173 (* 1 = 0.0152173 loss)
I0930 02:07:28.582820 11684 sgd_solver.cpp:106] Iteration 89600, lr = 0.001
I0930 02:07:47.757099 11684 solver.cpp:228] Iteration 89700, loss = 0.00978691
I0930 02:07:47.757099 11684 solver.cpp:244]     Train net output #0: loss = 0.00978757 (* 1 = 0.00978757 loss)
I0930 02:07:47.757099 11684 sgd_solver.cpp:106] Iteration 89700, lr = 0.001
I0930 02:08:06.935075 11684 solver.cpp:228] Iteration 89800, loss = 0.0105571
I0930 02:08:06.935075 11684 solver.cpp:244]     Train net output #0: loss = 0.0105577 (* 1 = 0.0105577 loss)
I0930 02:08:06.935075 11684 sgd_solver.cpp:106] Iteration 89800, lr = 0.001
I0930 02:08:26.107213 11684 solver.cpp:228] Iteration 89900, loss = 0.00994508
I0930 02:08:26.107213 11684 solver.cpp:244]     Train net output #0: loss = 0.00994573 (* 1 = 0.00994573 loss)
I0930 02:08:26.107213 11684 sgd_solver.cpp:106] Iteration 89900, lr = 0.001
I0930 02:08:45.247782 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_90000.caffemodel
I0930 02:08:45.865476 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_90000.solverstate
I0930 02:08:46.236739 11684 solver.cpp:337] Iteration 90000, Testing net (#0)
I0930 02:08:54.419313 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7356
I0930 02:08:54.419313 11684 solver.cpp:404]     Test net output #1: loss = 1.09569 (* 1 = 1.09569 loss)
I0930 02:08:54.469348 11684 solver.cpp:228] Iteration 90000, loss = 0.0272294
I0930 02:08:54.470350 11684 solver.cpp:244]     Train net output #0: loss = 0.0272301 (* 1 = 0.0272301 loss)
I0930 02:08:54.470350 11684 sgd_solver.cpp:106] Iteration 90000, lr = 0.001
I0930 02:09:13.666021 11684 solver.cpp:228] Iteration 90100, loss = 0.0111804
I0930 02:09:13.667022 11684 solver.cpp:244]     Train net output #0: loss = 0.011181 (* 1 = 0.011181 loss)
I0930 02:09:13.667022 11684 sgd_solver.cpp:106] Iteration 90100, lr = 0.001
I0930 02:09:32.844646 11684 solver.cpp:228] Iteration 90200, loss = 0.0125335
I0930 02:09:32.844646 11684 solver.cpp:244]     Train net output #0: loss = 0.0125342 (* 1 = 0.0125342 loss)
I0930 02:09:32.844646 11684 sgd_solver.cpp:106] Iteration 90200, lr = 0.001
I0930 02:09:52.048264 11684 solver.cpp:228] Iteration 90300, loss = 0.0102952
I0930 02:09:52.048264 11684 solver.cpp:244]     Train net output #0: loss = 0.0102958 (* 1 = 0.0102958 loss)
I0930 02:09:52.048264 11684 sgd_solver.cpp:106] Iteration 90300, lr = 0.001
I0930 02:10:11.232976 11684 solver.cpp:228] Iteration 90400, loss = 0.00915861
I0930 02:10:11.233976 11684 solver.cpp:244]     Train net output #0: loss = 0.00915926 (* 1 = 0.00915926 loss)
I0930 02:10:11.233976 11684 sgd_solver.cpp:106] Iteration 90400, lr = 0.001
I0930 02:10:30.433653 11684 solver.cpp:228] Iteration 90500, loss = 0.0190841
I0930 02:10:30.433653 11684 solver.cpp:244]     Train net output #0: loss = 0.0190848 (* 1 = 0.0190848 loss)
I0930 02:10:30.433653 11684 sgd_solver.cpp:106] Iteration 90500, lr = 0.001
I0930 02:10:49.613252 11684 solver.cpp:228] Iteration 90600, loss = 0.00588196
I0930 02:10:49.613252 11684 solver.cpp:244]     Train net output #0: loss = 0.00588261 (* 1 = 0.00588261 loss)
I0930 02:10:49.613252 11684 sgd_solver.cpp:106] Iteration 90600, lr = 0.001
I0930 02:11:08.820885 11684 solver.cpp:228] Iteration 90700, loss = 0.00893859
I0930 02:11:08.820885 11684 solver.cpp:244]     Train net output #0: loss = 0.00893924 (* 1 = 0.00893924 loss)
I0930 02:11:08.820885 11684 sgd_solver.cpp:106] Iteration 90700, lr = 0.001
I0930 02:11:28.008518 11684 solver.cpp:228] Iteration 90800, loss = 0.00848526
I0930 02:11:28.008518 11684 solver.cpp:244]     Train net output #0: loss = 0.00848592 (* 1 = 0.00848592 loss)
I0930 02:11:28.008518 11684 sgd_solver.cpp:106] Iteration 90800, lr = 0.001
I0930 02:11:47.206143 11684 solver.cpp:228] Iteration 90900, loss = 0.010886
I0930 02:11:47.206143 11684 solver.cpp:244]     Train net output #0: loss = 0.0108866 (* 1 = 0.0108866 loss)
I0930 02:11:47.206143 11684 sgd_solver.cpp:106] Iteration 90900, lr = 0.001
I0930 02:12:06.346729 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_91000.caffemodel
I0930 02:12:06.943153 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_91000.solverstate
I0930 02:12:07.310412 11684 solver.cpp:337] Iteration 91000, Testing net (#0)
I0930 02:12:15.474206 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7384
I0930 02:12:15.474206 11684 solver.cpp:404]     Test net output #1: loss = 1.0993 (* 1 = 1.0993 loss)
I0930 02:12:15.524242 11684 solver.cpp:228] Iteration 91000, loss = 0.013671
I0930 02:12:15.524242 11684 solver.cpp:244]     Train net output #0: loss = 0.0136716 (* 1 = 0.0136716 loss)
I0930 02:12:15.524242 11684 sgd_solver.cpp:106] Iteration 91000, lr = 0.001
I0930 02:12:34.692847 11684 solver.cpp:228] Iteration 91100, loss = 0.0126855
I0930 02:12:34.692847 11684 solver.cpp:244]     Train net output #0: loss = 0.0126861 (* 1 = 0.0126861 loss)
I0930 02:12:34.692847 11684 sgd_solver.cpp:106] Iteration 91100, lr = 0.001
I0930 02:12:53.867455 11684 solver.cpp:228] Iteration 91200, loss = 0.0110805
I0930 02:12:53.867455 11684 solver.cpp:244]     Train net output #0: loss = 0.0110812 (* 1 = 0.0110812 loss)
I0930 02:12:53.867455 11684 sgd_solver.cpp:106] Iteration 91200, lr = 0.001
I0930 02:13:13.049877 11684 solver.cpp:228] Iteration 91300, loss = 0.0138221
I0930 02:13:13.049877 11684 solver.cpp:244]     Train net output #0: loss = 0.0138228 (* 1 = 0.0138228 loss)
I0930 02:13:13.049877 11684 sgd_solver.cpp:106] Iteration 91300, lr = 0.001
I0930 02:13:32.232022 11684 solver.cpp:228] Iteration 91400, loss = 0.00964046
I0930 02:13:32.232022 11684 solver.cpp:244]     Train net output #0: loss = 0.00964111 (* 1 = 0.00964111 loss)
I0930 02:13:32.232022 11684 sgd_solver.cpp:106] Iteration 91400, lr = 0.001
I0930 02:13:51.406671 11684 solver.cpp:228] Iteration 91500, loss = 0.00708765
I0930 02:13:51.407671 11684 solver.cpp:244]     Train net output #0: loss = 0.0070883 (* 1 = 0.0070883 loss)
I0930 02:13:51.407671 11684 sgd_solver.cpp:106] Iteration 91500, lr = 0.001
I0930 02:14:10.575579 11684 solver.cpp:228] Iteration 91600, loss = 0.0102626
I0930 02:14:10.575579 11684 solver.cpp:244]     Train net output #0: loss = 0.0102633 (* 1 = 0.0102633 loss)
I0930 02:14:10.575579 11684 sgd_solver.cpp:106] Iteration 91600, lr = 0.001
I0930 02:14:29.750951 11684 solver.cpp:228] Iteration 91700, loss = 0.00938447
I0930 02:14:29.750951 11684 solver.cpp:244]     Train net output #0: loss = 0.00938512 (* 1 = 0.00938512 loss)
I0930 02:14:29.750951 11684 sgd_solver.cpp:106] Iteration 91700, lr = 0.001
I0930 02:14:48.942317 11684 solver.cpp:228] Iteration 91800, loss = 0.00884901
I0930 02:14:48.943318 11684 solver.cpp:244]     Train net output #0: loss = 0.00884966 (* 1 = 0.00884966 loss)
I0930 02:14:48.943318 11684 sgd_solver.cpp:106] Iteration 91800, lr = 0.001
I0930 02:15:08.120597 11684 solver.cpp:228] Iteration 91900, loss = 0.0181958
I0930 02:15:08.120597 11684 solver.cpp:244]     Train net output #0: loss = 0.0181964 (* 1 = 0.0181964 loss)
I0930 02:15:08.120597 11684 sgd_solver.cpp:106] Iteration 91900, lr = 0.001
I0930 02:15:27.265184 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_92000.caffemodel
I0930 02:15:27.871616 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_92000.solverstate
I0930 02:15:28.241878 11684 solver.cpp:337] Iteration 92000, Testing net (#0)
I0930 02:15:36.401463 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7355
I0930 02:15:36.401463 11684 solver.cpp:404]     Test net output #1: loss = 1.09047 (* 1 = 1.09047 loss)
I0930 02:15:36.450497 11684 solver.cpp:228] Iteration 92000, loss = 0.0141913
I0930 02:15:36.450497 11684 solver.cpp:244]     Train net output #0: loss = 0.014192 (* 1 = 0.014192 loss)
I0930 02:15:36.451498 11684 sgd_solver.cpp:106] Iteration 92000, lr = 0.001
I0930 02:15:55.629109 11684 solver.cpp:228] Iteration 92100, loss = 0.0164073
I0930 02:15:55.629109 11684 solver.cpp:244]     Train net output #0: loss = 0.016408 (* 1 = 0.016408 loss)
I0930 02:15:55.629109 11684 sgd_solver.cpp:106] Iteration 92100, lr = 0.001
I0930 02:16:14.798714 11684 solver.cpp:228] Iteration 92200, loss = 0.0074379
I0930 02:16:14.798714 11684 solver.cpp:244]     Train net output #0: loss = 0.00743856 (* 1 = 0.00743856 loss)
I0930 02:16:14.798714 11684 sgd_solver.cpp:106] Iteration 92200, lr = 0.001
I0930 02:16:33.974555 11684 solver.cpp:228] Iteration 92300, loss = 0.0139536
I0930 02:16:33.974555 11684 solver.cpp:244]     Train net output #0: loss = 0.0139542 (* 1 = 0.0139542 loss)
I0930 02:16:33.974555 11684 sgd_solver.cpp:106] Iteration 92300, lr = 0.001
I0930 02:16:53.148633 11684 solver.cpp:228] Iteration 92400, loss = 0.013855
I0930 02:16:53.148633 11684 solver.cpp:244]     Train net output #0: loss = 0.0138557 (* 1 = 0.0138557 loss)
I0930 02:16:53.148633 11684 sgd_solver.cpp:106] Iteration 92400, lr = 0.001
I0930 02:17:12.319238 11684 solver.cpp:228] Iteration 92500, loss = 0.0151948
I0930 02:17:12.319238 11684 solver.cpp:244]     Train net output #0: loss = 0.0151955 (* 1 = 0.0151955 loss)
I0930 02:17:12.320238 11684 sgd_solver.cpp:106] Iteration 92500, lr = 0.001
I0930 02:17:31.495700 11684 solver.cpp:228] Iteration 92600, loss = 0.011556
I0930 02:17:31.495700 11684 solver.cpp:244]     Train net output #0: loss = 0.0115567 (* 1 = 0.0115567 loss)
I0930 02:17:31.495700 11684 sgd_solver.cpp:106] Iteration 92600, lr = 0.001
I0930 02:17:50.668308 11684 solver.cpp:228] Iteration 92700, loss = 0.0155738
I0930 02:17:50.668308 11684 solver.cpp:244]     Train net output #0: loss = 0.0155745 (* 1 = 0.0155745 loss)
I0930 02:17:50.669308 11684 sgd_solver.cpp:106] Iteration 92700, lr = 0.001
I0930 02:18:09.866082 11684 solver.cpp:228] Iteration 92800, loss = 0.00927126
I0930 02:18:09.866082 11684 solver.cpp:244]     Train net output #0: loss = 0.00927193 (* 1 = 0.00927193 loss)
I0930 02:18:09.866082 11684 sgd_solver.cpp:106] Iteration 92800, lr = 0.001
I0930 02:18:29.046710 11684 solver.cpp:228] Iteration 92900, loss = 0.00838226
I0930 02:18:29.047710 11684 solver.cpp:244]     Train net output #0: loss = 0.00838293 (* 1 = 0.00838293 loss)
I0930 02:18:29.047710 11684 sgd_solver.cpp:106] Iteration 92900, lr = 0.001
I0930 02:18:48.173019 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_93000.caffemodel
I0930 02:18:48.768442 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_93000.solverstate
I0930 02:18:49.136703 11684 solver.cpp:337] Iteration 93000, Testing net (#0)
I0930 02:18:57.309504 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7393
I0930 02:18:57.309504 11684 solver.cpp:404]     Test net output #1: loss = 1.09043 (* 1 = 1.09043 loss)
I0930 02:18:57.359539 11684 solver.cpp:228] Iteration 93000, loss = 0.00973557
I0930 02:18:57.359539 11684 solver.cpp:244]     Train net output #0: loss = 0.00973623 (* 1 = 0.00973623 loss)
I0930 02:18:57.359539 11684 sgd_solver.cpp:106] Iteration 93000, lr = 0.001
I0930 02:19:16.536026 11684 solver.cpp:228] Iteration 93100, loss = 0.0127629
I0930 02:19:16.536026 11684 solver.cpp:244]     Train net output #0: loss = 0.0127635 (* 1 = 0.0127635 loss)
I0930 02:19:16.536026 11684 sgd_solver.cpp:106] Iteration 93100, lr = 0.001
I0930 02:19:35.730757 11684 solver.cpp:228] Iteration 93200, loss = 0.0119219
I0930 02:19:35.730757 11684 solver.cpp:244]     Train net output #0: loss = 0.0119226 (* 1 = 0.0119226 loss)
I0930 02:19:35.730757 11684 sgd_solver.cpp:106] Iteration 93200, lr = 0.001
I0930 02:19:54.915202 11684 solver.cpp:228] Iteration 93300, loss = 0.0141184
I0930 02:19:54.915202 11684 solver.cpp:244]     Train net output #0: loss = 0.0141191 (* 1 = 0.0141191 loss)
I0930 02:19:54.915202 11684 sgd_solver.cpp:106] Iteration 93300, lr = 0.001
I0930 02:20:14.099632 11684 solver.cpp:228] Iteration 93400, loss = 0.0137281
I0930 02:20:14.099632 11684 solver.cpp:244]     Train net output #0: loss = 0.0137288 (* 1 = 0.0137288 loss)
I0930 02:20:14.099632 11684 sgd_solver.cpp:106] Iteration 93400, lr = 0.001
I0930 02:20:33.306689 11684 solver.cpp:228] Iteration 93500, loss = 0.0160767
I0930 02:20:33.306689 11684 solver.cpp:244]     Train net output #0: loss = 0.0160773 (* 1 = 0.0160773 loss)
I0930 02:20:33.306689 11684 sgd_solver.cpp:106] Iteration 93500, lr = 0.001
I0930 02:20:52.492079 11684 solver.cpp:228] Iteration 93600, loss = 0.011022
I0930 02:20:52.493080 11684 solver.cpp:244]     Train net output #0: loss = 0.0110227 (* 1 = 0.0110227 loss)
I0930 02:20:52.493080 11684 sgd_solver.cpp:106] Iteration 93600, lr = 0.001
I0930 02:21:11.666895 11684 solver.cpp:228] Iteration 93700, loss = 0.0109246
I0930 02:21:11.666895 11684 solver.cpp:244]     Train net output #0: loss = 0.0109252 (* 1 = 0.0109252 loss)
I0930 02:21:11.666895 11684 sgd_solver.cpp:106] Iteration 93700, lr = 0.001
I0930 02:21:30.848523 11684 solver.cpp:228] Iteration 93800, loss = 0.0112029
I0930 02:21:30.848523 11684 solver.cpp:244]     Train net output #0: loss = 0.0112036 (* 1 = 0.0112036 loss)
I0930 02:21:30.848523 11684 sgd_solver.cpp:106] Iteration 93800, lr = 0.001
I0930 02:21:50.028123 11684 solver.cpp:228] Iteration 93900, loss = 0.0111047
I0930 02:21:50.028123 11684 solver.cpp:244]     Train net output #0: loss = 0.0111054 (* 1 = 0.0111054 loss)
I0930 02:21:50.028123 11684 sgd_solver.cpp:106] Iteration 93900, lr = 0.001
I0930 02:22:09.154384 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_94000.caffemodel
I0930 02:22:09.741802 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_94000.solverstate
I0930 02:22:10.101771 11684 solver.cpp:337] Iteration 94000, Testing net (#0)
I0930 02:22:18.288390 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7387
I0930 02:22:18.288390 11684 solver.cpp:404]     Test net output #1: loss = 1.08382 (* 1 = 1.08382 loss)
I0930 02:22:18.338413 11684 solver.cpp:228] Iteration 94000, loss = 0.0110932
I0930 02:22:18.338413 11684 solver.cpp:244]     Train net output #0: loss = 0.0110939 (* 1 = 0.0110939 loss)
I0930 02:22:18.338413 11684 sgd_solver.cpp:106] Iteration 94000, lr = 0.001
I0930 02:22:37.516036 11684 solver.cpp:228] Iteration 94100, loss = 0.0165343
I0930 02:22:37.516036 11684 solver.cpp:244]     Train net output #0: loss = 0.016535 (* 1 = 0.016535 loss)
I0930 02:22:37.516036 11684 sgd_solver.cpp:106] Iteration 94100, lr = 0.001
I0930 02:22:56.701640 11684 solver.cpp:228] Iteration 94200, loss = 0.0109028
I0930 02:22:56.701640 11684 solver.cpp:244]     Train net output #0: loss = 0.0109034 (* 1 = 0.0109034 loss)
I0930 02:22:56.701640 11684 sgd_solver.cpp:106] Iteration 94200, lr = 0.001
I0930 02:23:15.886031 11684 solver.cpp:228] Iteration 94300, loss = 0.0106788
I0930 02:23:15.886031 11684 solver.cpp:244]     Train net output #0: loss = 0.0106795 (* 1 = 0.0106795 loss)
I0930 02:23:15.886031 11684 sgd_solver.cpp:106] Iteration 94300, lr = 0.001
I0930 02:23:35.074759 11684 solver.cpp:228] Iteration 94400, loss = 0.0141132
I0930 02:23:35.074759 11684 solver.cpp:244]     Train net output #0: loss = 0.0141139 (* 1 = 0.0141139 loss)
I0930 02:23:35.074759 11684 sgd_solver.cpp:106] Iteration 94400, lr = 0.001
I0930 02:23:54.267424 11684 solver.cpp:228] Iteration 94500, loss = 0.0102552
I0930 02:23:54.267424 11684 solver.cpp:244]     Train net output #0: loss = 0.0102559 (* 1 = 0.0102559 loss)
I0930 02:23:54.267424 11684 sgd_solver.cpp:106] Iteration 94500, lr = 0.001
I0930 02:24:13.448098 11684 solver.cpp:228] Iteration 94600, loss = 0.0138585
I0930 02:24:13.448098 11684 solver.cpp:244]     Train net output #0: loss = 0.0138592 (* 1 = 0.0138592 loss)
I0930 02:24:13.448098 11684 sgd_solver.cpp:106] Iteration 94600, lr = 0.001
I0930 02:24:32.632295 11684 solver.cpp:228] Iteration 94700, loss = 0.00748034
I0930 02:24:32.632295 11684 solver.cpp:244]     Train net output #0: loss = 0.00748102 (* 1 = 0.00748102 loss)
I0930 02:24:32.632295 11684 sgd_solver.cpp:106] Iteration 94700, lr = 0.001
I0930 02:24:51.808773 11684 solver.cpp:228] Iteration 94800, loss = 0.0150536
I0930 02:24:51.809774 11684 solver.cpp:244]     Train net output #0: loss = 0.0150542 (* 1 = 0.0150542 loss)
I0930 02:24:51.809774 11684 sgd_solver.cpp:106] Iteration 94800, lr = 0.001
I0930 02:25:10.986407 11684 solver.cpp:228] Iteration 94900, loss = 0.0100458
I0930 02:25:10.986407 11684 solver.cpp:244]     Train net output #0: loss = 0.0100465 (* 1 = 0.0100465 loss)
I0930 02:25:10.986407 11684 sgd_solver.cpp:106] Iteration 94900, lr = 0.001
I0930 02:25:30.120987 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_95000.caffemodel
I0930 02:25:30.708405 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_95000.solverstate
I0930 02:25:31.063657 11684 solver.cpp:337] Iteration 95000, Testing net (#0)
I0930 02:25:39.244763 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7343
I0930 02:25:39.244763 11684 solver.cpp:404]     Test net output #1: loss = 1.10321 (* 1 = 1.10321 loss)
I0930 02:25:39.294798 11684 solver.cpp:228] Iteration 95000, loss = 0.0155846
I0930 02:25:39.294798 11684 solver.cpp:244]     Train net output #0: loss = 0.0155853 (* 1 = 0.0155853 loss)
I0930 02:25:39.294798 11684 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0930 02:25:58.469455 11684 solver.cpp:228] Iteration 95100, loss = 0.0157796
I0930 02:25:58.469455 11684 solver.cpp:244]     Train net output #0: loss = 0.0157803 (* 1 = 0.0157803 loss)
I0930 02:25:58.469455 11684 sgd_solver.cpp:106] Iteration 95100, lr = 0.001
I0930 02:26:17.640327 11684 solver.cpp:228] Iteration 95200, loss = 0.00687064
I0930 02:26:17.640327 11684 solver.cpp:244]     Train net output #0: loss = 0.00687131 (* 1 = 0.00687131 loss)
I0930 02:26:17.640327 11684 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0930 02:26:36.820953 11684 solver.cpp:228] Iteration 95300, loss = 0.0100836
I0930 02:26:36.820953 11684 solver.cpp:244]     Train net output #0: loss = 0.0100843 (* 1 = 0.0100843 loss)
I0930 02:26:36.820953 11684 sgd_solver.cpp:106] Iteration 95300, lr = 0.001
I0930 02:26:56.006906 11684 solver.cpp:228] Iteration 95400, loss = 0.00582126
I0930 02:26:56.007906 11684 solver.cpp:244]     Train net output #0: loss = 0.00582193 (* 1 = 0.00582193 loss)
I0930 02:26:56.007906 11684 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0930 02:27:15.186517 11684 solver.cpp:228] Iteration 95500, loss = 0.0101344
I0930 02:27:15.186517 11684 solver.cpp:244]     Train net output #0: loss = 0.0101351 (* 1 = 0.0101351 loss)
I0930 02:27:15.186517 11684 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0930 02:27:34.368132 11684 solver.cpp:228] Iteration 95600, loss = 0.00926231
I0930 02:27:34.368132 11684 solver.cpp:244]     Train net output #0: loss = 0.00926298 (* 1 = 0.00926298 loss)
I0930 02:27:34.368132 11684 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0930 02:27:53.548228 11684 solver.cpp:228] Iteration 95700, loss = 0.0161373
I0930 02:27:53.548228 11684 solver.cpp:244]     Train net output #0: loss = 0.016138 (* 1 = 0.016138 loss)
I0930 02:27:53.548228 11684 sgd_solver.cpp:106] Iteration 95700, lr = 0.001
I0930 02:28:12.742122 11684 solver.cpp:228] Iteration 95800, loss = 0.0175452
I0930 02:28:12.742122 11684 solver.cpp:244]     Train net output #0: loss = 0.0175459 (* 1 = 0.0175459 loss)
I0930 02:28:12.743122 11684 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0930 02:28:31.926730 11684 solver.cpp:228] Iteration 95900, loss = 0.00672763
I0930 02:28:31.926730 11684 solver.cpp:244]     Train net output #0: loss = 0.00672831 (* 1 = 0.00672831 loss)
I0930 02:28:31.926730 11684 sgd_solver.cpp:106] Iteration 95900, lr = 0.001
I0930 02:28:51.076321 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_96000.caffemodel
I0930 02:28:51.664741 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_96000.solverstate
I0930 02:28:52.113669 11684 solver.cpp:337] Iteration 96000, Testing net (#0)
I0930 02:29:00.282467 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7391
I0930 02:29:00.282467 11684 solver.cpp:404]     Test net output #1: loss = 1.07993 (* 1 = 1.07993 loss)
I0930 02:29:00.332502 11684 solver.cpp:228] Iteration 96000, loss = 0.0106394
I0930 02:29:00.332502 11684 solver.cpp:244]     Train net output #0: loss = 0.0106401 (* 1 = 0.0106401 loss)
I0930 02:29:00.332502 11684 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0930 02:29:19.506115 11684 solver.cpp:228] Iteration 96100, loss = 0.0132855
I0930 02:29:19.506115 11684 solver.cpp:244]     Train net output #0: loss = 0.0132862 (* 1 = 0.0132862 loss)
I0930 02:29:19.506115 11684 sgd_solver.cpp:106] Iteration 96100, lr = 0.001
I0930 02:29:38.692733 11684 solver.cpp:228] Iteration 96200, loss = 0.00910702
I0930 02:29:38.692733 11684 solver.cpp:244]     Train net output #0: loss = 0.00910769 (* 1 = 0.00910769 loss)
I0930 02:29:38.692733 11684 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0930 02:29:57.852649 11684 solver.cpp:228] Iteration 96300, loss = 0.020931
I0930 02:29:57.852649 11684 solver.cpp:244]     Train net output #0: loss = 0.0209317 (* 1 = 0.0209317 loss)
I0930 02:29:57.852649 11684 sgd_solver.cpp:106] Iteration 96300, lr = 0.001
I0930 02:30:17.040498 11684 solver.cpp:228] Iteration 96400, loss = 0.00713949
I0930 02:30:17.040498 11684 solver.cpp:244]     Train net output #0: loss = 0.00714016 (* 1 = 0.00714016 loss)
I0930 02:30:17.040498 11684 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0930 02:30:36.215402 11684 solver.cpp:228] Iteration 96500, loss = 0.0105177
I0930 02:30:36.215402 11684 solver.cpp:244]     Train net output #0: loss = 0.0105183 (* 1 = 0.0105183 loss)
I0930 02:30:36.215402 11684 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0930 02:30:55.395815 11684 solver.cpp:228] Iteration 96600, loss = 0.0136349
I0930 02:30:55.395815 11684 solver.cpp:244]     Train net output #0: loss = 0.0136356 (* 1 = 0.0136356 loss)
I0930 02:30:55.395815 11684 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0930 02:31:14.571810 11684 solver.cpp:228] Iteration 96700, loss = 0.0100493
I0930 02:31:14.571810 11684 solver.cpp:244]     Train net output #0: loss = 0.01005 (* 1 = 0.01005 loss)
I0930 02:31:14.571810 11684 sgd_solver.cpp:106] Iteration 96700, lr = 0.001
I0930 02:31:33.745417 11684 solver.cpp:228] Iteration 96800, loss = 0.00889221
I0930 02:31:33.745417 11684 solver.cpp:244]     Train net output #0: loss = 0.00889288 (* 1 = 0.00889288 loss)
I0930 02:31:33.745417 11684 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0930 02:31:52.916255 11684 solver.cpp:228] Iteration 96900, loss = 0.0114962
I0930 02:31:52.916255 11684 solver.cpp:244]     Train net output #0: loss = 0.0114968 (* 1 = 0.0114968 loss)
I0930 02:31:52.916255 11684 sgd_solver.cpp:106] Iteration 96900, lr = 0.001
I0930 02:32:12.046833 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_97000.caffemodel
I0930 02:32:12.639252 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_97000.solverstate
I0930 02:32:12.996506 11684 solver.cpp:337] Iteration 97000, Testing net (#0)
I0930 02:32:21.157297 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7365
I0930 02:32:21.157297 11684 solver.cpp:404]     Test net output #1: loss = 1.09322 (* 1 = 1.09322 loss)
I0930 02:32:21.207334 11684 solver.cpp:228] Iteration 97000, loss = 0.0086616
I0930 02:32:21.207334 11684 solver.cpp:244]     Train net output #0: loss = 0.00866228 (* 1 = 0.00866228 loss)
I0930 02:32:21.207334 11684 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0930 02:32:40.390405 11684 solver.cpp:228] Iteration 97100, loss = 0.0139543
I0930 02:32:40.391405 11684 solver.cpp:244]     Train net output #0: loss = 0.0139549 (* 1 = 0.0139549 loss)
I0930 02:32:40.391405 11684 sgd_solver.cpp:106] Iteration 97100, lr = 0.001
I0930 02:32:59.554021 11684 solver.cpp:228] Iteration 97200, loss = 0.00836546
I0930 02:32:59.554021 11684 solver.cpp:244]     Train net output #0: loss = 0.00836613 (* 1 = 0.00836613 loss)
I0930 02:32:59.554021 11684 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0930 02:33:18.732633 11684 solver.cpp:228] Iteration 97300, loss = 0.0123823
I0930 02:33:18.732633 11684 solver.cpp:244]     Train net output #0: loss = 0.0123829 (* 1 = 0.0123829 loss)
I0930 02:33:18.732633 11684 sgd_solver.cpp:106] Iteration 97300, lr = 0.001
I0930 02:33:37.910579 11684 solver.cpp:228] Iteration 97400, loss = 0.0129755
I0930 02:33:37.910579 11684 solver.cpp:244]     Train net output #0: loss = 0.0129762 (* 1 = 0.0129762 loss)
I0930 02:33:37.910579 11684 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0930 02:33:57.086189 11684 solver.cpp:228] Iteration 97500, loss = 0.022809
I0930 02:33:57.086189 11684 solver.cpp:244]     Train net output #0: loss = 0.0228096 (* 1 = 0.0228096 loss)
I0930 02:33:57.086189 11684 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0930 02:34:16.264801 11684 solver.cpp:228] Iteration 97600, loss = 0.0145504
I0930 02:34:16.264801 11684 solver.cpp:244]     Train net output #0: loss = 0.0145511 (* 1 = 0.0145511 loss)
I0930 02:34:16.264801 11684 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0930 02:34:35.445427 11684 solver.cpp:228] Iteration 97700, loss = 0.0090939
I0930 02:34:35.445427 11684 solver.cpp:244]     Train net output #0: loss = 0.00909457 (* 1 = 0.00909457 loss)
I0930 02:34:35.445427 11684 sgd_solver.cpp:106] Iteration 97700, lr = 0.001
I0930 02:34:54.608362 11684 solver.cpp:228] Iteration 97800, loss = 0.012455
I0930 02:34:54.608362 11684 solver.cpp:244]     Train net output #0: loss = 0.0124556 (* 1 = 0.0124556 loss)
I0930 02:34:54.608362 11684 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0930 02:35:13.794589 11684 solver.cpp:228] Iteration 97900, loss = 0.00833399
I0930 02:35:13.794589 11684 solver.cpp:244]     Train net output #0: loss = 0.00833466 (* 1 = 0.00833466 loss)
I0930 02:35:13.794589 11684 sgd_solver.cpp:106] Iteration 97900, lr = 0.001
I0930 02:35:32.915662 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_98000.caffemodel
I0930 02:35:33.523092 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_98000.solverstate
I0930 02:35:33.874341 11684 solver.cpp:337] Iteration 98000, Testing net (#0)
I0930 02:35:42.035800 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7403
I0930 02:35:42.035800 11684 solver.cpp:404]     Test net output #1: loss = 1.08916 (* 1 = 1.08916 loss)
I0930 02:35:42.085849 11684 solver.cpp:228] Iteration 98000, loss = 0.00933287
I0930 02:35:42.085849 11684 solver.cpp:244]     Train net output #0: loss = 0.00933355 (* 1 = 0.00933355 loss)
I0930 02:35:42.085849 11684 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0930 02:36:01.268450 11684 solver.cpp:228] Iteration 98100, loss = 0.00975468
I0930 02:36:01.268450 11684 solver.cpp:244]     Train net output #0: loss = 0.00975536 (* 1 = 0.00975536 loss)
I0930 02:36:01.268450 11684 sgd_solver.cpp:106] Iteration 98100, lr = 0.001
I0930 02:36:20.450449 11684 solver.cpp:228] Iteration 98200, loss = 0.00905597
I0930 02:36:20.450449 11684 solver.cpp:244]     Train net output #0: loss = 0.00905664 (* 1 = 0.00905664 loss)
I0930 02:36:20.450449 11684 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0930 02:36:39.623728 11684 solver.cpp:228] Iteration 98300, loss = 0.0117556
I0930 02:36:39.623728 11684 solver.cpp:244]     Train net output #0: loss = 0.0117563 (* 1 = 0.0117563 loss)
I0930 02:36:39.623728 11684 sgd_solver.cpp:106] Iteration 98300, lr = 0.001
I0930 02:36:58.803727 11684 solver.cpp:228] Iteration 98400, loss = 0.011739
I0930 02:36:58.803727 11684 solver.cpp:244]     Train net output #0: loss = 0.0117397 (* 1 = 0.0117397 loss)
I0930 02:36:58.803727 11684 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0930 02:37:17.983440 11684 solver.cpp:228] Iteration 98500, loss = 0.00638583
I0930 02:37:17.983440 11684 solver.cpp:244]     Train net output #0: loss = 0.00638651 (* 1 = 0.00638651 loss)
I0930 02:37:17.983440 11684 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0930 02:37:37.157773 11684 solver.cpp:228] Iteration 98600, loss = 0.0192982
I0930 02:37:37.157773 11684 solver.cpp:244]     Train net output #0: loss = 0.0192989 (* 1 = 0.0192989 loss)
I0930 02:37:37.157773 11684 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0930 02:37:56.332469 11684 solver.cpp:228] Iteration 98700, loss = 0.0143178
I0930 02:37:56.332469 11684 solver.cpp:244]     Train net output #0: loss = 0.0143185 (* 1 = 0.0143185 loss)
I0930 02:37:56.332469 11684 sgd_solver.cpp:106] Iteration 98700, lr = 0.001
I0930 02:38:15.508141 11684 solver.cpp:228] Iteration 98800, loss = 0.0114482
I0930 02:38:15.508141 11684 solver.cpp:244]     Train net output #0: loss = 0.0114489 (* 1 = 0.0114489 loss)
I0930 02:38:15.508141 11684 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0930 02:38:34.693924 11684 solver.cpp:228] Iteration 98900, loss = 0.0129239
I0930 02:38:34.693924 11684 solver.cpp:244]     Train net output #0: loss = 0.0129246 (* 1 = 0.0129246 loss)
I0930 02:38:34.693924 11684 sgd_solver.cpp:106] Iteration 98900, lr = 0.001
I0930 02:38:53.851521 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_99000.caffemodel
I0930 02:38:54.453950 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_99000.solverstate
I0930 02:38:54.804904 11684 solver.cpp:337] Iteration 99000, Testing net (#0)
I0930 02:39:02.966559 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7394
I0930 02:39:02.966559 11684 solver.cpp:404]     Test net output #1: loss = 1.07685 (* 1 = 1.07685 loss)
I0930 02:39:03.018596 11684 solver.cpp:228] Iteration 99000, loss = 0.00870981
I0930 02:39:03.018596 11684 solver.cpp:244]     Train net output #0: loss = 0.00871049 (* 1 = 0.00871049 loss)
I0930 02:39:03.018596 11684 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0930 02:39:22.181251 11684 solver.cpp:228] Iteration 99100, loss = 0.0142513
I0930 02:39:22.181251 11684 solver.cpp:244]     Train net output #0: loss = 0.0142519 (* 1 = 0.0142519 loss)
I0930 02:39:22.181251 11684 sgd_solver.cpp:106] Iteration 99100, lr = 0.001
I0930 02:39:41.371455 11684 solver.cpp:228] Iteration 99200, loss = 0.00934092
I0930 02:39:41.371455 11684 solver.cpp:244]     Train net output #0: loss = 0.0093416 (* 1 = 0.0093416 loss)
I0930 02:39:41.371455 11684 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0930 02:40:00.551488 11684 solver.cpp:228] Iteration 99300, loss = 0.0116529
I0930 02:40:00.551488 11684 solver.cpp:244]     Train net output #0: loss = 0.0116536 (* 1 = 0.0116536 loss)
I0930 02:40:00.551488 11684 sgd_solver.cpp:106] Iteration 99300, lr = 0.001
I0930 02:40:19.737105 11684 solver.cpp:228] Iteration 99400, loss = 0.0146856
I0930 02:40:19.737105 11684 solver.cpp:244]     Train net output #0: loss = 0.0146863 (* 1 = 0.0146863 loss)
I0930 02:40:19.737105 11684 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0930 02:40:38.919790 11684 solver.cpp:228] Iteration 99500, loss = 0.0141212
I0930 02:40:38.920790 11684 solver.cpp:244]     Train net output #0: loss = 0.0141219 (* 1 = 0.0141219 loss)
I0930 02:40:38.920790 11684 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0930 02:40:58.090409 11684 solver.cpp:228] Iteration 99600, loss = 0.00970575
I0930 02:40:58.090409 11684 solver.cpp:244]     Train net output #0: loss = 0.00970643 (* 1 = 0.00970643 loss)
I0930 02:40:58.090409 11684 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0930 02:41:17.264004 11684 solver.cpp:228] Iteration 99700, loss = 0.0120835
I0930 02:41:17.264004 11684 solver.cpp:244]     Train net output #0: loss = 0.0120842 (* 1 = 0.0120842 loss)
I0930 02:41:17.264004 11684 sgd_solver.cpp:106] Iteration 99700, lr = 0.001
I0930 02:41:36.439312 11684 solver.cpp:228] Iteration 99800, loss = 0.00826957
I0930 02:41:36.439312 11684 solver.cpp:244]     Train net output #0: loss = 0.00827025 (* 1 = 0.00827025 loss)
I0930 02:41:36.439312 11684 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0930 02:41:55.614006 11684 solver.cpp:228] Iteration 99900, loss = 0.009804
I0930 02:41:55.614006 11684 solver.cpp:244]     Train net output #0: loss = 0.00980468 (* 1 = 0.00980468 loss)
I0930 02:41:55.615007 11684 sgd_solver.cpp:106] Iteration 99900, lr = 0.001
I0930 02:42:14.739567 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_100000.caffemodel
I0930 02:42:15.341995 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_100000.solverstate
I0930 02:42:15.691243 11684 solver.cpp:337] Iteration 100000, Testing net (#0)
I0930 02:42:23.852035 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7359
I0930 02:42:23.852035 11684 solver.cpp:404]     Test net output #1: loss = 1.08746 (* 1 = 1.08746 loss)
I0930 02:42:23.906075 11684 solver.cpp:228] Iteration 100000, loss = 0.0103208
I0930 02:42:23.906075 11684 solver.cpp:244]     Train net output #0: loss = 0.0103215 (* 1 = 0.0103215 loss)
I0930 02:42:23.906075 11684 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I0930 02:42:43.080682 11684 solver.cpp:228] Iteration 100100, loss = 0.0111477
I0930 02:42:43.080682 11684 solver.cpp:244]     Train net output #0: loss = 0.0111484 (* 1 = 0.0111484 loss)
I0930 02:42:43.080682 11684 sgd_solver.cpp:106] Iteration 100100, lr = 0.001
I0930 02:43:02.270303 11684 solver.cpp:228] Iteration 100200, loss = 0.0116235
I0930 02:43:02.270303 11684 solver.cpp:244]     Train net output #0: loss = 0.0116242 (* 1 = 0.0116242 loss)
I0930 02:43:02.270303 11684 sgd_solver.cpp:106] Iteration 100200, lr = 0.001
I0930 02:43:21.454918 11684 solver.cpp:228] Iteration 100300, loss = 0.0147932
I0930 02:43:21.454918 11684 solver.cpp:244]     Train net output #0: loss = 0.0147939 (* 1 = 0.0147939 loss)
I0930 02:43:21.454918 11684 sgd_solver.cpp:106] Iteration 100300, lr = 0.001
I0930 02:43:40.642699 11684 solver.cpp:228] Iteration 100400, loss = 0.0147606
I0930 02:43:40.642699 11684 solver.cpp:244]     Train net output #0: loss = 0.0147612 (* 1 = 0.0147612 loss)
I0930 02:43:40.642699 11684 sgd_solver.cpp:106] Iteration 100400, lr = 0.001
I0930 02:43:59.813069 11684 solver.cpp:228] Iteration 100500, loss = 0.0115243
I0930 02:43:59.813069 11684 solver.cpp:244]     Train net output #0: loss = 0.0115249 (* 1 = 0.0115249 loss)
I0930 02:43:59.813069 11684 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I0930 02:44:18.997879 11684 solver.cpp:228] Iteration 100600, loss = 0.0107979
I0930 02:44:18.997879 11684 solver.cpp:244]     Train net output #0: loss = 0.0107986 (* 1 = 0.0107986 loss)
I0930 02:44:18.997879 11684 sgd_solver.cpp:106] Iteration 100600, lr = 0.001
I0930 02:44:38.173951 11684 solver.cpp:228] Iteration 100700, loss = 0.0129821
I0930 02:44:38.173951 11684 solver.cpp:244]     Train net output #0: loss = 0.0129827 (* 1 = 0.0129827 loss)
I0930 02:44:38.173951 11684 sgd_solver.cpp:106] Iteration 100700, lr = 0.001
I0930 02:44:57.348122 11684 solver.cpp:228] Iteration 100800, loss = 0.0151792
I0930 02:44:57.348122 11684 solver.cpp:244]     Train net output #0: loss = 0.0151798 (* 1 = 0.0151798 loss)
I0930 02:44:57.348122 11684 sgd_solver.cpp:106] Iteration 100800, lr = 0.001
I0930 02:45:16.523030 11684 solver.cpp:228] Iteration 100900, loss = 0.00931307
I0930 02:45:16.523030 11684 solver.cpp:244]     Train net output #0: loss = 0.00931373 (* 1 = 0.00931373 loss)
I0930 02:45:16.523030 11684 sgd_solver.cpp:106] Iteration 100900, lr = 0.001
I0930 02:45:35.655609 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_101000.caffemodel
I0930 02:45:36.257050 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_101000.solverstate
I0930 02:45:36.611289 11684 solver.cpp:337] Iteration 101000, Testing net (#0)
I0930 02:45:44.789091 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0930 02:45:44.789091 11684 solver.cpp:404]     Test net output #1: loss = 1.09193 (* 1 = 1.09193 loss)
I0930 02:45:44.839128 11684 solver.cpp:228] Iteration 101000, loss = 0.011167
I0930 02:45:44.839128 11684 solver.cpp:244]     Train net output #0: loss = 0.0111676 (* 1 = 0.0111676 loss)
I0930 02:45:44.839128 11684 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I0930 02:46:04.034397 11684 solver.cpp:228] Iteration 101100, loss = 0.0120104
I0930 02:46:04.034397 11684 solver.cpp:244]     Train net output #0: loss = 0.0120111 (* 1 = 0.0120111 loss)
I0930 02:46:04.034397 11684 sgd_solver.cpp:106] Iteration 101100, lr = 0.001
I0930 02:46:23.217169 11684 solver.cpp:228] Iteration 101200, loss = 0.00674475
I0930 02:46:23.217169 11684 solver.cpp:244]     Train net output #0: loss = 0.00674541 (* 1 = 0.00674541 loss)
I0930 02:46:23.217169 11684 sgd_solver.cpp:106] Iteration 101200, lr = 0.001
I0930 02:46:42.403937 11684 solver.cpp:228] Iteration 101300, loss = 0.0101093
I0930 02:46:42.404937 11684 solver.cpp:244]     Train net output #0: loss = 0.01011 (* 1 = 0.01011 loss)
I0930 02:46:42.404937 11684 sgd_solver.cpp:106] Iteration 101300, lr = 0.001
I0930 02:47:01.591554 11684 solver.cpp:228] Iteration 101400, loss = 0.0113124
I0930 02:47:01.591554 11684 solver.cpp:244]     Train net output #0: loss = 0.0113131 (* 1 = 0.0113131 loss)
I0930 02:47:01.591554 11684 sgd_solver.cpp:106] Iteration 101400, lr = 0.001
I0930 02:47:20.770547 11684 solver.cpp:228] Iteration 101500, loss = 0.012075
I0930 02:47:20.770547 11684 solver.cpp:244]     Train net output #0: loss = 0.0120757 (* 1 = 0.0120757 loss)
I0930 02:47:20.770547 11684 sgd_solver.cpp:106] Iteration 101500, lr = 0.001
I0930 02:47:39.950160 11684 solver.cpp:228] Iteration 101600, loss = 0.00799291
I0930 02:47:39.950160 11684 solver.cpp:244]     Train net output #0: loss = 0.00799358 (* 1 = 0.00799358 loss)
I0930 02:47:39.950160 11684 sgd_solver.cpp:106] Iteration 101600, lr = 0.001
I0930 02:47:59.138829 11684 solver.cpp:228] Iteration 101700, loss = 0.00811147
I0930 02:47:59.138829 11684 solver.cpp:244]     Train net output #0: loss = 0.00811214 (* 1 = 0.00811214 loss)
I0930 02:47:59.138829 11684 sgd_solver.cpp:106] Iteration 101700, lr = 0.001
I0930 02:48:18.337673 11684 solver.cpp:228] Iteration 101800, loss = 0.00875788
I0930 02:48:18.337673 11684 solver.cpp:244]     Train net output #0: loss = 0.00875855 (* 1 = 0.00875855 loss)
I0930 02:48:18.337673 11684 sgd_solver.cpp:106] Iteration 101800, lr = 0.001
I0930 02:48:37.524278 11684 solver.cpp:228] Iteration 101900, loss = 0.0103751
I0930 02:48:37.524278 11684 solver.cpp:244]     Train net output #0: loss = 0.0103757 (* 1 = 0.0103757 loss)
I0930 02:48:37.524278 11684 sgd_solver.cpp:106] Iteration 101900, lr = 0.001
I0930 02:48:56.649524 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_102000.caffemodel
I0930 02:48:57.256942 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_102000.solverstate
I0930 02:48:57.617022 11684 solver.cpp:337] Iteration 102000, Testing net (#0)
I0930 02:49:05.783104 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7385
I0930 02:49:05.783104 11684 solver.cpp:404]     Test net output #1: loss = 1.09003 (* 1 = 1.09003 loss)
I0930 02:49:05.833140 11684 solver.cpp:228] Iteration 102000, loss = 0.0135941
I0930 02:49:05.833140 11684 solver.cpp:244]     Train net output #0: loss = 0.0135948 (* 1 = 0.0135948 loss)
I0930 02:49:05.833140 11684 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0930 02:49:25.034340 11684 solver.cpp:228] Iteration 102100, loss = 0.0118179
I0930 02:49:25.035341 11684 solver.cpp:244]     Train net output #0: loss = 0.0118185 (* 1 = 0.0118185 loss)
I0930 02:49:25.035341 11684 sgd_solver.cpp:106] Iteration 102100, lr = 0.001
I0930 02:49:44.214028 11684 solver.cpp:228] Iteration 102200, loss = 0.0129443
I0930 02:49:44.214028 11684 solver.cpp:244]     Train net output #0: loss = 0.012945 (* 1 = 0.012945 loss)
I0930 02:49:44.214028 11684 sgd_solver.cpp:106] Iteration 102200, lr = 0.001
I0930 02:50:03.385177 11684 solver.cpp:228] Iteration 102300, loss = 0.0108852
I0930 02:50:03.385177 11684 solver.cpp:244]     Train net output #0: loss = 0.0108858 (* 1 = 0.0108858 loss)
I0930 02:50:03.385177 11684 sgd_solver.cpp:106] Iteration 102300, lr = 0.001
I0930 02:50:22.567073 11684 solver.cpp:228] Iteration 102400, loss = 0.00759982
I0930 02:50:22.567073 11684 solver.cpp:244]     Train net output #0: loss = 0.00760049 (* 1 = 0.00760049 loss)
I0930 02:50:22.567073 11684 sgd_solver.cpp:106] Iteration 102400, lr = 0.001
I0930 02:50:41.745551 11684 solver.cpp:228] Iteration 102500, loss = 0.0109206
I0930 02:50:41.745551 11684 solver.cpp:244]     Train net output #0: loss = 0.0109213 (* 1 = 0.0109213 loss)
I0930 02:50:41.745551 11684 sgd_solver.cpp:106] Iteration 102500, lr = 0.001
I0930 02:51:00.915556 11684 solver.cpp:228] Iteration 102600, loss = 0.0120498
I0930 02:51:00.915556 11684 solver.cpp:244]     Train net output #0: loss = 0.0120505 (* 1 = 0.0120505 loss)
I0930 02:51:00.915556 11684 sgd_solver.cpp:106] Iteration 102600, lr = 0.001
I0930 02:51:20.091500 11684 solver.cpp:228] Iteration 102700, loss = 0.0121871
I0930 02:51:20.091500 11684 solver.cpp:244]     Train net output #0: loss = 0.0121878 (* 1 = 0.0121878 loss)
I0930 02:51:20.092500 11684 sgd_solver.cpp:106] Iteration 102700, lr = 0.001
I0930 02:51:39.269110 11684 solver.cpp:228] Iteration 102800, loss = 0.0100378
I0930 02:51:39.269110 11684 solver.cpp:244]     Train net output #0: loss = 0.0100385 (* 1 = 0.0100385 loss)
I0930 02:51:39.269110 11684 sgd_solver.cpp:106] Iteration 102800, lr = 0.001
I0930 02:51:58.444785 11684 solver.cpp:228] Iteration 102900, loss = 0.00851375
I0930 02:51:58.444785 11684 solver.cpp:244]     Train net output #0: loss = 0.00851441 (* 1 = 0.00851441 loss)
I0930 02:51:58.444785 11684 sgd_solver.cpp:106] Iteration 102900, lr = 0.001
I0930 02:52:17.571369 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_103000.caffemodel
I0930 02:52:18.176620 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_103000.solverstate
I0930 02:52:18.535876 11684 solver.cpp:337] Iteration 103000, Testing net (#0)
I0930 02:52:26.702671 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7391
I0930 02:52:26.702671 11684 solver.cpp:404]     Test net output #1: loss = 1.08427 (* 1 = 1.08427 loss)
I0930 02:52:26.753706 11684 solver.cpp:228] Iteration 103000, loss = 0.00707804
I0930 02:52:26.753706 11684 solver.cpp:244]     Train net output #0: loss = 0.0070787 (* 1 = 0.0070787 loss)
I0930 02:52:26.753706 11684 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I0930 02:52:45.936764 11684 solver.cpp:228] Iteration 103100, loss = 0.0139092
I0930 02:52:45.936764 11684 solver.cpp:244]     Train net output #0: loss = 0.0139099 (* 1 = 0.0139099 loss)
I0930 02:52:45.936764 11684 sgd_solver.cpp:106] Iteration 103100, lr = 0.001
I0930 02:53:05.110497 11684 solver.cpp:228] Iteration 103200, loss = 0.0171078
I0930 02:53:05.110497 11684 solver.cpp:244]     Train net output #0: loss = 0.0171085 (* 1 = 0.0171085 loss)
I0930 02:53:05.110497 11684 sgd_solver.cpp:106] Iteration 103200, lr = 0.001
I0930 02:53:24.282171 11684 solver.cpp:228] Iteration 103300, loss = 0.0122503
I0930 02:53:24.282171 11684 solver.cpp:244]     Train net output #0: loss = 0.012251 (* 1 = 0.012251 loss)
I0930 02:53:24.282171 11684 sgd_solver.cpp:106] Iteration 103300, lr = 0.001
I0930 02:53:43.465723 11684 solver.cpp:228] Iteration 103400, loss = 0.00709496
I0930 02:53:43.465723 11684 solver.cpp:244]     Train net output #0: loss = 0.00709563 (* 1 = 0.00709563 loss)
I0930 02:53:43.465723 11684 sgd_solver.cpp:106] Iteration 103400, lr = 0.001
I0930 02:54:02.639724 11684 solver.cpp:228] Iteration 103500, loss = 0.0139697
I0930 02:54:02.639724 11684 solver.cpp:244]     Train net output #0: loss = 0.0139704 (* 1 = 0.0139704 loss)
I0930 02:54:02.639724 11684 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I0930 02:54:21.826355 11684 solver.cpp:228] Iteration 103600, loss = 0.0145813
I0930 02:54:21.826355 11684 solver.cpp:244]     Train net output #0: loss = 0.014582 (* 1 = 0.014582 loss)
I0930 02:54:21.826355 11684 sgd_solver.cpp:106] Iteration 103600, lr = 0.001
I0930 02:54:41.023210 11684 solver.cpp:228] Iteration 103700, loss = 0.00665702
I0930 02:54:41.023210 11684 solver.cpp:244]     Train net output #0: loss = 0.00665769 (* 1 = 0.00665769 loss)
I0930 02:54:41.023210 11684 sgd_solver.cpp:106] Iteration 103700, lr = 0.001
I0930 02:55:00.189672 11684 solver.cpp:228] Iteration 103800, loss = 0.00940277
I0930 02:55:00.189672 11684 solver.cpp:244]     Train net output #0: loss = 0.00940344 (* 1 = 0.00940344 loss)
I0930 02:55:00.189672 11684 sgd_solver.cpp:106] Iteration 103800, lr = 0.001
I0930 02:55:19.380332 11684 solver.cpp:228] Iteration 103900, loss = 0.0124141
I0930 02:55:19.380332 11684 solver.cpp:244]     Train net output #0: loss = 0.0124147 (* 1 = 0.0124147 loss)
I0930 02:55:19.380332 11684 sgd_solver.cpp:106] Iteration 103900, lr = 0.001
I0930 02:55:38.516127 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_104000.caffemodel
I0930 02:55:39.114552 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_104000.solverstate
I0930 02:55:39.470804 11684 solver.cpp:337] Iteration 104000, Testing net (#0)
I0930 02:55:47.641944 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7399
I0930 02:55:47.641944 11684 solver.cpp:404]     Test net output #1: loss = 1.07285 (* 1 = 1.07285 loss)
I0930 02:55:47.690979 11684 solver.cpp:228] Iteration 104000, loss = 0.0123256
I0930 02:55:47.690979 11684 solver.cpp:244]     Train net output #0: loss = 0.0123262 (* 1 = 0.0123262 loss)
I0930 02:55:47.690979 11684 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I0930 02:56:06.858834 11684 solver.cpp:228] Iteration 104100, loss = 0.0141688
I0930 02:56:06.858834 11684 solver.cpp:244]     Train net output #0: loss = 0.0141695 (* 1 = 0.0141695 loss)
I0930 02:56:06.858834 11684 sgd_solver.cpp:106] Iteration 104100, lr = 0.001
I0930 02:56:26.031429 11684 solver.cpp:228] Iteration 104200, loss = 0.00864767
I0930 02:56:26.032428 11684 solver.cpp:244]     Train net output #0: loss = 0.00864833 (* 1 = 0.00864833 loss)
I0930 02:56:26.032428 11684 sgd_solver.cpp:106] Iteration 104200, lr = 0.001
I0930 02:56:45.206037 11684 solver.cpp:228] Iteration 104300, loss = 0.0143329
I0930 02:56:45.206037 11684 solver.cpp:244]     Train net output #0: loss = 0.0143336 (* 1 = 0.0143336 loss)
I0930 02:56:45.206037 11684 sgd_solver.cpp:106] Iteration 104300, lr = 0.001
I0930 02:57:04.369638 11684 solver.cpp:228] Iteration 104400, loss = 0.0174702
I0930 02:57:04.369638 11684 solver.cpp:244]     Train net output #0: loss = 0.0174709 (* 1 = 0.0174709 loss)
I0930 02:57:04.369638 11684 sgd_solver.cpp:106] Iteration 104400, lr = 0.001
I0930 02:57:23.542016 11684 solver.cpp:228] Iteration 104500, loss = 0.0131633
I0930 02:57:23.542016 11684 solver.cpp:244]     Train net output #0: loss = 0.013164 (* 1 = 0.013164 loss)
I0930 02:57:23.542016 11684 sgd_solver.cpp:106] Iteration 104500, lr = 0.001
I0930 02:57:42.711621 11684 solver.cpp:228] Iteration 104600, loss = 0.0120801
I0930 02:57:42.711621 11684 solver.cpp:244]     Train net output #0: loss = 0.0120808 (* 1 = 0.0120808 loss)
I0930 02:57:42.711621 11684 sgd_solver.cpp:106] Iteration 104600, lr = 0.001
I0930 02:58:01.899147 11684 solver.cpp:228] Iteration 104700, loss = 0.0100302
I0930 02:58:01.900147 11684 solver.cpp:244]     Train net output #0: loss = 0.0100309 (* 1 = 0.0100309 loss)
I0930 02:58:01.900147 11684 sgd_solver.cpp:106] Iteration 104700, lr = 0.001
I0930 02:58:21.073812 11684 solver.cpp:228] Iteration 104800, loss = 0.00922414
I0930 02:58:21.073812 11684 solver.cpp:244]     Train net output #0: loss = 0.00922481 (* 1 = 0.00922481 loss)
I0930 02:58:21.073812 11684 sgd_solver.cpp:106] Iteration 104800, lr = 0.001
I0930 02:58:40.239521 11684 solver.cpp:228] Iteration 104900, loss = 0.00973838
I0930 02:58:40.240521 11684 solver.cpp:244]     Train net output #0: loss = 0.00973905 (* 1 = 0.00973905 loss)
I0930 02:58:40.240521 11684 sgd_solver.cpp:106] Iteration 104900, lr = 0.001
I0930 02:58:59.354989 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_105000.caffemodel
I0930 02:58:59.945410 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_105000.solverstate
I0930 02:59:00.345748 11684 solver.cpp:337] Iteration 105000, Testing net (#0)
I0930 02:59:08.512545 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7427
I0930 02:59:08.513546 11684 solver.cpp:404]     Test net output #1: loss = 1.07044 (* 1 = 1.07044 loss)
I0930 02:59:08.563582 11684 solver.cpp:228] Iteration 105000, loss = 0.012169
I0930 02:59:08.563582 11684 solver.cpp:244]     Train net output #0: loss = 0.0121696 (* 1 = 0.0121696 loss)
I0930 02:59:08.563582 11684 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0930 02:59:27.754639 11684 solver.cpp:228] Iteration 105100, loss = 0.0136059
I0930 02:59:27.754639 11684 solver.cpp:244]     Train net output #0: loss = 0.0136065 (* 1 = 0.0136065 loss)
I0930 02:59:27.754639 11684 sgd_solver.cpp:106] Iteration 105100, lr = 0.001
I0930 02:59:46.933974 11684 solver.cpp:228] Iteration 105200, loss = 0.00890121
I0930 02:59:46.933974 11684 solver.cpp:244]     Train net output #0: loss = 0.00890188 (* 1 = 0.00890188 loss)
I0930 02:59:46.933974 11684 sgd_solver.cpp:106] Iteration 105200, lr = 0.001
I0930 03:00:06.122606 11684 solver.cpp:228] Iteration 105300, loss = 0.00974505
I0930 03:00:06.122606 11684 solver.cpp:244]     Train net output #0: loss = 0.00974572 (* 1 = 0.00974572 loss)
I0930 03:00:06.122606 11684 sgd_solver.cpp:106] Iteration 105300, lr = 0.001
I0930 03:00:25.306270 11684 solver.cpp:228] Iteration 105400, loss = 0.0175372
I0930 03:00:25.306270 11684 solver.cpp:244]     Train net output #0: loss = 0.0175378 (* 1 = 0.0175378 loss)
I0930 03:00:25.306270 11684 sgd_solver.cpp:106] Iteration 105400, lr = 0.001
I0930 03:00:44.479879 11684 solver.cpp:228] Iteration 105500, loss = 0.0122016
I0930 03:00:44.479879 11684 solver.cpp:244]     Train net output #0: loss = 0.0122023 (* 1 = 0.0122023 loss)
I0930 03:00:44.479879 11684 sgd_solver.cpp:106] Iteration 105500, lr = 0.001
I0930 03:01:03.665529 11684 solver.cpp:228] Iteration 105600, loss = 0.0103999
I0930 03:01:03.665529 11684 solver.cpp:244]     Train net output #0: loss = 0.0104006 (* 1 = 0.0104006 loss)
I0930 03:01:03.665529 11684 sgd_solver.cpp:106] Iteration 105600, lr = 0.001
I0930 03:01:22.834264 11684 solver.cpp:228] Iteration 105700, loss = 0.00952971
I0930 03:01:22.834264 11684 solver.cpp:244]     Train net output #0: loss = 0.00953038 (* 1 = 0.00953038 loss)
I0930 03:01:22.834264 11684 sgd_solver.cpp:106] Iteration 105700, lr = 0.001
I0930 03:01:42.009352 11684 solver.cpp:228] Iteration 105800, loss = 0.00860677
I0930 03:01:42.009352 11684 solver.cpp:244]     Train net output #0: loss = 0.00860744 (* 1 = 0.00860744 loss)
I0930 03:01:42.009352 11684 sgd_solver.cpp:106] Iteration 105800, lr = 0.001
I0930 03:02:01.183027 11684 solver.cpp:228] Iteration 105900, loss = 0.0110755
I0930 03:02:01.183027 11684 solver.cpp:244]     Train net output #0: loss = 0.0110762 (* 1 = 0.0110762 loss)
I0930 03:02:01.183027 11684 sgd_solver.cpp:106] Iteration 105900, lr = 0.001
I0930 03:02:20.319509 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_106000.caffemodel
I0930 03:02:20.914930 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_106000.solverstate
I0930 03:02:21.281190 11684 solver.cpp:337] Iteration 106000, Testing net (#0)
I0930 03:02:29.452136 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7385
I0930 03:02:29.452136 11684 solver.cpp:404]     Test net output #1: loss = 1.08078 (* 1 = 1.08078 loss)
I0930 03:02:29.503172 11684 solver.cpp:228] Iteration 106000, loss = 0.0116501
I0930 03:02:29.503172 11684 solver.cpp:244]     Train net output #0: loss = 0.0116507 (* 1 = 0.0116507 loss)
I0930 03:02:29.503172 11684 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I0930 03:02:48.685806 11684 solver.cpp:228] Iteration 106100, loss = 0.0104893
I0930 03:02:48.686806 11684 solver.cpp:244]     Train net output #0: loss = 0.01049 (* 1 = 0.01049 loss)
I0930 03:02:48.686806 11684 sgd_solver.cpp:106] Iteration 106100, lr = 0.001
I0930 03:03:07.863365 11684 solver.cpp:228] Iteration 106200, loss = 0.00530696
I0930 03:03:07.863365 11684 solver.cpp:244]     Train net output #0: loss = 0.00530763 (* 1 = 0.00530763 loss)
I0930 03:03:07.863365 11684 sgd_solver.cpp:106] Iteration 106200, lr = 0.001
I0930 03:03:27.066995 11684 solver.cpp:228] Iteration 106300, loss = 0.0123201
I0930 03:03:27.066995 11684 solver.cpp:244]     Train net output #0: loss = 0.0123207 (* 1 = 0.0123207 loss)
I0930 03:03:27.066995 11684 sgd_solver.cpp:106] Iteration 106300, lr = 0.001
I0930 03:03:46.248601 11684 solver.cpp:228] Iteration 106400, loss = 0.00940537
I0930 03:03:46.248601 11684 solver.cpp:244]     Train net output #0: loss = 0.00940604 (* 1 = 0.00940604 loss)
I0930 03:03:46.248601 11684 sgd_solver.cpp:106] Iteration 106400, lr = 0.001
I0930 03:04:05.419208 11684 solver.cpp:228] Iteration 106500, loss = 0.0100507
I0930 03:04:05.419208 11684 solver.cpp:244]     Train net output #0: loss = 0.0100513 (* 1 = 0.0100513 loss)
I0930 03:04:05.419208 11684 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I0930 03:04:24.606825 11684 solver.cpp:228] Iteration 106600, loss = 0.00928264
I0930 03:04:24.606825 11684 solver.cpp:244]     Train net output #0: loss = 0.00928331 (* 1 = 0.00928331 loss)
I0930 03:04:24.607826 11684 sgd_solver.cpp:106] Iteration 106600, lr = 0.001
I0930 03:04:43.793498 11684 solver.cpp:228] Iteration 106700, loss = 0.00934987
I0930 03:04:43.794497 11684 solver.cpp:244]     Train net output #0: loss = 0.00935054 (* 1 = 0.00935054 loss)
I0930 03:04:43.794497 11684 sgd_solver.cpp:106] Iteration 106700, lr = 0.001
I0930 03:05:02.970563 11684 solver.cpp:228] Iteration 106800, loss = 0.00753977
I0930 03:05:02.971565 11684 solver.cpp:244]     Train net output #0: loss = 0.00754044 (* 1 = 0.00754044 loss)
I0930 03:05:02.971565 11684 sgd_solver.cpp:106] Iteration 106800, lr = 0.001
I0930 03:05:22.145941 11684 solver.cpp:228] Iteration 106900, loss = 0.011706
I0930 03:05:22.145941 11684 solver.cpp:244]     Train net output #0: loss = 0.0117066 (* 1 = 0.0117066 loss)
I0930 03:05:22.145941 11684 sgd_solver.cpp:106] Iteration 106900, lr = 0.001
I0930 03:05:41.286862 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_107000.caffemodel
I0930 03:05:41.891293 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_107000.solverstate
I0930 03:05:42.256115 11684 solver.cpp:337] Iteration 107000, Testing net (#0)
I0930 03:05:50.454784 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7388
I0930 03:05:50.454784 11684 solver.cpp:404]     Test net output #1: loss = 1.08152 (* 1 = 1.08152 loss)
I0930 03:05:50.504820 11684 solver.cpp:228] Iteration 107000, loss = 0.0102627
I0930 03:05:50.504820 11684 solver.cpp:244]     Train net output #0: loss = 0.0102633 (* 1 = 0.0102633 loss)
I0930 03:05:50.504820 11684 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I0930 03:06:09.671423 11684 solver.cpp:228] Iteration 107100, loss = 0.0113626
I0930 03:06:09.671423 11684 solver.cpp:244]     Train net output #0: loss = 0.0113633 (* 1 = 0.0113633 loss)
I0930 03:06:09.671423 11684 sgd_solver.cpp:106] Iteration 107100, lr = 0.001
I0930 03:06:28.853077 11684 solver.cpp:228] Iteration 107200, loss = 0.013283
I0930 03:06:28.853077 11684 solver.cpp:244]     Train net output #0: loss = 0.0132837 (* 1 = 0.0132837 loss)
I0930 03:06:28.853077 11684 sgd_solver.cpp:106] Iteration 107200, lr = 0.001
I0930 03:06:48.027719 11684 solver.cpp:228] Iteration 107300, loss = 0.0130543
I0930 03:06:48.027719 11684 solver.cpp:244]     Train net output #0: loss = 0.013055 (* 1 = 0.013055 loss)
I0930 03:06:48.027719 11684 sgd_solver.cpp:106] Iteration 107300, lr = 0.001
I0930 03:07:07.207345 11684 solver.cpp:228] Iteration 107400, loss = 0.0120264
I0930 03:07:07.207345 11684 solver.cpp:244]     Train net output #0: loss = 0.0120271 (* 1 = 0.0120271 loss)
I0930 03:07:07.207345 11684 sgd_solver.cpp:106] Iteration 107400, lr = 0.001
I0930 03:07:26.461997 11684 solver.cpp:228] Iteration 107500, loss = 0.00850032
I0930 03:07:26.461997 11684 solver.cpp:244]     Train net output #0: loss = 0.00850099 (* 1 = 0.00850099 loss)
I0930 03:07:26.461997 11684 sgd_solver.cpp:106] Iteration 107500, lr = 0.001
I0930 03:07:45.650384 11684 solver.cpp:228] Iteration 107600, loss = 0.00947324
I0930 03:07:45.650384 11684 solver.cpp:244]     Train net output #0: loss = 0.00947391 (* 1 = 0.00947391 loss)
I0930 03:07:45.651386 11684 sgd_solver.cpp:106] Iteration 107600, lr = 0.001
I0930 03:08:04.838003 11684 solver.cpp:228] Iteration 107700, loss = 0.00887965
I0930 03:08:04.838003 11684 solver.cpp:244]     Train net output #0: loss = 0.00888032 (* 1 = 0.00888032 loss)
I0930 03:08:04.838003 11684 sgd_solver.cpp:106] Iteration 107700, lr = 0.001
I0930 03:08:24.023522 11684 solver.cpp:228] Iteration 107800, loss = 0.0114716
I0930 03:08:24.023522 11684 solver.cpp:244]     Train net output #0: loss = 0.0114723 (* 1 = 0.0114723 loss)
I0930 03:08:24.023522 11684 sgd_solver.cpp:106] Iteration 107800, lr = 0.001
I0930 03:08:43.194993 11684 solver.cpp:228] Iteration 107900, loss = 0.0103992
I0930 03:08:43.194993 11684 solver.cpp:244]     Train net output #0: loss = 0.0103999 (* 1 = 0.0103999 loss)
I0930 03:08:43.194993 11684 sgd_solver.cpp:106] Iteration 107900, lr = 0.001
I0930 03:09:02.310482 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_108000.caffemodel
I0930 03:09:02.912910 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_108000.solverstate
I0930 03:09:03.274166 11684 solver.cpp:337] Iteration 108000, Testing net (#0)
I0930 03:09:11.428863 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7411
I0930 03:09:11.428863 11684 solver.cpp:404]     Test net output #1: loss = 1.07245 (* 1 = 1.07245 loss)
I0930 03:09:11.478899 11684 solver.cpp:228] Iteration 108000, loss = 0.0132001
I0930 03:09:11.478899 11684 solver.cpp:244]     Train net output #0: loss = 0.0132008 (* 1 = 0.0132008 loss)
I0930 03:09:11.478899 11684 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0930 03:09:30.649826 11684 solver.cpp:228] Iteration 108100, loss = 0.011829
I0930 03:09:30.649826 11684 solver.cpp:244]     Train net output #0: loss = 0.0118297 (* 1 = 0.0118297 loss)
I0930 03:09:30.649826 11684 sgd_solver.cpp:106] Iteration 108100, lr = 0.001
I0930 03:09:49.845741 11684 solver.cpp:228] Iteration 108200, loss = 0.00792247
I0930 03:09:49.845741 11684 solver.cpp:244]     Train net output #0: loss = 0.00792314 (* 1 = 0.00792314 loss)
I0930 03:09:49.845741 11684 sgd_solver.cpp:106] Iteration 108200, lr = 0.001
I0930 03:10:09.035425 11684 solver.cpp:228] Iteration 108300, loss = 0.00879486
I0930 03:10:09.035425 11684 solver.cpp:244]     Train net output #0: loss = 0.00879553 (* 1 = 0.00879553 loss)
I0930 03:10:09.035425 11684 sgd_solver.cpp:106] Iteration 108300, lr = 0.001
I0930 03:10:28.213719 11684 solver.cpp:228] Iteration 108400, loss = 0.0102963
I0930 03:10:28.213719 11684 solver.cpp:244]     Train net output #0: loss = 0.010297 (* 1 = 0.010297 loss)
I0930 03:10:28.213719 11684 sgd_solver.cpp:106] Iteration 108400, lr = 0.001
I0930 03:10:47.384585 11684 solver.cpp:228] Iteration 108500, loss = 0.00822634
I0930 03:10:47.384585 11684 solver.cpp:244]     Train net output #0: loss = 0.00822701 (* 1 = 0.00822701 loss)
I0930 03:10:47.384585 11684 sgd_solver.cpp:106] Iteration 108500, lr = 0.001
I0930 03:11:06.561326 11684 solver.cpp:228] Iteration 108600, loss = 0.0135129
I0930 03:11:06.561326 11684 solver.cpp:244]     Train net output #0: loss = 0.0135136 (* 1 = 0.0135136 loss)
I0930 03:11:06.561326 11684 sgd_solver.cpp:106] Iteration 108600, lr = 0.001
I0930 03:11:25.755153 11684 solver.cpp:228] Iteration 108700, loss = 0.0140354
I0930 03:11:25.755153 11684 solver.cpp:244]     Train net output #0: loss = 0.0140361 (* 1 = 0.0140361 loss)
I0930 03:11:25.755153 11684 sgd_solver.cpp:106] Iteration 108700, lr = 0.001
I0930 03:11:44.943785 11684 solver.cpp:228] Iteration 108800, loss = 0.0120485
I0930 03:11:44.943785 11684 solver.cpp:244]     Train net output #0: loss = 0.0120492 (* 1 = 0.0120492 loss)
I0930 03:11:44.943785 11684 sgd_solver.cpp:106] Iteration 108800, lr = 0.001
I0930 03:12:04.132141 11684 solver.cpp:228] Iteration 108900, loss = 0.0107522
I0930 03:12:04.132141 11684 solver.cpp:244]     Train net output #0: loss = 0.0107529 (* 1 = 0.0107529 loss)
I0930 03:12:04.132141 11684 sgd_solver.cpp:106] Iteration 108900, lr = 0.001
I0930 03:12:23.270712 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_109000.caffemodel
I0930 03:12:23.867136 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_109000.solverstate
I0930 03:12:24.226392 11684 solver.cpp:337] Iteration 109000, Testing net (#0)
I0930 03:12:32.390513 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7375
I0930 03:12:32.390513 11684 solver.cpp:404]     Test net output #1: loss = 1.07661 (* 1 = 1.07661 loss)
I0930 03:12:32.440536 11684 solver.cpp:228] Iteration 109000, loss = 0.00837863
I0930 03:12:32.440536 11684 solver.cpp:244]     Train net output #0: loss = 0.0083793 (* 1 = 0.0083793 loss)
I0930 03:12:32.440536 11684 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I0930 03:12:51.619148 11684 solver.cpp:228] Iteration 109100, loss = 0.0159715
I0930 03:12:51.619148 11684 solver.cpp:244]     Train net output #0: loss = 0.0159722 (* 1 = 0.0159722 loss)
I0930 03:12:51.619148 11684 sgd_solver.cpp:106] Iteration 109100, lr = 0.001
I0930 03:13:10.806766 11684 solver.cpp:228] Iteration 109200, loss = 0.0100858
I0930 03:13:10.806766 11684 solver.cpp:244]     Train net output #0: loss = 0.0100864 (* 1 = 0.0100864 loss)
I0930 03:13:10.806766 11684 sgd_solver.cpp:106] Iteration 109200, lr = 0.001
I0930 03:13:29.989156 11684 solver.cpp:228] Iteration 109300, loss = 0.00969239
I0930 03:13:29.989156 11684 solver.cpp:244]     Train net output #0: loss = 0.00969306 (* 1 = 0.00969306 loss)
I0930 03:13:29.989156 11684 sgd_solver.cpp:106] Iteration 109300, lr = 0.001
I0930 03:13:49.172771 11684 solver.cpp:228] Iteration 109400, loss = 0.0104482
I0930 03:13:49.172771 11684 solver.cpp:244]     Train net output #0: loss = 0.0104488 (* 1 = 0.0104488 loss)
I0930 03:13:49.172771 11684 sgd_solver.cpp:106] Iteration 109400, lr = 0.001
I0930 03:14:08.358388 11684 solver.cpp:228] Iteration 109500, loss = 0.0128227
I0930 03:14:08.359390 11684 solver.cpp:244]     Train net output #0: loss = 0.0128234 (* 1 = 0.0128234 loss)
I0930 03:14:08.359390 11684 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I0930 03:14:27.551733 11684 solver.cpp:228] Iteration 109600, loss = 0.00924632
I0930 03:14:27.551733 11684 solver.cpp:244]     Train net output #0: loss = 0.00924699 (* 1 = 0.00924699 loss)
I0930 03:14:27.551733 11684 sgd_solver.cpp:106] Iteration 109600, lr = 0.001
I0930 03:14:46.734480 11684 solver.cpp:228] Iteration 109700, loss = 0.0120028
I0930 03:14:46.734480 11684 solver.cpp:244]     Train net output #0: loss = 0.0120035 (* 1 = 0.0120035 loss)
I0930 03:14:46.734480 11684 sgd_solver.cpp:106] Iteration 109700, lr = 0.001
I0930 03:15:05.922086 11684 solver.cpp:228] Iteration 109800, loss = 0.00655376
I0930 03:15:05.922086 11684 solver.cpp:244]     Train net output #0: loss = 0.00655443 (* 1 = 0.00655443 loss)
I0930 03:15:05.922086 11684 sgd_solver.cpp:106] Iteration 109800, lr = 0.001
I0930 03:15:25.120517 11684 solver.cpp:228] Iteration 109900, loss = 0.00885457
I0930 03:15:25.120517 11684 solver.cpp:244]     Train net output #0: loss = 0.00885524 (* 1 = 0.00885524 loss)
I0930 03:15:25.120517 11684 sgd_solver.cpp:106] Iteration 109900, lr = 0.001
I0930 03:15:44.240087 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_110000.caffemodel
I0930 03:15:44.835510 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_110000.solverstate
I0930 03:15:45.199769 11684 solver.cpp:337] Iteration 110000, Testing net (#0)
I0930 03:15:53.361827 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7372
I0930 03:15:53.361827 11684 solver.cpp:404]     Test net output #1: loss = 1.07933 (* 1 = 1.07933 loss)
I0930 03:15:53.412863 11684 solver.cpp:228] Iteration 110000, loss = 0.0126988
I0930 03:15:53.412863 11684 solver.cpp:244]     Train net output #0: loss = 0.0126994 (* 1 = 0.0126994 loss)
I0930 03:15:53.412863 11684 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I0930 03:16:12.593927 11684 solver.cpp:228] Iteration 110100, loss = 0.0123696
I0930 03:16:12.593927 11684 solver.cpp:244]     Train net output #0: loss = 0.0123703 (* 1 = 0.0123703 loss)
I0930 03:16:12.593927 11684 sgd_solver.cpp:106] Iteration 110100, lr = 0.001
I0930 03:16:31.780545 11684 solver.cpp:228] Iteration 110200, loss = 0.0100192
I0930 03:16:31.780545 11684 solver.cpp:244]     Train net output #0: loss = 0.0100199 (* 1 = 0.0100199 loss)
I0930 03:16:31.780545 11684 sgd_solver.cpp:106] Iteration 110200, lr = 0.001
I0930 03:16:50.967043 11684 solver.cpp:228] Iteration 110300, loss = 0.0164188
I0930 03:16:50.967043 11684 solver.cpp:244]     Train net output #0: loss = 0.0164195 (* 1 = 0.0164195 loss)
I0930 03:16:50.967043 11684 sgd_solver.cpp:106] Iteration 110300, lr = 0.001
I0930 03:17:10.168074 11684 solver.cpp:228] Iteration 110400, loss = 0.00697809
I0930 03:17:10.168074 11684 solver.cpp:244]     Train net output #0: loss = 0.00697876 (* 1 = 0.00697876 loss)
I0930 03:17:10.168074 11684 sgd_solver.cpp:106] Iteration 110400, lr = 0.001
I0930 03:17:29.366834 11684 solver.cpp:228] Iteration 110500, loss = 0.00994899
I0930 03:17:29.366834 11684 solver.cpp:244]     Train net output #0: loss = 0.00994967 (* 1 = 0.00994967 loss)
I0930 03:17:29.366834 11684 sgd_solver.cpp:106] Iteration 110500, lr = 0.001
I0930 03:17:48.551206 11684 solver.cpp:228] Iteration 110600, loss = 0.0124011
I0930 03:17:48.551206 11684 solver.cpp:244]     Train net output #0: loss = 0.0124018 (* 1 = 0.0124018 loss)
I0930 03:17:48.551206 11684 sgd_solver.cpp:106] Iteration 110600, lr = 0.001
I0930 03:18:07.717420 11684 solver.cpp:228] Iteration 110700, loss = 0.00892123
I0930 03:18:07.717420 11684 solver.cpp:244]     Train net output #0: loss = 0.00892191 (* 1 = 0.00892191 loss)
I0930 03:18:07.717420 11684 sgd_solver.cpp:106] Iteration 110700, lr = 0.001
I0930 03:18:26.896422 11684 solver.cpp:228] Iteration 110800, loss = 0.0124384
I0930 03:18:26.896422 11684 solver.cpp:244]     Train net output #0: loss = 0.0124391 (* 1 = 0.0124391 loss)
I0930 03:18:26.896422 11684 sgd_solver.cpp:106] Iteration 110800, lr = 0.001
I0930 03:18:46.082010 11684 solver.cpp:228] Iteration 110900, loss = 0.00889199
I0930 03:18:46.082010 11684 solver.cpp:244]     Train net output #0: loss = 0.00889266 (* 1 = 0.00889266 loss)
I0930 03:18:46.082010 11684 sgd_solver.cpp:106] Iteration 110900, lr = 0.001
I0930 03:19:05.212630 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_111000.caffemodel
I0930 03:19:05.819061 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_111000.solverstate
I0930 03:19:06.187321 11684 solver.cpp:337] Iteration 111000, Testing net (#0)
I0930 03:19:14.350615 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7374
I0930 03:19:14.350615 11684 solver.cpp:404]     Test net output #1: loss = 1.07977 (* 1 = 1.07977 loss)
I0930 03:19:14.400650 11684 solver.cpp:228] Iteration 111000, loss = 0.0113219
I0930 03:19:14.400650 11684 solver.cpp:244]     Train net output #0: loss = 0.0113225 (* 1 = 0.0113225 loss)
I0930 03:19:14.400650 11684 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0930 03:19:33.598276 11684 solver.cpp:228] Iteration 111100, loss = 0.0105026
I0930 03:19:33.598276 11684 solver.cpp:244]     Train net output #0: loss = 0.0105033 (* 1 = 0.0105033 loss)
I0930 03:19:33.598276 11684 sgd_solver.cpp:106] Iteration 111100, lr = 0.001
I0930 03:19:52.784595 11684 solver.cpp:228] Iteration 111200, loss = 0.0116188
I0930 03:19:52.784595 11684 solver.cpp:244]     Train net output #0: loss = 0.0116195 (* 1 = 0.0116195 loss)
I0930 03:19:52.784595 11684 sgd_solver.cpp:106] Iteration 111200, lr = 0.001
I0930 03:20:11.967196 11684 solver.cpp:228] Iteration 111300, loss = 0.0191528
I0930 03:20:11.967196 11684 solver.cpp:244]     Train net output #0: loss = 0.0191535 (* 1 = 0.0191535 loss)
I0930 03:20:11.967196 11684 sgd_solver.cpp:106] Iteration 111300, lr = 0.001
I0930 03:20:31.159818 11684 solver.cpp:228] Iteration 111400, loss = 0.0080526
I0930 03:20:31.159818 11684 solver.cpp:244]     Train net output #0: loss = 0.00805327 (* 1 = 0.00805327 loss)
I0930 03:20:31.159818 11684 sgd_solver.cpp:106] Iteration 111400, lr = 0.001
I0930 03:20:50.332345 11684 solver.cpp:228] Iteration 111500, loss = 0.015469
I0930 03:20:50.332345 11684 solver.cpp:244]     Train net output #0: loss = 0.0154697 (* 1 = 0.0154697 loss)
I0930 03:20:50.332345 11684 sgd_solver.cpp:106] Iteration 111500, lr = 0.001
I0930 03:21:09.508421 11684 solver.cpp:228] Iteration 111600, loss = 0.0120313
I0930 03:21:09.508421 11684 solver.cpp:244]     Train net output #0: loss = 0.012032 (* 1 = 0.012032 loss)
I0930 03:21:09.508421 11684 sgd_solver.cpp:106] Iteration 111600, lr = 0.001
I0930 03:21:28.690048 11684 solver.cpp:228] Iteration 111700, loss = 0.0113544
I0930 03:21:28.690048 11684 solver.cpp:244]     Train net output #0: loss = 0.0113551 (* 1 = 0.0113551 loss)
I0930 03:21:28.690048 11684 sgd_solver.cpp:106] Iteration 111700, lr = 0.001
I0930 03:21:47.867534 11684 solver.cpp:228] Iteration 111800, loss = 0.00813934
I0930 03:21:47.867534 11684 solver.cpp:244]     Train net output #0: loss = 0.00814001 (* 1 = 0.00814001 loss)
I0930 03:21:47.867534 11684 sgd_solver.cpp:106] Iteration 111800, lr = 0.001
I0930 03:22:07.038127 11684 solver.cpp:228] Iteration 111900, loss = 0.00834399
I0930 03:22:07.038127 11684 solver.cpp:244]     Train net output #0: loss = 0.00834466 (* 1 = 0.00834466 loss)
I0930 03:22:07.038127 11684 sgd_solver.cpp:106] Iteration 111900, lr = 0.001
I0930 03:22:26.169636 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_112000.caffemodel
I0930 03:22:26.768059 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_112000.solverstate
I0930 03:22:27.125313 11684 solver.cpp:337] Iteration 112000, Testing net (#0)
I0930 03:22:35.301758 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7393
I0930 03:22:35.301758 11684 solver.cpp:404]     Test net output #1: loss = 1.07622 (* 1 = 1.07622 loss)
I0930 03:22:35.353795 11684 solver.cpp:228] Iteration 112000, loss = 0.00747534
I0930 03:22:35.353795 11684 solver.cpp:244]     Train net output #0: loss = 0.00747602 (* 1 = 0.00747602 loss)
I0930 03:22:35.353795 11684 sgd_solver.cpp:106] Iteration 112000, lr = 0.001
I0930 03:22:54.529734 11684 solver.cpp:228] Iteration 112100, loss = 0.0157326
I0930 03:22:54.529734 11684 solver.cpp:244]     Train net output #0: loss = 0.0157333 (* 1 = 0.0157333 loss)
I0930 03:22:54.529734 11684 sgd_solver.cpp:106] Iteration 112100, lr = 0.001
I0930 03:23:13.712402 11684 solver.cpp:228] Iteration 112200, loss = 0.00950167
I0930 03:23:13.712402 11684 solver.cpp:244]     Train net output #0: loss = 0.00950234 (* 1 = 0.00950234 loss)
I0930 03:23:13.712402 11684 sgd_solver.cpp:106] Iteration 112200, lr = 0.001
I0930 03:23:32.907025 11684 solver.cpp:228] Iteration 112300, loss = 0.0101784
I0930 03:23:32.907025 11684 solver.cpp:244]     Train net output #0: loss = 0.0101791 (* 1 = 0.0101791 loss)
I0930 03:23:32.907025 11684 sgd_solver.cpp:106] Iteration 112300, lr = 0.001
I0930 03:23:52.093799 11684 solver.cpp:228] Iteration 112400, loss = 0.00859939
I0930 03:23:52.093799 11684 solver.cpp:244]     Train net output #0: loss = 0.00860007 (* 1 = 0.00860007 loss)
I0930 03:23:52.093799 11684 sgd_solver.cpp:106] Iteration 112400, lr = 0.001
I0930 03:24:11.274801 11684 solver.cpp:228] Iteration 112500, loss = 0.00685555
I0930 03:24:11.274801 11684 solver.cpp:244]     Train net output #0: loss = 0.00685622 (* 1 = 0.00685622 loss)
I0930 03:24:11.274801 11684 sgd_solver.cpp:106] Iteration 112500, lr = 0.001
I0930 03:24:30.458416 11684 solver.cpp:228] Iteration 112600, loss = 0.00863976
I0930 03:24:30.458416 11684 solver.cpp:244]     Train net output #0: loss = 0.00864044 (* 1 = 0.00864044 loss)
I0930 03:24:30.458416 11684 sgd_solver.cpp:106] Iteration 112600, lr = 0.001
I0930 03:24:49.627418 11684 solver.cpp:228] Iteration 112700, loss = 0.0103823
I0930 03:24:49.627418 11684 solver.cpp:244]     Train net output #0: loss = 0.010383 (* 1 = 0.010383 loss)
I0930 03:24:49.627418 11684 sgd_solver.cpp:106] Iteration 112700, lr = 0.001
I0930 03:25:08.801049 11684 solver.cpp:228] Iteration 112800, loss = 0.00996815
I0930 03:25:08.801049 11684 solver.cpp:244]     Train net output #0: loss = 0.00996882 (* 1 = 0.00996882 loss)
I0930 03:25:08.801049 11684 sgd_solver.cpp:106] Iteration 112800, lr = 0.001
I0930 03:25:27.987252 11684 solver.cpp:228] Iteration 112900, loss = 0.00809906
I0930 03:25:27.987252 11684 solver.cpp:244]     Train net output #0: loss = 0.00809973 (* 1 = 0.00809973 loss)
I0930 03:25:27.987252 11684 sgd_solver.cpp:106] Iteration 112900, lr = 0.001
I0930 03:25:47.111812 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_113000.caffemodel
I0930 03:25:47.706235 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_113000.solverstate
I0930 03:25:48.109205 11684 solver.cpp:337] Iteration 113000, Testing net (#0)
I0930 03:25:56.289494 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7415
I0930 03:25:56.289494 11684 solver.cpp:404]     Test net output #1: loss = 1.07745 (* 1 = 1.07745 loss)
I0930 03:25:56.339543 11684 solver.cpp:228] Iteration 113000, loss = 0.0103272
I0930 03:25:56.339543 11684 solver.cpp:244]     Train net output #0: loss = 0.0103279 (* 1 = 0.0103279 loss)
I0930 03:25:56.339543 11684 sgd_solver.cpp:106] Iteration 113000, lr = 0.001
I0930 03:26:15.515350 11684 solver.cpp:228] Iteration 113100, loss = 0.0149429
I0930 03:26:15.515350 11684 solver.cpp:244]     Train net output #0: loss = 0.0149436 (* 1 = 0.0149436 loss)
I0930 03:26:15.515350 11684 sgd_solver.cpp:106] Iteration 113100, lr = 0.001
I0930 03:26:34.698043 11684 solver.cpp:228] Iteration 113200, loss = 0.00952832
I0930 03:26:34.698043 11684 solver.cpp:244]     Train net output #0: loss = 0.00952899 (* 1 = 0.00952899 loss)
I0930 03:26:34.698043 11684 sgd_solver.cpp:106] Iteration 113200, lr = 0.001
I0930 03:26:53.875133 11684 solver.cpp:228] Iteration 113300, loss = 0.00999688
I0930 03:26:53.875133 11684 solver.cpp:244]     Train net output #0: loss = 0.00999754 (* 1 = 0.00999754 loss)
I0930 03:26:53.875133 11684 sgd_solver.cpp:106] Iteration 113300, lr = 0.001
I0930 03:27:13.065753 11684 solver.cpp:228] Iteration 113400, loss = 0.00943691
I0930 03:27:13.066754 11684 solver.cpp:244]     Train net output #0: loss = 0.00943758 (* 1 = 0.00943758 loss)
I0930 03:27:13.066754 11684 sgd_solver.cpp:106] Iteration 113400, lr = 0.001
I0930 03:27:32.244365 11684 solver.cpp:228] Iteration 113500, loss = 0.00767107
I0930 03:27:32.244365 11684 solver.cpp:244]     Train net output #0: loss = 0.00767174 (* 1 = 0.00767174 loss)
I0930 03:27:32.244365 11684 sgd_solver.cpp:106] Iteration 113500, lr = 0.001
I0930 03:27:51.427980 11684 solver.cpp:228] Iteration 113600, loss = 0.0119556
I0930 03:27:51.427980 11684 solver.cpp:244]     Train net output #0: loss = 0.0119563 (* 1 = 0.0119563 loss)
I0930 03:27:51.427980 11684 sgd_solver.cpp:106] Iteration 113600, lr = 0.001
I0930 03:28:10.622884 11684 solver.cpp:228] Iteration 113700, loss = 0.0127941
I0930 03:28:10.622884 11684 solver.cpp:244]     Train net output #0: loss = 0.0127948 (* 1 = 0.0127948 loss)
I0930 03:28:10.622884 11684 sgd_solver.cpp:106] Iteration 113700, lr = 0.001
I0930 03:28:29.827024 11684 solver.cpp:228] Iteration 113800, loss = 0.0103365
I0930 03:28:29.827024 11684 solver.cpp:244]     Train net output #0: loss = 0.0103372 (* 1 = 0.0103372 loss)
I0930 03:28:29.827024 11684 sgd_solver.cpp:106] Iteration 113800, lr = 0.001
I0930 03:28:49.014724 11684 solver.cpp:228] Iteration 113900, loss = 0.00803486
I0930 03:28:49.014724 11684 solver.cpp:244]     Train net output #0: loss = 0.00803553 (* 1 = 0.00803553 loss)
I0930 03:28:49.014724 11684 sgd_solver.cpp:106] Iteration 113900, lr = 0.001
I0930 03:29:08.185189 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_114000.caffemodel
I0930 03:29:08.791669 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_114000.solverstate
I0930 03:29:09.146960 11684 solver.cpp:337] Iteration 114000, Testing net (#0)
I0930 03:29:17.314337 11684 solver.cpp:404]     Test net output #0: accuracy = 0.741
I0930 03:29:17.314337 11684 solver.cpp:404]     Test net output #1: loss = 1.06456 (* 1 = 1.06456 loss)
I0930 03:29:17.364373 11684 solver.cpp:228] Iteration 114000, loss = 0.00814072
I0930 03:29:17.364373 11684 solver.cpp:244]     Train net output #0: loss = 0.00814139 (* 1 = 0.00814139 loss)
I0930 03:29:17.364373 11684 sgd_solver.cpp:106] Iteration 114000, lr = 0.001
I0930 03:29:36.556782 11684 solver.cpp:228] Iteration 114100, loss = 0.0122382
I0930 03:29:36.556782 11684 solver.cpp:244]     Train net output #0: loss = 0.0122388 (* 1 = 0.0122388 loss)
I0930 03:29:36.556782 11684 sgd_solver.cpp:106] Iteration 114100, lr = 0.001
I0930 03:29:55.730517 11684 solver.cpp:228] Iteration 114200, loss = 0.0110177
I0930 03:29:55.730517 11684 solver.cpp:244]     Train net output #0: loss = 0.0110183 (* 1 = 0.0110183 loss)
I0930 03:29:55.730517 11684 sgd_solver.cpp:106] Iteration 114200, lr = 0.001
I0930 03:30:14.916221 11684 solver.cpp:228] Iteration 114300, loss = 0.019118
I0930 03:30:14.916221 11684 solver.cpp:244]     Train net output #0: loss = 0.0191187 (* 1 = 0.0191187 loss)
I0930 03:30:14.916221 11684 sgd_solver.cpp:106] Iteration 114300, lr = 0.001
I0930 03:30:34.087458 11684 solver.cpp:228] Iteration 114400, loss = 0.0105387
I0930 03:30:34.087458 11684 solver.cpp:244]     Train net output #0: loss = 0.0105393 (* 1 = 0.0105393 loss)
I0930 03:30:34.087458 11684 sgd_solver.cpp:106] Iteration 114400, lr = 0.001
I0930 03:30:53.268111 11684 solver.cpp:228] Iteration 114500, loss = 0.0100462
I0930 03:30:53.268111 11684 solver.cpp:244]     Train net output #0: loss = 0.0100469 (* 1 = 0.0100469 loss)
I0930 03:30:53.268111 11684 sgd_solver.cpp:106] Iteration 114500, lr = 0.001
I0930 03:31:12.438717 11684 solver.cpp:228] Iteration 114600, loss = 0.0110631
I0930 03:31:12.438717 11684 solver.cpp:244]     Train net output #0: loss = 0.0110637 (* 1 = 0.0110637 loss)
I0930 03:31:12.438717 11684 sgd_solver.cpp:106] Iteration 114600, lr = 0.001
I0930 03:31:31.621405 11684 solver.cpp:228] Iteration 114700, loss = 0.0100474
I0930 03:31:31.621405 11684 solver.cpp:244]     Train net output #0: loss = 0.010048 (* 1 = 0.010048 loss)
I0930 03:31:31.621405 11684 sgd_solver.cpp:106] Iteration 114700, lr = 0.001
I0930 03:31:50.805078 11684 solver.cpp:228] Iteration 114800, loss = 0.00865067
I0930 03:31:50.805078 11684 solver.cpp:244]     Train net output #0: loss = 0.00865133 (* 1 = 0.00865133 loss)
I0930 03:31:50.805078 11684 sgd_solver.cpp:106] Iteration 114800, lr = 0.001
I0930 03:32:09.985163 11684 solver.cpp:228] Iteration 114900, loss = 0.00897932
I0930 03:32:09.985163 11684 solver.cpp:244]     Train net output #0: loss = 0.00897998 (* 1 = 0.00897998 loss)
I0930 03:32:09.985163 11684 sgd_solver.cpp:106] Iteration 114900, lr = 0.001
I0930 03:32:29.114614 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_115000.caffemodel
I0930 03:32:29.692024 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_115000.solverstate
I0930 03:32:30.087357 11684 solver.cpp:337] Iteration 115000, Testing net (#0)
I0930 03:32:38.253152 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7402
I0930 03:32:38.253152 11684 solver.cpp:404]     Test net output #1: loss = 1.07223 (* 1 = 1.07223 loss)
I0930 03:32:38.303187 11684 solver.cpp:228] Iteration 115000, loss = 0.00838783
I0930 03:32:38.303187 11684 solver.cpp:244]     Train net output #0: loss = 0.00838849 (* 1 = 0.00838849 loss)
I0930 03:32:38.303187 11684 sgd_solver.cpp:106] Iteration 115000, lr = 0.001
I0930 03:32:57.486834 11684 solver.cpp:228] Iteration 115100, loss = 0.00836647
I0930 03:32:57.486834 11684 solver.cpp:244]     Train net output #0: loss = 0.00836713 (* 1 = 0.00836713 loss)
I0930 03:32:57.486834 11684 sgd_solver.cpp:106] Iteration 115100, lr = 0.001
I0930 03:33:16.687757 11684 solver.cpp:228] Iteration 115200, loss = 0.00800295
I0930 03:33:16.687757 11684 solver.cpp:244]     Train net output #0: loss = 0.00800361 (* 1 = 0.00800361 loss)
I0930 03:33:16.687757 11684 sgd_solver.cpp:106] Iteration 115200, lr = 0.001
I0930 03:33:35.880586 11684 solver.cpp:228] Iteration 115300, loss = 0.0148671
I0930 03:33:35.880586 11684 solver.cpp:244]     Train net output #0: loss = 0.0148677 (* 1 = 0.0148677 loss)
I0930 03:33:35.880586 11684 sgd_solver.cpp:106] Iteration 115300, lr = 0.001
I0930 03:33:55.076210 11684 solver.cpp:228] Iteration 115400, loss = 0.00867928
I0930 03:33:55.076210 11684 solver.cpp:244]     Train net output #0: loss = 0.00867994 (* 1 = 0.00867994 loss)
I0930 03:33:55.076210 11684 sgd_solver.cpp:106] Iteration 115400, lr = 0.001
I0930 03:34:14.271903 11684 solver.cpp:228] Iteration 115500, loss = 0.00722119
I0930 03:34:14.271903 11684 solver.cpp:244]     Train net output #0: loss = 0.00722184 (* 1 = 0.00722184 loss)
I0930 03:34:14.271903 11684 sgd_solver.cpp:106] Iteration 115500, lr = 0.001
I0930 03:34:33.483885 11684 solver.cpp:228] Iteration 115600, loss = 0.0118025
I0930 03:34:33.483885 11684 solver.cpp:244]     Train net output #0: loss = 0.0118031 (* 1 = 0.0118031 loss)
I0930 03:34:33.483885 11684 sgd_solver.cpp:106] Iteration 115600, lr = 0.001
I0930 03:34:52.671550 11684 solver.cpp:228] Iteration 115700, loss = 0.00804425
I0930 03:34:52.672550 11684 solver.cpp:244]     Train net output #0: loss = 0.00804491 (* 1 = 0.00804491 loss)
I0930 03:34:52.672550 11684 sgd_solver.cpp:106] Iteration 115700, lr = 0.001
I0930 03:35:11.856649 11684 solver.cpp:228] Iteration 115800, loss = 0.0111284
I0930 03:35:11.856649 11684 solver.cpp:244]     Train net output #0: loss = 0.0111291 (* 1 = 0.0111291 loss)
I0930 03:35:11.856649 11684 sgd_solver.cpp:106] Iteration 115800, lr = 0.001
I0930 03:35:31.047271 11684 solver.cpp:228] Iteration 115900, loss = 0.00794512
I0930 03:35:31.047271 11684 solver.cpp:244]     Train net output #0: loss = 0.00794578 (* 1 = 0.00794578 loss)
I0930 03:35:31.047271 11684 sgd_solver.cpp:106] Iteration 115900, lr = 0.001
I0930 03:35:50.175846 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_116000.caffemodel
I0930 03:35:50.758260 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_116000.solverstate
I0930 03:35:51.142690 11684 solver.cpp:337] Iteration 116000, Testing net (#0)
I0930 03:35:59.319689 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7385
I0930 03:35:59.319689 11684 solver.cpp:404]     Test net output #1: loss = 1.07182 (* 1 = 1.07182 loss)
I0930 03:35:59.369738 11684 solver.cpp:228] Iteration 116000, loss = 0.0072507
I0930 03:35:59.369738 11684 solver.cpp:244]     Train net output #0: loss = 0.00725136 (* 1 = 0.00725136 loss)
I0930 03:35:59.369738 11684 sgd_solver.cpp:106] Iteration 116000, lr = 0.001
I0930 03:36:18.549365 11684 solver.cpp:228] Iteration 116100, loss = 0.0129709
I0930 03:36:18.549365 11684 solver.cpp:244]     Train net output #0: loss = 0.0129716 (* 1 = 0.0129716 loss)
I0930 03:36:18.549365 11684 sgd_solver.cpp:106] Iteration 116100, lr = 0.001
I0930 03:36:37.719431 11684 solver.cpp:228] Iteration 116200, loss = 0.0061568
I0930 03:36:37.720432 11684 solver.cpp:244]     Train net output #0: loss = 0.00615746 (* 1 = 0.00615746 loss)
I0930 03:36:37.720432 11684 sgd_solver.cpp:106] Iteration 116200, lr = 0.001
I0930 03:36:56.916082 11684 solver.cpp:228] Iteration 116300, loss = 0.0209872
I0930 03:36:56.916082 11684 solver.cpp:244]     Train net output #0: loss = 0.0209879 (* 1 = 0.0209879 loss)
I0930 03:36:56.916082 11684 sgd_solver.cpp:106] Iteration 116300, lr = 0.001
I0930 03:37:16.085595 11684 solver.cpp:228] Iteration 116400, loss = 0.00925214
I0930 03:37:16.085595 11684 solver.cpp:244]     Train net output #0: loss = 0.0092528 (* 1 = 0.0092528 loss)
I0930 03:37:16.085595 11684 sgd_solver.cpp:106] Iteration 116400, lr = 0.001
I0930 03:37:35.261193 11684 solver.cpp:228] Iteration 116500, loss = 0.0149227
I0930 03:37:35.261193 11684 solver.cpp:244]     Train net output #0: loss = 0.0149234 (* 1 = 0.0149234 loss)
I0930 03:37:35.261193 11684 sgd_solver.cpp:106] Iteration 116500, lr = 0.001
I0930 03:37:54.436802 11684 solver.cpp:228] Iteration 116600, loss = 0.0110644
I0930 03:37:54.436802 11684 solver.cpp:244]     Train net output #0: loss = 0.011065 (* 1 = 0.011065 loss)
I0930 03:37:54.436802 11684 sgd_solver.cpp:106] Iteration 116600, lr = 0.001
I0930 03:38:13.614985 11684 solver.cpp:228] Iteration 116700, loss = 0.00969469
I0930 03:38:13.614985 11684 solver.cpp:244]     Train net output #0: loss = 0.00969535 (* 1 = 0.00969535 loss)
I0930 03:38:13.614985 11684 sgd_solver.cpp:106] Iteration 116700, lr = 0.001
I0930 03:38:32.788594 11684 solver.cpp:228] Iteration 116800, loss = 0.00782461
I0930 03:38:32.788594 11684 solver.cpp:244]     Train net output #0: loss = 0.00782527 (* 1 = 0.00782527 loss)
I0930 03:38:32.788594 11684 sgd_solver.cpp:106] Iteration 116800, lr = 0.001
I0930 03:38:51.968125 11684 solver.cpp:228] Iteration 116900, loss = 0.00958537
I0930 03:38:51.968125 11684 solver.cpp:244]     Train net output #0: loss = 0.00958603 (* 1 = 0.00958603 loss)
I0930 03:38:51.968125 11684 sgd_solver.cpp:106] Iteration 116900, lr = 0.001
I0930 03:39:11.098182 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_117000.caffemodel
I0930 03:39:11.714707 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_117000.solverstate
I0930 03:39:12.089056 11684 solver.cpp:337] Iteration 117000, Testing net (#0)
I0930 03:39:20.249770 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7365
I0930 03:39:20.249770 11684 solver.cpp:404]     Test net output #1: loss = 1.07731 (* 1 = 1.07731 loss)
I0930 03:39:20.299805 11684 solver.cpp:228] Iteration 117000, loss = 0.0101333
I0930 03:39:20.299805 11684 solver.cpp:244]     Train net output #0: loss = 0.010134 (* 1 = 0.010134 loss)
I0930 03:39:20.299805 11684 sgd_solver.cpp:106] Iteration 117000, lr = 0.001
I0930 03:39:39.476474 11684 solver.cpp:228] Iteration 117100, loss = 0.00959666
I0930 03:39:39.476474 11684 solver.cpp:244]     Train net output #0: loss = 0.00959731 (* 1 = 0.00959731 loss)
I0930 03:39:39.476474 11684 sgd_solver.cpp:106] Iteration 117100, lr = 0.001
I0930 03:39:58.658349 11684 solver.cpp:228] Iteration 117200, loss = 0.00938913
I0930 03:39:58.658349 11684 solver.cpp:244]     Train net output #0: loss = 0.00938978 (* 1 = 0.00938978 loss)
I0930 03:39:58.658349 11684 sgd_solver.cpp:106] Iteration 117200, lr = 0.001
I0930 03:40:17.846338 11684 solver.cpp:228] Iteration 117300, loss = 0.00888696
I0930 03:40:17.846338 11684 solver.cpp:244]     Train net output #0: loss = 0.00888761 (* 1 = 0.00888761 loss)
I0930 03:40:17.846338 11684 sgd_solver.cpp:106] Iteration 117300, lr = 0.001
I0930 03:40:37.032941 11684 solver.cpp:228] Iteration 117400, loss = 0.00970418
I0930 03:40:37.032941 11684 solver.cpp:244]     Train net output #0: loss = 0.00970484 (* 1 = 0.00970484 loss)
I0930 03:40:37.032941 11684 sgd_solver.cpp:106] Iteration 117400, lr = 0.001
I0930 03:40:56.216558 11684 solver.cpp:228] Iteration 117500, loss = 0.0127969
I0930 03:40:56.216558 11684 solver.cpp:244]     Train net output #0: loss = 0.0127976 (* 1 = 0.0127976 loss)
I0930 03:40:56.216558 11684 sgd_solver.cpp:106] Iteration 117500, lr = 0.001
I0930 03:41:15.395122 11684 solver.cpp:228] Iteration 117600, loss = 0.00955012
I0930 03:41:15.395122 11684 solver.cpp:244]     Train net output #0: loss = 0.00955077 (* 1 = 0.00955077 loss)
I0930 03:41:15.395122 11684 sgd_solver.cpp:106] Iteration 117600, lr = 0.001
I0930 03:41:34.585770 11684 solver.cpp:228] Iteration 117700, loss = 0.0124047
I0930 03:41:34.585770 11684 solver.cpp:244]     Train net output #0: loss = 0.0124054 (* 1 = 0.0124054 loss)
I0930 03:41:34.585770 11684 sgd_solver.cpp:106] Iteration 117700, lr = 0.001
I0930 03:41:53.759924 11684 solver.cpp:228] Iteration 117800, loss = 0.00579569
I0930 03:41:53.759924 11684 solver.cpp:244]     Train net output #0: loss = 0.00579635 (* 1 = 0.00579635 loss)
I0930 03:41:53.759924 11684 sgd_solver.cpp:106] Iteration 117800, lr = 0.001
I0930 03:42:12.934546 11684 solver.cpp:228] Iteration 117900, loss = 0.00914423
I0930 03:42:12.934546 11684 solver.cpp:244]     Train net output #0: loss = 0.00914488 (* 1 = 0.00914488 loss)
I0930 03:42:12.934546 11684 sgd_solver.cpp:106] Iteration 117900, lr = 0.001
I0930 03:42:32.075074 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_118000.caffemodel
I0930 03:42:32.679365 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_118000.solverstate
I0930 03:42:33.107776 11684 solver.cpp:337] Iteration 118000, Testing net (#0)
I0930 03:42:41.270570 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7385
I0930 03:42:41.270570 11684 solver.cpp:404]     Test net output #1: loss = 1.07044 (* 1 = 1.07044 loss)
I0930 03:42:41.321605 11684 solver.cpp:228] Iteration 118000, loss = 0.00785051
I0930 03:42:41.321605 11684 solver.cpp:244]     Train net output #0: loss = 0.00785116 (* 1 = 0.00785116 loss)
I0930 03:42:41.321605 11684 sgd_solver.cpp:106] Iteration 118000, lr = 0.001
I0930 03:43:00.487249 11684 solver.cpp:228] Iteration 118100, loss = 0.012621
I0930 03:43:00.487249 11684 solver.cpp:244]     Train net output #0: loss = 0.0126216 (* 1 = 0.0126216 loss)
I0930 03:43:00.487249 11684 sgd_solver.cpp:106] Iteration 118100, lr = 0.001
I0930 03:43:19.658843 11684 solver.cpp:228] Iteration 118200, loss = 0.00960845
I0930 03:43:19.658843 11684 solver.cpp:244]     Train net output #0: loss = 0.00960911 (* 1 = 0.00960911 loss)
I0930 03:43:19.658843 11684 sgd_solver.cpp:106] Iteration 118200, lr = 0.001
I0930 03:43:38.844804 11684 solver.cpp:228] Iteration 118300, loss = 0.00999653
I0930 03:43:38.844804 11684 solver.cpp:244]     Train net output #0: loss = 0.00999719 (* 1 = 0.00999719 loss)
I0930 03:43:38.844804 11684 sgd_solver.cpp:106] Iteration 118300, lr = 0.001
I0930 03:43:58.022403 11684 solver.cpp:228] Iteration 118400, loss = 0.00869247
I0930 03:43:58.022403 11684 solver.cpp:244]     Train net output #0: loss = 0.00869313 (* 1 = 0.00869313 loss)
I0930 03:43:58.022403 11684 sgd_solver.cpp:106] Iteration 118400, lr = 0.001
I0930 03:44:17.206542 11684 solver.cpp:228] Iteration 118500, loss = 0.0139727
I0930 03:44:17.206542 11684 solver.cpp:244]     Train net output #0: loss = 0.0139733 (* 1 = 0.0139733 loss)
I0930 03:44:17.206542 11684 sgd_solver.cpp:106] Iteration 118500, lr = 0.001
I0930 03:44:36.387810 11684 solver.cpp:228] Iteration 118600, loss = 0.00950447
I0930 03:44:36.387810 11684 solver.cpp:244]     Train net output #0: loss = 0.00950512 (* 1 = 0.00950512 loss)
I0930 03:44:36.387810 11684 sgd_solver.cpp:106] Iteration 118600, lr = 0.001
I0930 03:44:55.560746 11684 solver.cpp:228] Iteration 118700, loss = 0.006143
I0930 03:44:55.560746 11684 solver.cpp:244]     Train net output #0: loss = 0.00614365 (* 1 = 0.00614365 loss)
I0930 03:44:55.560746 11684 sgd_solver.cpp:106] Iteration 118700, lr = 0.001
I0930 03:45:14.755610 11684 solver.cpp:228] Iteration 118800, loss = 0.00909481
I0930 03:45:14.755610 11684 solver.cpp:244]     Train net output #0: loss = 0.00909546 (* 1 = 0.00909546 loss)
I0930 03:45:14.755610 11684 sgd_solver.cpp:106] Iteration 118800, lr = 0.001
I0930 03:45:33.961256 11684 solver.cpp:228] Iteration 118900, loss = 0.00760884
I0930 03:45:33.961256 11684 solver.cpp:244]     Train net output #0: loss = 0.0076095 (* 1 = 0.0076095 loss)
I0930 03:45:33.961256 11684 sgd_solver.cpp:106] Iteration 118900, lr = 0.001
I0930 03:45:53.097898 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_119000.caffemodel
I0930 03:45:53.692306 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_119000.solverstate
I0930 03:45:54.087714 11684 solver.cpp:337] Iteration 119000, Testing net (#0)
I0930 03:46:02.256156 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7351
I0930 03:46:02.256156 11684 solver.cpp:404]     Test net output #1: loss = 1.07629 (* 1 = 1.07629 loss)
I0930 03:46:02.307193 11684 solver.cpp:228] Iteration 119000, loss = 0.00936529
I0930 03:46:02.307193 11684 solver.cpp:244]     Train net output #0: loss = 0.00936595 (* 1 = 0.00936595 loss)
I0930 03:46:02.307193 11684 sgd_solver.cpp:106] Iteration 119000, lr = 0.001
I0930 03:46:21.477747 11684 solver.cpp:228] Iteration 119100, loss = 0.0126858
I0930 03:46:21.477747 11684 solver.cpp:244]     Train net output #0: loss = 0.0126865 (* 1 = 0.0126865 loss)
I0930 03:46:21.477747 11684 sgd_solver.cpp:106] Iteration 119100, lr = 0.001
I0930 03:46:40.656359 11684 solver.cpp:228] Iteration 119200, loss = 0.00928156
I0930 03:46:40.656359 11684 solver.cpp:244]     Train net output #0: loss = 0.00928221 (* 1 = 0.00928221 loss)
I0930 03:46:40.656359 11684 sgd_solver.cpp:106] Iteration 119200, lr = 0.001
I0930 03:46:59.831214 11684 solver.cpp:228] Iteration 119300, loss = 0.0111548
I0930 03:46:59.831214 11684 solver.cpp:244]     Train net output #0: loss = 0.0111555 (* 1 = 0.0111555 loss)
I0930 03:46:59.831214 11684 sgd_solver.cpp:106] Iteration 119300, lr = 0.001
I0930 03:47:19.004117 11684 solver.cpp:228] Iteration 119400, loss = 0.00867756
I0930 03:47:19.004117 11684 solver.cpp:244]     Train net output #0: loss = 0.00867821 (* 1 = 0.00867821 loss)
I0930 03:47:19.004117 11684 sgd_solver.cpp:106] Iteration 119400, lr = 0.001
I0930 03:47:38.175771 11684 solver.cpp:228] Iteration 119500, loss = 0.00834053
I0930 03:47:38.175771 11684 solver.cpp:244]     Train net output #0: loss = 0.00834119 (* 1 = 0.00834119 loss)
I0930 03:47:38.175771 11684 sgd_solver.cpp:106] Iteration 119500, lr = 0.001
I0930 03:47:57.369395 11684 solver.cpp:228] Iteration 119600, loss = 0.0108888
I0930 03:47:57.370395 11684 solver.cpp:244]     Train net output #0: loss = 0.0108895 (* 1 = 0.0108895 loss)
I0930 03:47:57.370395 11684 sgd_solver.cpp:106] Iteration 119600, lr = 0.001
I0930 03:48:16.594038 11684 solver.cpp:228] Iteration 119700, loss = 0.0113219
I0930 03:48:16.594038 11684 solver.cpp:244]     Train net output #0: loss = 0.0113225 (* 1 = 0.0113225 loss)
I0930 03:48:16.594038 11684 sgd_solver.cpp:106] Iteration 119700, lr = 0.001
I0930 03:48:35.797668 11684 solver.cpp:228] Iteration 119800, loss = 0.00845151
I0930 03:48:35.797668 11684 solver.cpp:244]     Train net output #0: loss = 0.00845216 (* 1 = 0.00845216 loss)
I0930 03:48:35.797668 11684 sgd_solver.cpp:106] Iteration 119800, lr = 0.001
I0930 03:48:55.088418 11684 solver.cpp:228] Iteration 119900, loss = 0.0094603
I0930 03:48:55.088418 11684 solver.cpp:244]     Train net output #0: loss = 0.00946095 (* 1 = 0.00946095 loss)
I0930 03:48:55.088418 11684 sgd_solver.cpp:106] Iteration 119900, lr = 0.001
I0930 03:49:14.212991 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_120000.caffemodel
I0930 03:49:14.828872 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_120000.solverstate
I0930 03:49:15.189452 11684 solver.cpp:337] Iteration 120000, Testing net (#0)
I0930 03:49:23.356250 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7354
I0930 03:49:23.357249 11684 solver.cpp:404]     Test net output #1: loss = 1.07041 (* 1 = 1.07041 loss)
I0930 03:49:23.406285 11684 solver.cpp:228] Iteration 120000, loss = 0.00960001
I0930 03:49:23.406285 11684 solver.cpp:244]     Train net output #0: loss = 0.00960066 (* 1 = 0.00960066 loss)
I0930 03:49:23.406285 11684 sgd_solver.cpp:106] Iteration 120000, lr = 0.001
I0930 03:49:42.585104 11684 solver.cpp:228] Iteration 120100, loss = 0.00987753
I0930 03:49:42.586104 11684 solver.cpp:244]     Train net output #0: loss = 0.00987818 (* 1 = 0.00987818 loss)
I0930 03:49:42.586104 11684 sgd_solver.cpp:106] Iteration 120100, lr = 0.001
I0930 03:50:01.773360 11684 solver.cpp:228] Iteration 120200, loss = 0.00651985
I0930 03:50:01.773360 11684 solver.cpp:244]     Train net output #0: loss = 0.0065205 (* 1 = 0.0065205 loss)
I0930 03:50:01.773360 11684 sgd_solver.cpp:106] Iteration 120200, lr = 0.001
I0930 03:50:20.950970 11684 solver.cpp:228] Iteration 120300, loss = 0.0148811
I0930 03:50:20.950970 11684 solver.cpp:244]     Train net output #0: loss = 0.0148818 (* 1 = 0.0148818 loss)
I0930 03:50:20.951972 11684 sgd_solver.cpp:106] Iteration 120300, lr = 0.001
I0930 03:50:40.134282 11684 solver.cpp:228] Iteration 120400, loss = 0.00922612
I0930 03:50:40.134282 11684 solver.cpp:244]     Train net output #0: loss = 0.00922677 (* 1 = 0.00922677 loss)
I0930 03:50:40.134282 11684 sgd_solver.cpp:106] Iteration 120400, lr = 0.001
I0930 03:50:59.313905 11684 solver.cpp:228] Iteration 120500, loss = 0.00850177
I0930 03:50:59.313905 11684 solver.cpp:244]     Train net output #0: loss = 0.00850242 (* 1 = 0.00850242 loss)
I0930 03:50:59.313905 11684 sgd_solver.cpp:106] Iteration 120500, lr = 0.001
I0930 03:51:18.500551 11684 solver.cpp:228] Iteration 120600, loss = 0.0112673
I0930 03:51:18.500551 11684 solver.cpp:244]     Train net output #0: loss = 0.0112679 (* 1 = 0.0112679 loss)
I0930 03:51:18.500551 11684 sgd_solver.cpp:106] Iteration 120600, lr = 0.001
I0930 03:51:37.675173 11684 solver.cpp:228] Iteration 120700, loss = 0.00856643
I0930 03:51:37.675173 11684 solver.cpp:244]     Train net output #0: loss = 0.00856708 (* 1 = 0.00856708 loss)
I0930 03:51:37.675173 11684 sgd_solver.cpp:106] Iteration 120700, lr = 0.001
I0930 03:51:56.859829 11684 solver.cpp:228] Iteration 120800, loss = 0.0112907
I0930 03:51:56.859829 11684 solver.cpp:244]     Train net output #0: loss = 0.0112913 (* 1 = 0.0112913 loss)
I0930 03:51:56.859829 11684 sgd_solver.cpp:106] Iteration 120800, lr = 0.001
I0930 03:52:16.050451 11684 solver.cpp:228] Iteration 120900, loss = 0.0114498
I0930 03:52:16.050451 11684 solver.cpp:244]     Train net output #0: loss = 0.0114505 (* 1 = 0.0114505 loss)
I0930 03:52:16.050451 11684 sgd_solver.cpp:106] Iteration 120900, lr = 0.001
I0930 03:52:35.181128 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_121000.caffemodel
I0930 03:52:35.777552 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_121000.solverstate
I0930 03:52:36.149325 11684 solver.cpp:337] Iteration 121000, Testing net (#0)
I0930 03:52:44.322628 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7406
I0930 03:52:44.322628 11684 solver.cpp:404]     Test net output #1: loss = 1.05904 (* 1 = 1.05904 loss)
I0930 03:52:44.372664 11684 solver.cpp:228] Iteration 121000, loss = 0.0148621
I0930 03:52:44.372664 11684 solver.cpp:244]     Train net output #0: loss = 0.0148627 (* 1 = 0.0148627 loss)
I0930 03:52:44.372664 11684 sgd_solver.cpp:106] Iteration 121000, lr = 0.001
I0930 03:53:03.561296 11684 solver.cpp:228] Iteration 121100, loss = 0.00861593
I0930 03:53:03.561296 11684 solver.cpp:244]     Train net output #0: loss = 0.00861658 (* 1 = 0.00861658 loss)
I0930 03:53:03.561296 11684 sgd_solver.cpp:106] Iteration 121100, lr = 0.001
I0930 03:53:22.742905 11684 solver.cpp:228] Iteration 121200, loss = 0.00669526
I0930 03:53:22.742905 11684 solver.cpp:244]     Train net output #0: loss = 0.00669591 (* 1 = 0.00669591 loss)
I0930 03:53:22.742905 11684 sgd_solver.cpp:106] Iteration 121200, lr = 0.001
I0930 03:53:41.916003 11684 solver.cpp:228] Iteration 121300, loss = 0.0102882
I0930 03:53:41.916003 11684 solver.cpp:244]     Train net output #0: loss = 0.0102888 (* 1 = 0.0102888 loss)
I0930 03:53:41.916003 11684 sgd_solver.cpp:106] Iteration 121300, lr = 0.001
I0930 03:54:01.089612 11684 solver.cpp:228] Iteration 121400, loss = 0.0136526
I0930 03:54:01.089612 11684 solver.cpp:244]     Train net output #0: loss = 0.0136533 (* 1 = 0.0136533 loss)
I0930 03:54:01.089612 11684 sgd_solver.cpp:106] Iteration 121400, lr = 0.001
I0930 03:54:20.270836 11684 solver.cpp:228] Iteration 121500, loss = 0.0104767
I0930 03:54:20.271837 11684 solver.cpp:244]     Train net output #0: loss = 0.0104773 (* 1 = 0.0104773 loss)
I0930 03:54:20.271837 11684 sgd_solver.cpp:106] Iteration 121500, lr = 0.001
I0930 03:54:39.438534 11684 solver.cpp:228] Iteration 121600, loss = 0.0110422
I0930 03:54:39.438534 11684 solver.cpp:244]     Train net output #0: loss = 0.0110429 (* 1 = 0.0110429 loss)
I0930 03:54:39.438534 11684 sgd_solver.cpp:106] Iteration 121600, lr = 0.001
I0930 03:54:58.611378 11684 solver.cpp:228] Iteration 121700, loss = 0.0110697
I0930 03:54:58.611378 11684 solver.cpp:244]     Train net output #0: loss = 0.0110704 (* 1 = 0.0110704 loss)
I0930 03:54:58.611378 11684 sgd_solver.cpp:106] Iteration 121700, lr = 0.001
I0930 03:55:17.783391 11684 solver.cpp:228] Iteration 121800, loss = 0.0103972
I0930 03:55:17.783391 11684 solver.cpp:244]     Train net output #0: loss = 0.0103979 (* 1 = 0.0103979 loss)
I0930 03:55:17.783391 11684 sgd_solver.cpp:106] Iteration 121800, lr = 0.001
I0930 03:55:36.965870 11684 solver.cpp:228] Iteration 121900, loss = 0.00861225
I0930 03:55:36.965870 11684 solver.cpp:244]     Train net output #0: loss = 0.0086129 (* 1 = 0.0086129 loss)
I0930 03:55:36.965870 11684 sgd_solver.cpp:106] Iteration 121900, lr = 0.001
I0930 03:55:56.084426 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_122000.caffemodel
I0930 03:55:56.673846 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_122000.solverstate
I0930 03:55:57.048166 11684 solver.cpp:337] Iteration 122000, Testing net (#0)
I0930 03:56:05.245983 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7403
I0930 03:56:05.245983 11684 solver.cpp:404]     Test net output #1: loss = 1.05931 (* 1 = 1.05931 loss)
I0930 03:56:05.296018 11684 solver.cpp:228] Iteration 122000, loss = 0.00995982
I0930 03:56:05.296018 11684 solver.cpp:244]     Train net output #0: loss = 0.00996047 (* 1 = 0.00996047 loss)
I0930 03:56:05.296018 11684 sgd_solver.cpp:106] Iteration 122000, lr = 0.001
I0930 03:56:24.473656 11684 solver.cpp:228] Iteration 122100, loss = 0.00889874
I0930 03:56:24.473656 11684 solver.cpp:244]     Train net output #0: loss = 0.00889939 (* 1 = 0.00889939 loss)
I0930 03:56:24.473656 11684 sgd_solver.cpp:106] Iteration 122100, lr = 0.001
I0930 03:56:43.662288 11684 solver.cpp:228] Iteration 122200, loss = 0.00955214
I0930 03:56:43.662288 11684 solver.cpp:244]     Train net output #0: loss = 0.00955279 (* 1 = 0.00955279 loss)
I0930 03:56:43.662288 11684 sgd_solver.cpp:106] Iteration 122200, lr = 0.001
I0930 03:57:02.863903 11684 solver.cpp:228] Iteration 122300, loss = 0.00975261
I0930 03:57:02.864904 11684 solver.cpp:244]     Train net output #0: loss = 0.00975326 (* 1 = 0.00975326 loss)
I0930 03:57:02.864904 11684 sgd_solver.cpp:106] Iteration 122300, lr = 0.001
I0930 03:57:22.039538 11684 solver.cpp:228] Iteration 122400, loss = 0.00992709
I0930 03:57:22.039538 11684 solver.cpp:244]     Train net output #0: loss = 0.00992774 (* 1 = 0.00992774 loss)
I0930 03:57:22.039538 11684 sgd_solver.cpp:106] Iteration 122400, lr = 0.001
I0930 03:57:41.216990 11684 solver.cpp:228] Iteration 122500, loss = 0.00854123
I0930 03:57:41.216990 11684 solver.cpp:244]     Train net output #0: loss = 0.00854188 (* 1 = 0.00854188 loss)
I0930 03:57:41.216990 11684 sgd_solver.cpp:106] Iteration 122500, lr = 0.001
I0930 03:58:00.406358 11684 solver.cpp:228] Iteration 122600, loss = 0.00901984
I0930 03:58:00.406358 11684 solver.cpp:244]     Train net output #0: loss = 0.00902049 (* 1 = 0.00902049 loss)
I0930 03:58:00.406358 11684 sgd_solver.cpp:106] Iteration 122600, lr = 0.001
I0930 03:58:19.584950 11684 solver.cpp:228] Iteration 122700, loss = 0.00999285
I0930 03:58:19.584950 11684 solver.cpp:244]     Train net output #0: loss = 0.00999351 (* 1 = 0.00999351 loss)
I0930 03:58:19.584950 11684 sgd_solver.cpp:106] Iteration 122700, lr = 0.001
I0930 03:58:38.750879 11684 solver.cpp:228] Iteration 122800, loss = 0.00703441
I0930 03:58:38.750879 11684 solver.cpp:244]     Train net output #0: loss = 0.00703506 (* 1 = 0.00703506 loss)
I0930 03:58:38.750879 11684 sgd_solver.cpp:106] Iteration 122800, lr = 0.001
I0930 03:58:57.937546 11684 solver.cpp:228] Iteration 122900, loss = 0.00856322
I0930 03:58:57.937546 11684 solver.cpp:244]     Train net output #0: loss = 0.00856387 (* 1 = 0.00856387 loss)
I0930 03:58:57.937546 11684 sgd_solver.cpp:106] Iteration 122900, lr = 0.001
I0930 03:59:17.070752 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_123000.caffemodel
I0930 03:59:17.686147 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_123000.solverstate
I0930 03:59:18.037487 11684 solver.cpp:337] Iteration 123000, Testing net (#0)
I0930 03:59:26.227697 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7401
I0930 03:59:26.227697 11684 solver.cpp:404]     Test net output #1: loss = 1.06221 (* 1 = 1.06221 loss)
I0930 03:59:26.278734 11684 solver.cpp:228] Iteration 123000, loss = 0.00967525
I0930 03:59:26.278734 11684 solver.cpp:244]     Train net output #0: loss = 0.0096759 (* 1 = 0.0096759 loss)
I0930 03:59:26.278734 11684 sgd_solver.cpp:106] Iteration 123000, lr = 0.001
I0930 03:59:45.471369 11684 solver.cpp:228] Iteration 123100, loss = 0.00794375
I0930 03:59:45.471369 11684 solver.cpp:244]     Train net output #0: loss = 0.0079444 (* 1 = 0.0079444 loss)
I0930 03:59:45.471369 11684 sgd_solver.cpp:106] Iteration 123100, lr = 0.001
I0930 04:00:04.657974 11684 solver.cpp:228] Iteration 123200, loss = 0.0128635
I0930 04:00:04.657974 11684 solver.cpp:244]     Train net output #0: loss = 0.0128641 (* 1 = 0.0128641 loss)
I0930 04:00:04.657974 11684 sgd_solver.cpp:106] Iteration 123200, lr = 0.001
I0930 04:00:23.858649 11684 solver.cpp:228] Iteration 123300, loss = 0.00802007
I0930 04:00:23.858649 11684 solver.cpp:244]     Train net output #0: loss = 0.00802072 (* 1 = 0.00802072 loss)
I0930 04:00:23.858649 11684 sgd_solver.cpp:106] Iteration 123300, lr = 0.001
I0930 04:00:43.042316 11684 solver.cpp:228] Iteration 123400, loss = 0.0107714
I0930 04:00:43.042316 11684 solver.cpp:244]     Train net output #0: loss = 0.010772 (* 1 = 0.010772 loss)
I0930 04:00:43.042316 11684 sgd_solver.cpp:106] Iteration 123400, lr = 0.001
I0930 04:01:02.217011 11684 solver.cpp:228] Iteration 123500, loss = 0.0138115
I0930 04:01:02.217011 11684 solver.cpp:244]     Train net output #0: loss = 0.0138122 (* 1 = 0.0138122 loss)
I0930 04:01:02.217011 11684 sgd_solver.cpp:106] Iteration 123500, lr = 0.001
I0930 04:01:21.400223 11684 solver.cpp:228] Iteration 123600, loss = 0.00955059
I0930 04:01:21.400223 11684 solver.cpp:244]     Train net output #0: loss = 0.00955124 (* 1 = 0.00955124 loss)
I0930 04:01:21.400223 11684 sgd_solver.cpp:106] Iteration 123600, lr = 0.001
I0930 04:01:40.592947 11684 solver.cpp:228] Iteration 123700, loss = 0.00784657
I0930 04:01:40.592947 11684 solver.cpp:244]     Train net output #0: loss = 0.00784722 (* 1 = 0.00784722 loss)
I0930 04:01:40.592947 11684 sgd_solver.cpp:106] Iteration 123700, lr = 0.001
I0930 04:01:59.781994 11684 solver.cpp:228] Iteration 123800, loss = 0.012086
I0930 04:01:59.781994 11684 solver.cpp:244]     Train net output #0: loss = 0.0120867 (* 1 = 0.0120867 loss)
I0930 04:01:59.781994 11684 sgd_solver.cpp:106] Iteration 123800, lr = 0.001
I0930 04:02:18.978886 11684 solver.cpp:228] Iteration 123900, loss = 0.00912944
I0930 04:02:18.978886 11684 solver.cpp:244]     Train net output #0: loss = 0.0091301 (* 1 = 0.0091301 loss)
I0930 04:02:18.978886 11684 sgd_solver.cpp:106] Iteration 123900, lr = 0.001
I0930 04:02:38.120265 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_124000.caffemodel
I0930 04:02:38.734591 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_124000.solverstate
I0930 04:02:39.090421 11684 solver.cpp:337] Iteration 124000, Testing net (#0)
I0930 04:02:47.261220 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7404
I0930 04:02:47.261220 11684 solver.cpp:404]     Test net output #1: loss = 1.06615 (* 1 = 1.06615 loss)
I0930 04:02:47.311256 11684 solver.cpp:228] Iteration 124000, loss = 0.0108128
I0930 04:02:47.311256 11684 solver.cpp:244]     Train net output #0: loss = 0.0108134 (* 1 = 0.0108134 loss)
I0930 04:02:47.311256 11684 sgd_solver.cpp:106] Iteration 124000, lr = 0.001
I0930 04:03:06.494801 11684 solver.cpp:228] Iteration 124100, loss = 0.00960733
I0930 04:03:06.494801 11684 solver.cpp:244]     Train net output #0: loss = 0.00960798 (* 1 = 0.00960798 loss)
I0930 04:03:06.494801 11684 sgd_solver.cpp:106] Iteration 124100, lr = 0.001
I0930 04:03:25.693996 11684 solver.cpp:228] Iteration 124200, loss = 0.0122555
I0930 04:03:25.693996 11684 solver.cpp:244]     Train net output #0: loss = 0.0122561 (* 1 = 0.0122561 loss)
I0930 04:03:25.693996 11684 sgd_solver.cpp:106] Iteration 124200, lr = 0.001
I0930 04:03:44.848592 11684 solver.cpp:228] Iteration 124300, loss = 0.0180987
I0930 04:03:44.848592 11684 solver.cpp:244]     Train net output #0: loss = 0.0180993 (* 1 = 0.0180993 loss)
I0930 04:03:44.848592 11684 sgd_solver.cpp:106] Iteration 124300, lr = 0.001
I0930 04:04:04.025202 11684 solver.cpp:228] Iteration 124400, loss = 0.0102081
I0930 04:04:04.025202 11684 solver.cpp:244]     Train net output #0: loss = 0.0102087 (* 1 = 0.0102087 loss)
I0930 04:04:04.025202 11684 sgd_solver.cpp:106] Iteration 124400, lr = 0.001
I0930 04:04:23.216454 11684 solver.cpp:228] Iteration 124500, loss = 0.0108702
I0930 04:04:23.216454 11684 solver.cpp:244]     Train net output #0: loss = 0.0108708 (* 1 = 0.0108708 loss)
I0930 04:04:23.216454 11684 sgd_solver.cpp:106] Iteration 124500, lr = 0.001
I0930 04:04:42.411077 11684 solver.cpp:228] Iteration 124600, loss = 0.00769802
I0930 04:04:42.411077 11684 solver.cpp:244]     Train net output #0: loss = 0.00769867 (* 1 = 0.00769867 loss)
I0930 04:04:42.411077 11684 sgd_solver.cpp:106] Iteration 124600, lr = 0.001
I0930 04:05:01.588964 11684 solver.cpp:228] Iteration 124700, loss = 0.00712439
I0930 04:05:01.588964 11684 solver.cpp:244]     Train net output #0: loss = 0.00712504 (* 1 = 0.00712504 loss)
I0930 04:05:01.588964 11684 sgd_solver.cpp:106] Iteration 124700, lr = 0.001
I0930 04:05:20.757313 11684 solver.cpp:228] Iteration 124800, loss = 0.00978757
I0930 04:05:20.757313 11684 solver.cpp:244]     Train net output #0: loss = 0.00978823 (* 1 = 0.00978823 loss)
I0930 04:05:20.757313 11684 sgd_solver.cpp:106] Iteration 124800, lr = 0.001
I0930 04:05:39.955937 11684 solver.cpp:228] Iteration 124900, loss = 0.0100146
I0930 04:05:39.955937 11684 solver.cpp:244]     Train net output #0: loss = 0.0100152 (* 1 = 0.0100152 loss)
I0930 04:05:39.955937 11684 sgd_solver.cpp:106] Iteration 124900, lr = 0.001
I0930 04:05:59.095470 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_125000.caffemodel
I0930 04:05:59.702836 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_125000.solverstate
I0930 04:06:00.072252 11684 solver.cpp:337] Iteration 125000, Testing net (#0)
I0930 04:06:08.238220 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7379
I0930 04:06:08.238220 11684 solver.cpp:404]     Test net output #1: loss = 1.06013 (* 1 = 1.06013 loss)
I0930 04:06:08.288256 11684 solver.cpp:228] Iteration 125000, loss = 0.00931612
I0930 04:06:08.288256 11684 solver.cpp:244]     Train net output #0: loss = 0.00931677 (* 1 = 0.00931677 loss)
I0930 04:06:08.288256 11684 sgd_solver.cpp:106] Iteration 125000, lr = 0.001
I0930 04:06:27.468915 11684 solver.cpp:228] Iteration 125100, loss = 0.010329
I0930 04:06:27.468915 11684 solver.cpp:244]     Train net output #0: loss = 0.0103297 (* 1 = 0.0103297 loss)
I0930 04:06:27.468915 11684 sgd_solver.cpp:106] Iteration 125100, lr = 0.001
I0930 04:06:46.648527 11684 solver.cpp:228] Iteration 125200, loss = 0.00877727
I0930 04:06:46.648527 11684 solver.cpp:244]     Train net output #0: loss = 0.00877792 (* 1 = 0.00877792 loss)
I0930 04:06:46.648527 11684 sgd_solver.cpp:106] Iteration 125200, lr = 0.001
I0930 04:07:05.826125 11684 solver.cpp:228] Iteration 125300, loss = 0.0095965
I0930 04:07:05.826125 11684 solver.cpp:244]     Train net output #0: loss = 0.00959715 (* 1 = 0.00959715 loss)
I0930 04:07:05.826125 11684 sgd_solver.cpp:106] Iteration 125300, lr = 0.001
I0930 04:07:25.009054 11684 solver.cpp:228] Iteration 125400, loss = 0.011353
I0930 04:07:25.010054 11684 solver.cpp:244]     Train net output #0: loss = 0.0113537 (* 1 = 0.0113537 loss)
I0930 04:07:25.010054 11684 sgd_solver.cpp:106] Iteration 125400, lr = 0.001
I0930 04:07:44.219312 11684 solver.cpp:228] Iteration 125500, loss = 0.00771642
I0930 04:07:44.219312 11684 solver.cpp:244]     Train net output #0: loss = 0.00771708 (* 1 = 0.00771708 loss)
I0930 04:07:44.219312 11684 sgd_solver.cpp:106] Iteration 125500, lr = 0.001
I0930 04:08:03.400599 11684 solver.cpp:228] Iteration 125600, loss = 0.00845135
I0930 04:08:03.400599 11684 solver.cpp:244]     Train net output #0: loss = 0.008452 (* 1 = 0.008452 loss)
I0930 04:08:03.400599 11684 sgd_solver.cpp:106] Iteration 125600, lr = 0.001
I0930 04:08:22.584214 11684 solver.cpp:228] Iteration 125700, loss = 0.00935397
I0930 04:08:22.584214 11684 solver.cpp:244]     Train net output #0: loss = 0.00935463 (* 1 = 0.00935463 loss)
I0930 04:08:22.584214 11684 sgd_solver.cpp:106] Iteration 125700, lr = 0.001
I0930 04:08:41.755177 11684 solver.cpp:228] Iteration 125800, loss = 0.00953271
I0930 04:08:41.755177 11684 solver.cpp:244]     Train net output #0: loss = 0.00953336 (* 1 = 0.00953336 loss)
I0930 04:08:41.755177 11684 sgd_solver.cpp:106] Iteration 125800, lr = 0.001
I0930 04:09:00.925561 11684 solver.cpp:228] Iteration 125900, loss = 0.0100076
I0930 04:09:00.925561 11684 solver.cpp:244]     Train net output #0: loss = 0.0100083 (* 1 = 0.0100083 loss)
I0930 04:09:00.925561 11684 sgd_solver.cpp:106] Iteration 125900, lr = 0.001
I0930 04:09:20.053141 11684 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_126000.caffemodel
I0930 04:09:20.645562 11684 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_126000.solverstate
I0930 04:09:21.059278 11684 solver.cpp:337] Iteration 126000, Testing net (#0)
I0930 04:09:29.227074 11684 solver.cpp:404]     Test net output #0: accuracy = 0.7407
I0930 04:09:29.227074 11684 solver.cpp:404]     Test net output #1: loss = 1.06617 (* 1 = 1.06617 loss)
I0930 04:09:29.278121 11684 solver.cpp:228] Iteration 126000, loss = 0.00843419
I0930 04:09:29.278121 11684 solver.cpp:244]     Train net output #0: loss = 0.00843484 (* 1 = 0.00843484 loss)
I0930 04:09:29.278121 11684 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I0930 04:09:48.464460 11684 solver.cpp:228] Iteration 126100, loss = 0.00829557
I0930 04:09:48.465461 11684 solver.cpp:244]     Train net output #0: loss = 0.00829622 (* 1 = 0.00829622 loss)
I0930 04:09:48.465461 11684 sgd_solver.cpp:106] Iteration 126100, lr = 0.001
I0930 04:10:07.644062 11684 solver.cpp:228] Iteration 126200, loss = 0.00996052
I0930 04:10:07.644062 11684 solver.cpp:244]     Train net output #0: loss = 0.00996117 (* 1 = 0.00996117 loss)
I0930 04:10:07.644062 11684 sgd_solver.cpp:106] Iteration 126200, lr = 0.001
I0930 04:10:26.827172 11684 solver.cpp:228] Iteration 126300, loss = 0.00910576
I0930 04:10:26.827172 11684 solver.cpp:244]     Train net output #0: loss = 0.00910641 (* 1 = 0.00910641 loss)
I0930 04:10:26.827172 11684 sgd_solver.cpp:106] Iteration 126300, lr = 0.001
I0930 04:10:46.015786 11684 solver.cpp:228] Iteration 126400, loss = 0.0105837
I0930 04:10:46.015786 11684 solver.cpp:244]     Train net output #0: loss = 0.0105844 (* 1 = 0.0105844 loss)
I0930 04:10:46.015786 11684 sgd_solver.cpp:106] Iteration 126400, lr = 0.001
I0930 04:11:05.197401 11684 solver.cpp:228] Iteration 126500, loss = 0.0106178
I0930 04:11:05.197401 11684 solver.cpp:244]     Train net output #0: loss = 0.0106184 (* 1 = 0.0106184 loss)
I0930 04:11:05.197401 11684 sgd_solver.cpp:106] Iteration 126500, lr = 0.001
I0930 04:11:24.378013 11684 solver.cpp:228] Iteration 126600, loss = 0.0153557
I0930 04:11:24.378013 11684 solver.cpp:244]     Train net output #0: loss = 0.0153563 (* 1 = 0.0153563 loss)
I0930 04:11:24.378013 11684 sgd_solver.cpp:106] Iteration 126600, lr = 0.001
I0930 04:11:43.550673 11684 solver.cpp:228] Iteration 126700, loss = 0.00993647
I0930 04:11:43.550673 11684 solver.cpp:244]     Train net output #0: loss = 0.00993712 (* 1 = 0.00993712 loss)
I0930 04:11:43.550673 11684 sgd_solver.cpp:106] Iteratio*** Check failure stack trace: ***
& was unexpected at this time.
N:\Caffe> > caffe.log & type c:\directory.txt