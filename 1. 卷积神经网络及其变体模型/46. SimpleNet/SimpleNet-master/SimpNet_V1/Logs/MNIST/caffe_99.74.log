
N:\Caffe\examples\mnist>REM go to the caffe root 

N:\Caffe\examples\mnist>cd ../../ 

N:\Caffe>set BIN=build/x64/Release 

N:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/mnist/solver.prototxt --weights=examples/mnist/simpnet_nodrp_iter_6000.caffemodel 
I1101 13:07:02.504808  8672 caffe.cpp:186] Using GPUs 0
I1101 13:07:02.751842  8672 caffe.cpp:191] GPU 0: GeForce GTX 980
I1101 13:07:03.013686  8672 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.013686  8672 solver.cpp:48] Initializing solver from parameters: 
test_iter: 100
test_interval: 600
base_lr: 0.01983656
display: 100
max_iter: 800000
lr_policy: "poly"
power: 1
momentum: 0.55
weight_decay: 0.0001
snapshot: 600
snapshot_prefix: "examples/mnist/simpnet_nodrp"
solver_mode: GPU
device_id: 0
net: "examples/mnist/simpnet_nodrp_train_test.prototxt"
I1101 13:07:03.014689  8672 solver.cpp:91] Creating training net from net file: examples/mnist/simpnet_nodrp_train_test.prototxt
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer mnist
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I1101 13:07:03.015689  8672 net.cpp:313] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1101 13:07:03.015689  8672 net.cpp:49] Initializing net from parameters: 
name: "SimpNet"
state {
  phase: TRAIN
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  data_param {
    source: "examples/mnist/mnist_train_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1101 13:07:03.016690  8672 layer_factory.hpp:77] Creating layer mnist
I1101 13:07:03.016690  8672 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.017691  8672 net.cpp:91] Creating Layer mnist
I1101 13:07:03.017691  8672 net.cpp:399] mnist -> data
I1101 13:07:03.017691  8672 net.cpp:399] mnist -> label
I1101 13:07:03.018692 11052 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.026698 11052 db_lmdb.cpp:52] Opened lmdb examples/mnist/mnist_train_lmdb_norm2
I1101 13:07:03.050714  8672 data_layer.cpp:41] output data size: 100,1,28,28
I1101 13:07:03.052716  8672 net.cpp:141] Setting up mnist
I1101 13:07:03.052716  8672 net.cpp:148] Top shape: 100 1 28 28 (78400)
I1101 13:07:03.052716  8672 net.cpp:148] Top shape: 100 (100)
I1101 13:07:03.052716  8672 net.cpp:156] Memory required for data: 314000
I1101 13:07:03.052716  8672 layer_factory.hpp:77] Creating layer conv1
I1101 13:07:03.052716  8672 net.cpp:91] Creating Layer conv1
I1101 13:07:03.052716  8672 net.cpp:425] conv1 <- data
I1101 13:07:03.052716  8672 net.cpp:399] conv1 -> conv1
I1101 13:07:03.053717 10456 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.327587  8672 net.cpp:141] Setting up conv1
I1101 13:07:03.327587  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.327587  8672 net.cpp:156] Memory required for data: 20384400
I1101 13:07:03.327587  8672 layer_factory.hpp:77] Creating layer bn1
I1101 13:07:03.327587  8672 net.cpp:91] Creating Layer bn1
I1101 13:07:03.327587  8672 net.cpp:425] bn1 <- conv1
I1101 13:07:03.327587  8672 net.cpp:399] bn1 -> bn1
I1101 13:07:03.328088  8672 net.cpp:141] Setting up bn1
I1101 13:07:03.328088  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.328088  8672 net.cpp:156] Memory required for data: 40454800
I1101 13:07:03.328088  8672 layer_factory.hpp:77] Creating layer scale1
I1101 13:07:03.328088  8672 net.cpp:91] Creating Layer scale1
I1101 13:07:03.328088  8672 net.cpp:425] scale1 <- bn1
I1101 13:07:03.328088  8672 net.cpp:399] scale1 -> scale1
I1101 13:07:03.328088  8672 layer_factory.hpp:77] Creating layer scale1
I1101 13:07:03.328088  8672 net.cpp:141] Setting up scale1
I1101 13:07:03.328088  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.328088  8672 net.cpp:156] Memory required for data: 60525200
I1101 13:07:03.328088  8672 layer_factory.hpp:77] Creating layer relu1
I1101 13:07:03.328088  8672 net.cpp:91] Creating Layer relu1
I1101 13:07:03.328088  8672 net.cpp:425] relu1 <- scale1
I1101 13:07:03.328088  8672 net.cpp:399] relu1 -> relu1
I1101 13:07:03.328769  8672 net.cpp:141] Setting up relu1
I1101 13:07:03.328769  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.328769  8672 net.cpp:156] Memory required for data: 80595600
I1101 13:07:03.328769  8672 layer_factory.hpp:77] Creating layer conv1_0
I1101 13:07:03.328769  8672 net.cpp:91] Creating Layer conv1_0
I1101 13:07:03.328769  8672 net.cpp:425] conv1_0 <- relu1
I1101 13:07:03.328769  8672 net.cpp:399] conv1_0 -> conv1_0
I1101 13:07:03.330771  8672 net.cpp:141] Setting up conv1_0
I1101 13:07:03.330771  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.330771  8672 net.cpp:156] Memory required for data: 120736400
I1101 13:07:03.330771  8672 layer_factory.hpp:77] Creating layer bn1_0
I1101 13:07:03.330771  8672 net.cpp:91] Creating Layer bn1_0
I1101 13:07:03.330771  8672 net.cpp:425] bn1_0 <- conv1_0
I1101 13:07:03.330771  8672 net.cpp:399] bn1_0 -> bn1_0
I1101 13:07:03.331272  8672 net.cpp:141] Setting up bn1_0
I1101 13:07:03.331272  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.331272  8672 net.cpp:156] Memory required for data: 160877200
I1101 13:07:03.331272  8672 layer_factory.hpp:77] Creating layer scale1_0
I1101 13:07:03.331272  8672 net.cpp:91] Creating Layer scale1_0
I1101 13:07:03.331272  8672 net.cpp:425] scale1_0 <- bn1_0
I1101 13:07:03.331272  8672 net.cpp:399] scale1_0 -> scale1_0
I1101 13:07:03.331272  8672 layer_factory.hpp:77] Creating layer scale1_0
I1101 13:07:03.331272  8672 net.cpp:141] Setting up scale1_0
I1101 13:07:03.331272  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.331272  8672 net.cpp:156] Memory required for data: 201018000
I1101 13:07:03.331272  8672 layer_factory.hpp:77] Creating layer relu1_0
I1101 13:07:03.331272  8672 net.cpp:91] Creating Layer relu1_0
I1101 13:07:03.331272  8672 net.cpp:425] relu1_0 <- scale1_0
I1101 13:07:03.331272  8672 net.cpp:399] relu1_0 -> relu1_0
I1101 13:07:03.331892  8672 net.cpp:141] Setting up relu1_0
I1101 13:07:03.331892  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.331892  8672 net.cpp:156] Memory required for data: 241158800
I1101 13:07:03.331892  8672 layer_factory.hpp:77] Creating layer conv2
I1101 13:07:03.331892  8672 net.cpp:91] Creating Layer conv2
I1101 13:07:03.331892  8672 net.cpp:425] conv2 <- relu1_0
I1101 13:07:03.331892  8672 net.cpp:399] conv2 -> conv2
I1101 13:07:03.334895  8672 net.cpp:141] Setting up conv2
I1101 13:07:03.334895  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.334895  8672 net.cpp:156] Memory required for data: 281299600
I1101 13:07:03.334895  8672 layer_factory.hpp:77] Creating layer bn2
I1101 13:07:03.334895  8672 net.cpp:91] Creating Layer bn2
I1101 13:07:03.334895  8672 net.cpp:425] bn2 <- conv2
I1101 13:07:03.334895  8672 net.cpp:399] bn2 -> bn2
I1101 13:07:03.335397  8672 net.cpp:141] Setting up bn2
I1101 13:07:03.335397  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.335397  8672 net.cpp:156] Memory required for data: 321440400
I1101 13:07:03.335397  8672 layer_factory.hpp:77] Creating layer scale2
I1101 13:07:03.335397  8672 net.cpp:91] Creating Layer scale2
I1101 13:07:03.335397  8672 net.cpp:425] scale2 <- bn2
I1101 13:07:03.335397  8672 net.cpp:399] scale2 -> scale2
I1101 13:07:03.335397  8672 layer_factory.hpp:77] Creating layer scale2
I1101 13:07:03.335397  8672 net.cpp:141] Setting up scale2
I1101 13:07:03.335397  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.335397  8672 net.cpp:156] Memory required for data: 361581200
I1101 13:07:03.335397  8672 layer_factory.hpp:77] Creating layer relu2
I1101 13:07:03.335397  8672 net.cpp:91] Creating Layer relu2
I1101 13:07:03.335397  8672 net.cpp:425] relu2 <- scale2
I1101 13:07:03.335397  8672 net.cpp:399] relu2 -> relu2
I1101 13:07:03.336397  8672 net.cpp:141] Setting up relu2
I1101 13:07:03.336397  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.336397  8672 net.cpp:156] Memory required for data: 401722000
I1101 13:07:03.336397  8672 layer_factory.hpp:77] Creating layer conv2_1
I1101 13:07:03.336397  8672 net.cpp:91] Creating Layer conv2_1
I1101 13:07:03.336397  8672 net.cpp:425] conv2_1 <- relu2
I1101 13:07:03.336397  8672 net.cpp:399] conv2_1 -> conv2_1
I1101 13:07:03.340884  8672 net.cpp:141] Setting up conv2_1
I1101 13:07:03.341385  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.341385  8672 net.cpp:156] Memory required for data: 441862800
I1101 13:07:03.341385  8672 layer_factory.hpp:77] Creating layer bn2_1
I1101 13:07:03.341385  8672 net.cpp:91] Creating Layer bn2_1
I1101 13:07:03.341385  8672 net.cpp:425] bn2_1 <- conv2_1
I1101 13:07:03.341385  8672 net.cpp:399] bn2_1 -> bn2_1
I1101 13:07:03.341385  8672 net.cpp:141] Setting up bn2_1
I1101 13:07:03.341385  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.341385  8672 net.cpp:156] Memory required for data: 482003600
I1101 13:07:03.341385  8672 layer_factory.hpp:77] Creating layer scale2_1
I1101 13:07:03.341385  8672 net.cpp:91] Creating Layer scale2_1
I1101 13:07:03.341385  8672 net.cpp:425] scale2_1 <- bn2_1
I1101 13:07:03.341385  8672 net.cpp:399] scale2_1 -> scale2_1
I1101 13:07:03.341385  8672 layer_factory.hpp:77] Creating layer scale2_1
I1101 13:07:03.342386  8672 net.cpp:141] Setting up scale2_1
I1101 13:07:03.342386  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.342386  8672 net.cpp:156] Memory required for data: 522144400
I1101 13:07:03.342386  8672 layer_factory.hpp:77] Creating layer relu2_1
I1101 13:07:03.342386  8672 net.cpp:91] Creating Layer relu2_1
I1101 13:07:03.342386  8672 net.cpp:425] relu2_1 <- scale2_1
I1101 13:07:03.342386  8672 net.cpp:399] relu2_1 -> relu2_1
I1101 13:07:03.343387  8672 net.cpp:141] Setting up relu2_1
I1101 13:07:03.343387  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.343387  8672 net.cpp:156] Memory required for data: 562285200
I1101 13:07:03.343387  8672 layer_factory.hpp:77] Creating layer pool2_1
I1101 13:07:03.343387  8672 net.cpp:91] Creating Layer pool2_1
I1101 13:07:03.343387  8672 net.cpp:425] pool2_1 <- relu2_1
I1101 13:07:03.343387  8672 net.cpp:399] pool2_1 -> pool2_1
I1101 13:07:03.343387  8672 net.cpp:141] Setting up pool2_1
I1101 13:07:03.343387  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.343387  8672 net.cpp:156] Memory required for data: 572320400
I1101 13:07:03.343387  8672 layer_factory.hpp:77] Creating layer conv2_2
I1101 13:07:03.343387  8672 net.cpp:91] Creating Layer conv2_2
I1101 13:07:03.343387  8672 net.cpp:425] conv2_2 <- pool2_1
I1101 13:07:03.343387  8672 net.cpp:399] conv2_2 -> conv2_2
I1101 13:07:03.346889  8672 net.cpp:141] Setting up conv2_2
I1101 13:07:03.346889  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.346889  8672 net.cpp:156] Memory required for data: 582355600
I1101 13:07:03.346889  8672 layer_factory.hpp:77] Creating layer bn2_2
I1101 13:07:03.346889  8672 net.cpp:91] Creating Layer bn2_2
I1101 13:07:03.346889  8672 net.cpp:425] bn2_2 <- conv2_2
I1101 13:07:03.346889  8672 net.cpp:399] bn2_2 -> bn2_2
I1101 13:07:03.347389  8672 net.cpp:141] Setting up bn2_2
I1101 13:07:03.347389  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.347389  8672 net.cpp:156] Memory required for data: 592390800
I1101 13:07:03.347389  8672 layer_factory.hpp:77] Creating layer scale2_2
I1101 13:07:03.347389  8672 net.cpp:91] Creating Layer scale2_2
I1101 13:07:03.347389  8672 net.cpp:425] scale2_2 <- bn2_2
I1101 13:07:03.347389  8672 net.cpp:399] scale2_2 -> scale2_2
I1101 13:07:03.347389  8672 layer_factory.hpp:77] Creating layer scale2_2
I1101 13:07:03.347389  8672 net.cpp:141] Setting up scale2_2
I1101 13:07:03.347389  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.347389  8672 net.cpp:156] Memory required for data: 602426000
I1101 13:07:03.347389  8672 layer_factory.hpp:77] Creating layer relu2_2
I1101 13:07:03.347389  8672 net.cpp:91] Creating Layer relu2_2
I1101 13:07:03.347389  8672 net.cpp:425] relu2_2 <- scale2_2
I1101 13:07:03.347389  8672 net.cpp:399] relu2_2 -> relu2_2
I1101 13:07:03.347889  8672 net.cpp:141] Setting up relu2_2
I1101 13:07:03.347889  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.347889  8672 net.cpp:156] Memory required for data: 612461200
I1101 13:07:03.347889  8672 layer_factory.hpp:77] Creating layer conv3
I1101 13:07:03.347889  8672 net.cpp:91] Creating Layer conv3
I1101 13:07:03.347889  8672 net.cpp:425] conv3 <- relu2_2
I1101 13:07:03.347889  8672 net.cpp:399] conv3 -> conv3
I1101 13:07:03.350692  8672 net.cpp:141] Setting up conv3
I1101 13:07:03.350692  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.350692  8672 net.cpp:156] Memory required for data: 622496400
I1101 13:07:03.350692  8672 layer_factory.hpp:77] Creating layer bn3
I1101 13:07:03.350692  8672 net.cpp:91] Creating Layer bn3
I1101 13:07:03.350692  8672 net.cpp:425] bn3 <- conv3
I1101 13:07:03.350692  8672 net.cpp:399] bn3 -> bn3
I1101 13:07:03.351193  8672 net.cpp:141] Setting up bn3
I1101 13:07:03.351193  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.351193  8672 net.cpp:156] Memory required for data: 632531600
I1101 13:07:03.351193  8672 layer_factory.hpp:77] Creating layer scale3
I1101 13:07:03.351193  8672 net.cpp:91] Creating Layer scale3
I1101 13:07:03.351193  8672 net.cpp:425] scale3 <- bn3
I1101 13:07:03.351193  8672 net.cpp:399] scale3 -> scale3
I1101 13:07:03.351193  8672 layer_factory.hpp:77] Creating layer scale3
I1101 13:07:03.351193  8672 net.cpp:141] Setting up scale3
I1101 13:07:03.351193  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.351193  8672 net.cpp:156] Memory required for data: 642566800
I1101 13:07:03.351193  8672 layer_factory.hpp:77] Creating layer relu3
I1101 13:07:03.351193  8672 net.cpp:91] Creating Layer relu3
I1101 13:07:03.351193  8672 net.cpp:425] relu3 <- scale3
I1101 13:07:03.351193  8672 net.cpp:399] relu3 -> relu3
I1101 13:07:03.351693  8672 net.cpp:141] Setting up relu3
I1101 13:07:03.351693  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.351693  8672 net.cpp:156] Memory required for data: 652602000
I1101 13:07:03.351693  8672 layer_factory.hpp:77] Creating layer conv4
I1101 13:07:03.351693  8672 net.cpp:91] Creating Layer conv4
I1101 13:07:03.351693  8672 net.cpp:425] conv4 <- relu3
I1101 13:07:03.351693  8672 net.cpp:399] conv4 -> conv4
I1101 13:07:03.357141  8672 net.cpp:141] Setting up conv4
I1101 13:07:03.357141  8672 net.cpp:148] Top shape: 100 256 14 14 (5017600)
I1101 13:07:03.357141  8672 net.cpp:156] Memory required for data: 672672400
I1101 13:07:03.357141  8672 layer_factory.hpp:77] Creating layer pool4
I1101 13:07:03.357141  8672 net.cpp:91] Creating Layer pool4
I1101 13:07:03.357141  8672 net.cpp:425] pool4 <- conv4
I1101 13:07:03.357141  8672 net.cpp:399] pool4 -> pool4
I1101 13:07:03.357141  8672 net.cpp:141] Setting up pool4
I1101 13:07:03.357141  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.357141  8672 net.cpp:156] Memory required for data: 677690000
I1101 13:07:03.357642  8672 layer_factory.hpp:77] Creating layer bn4
I1101 13:07:03.357642  8672 net.cpp:91] Creating Layer bn4
I1101 13:07:03.357642  8672 net.cpp:425] bn4 <- pool4
I1101 13:07:03.357642  8672 net.cpp:399] bn4 -> bn4
I1101 13:07:03.357642  8672 net.cpp:141] Setting up bn4
I1101 13:07:03.357642  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.357642  8672 net.cpp:156] Memory required for data: 682707600
I1101 13:07:03.357642  8672 layer_factory.hpp:77] Creating layer scale4
I1101 13:07:03.357642  8672 net.cpp:91] Creating Layer scale4
I1101 13:07:03.357642  8672 net.cpp:425] scale4 <- bn4
I1101 13:07:03.357642  8672 net.cpp:399] scale4 -> scale4
I1101 13:07:03.357642  8672 layer_factory.hpp:77] Creating layer scale4
I1101 13:07:03.357642  8672 net.cpp:141] Setting up scale4
I1101 13:07:03.357642  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.357642  8672 net.cpp:156] Memory required for data: 687725200
I1101 13:07:03.357642  8672 layer_factory.hpp:77] Creating layer relu4
I1101 13:07:03.357642  8672 net.cpp:91] Creating Layer relu4
I1101 13:07:03.357642  8672 net.cpp:425] relu4 <- scale4
I1101 13:07:03.357642  8672 net.cpp:399] relu4 -> relu4
I1101 13:07:03.358644  8672 net.cpp:141] Setting up relu4
I1101 13:07:03.358644  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.358644  8672 net.cpp:156] Memory required for data: 692742800
I1101 13:07:03.358644  8672 layer_factory.hpp:77] Creating layer conv4_1
I1101 13:07:03.358644  8672 net.cpp:91] Creating Layer conv4_1
I1101 13:07:03.358644  8672 net.cpp:425] conv4_1 <- relu4
I1101 13:07:03.359143  8672 net.cpp:399] conv4_1 -> conv4_1
I1101 13:07:03.365648  8672 net.cpp:141] Setting up conv4_1
I1101 13:07:03.366148  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.366148  8672 net.cpp:156] Memory required for data: 697760400
I1101 13:07:03.366148  8672 layer_factory.hpp:77] Creating layer bn4_1
I1101 13:07:03.366148  8672 net.cpp:91] Creating Layer bn4_1
I1101 13:07:03.366148  8672 net.cpp:425] bn4_1 <- conv4_1
I1101 13:07:03.366148  8672 net.cpp:399] bn4_1 -> bn4_1
I1101 13:07:03.366148  8672 net.cpp:141] Setting up bn4_1
I1101 13:07:03.366148  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.366148  8672 net.cpp:156] Memory required for data: 702778000
I1101 13:07:03.366148  8672 layer_factory.hpp:77] Creating layer scale4_1
I1101 13:07:03.366148  8672 net.cpp:91] Creating Layer scale4_1
I1101 13:07:03.366148  8672 net.cpp:425] scale4_1 <- bn4_1
I1101 13:07:03.366148  8672 net.cpp:399] scale4_1 -> scale4_1
I1101 13:07:03.366148  8672 layer_factory.hpp:77] Creating layer scale4_1
I1101 13:07:03.366649  8672 net.cpp:141] Setting up scale4_1
I1101 13:07:03.366649  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.366649  8672 net.cpp:156] Memory required for data: 707795600
I1101 13:07:03.366649  8672 layer_factory.hpp:77] Creating layer relu4_1
I1101 13:07:03.366649  8672 net.cpp:91] Creating Layer relu4_1
I1101 13:07:03.366649  8672 net.cpp:425] relu4_1 <- scale4_1
I1101 13:07:03.366649  8672 net.cpp:399] relu4_1 -> relu4_1
I1101 13:07:03.367148  8672 net.cpp:141] Setting up relu4_1
I1101 13:07:03.367148  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.367148  8672 net.cpp:156] Memory required for data: 712813200
I1101 13:07:03.367148  8672 layer_factory.hpp:77] Creating layer conv4_2
I1101 13:07:03.367148  8672 net.cpp:91] Creating Layer conv4_2
I1101 13:07:03.367148  8672 net.cpp:425] conv4_2 <- relu4_1
I1101 13:07:03.367148  8672 net.cpp:399] conv4_2 -> conv4_2
I1101 13:07:03.375154  8672 net.cpp:141] Setting up conv4_2
I1101 13:07:03.375154  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.375154  8672 net.cpp:156] Memory required for data: 717830800
I1101 13:07:03.375154  8672 layer_factory.hpp:77] Creating layer bn4_2
I1101 13:07:03.375154  8672 net.cpp:91] Creating Layer bn4_2
I1101 13:07:03.375154  8672 net.cpp:425] bn4_2 <- conv4_2
I1101 13:07:03.375154  8672 net.cpp:399] bn4_2 -> bn4_2
I1101 13:07:03.375655  8672 net.cpp:141] Setting up bn4_2
I1101 13:07:03.376157  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.376157  8672 net.cpp:156] Memory required for data: 722848400
I1101 13:07:03.376157  8672 layer_factory.hpp:77] Creating layer scale4_2
I1101 13:07:03.376157  8672 net.cpp:91] Creating Layer scale4_2
I1101 13:07:03.376157  8672 net.cpp:425] scale4_2 <- bn4_2
I1101 13:07:03.376157  8672 net.cpp:399] scale4_2 -> scale4_2
I1101 13:07:03.376157  8672 layer_factory.hpp:77] Creating layer scale4_2
I1101 13:07:03.376157  8672 net.cpp:141] Setting up scale4_2
I1101 13:07:03.376157  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.376157  8672 net.cpp:156] Memory required for data: 727866000
I1101 13:07:03.376157  8672 layer_factory.hpp:77] Creating layer relu4_2
I1101 13:07:03.376157  8672 net.cpp:91] Creating Layer relu4_2
I1101 13:07:03.376657  8672 net.cpp:425] relu4_2 <- scale4_2
I1101 13:07:03.376657  8672 net.cpp:399] relu4_2 -> relu4_2
I1101 13:07:03.376657  8672 net.cpp:141] Setting up relu4_2
I1101 13:07:03.377156  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.377156  8672 net.cpp:156] Memory required for data: 732883600
I1101 13:07:03.377156  8672 layer_factory.hpp:77] Creating layer pool4_2
I1101 13:07:03.377156  8672 net.cpp:91] Creating Layer pool4_2
I1101 13:07:03.377156  8672 net.cpp:425] pool4_2 <- relu4_2
I1101 13:07:03.377156  8672 net.cpp:399] pool4_2 -> pool4_2
I1101 13:07:03.377156  8672 net.cpp:141] Setting up pool4_2
I1101 13:07:03.377156  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.377156  8672 net.cpp:156] Memory required for data: 734522000
I1101 13:07:03.377156  8672 layer_factory.hpp:77] Creating layer conv4_0
I1101 13:07:03.377156  8672 net.cpp:91] Creating Layer conv4_0
I1101 13:07:03.377156  8672 net.cpp:425] conv4_0 <- pool4_2
I1101 13:07:03.377156  8672 net.cpp:399] conv4_0 -> conv4_0
I1101 13:07:03.390386  8672 net.cpp:141] Setting up conv4_0
I1101 13:07:03.390386  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.390386  8672 net.cpp:156] Memory required for data: 737798800
I1101 13:07:03.390386  8672 layer_factory.hpp:77] Creating layer bn4_0
I1101 13:07:03.390386  8672 net.cpp:91] Creating Layer bn4_0
I1101 13:07:03.390386  8672 net.cpp:425] bn4_0 <- conv4_0
I1101 13:07:03.390386  8672 net.cpp:399] bn4_0 -> bn4_0
I1101 13:07:03.390887  8672 net.cpp:141] Setting up bn4_0
I1101 13:07:03.390887  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.390887  8672 net.cpp:156] Memory required for data: 741075600
I1101 13:07:03.390887  8672 layer_factory.hpp:77] Creating layer scale4_0
I1101 13:07:03.390887  8672 net.cpp:91] Creating Layer scale4_0
I1101 13:07:03.390887  8672 net.cpp:425] scale4_0 <- bn4_0
I1101 13:07:03.390887  8672 net.cpp:399] scale4_0 -> scale4_0
I1101 13:07:03.390887  8672 layer_factory.hpp:77] Creating layer scale4_0
I1101 13:07:03.390887  8672 net.cpp:141] Setting up scale4_0
I1101 13:07:03.390887  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.390887  8672 net.cpp:156] Memory required for data: 744352400
I1101 13:07:03.390887  8672 layer_factory.hpp:77] Creating layer relu4_0
I1101 13:07:03.390887  8672 net.cpp:91] Creating Layer relu4_0
I1101 13:07:03.390887  8672 net.cpp:425] relu4_0 <- scale4_0
I1101 13:07:03.390887  8672 net.cpp:399] relu4_0 -> relu4_0
I1101 13:07:03.391388  8672 net.cpp:141] Setting up relu4_0
I1101 13:07:03.391388  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.391388  8672 net.cpp:156] Memory required for data: 747629200
I1101 13:07:03.391388  8672 layer_factory.hpp:77] Creating layer cccp4
I1101 13:07:03.391388  8672 net.cpp:91] Creating Layer cccp4
I1101 13:07:03.391388  8672 net.cpp:425] cccp4 <- relu4_0
I1101 13:07:03.391388  8672 net.cpp:399] cccp4 -> cccp4
I1101 13:07:03.414904  8672 net.cpp:141] Setting up cccp4
I1101 13:07:03.415405  8672 net.cpp:148] Top shape: 100 2048 4 4 (3276800)
I1101 13:07:03.415405  8672 net.cpp:156] Memory required for data: 760736400
I1101 13:07:03.415405  8672 layer_factory.hpp:77] Creating layer relu_cccp4
I1101 13:07:03.415405  8672 net.cpp:91] Creating Layer relu_cccp4
I1101 13:07:03.415405  8672 net.cpp:425] relu_cccp4 <- cccp4
I1101 13:07:03.415405  8672 net.cpp:386] relu_cccp4 -> cccp4 (in-place)
I1101 13:07:03.415742  8672 net.cpp:141] Setting up relu_cccp4
I1101 13:07:03.415742  8672 net.cpp:148] Top shape: 100 2048 4 4 (3276800)
I1101 13:07:03.415742  8672 net.cpp:156] Memory required for data: 773843600
I1101 13:07:03.415742  8672 layer_factory.hpp:77] Creating layer cccp5
I1101 13:07:03.415742  8672 net.cpp:91] Creating Layer cccp5
I1101 13:07:03.415742  8672 net.cpp:425] cccp5 <- cccp4
I1101 13:07:03.415742  8672 net.cpp:399] cccp5 -> cccp5
I1101 13:07:03.423208  8672 net.cpp:141] Setting up cccp5
I1101 13:07:03.423208  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.423208  8672 net.cpp:156] Memory required for data: 775482000
I1101 13:07:03.423208  8672 layer_factory.hpp:77] Creating layer relu_cccp5
I1101 13:07:03.423208  8672 net.cpp:91] Creating Layer relu_cccp5
I1101 13:07:03.423208  8672 net.cpp:425] relu_cccp5 <- cccp5
I1101 13:07:03.423208  8672 net.cpp:386] relu_cccp5 -> cccp5 (in-place)
I1101 13:07:03.423704  8672 net.cpp:141] Setting up relu_cccp5
I1101 13:07:03.423704  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.423704  8672 net.cpp:156] Memory required for data: 777120400
I1101 13:07:03.423704  8672 layer_factory.hpp:77] Creating layer poolcp5
I1101 13:07:03.423704  8672 net.cpp:91] Creating Layer poolcp5
I1101 13:07:03.423704  8672 net.cpp:425] poolcp5 <- cccp5
I1101 13:07:03.423704  8672 net.cpp:399] poolcp5 -> poolcp5
I1101 13:07:03.423704  8672 net.cpp:141] Setting up poolcp5
I1101 13:07:03.423704  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.423704  8672 net.cpp:156] Memory required for data: 777530000
I1101 13:07:03.423704  8672 layer_factory.hpp:77] Creating layer cccp6
I1101 13:07:03.423704  8672 net.cpp:91] Creating Layer cccp6
I1101 13:07:03.423704  8672 net.cpp:425] cccp6 <- poolcp5
I1101 13:07:03.423704  8672 net.cpp:399] cccp6 -> cccp6
I1101 13:07:03.431560  8672 net.cpp:141] Setting up cccp6
I1101 13:07:03.431560  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.431560  8672 net.cpp:156] Memory required for data: 777939600
I1101 13:07:03.431560  8672 layer_factory.hpp:77] Creating layer relu_cccp6
I1101 13:07:03.431560  8672 net.cpp:91] Creating Layer relu_cccp6
I1101 13:07:03.431560  8672 net.cpp:425] relu_cccp6 <- cccp6
I1101 13:07:03.432061  8672 net.cpp:386] relu_cccp6 -> cccp6 (in-place)
I1101 13:07:03.432356  8672 net.cpp:141] Setting up relu_cccp6
I1101 13:07:03.432356  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.432356  8672 net.cpp:156] Memory required for data: 778349200
I1101 13:07:03.432356  8672 layer_factory.hpp:77] Creating layer poolcp6
I1101 13:07:03.432356  8672 net.cpp:91] Creating Layer poolcp6
I1101 13:07:03.432356  8672 net.cpp:425] poolcp6 <- cccp6
I1101 13:07:03.432356  8672 net.cpp:399] poolcp6 -> poolcp6
I1101 13:07:03.432356  8672 net.cpp:141] Setting up poolcp6
I1101 13:07:03.432356  8672 net.cpp:148] Top shape: 100 256 1 1 (25600)
I1101 13:07:03.432356  8672 net.cpp:156] Memory required for data: 778451600
I1101 13:07:03.432356  8672 layer_factory.hpp:77] Creating layer ip1
I1101 13:07:03.432356  8672 net.cpp:91] Creating Layer ip1
I1101 13:07:03.432356  8672 net.cpp:425] ip1 <- poolcp6
I1101 13:07:03.432356  8672 net.cpp:399] ip1 -> ip1
I1101 13:07:03.432857  8672 net.cpp:141] Setting up ip1
I1101 13:07:03.432857  8672 net.cpp:148] Top shape: 100 10 (1000)
I1101 13:07:03.432857  8672 net.cpp:156] Memory required for data: 778455600
I1101 13:07:03.432857  8672 layer_factory.hpp:77] Creating layer loss
I1101 13:07:03.432857  8672 net.cpp:91] Creating Layer loss
I1101 13:07:03.432857  8672 net.cpp:425] loss <- ip1
I1101 13:07:03.432857  8672 net.cpp:425] loss <- label
I1101 13:07:03.432857  8672 net.cpp:399] loss -> loss
I1101 13:07:03.432857  8672 layer_factory.hpp:77] Creating layer loss
I1101 13:07:03.432857  8672 net.cpp:141] Setting up loss
I1101 13:07:03.432857  8672 net.cpp:148] Top shape: (1)
I1101 13:07:03.432857  8672 net.cpp:151]     with loss weight 1
I1101 13:07:03.432857  8672 net.cpp:156] Memory required for data: 778455604
I1101 13:07:03.432857  8672 net.cpp:217] loss needs backward computation.
I1101 13:07:03.432857  8672 net.cpp:217] ip1 needs backward computation.
I1101 13:07:03.432857  8672 net.cpp:217] poolcp6 needs backward computation.
I1101 13:07:03.432857  8672 net.cpp:217] relu_cccp6 needs backward computation.
I1101 13:07:03.432857  8672 net.cpp:217] cccp6 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] poolcp5 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu_cccp5 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] cccp5 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu_cccp4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] cccp4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu4_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale4_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn4_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv4_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] pool4_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu4_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale4_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn4_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv4_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu4_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale4_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn4_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv4_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] pool4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv4 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu3 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale3 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn3 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv3 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu2_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale2_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn2_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv2_2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] pool2_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu2_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale2_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn2_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv2_1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv2 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu1_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale1_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn1_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv1_0 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] relu1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] scale1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] bn1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:217] conv1 needs backward computation.
I1101 13:07:03.433357  8672 net.cpp:219] mnist does not need backward computation.
I1101 13:07:03.433357  8672 net.cpp:261] This network produces output loss
I1101 13:07:03.433357  8672 net.cpp:274] Network initialization done.
I1101 13:07:03.434360  8672 solver.cpp:181] Creating test net (#0) specified by net file: examples/mnist/simpnet_nodrp_train_test.prototxt
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer mnist
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I1101 13:07:03.434859  8672 net.cpp:313] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I1101 13:07:03.434859  8672 net.cpp:49] Initializing net from parameters: 
name: "SimpNet"
state {
  phase: TEST
}
layer {
  name: "mnist"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  data_param {
    source: "examples/mnist/mnist_test_lmdb_norm2"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I1101 13:07:03.435359  8672 layer_factory.hpp:77] Creating layer mnist
I1101 13:07:03.436360  8672 net.cpp:91] Creating Layer mnist
I1101 13:07:03.436360  8672 net.cpp:399] mnist -> data
I1101 13:07:03.436360  8672 net.cpp:399] mnist -> label
I1101 13:07:03.438361 10164 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.444847 10164 db_lmdb.cpp:52] Opened lmdb examples/mnist/mnist_test_lmdb_norm2
I1101 13:07:03.445348  8672 data_layer.cpp:41] output data size: 100,1,28,28
I1101 13:07:03.446851  8672 net.cpp:141] Setting up mnist
I1101 13:07:03.446851  8672 net.cpp:148] Top shape: 100 1 28 28 (78400)
I1101 13:07:03.446851  8672 net.cpp:148] Top shape: 100 (100)
I1101 13:07:03.446851  8672 net.cpp:156] Memory required for data: 314000
I1101 13:07:03.446851  8672 layer_factory.hpp:77] Creating layer label_mnist_1_split
I1101 13:07:03.446851  8672 net.cpp:91] Creating Layer label_mnist_1_split
I1101 13:07:03.446851  8672 net.cpp:425] label_mnist_1_split <- label
I1101 13:07:03.446851  8672 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_0
I1101 13:07:03.446851  8672 net.cpp:399] label_mnist_1_split -> label_mnist_1_split_1
I1101 13:07:03.446851  8672 net.cpp:141] Setting up label_mnist_1_split
I1101 13:07:03.446851  8672 net.cpp:148] Top shape: 100 (100)
I1101 13:07:03.446851  8672 net.cpp:148] Top shape: 100 (100)
I1101 13:07:03.446851  8672 net.cpp:156] Memory required for data: 314800
I1101 13:07:03.446851  8672 layer_factory.hpp:77] Creating layer conv1
I1101 13:07:03.446851  8672 net.cpp:91] Creating Layer conv1
I1101 13:07:03.446851  8672 net.cpp:425] conv1 <- data
I1101 13:07:03.446851  8672 net.cpp:399] conv1 -> conv1
I1101 13:07:03.448851  8672 net.cpp:141] Setting up conv1
I1101 13:07:03.448851  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.448851  8672 net.cpp:156] Memory required for data: 20385200
I1101 13:07:03.448851  8672 layer_factory.hpp:77] Creating layer bn1
I1101 13:07:03.448851  8672 net.cpp:91] Creating Layer bn1
I1101 13:07:03.448851  8672 net.cpp:425] bn1 <- conv1
I1101 13:07:03.448851  8672 net.cpp:399] bn1 -> bn1
I1101 13:07:03.448851 12272 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I1101 13:07:03.449851  8672 net.cpp:141] Setting up bn1
I1101 13:07:03.449851  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.449851  8672 net.cpp:156] Memory required for data: 40455600
I1101 13:07:03.449851  8672 layer_factory.hpp:77] Creating layer scale1
I1101 13:07:03.449851  8672 net.cpp:91] Creating Layer scale1
I1101 13:07:03.449851  8672 net.cpp:425] scale1 <- bn1
I1101 13:07:03.449851  8672 net.cpp:399] scale1 -> scale1
I1101 13:07:03.449851  8672 layer_factory.hpp:77] Creating layer scale1
I1101 13:07:03.449851  8672 net.cpp:141] Setting up scale1
I1101 13:07:03.449851  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.449851  8672 net.cpp:156] Memory required for data: 60526000
I1101 13:07:03.450352  8672 layer_factory.hpp:77] Creating layer relu1
I1101 13:07:03.450352  8672 net.cpp:91] Creating Layer relu1
I1101 13:07:03.450352  8672 net.cpp:425] relu1 <- scale1
I1101 13:07:03.450352  8672 net.cpp:399] relu1 -> relu1
I1101 13:07:03.450352  8672 net.cpp:141] Setting up relu1
I1101 13:07:03.450352  8672 net.cpp:148] Top shape: 100 64 28 28 (5017600)
I1101 13:07:03.450352  8672 net.cpp:156] Memory required for data: 80596400
I1101 13:07:03.450352  8672 layer_factory.hpp:77] Creating layer conv1_0
I1101 13:07:03.450352  8672 net.cpp:91] Creating Layer conv1_0
I1101 13:07:03.450352  8672 net.cpp:425] conv1_0 <- relu1
I1101 13:07:03.450352  8672 net.cpp:399] conv1_0 -> conv1_0
I1101 13:07:03.514765  8672 net.cpp:141] Setting up conv1_0
I1101 13:07:03.514765  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.514765  8672 net.cpp:156] Memory required for data: 120737200
I1101 13:07:03.514765  8672 layer_factory.hpp:77] Creating layer bn1_0
I1101 13:07:03.514765  8672 net.cpp:91] Creating Layer bn1_0
I1101 13:07:03.514765  8672 net.cpp:425] bn1_0 <- conv1_0
I1101 13:07:03.514765  8672 net.cpp:399] bn1_0 -> bn1_0
I1101 13:07:03.514765  8672 net.cpp:141] Setting up bn1_0
I1101 13:07:03.514765  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.514765  8672 net.cpp:156] Memory required for data: 160878000
I1101 13:07:03.514765  8672 layer_factory.hpp:77] Creating layer scale1_0
I1101 13:07:03.514765  8672 net.cpp:91] Creating Layer scale1_0
I1101 13:07:03.514765  8672 net.cpp:425] scale1_0 <- bn1_0
I1101 13:07:03.514765  8672 net.cpp:399] scale1_0 -> scale1_0
I1101 13:07:03.514765  8672 layer_factory.hpp:77] Creating layer scale1_0
I1101 13:07:03.515766  8672 net.cpp:141] Setting up scale1_0
I1101 13:07:03.515766  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.515766  8672 net.cpp:156] Memory required for data: 201018800
I1101 13:07:03.515766  8672 layer_factory.hpp:77] Creating layer relu1_0
I1101 13:07:03.515766  8672 net.cpp:91] Creating Layer relu1_0
I1101 13:07:03.515766  8672 net.cpp:425] relu1_0 <- scale1_0
I1101 13:07:03.515766  8672 net.cpp:399] relu1_0 -> relu1_0
I1101 13:07:03.515766  8672 net.cpp:141] Setting up relu1_0
I1101 13:07:03.515766  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.515766  8672 net.cpp:156] Memory required for data: 241159600
I1101 13:07:03.515766  8672 layer_factory.hpp:77] Creating layer conv2
I1101 13:07:03.515766  8672 net.cpp:91] Creating Layer conv2
I1101 13:07:03.515766  8672 net.cpp:425] conv2 <- relu1_0
I1101 13:07:03.515766  8672 net.cpp:399] conv2 -> conv2
I1101 13:07:03.521770  8672 net.cpp:141] Setting up conv2
I1101 13:07:03.521770  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.521770  8672 net.cpp:156] Memory required for data: 281300400
I1101 13:07:03.521770  8672 layer_factory.hpp:77] Creating layer bn2
I1101 13:07:03.521770  8672 net.cpp:91] Creating Layer bn2
I1101 13:07:03.521770  8672 net.cpp:425] bn2 <- conv2
I1101 13:07:03.521770  8672 net.cpp:399] bn2 -> bn2
I1101 13:07:03.521770  8672 net.cpp:141] Setting up bn2
I1101 13:07:03.521770  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.521770  8672 net.cpp:156] Memory required for data: 321441200
I1101 13:07:03.521770  8672 layer_factory.hpp:77] Creating layer scale2
I1101 13:07:03.521770  8672 net.cpp:91] Creating Layer scale2
I1101 13:07:03.521770  8672 net.cpp:425] scale2 <- bn2
I1101 13:07:03.521770  8672 net.cpp:399] scale2 -> scale2
I1101 13:07:03.521770  8672 layer_factory.hpp:77] Creating layer scale2
I1101 13:07:03.521770  8672 net.cpp:141] Setting up scale2
I1101 13:07:03.521770  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.521770  8672 net.cpp:156] Memory required for data: 361582000
I1101 13:07:03.521770  8672 layer_factory.hpp:77] Creating layer relu2
I1101 13:07:03.521770  8672 net.cpp:91] Creating Layer relu2
I1101 13:07:03.521770  8672 net.cpp:425] relu2 <- scale2
I1101 13:07:03.521770  8672 net.cpp:399] relu2 -> relu2
I1101 13:07:03.522770  8672 net.cpp:141] Setting up relu2
I1101 13:07:03.522770  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.522770  8672 net.cpp:156] Memory required for data: 401722800
I1101 13:07:03.522770  8672 layer_factory.hpp:77] Creating layer conv2_1
I1101 13:07:03.522770  8672 net.cpp:91] Creating Layer conv2_1
I1101 13:07:03.522770  8672 net.cpp:425] conv2_1 <- relu2
I1101 13:07:03.522770  8672 net.cpp:399] conv2_1 -> conv2_1
I1101 13:07:03.527775  8672 net.cpp:141] Setting up conv2_1
I1101 13:07:03.527775  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.527775  8672 net.cpp:156] Memory required for data: 441863600
I1101 13:07:03.527775  8672 layer_factory.hpp:77] Creating layer bn2_1
I1101 13:07:03.527775  8672 net.cpp:91] Creating Layer bn2_1
I1101 13:07:03.527775  8672 net.cpp:425] bn2_1 <- conv2_1
I1101 13:07:03.527775  8672 net.cpp:399] bn2_1 -> bn2_1
I1101 13:07:03.528775  8672 net.cpp:141] Setting up bn2_1
I1101 13:07:03.528775  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.528775  8672 net.cpp:156] Memory required for data: 482004400
I1101 13:07:03.528775  8672 layer_factory.hpp:77] Creating layer scale2_1
I1101 13:07:03.528775  8672 net.cpp:91] Creating Layer scale2_1
I1101 13:07:03.528775  8672 net.cpp:425] scale2_1 <- bn2_1
I1101 13:07:03.528775  8672 net.cpp:399] scale2_1 -> scale2_1
I1101 13:07:03.528775  8672 layer_factory.hpp:77] Creating layer scale2_1
I1101 13:07:03.528775  8672 net.cpp:141] Setting up scale2_1
I1101 13:07:03.528775  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.528775  8672 net.cpp:156] Memory required for data: 522145200
I1101 13:07:03.528775  8672 layer_factory.hpp:77] Creating layer relu2_1
I1101 13:07:03.528775  8672 net.cpp:91] Creating Layer relu2_1
I1101 13:07:03.528775  8672 net.cpp:425] relu2_1 <- scale2_1
I1101 13:07:03.528775  8672 net.cpp:399] relu2_1 -> relu2_1
I1101 13:07:03.528775  8672 net.cpp:141] Setting up relu2_1
I1101 13:07:03.528775  8672 net.cpp:148] Top shape: 100 128 28 28 (10035200)
I1101 13:07:03.528775  8672 net.cpp:156] Memory required for data: 562286000
I1101 13:07:03.528775  8672 layer_factory.hpp:77] Creating layer pool2_1
I1101 13:07:03.528775  8672 net.cpp:91] Creating Layer pool2_1
I1101 13:07:03.528775  8672 net.cpp:425] pool2_1 <- relu2_1
I1101 13:07:03.528775  8672 net.cpp:399] pool2_1 -> pool2_1
I1101 13:07:03.528775  8672 net.cpp:141] Setting up pool2_1
I1101 13:07:03.528775  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.528775  8672 net.cpp:156] Memory required for data: 572321200
I1101 13:07:03.528775  8672 layer_factory.hpp:77] Creating layer conv2_2
I1101 13:07:03.528775  8672 net.cpp:91] Creating Layer conv2_2
I1101 13:07:03.528775  8672 net.cpp:425] conv2_2 <- pool2_1
I1101 13:07:03.528775  8672 net.cpp:399] conv2_2 -> conv2_2
I1101 13:07:03.533396  8672 net.cpp:141] Setting up conv2_2
I1101 13:07:03.533396  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.533396  8672 net.cpp:156] Memory required for data: 582356400
I1101 13:07:03.533396  8672 layer_factory.hpp:77] Creating layer bn2_2
I1101 13:07:03.533396  8672 net.cpp:91] Creating Layer bn2_2
I1101 13:07:03.533396  8672 net.cpp:425] bn2_2 <- conv2_2
I1101 13:07:03.533396  8672 net.cpp:399] bn2_2 -> bn2_2
I1101 13:07:03.533396  8672 net.cpp:141] Setting up bn2_2
I1101 13:07:03.533396  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.533396  8672 net.cpp:156] Memory required for data: 592391600
I1101 13:07:03.533396  8672 layer_factory.hpp:77] Creating layer scale2_2
I1101 13:07:03.533396  8672 net.cpp:91] Creating Layer scale2_2
I1101 13:07:03.533396  8672 net.cpp:425] scale2_2 <- bn2_2
I1101 13:07:03.533396  8672 net.cpp:399] scale2_2 -> scale2_2
I1101 13:07:03.533396  8672 layer_factory.hpp:77] Creating layer scale2_2
I1101 13:07:03.533396  8672 net.cpp:141] Setting up scale2_2
I1101 13:07:03.533396  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.533396  8672 net.cpp:156] Memory required for data: 602426800
I1101 13:07:03.533396  8672 layer_factory.hpp:77] Creating layer relu2_2
I1101 13:07:03.533396  8672 net.cpp:91] Creating Layer relu2_2
I1101 13:07:03.533396  8672 net.cpp:425] relu2_2 <- scale2_2
I1101 13:07:03.533396  8672 net.cpp:399] relu2_2 -> relu2_2
I1101 13:07:03.534396  8672 net.cpp:141] Setting up relu2_2
I1101 13:07:03.534396  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.534396  8672 net.cpp:156] Memory required for data: 612462000
I1101 13:07:03.534396  8672 layer_factory.hpp:77] Creating layer conv3
I1101 13:07:03.534396  8672 net.cpp:91] Creating Layer conv3
I1101 13:07:03.534396  8672 net.cpp:425] conv3 <- relu2_2
I1101 13:07:03.534396  8672 net.cpp:399] conv3 -> conv3
I1101 13:07:03.538400  8672 net.cpp:141] Setting up conv3
I1101 13:07:03.538400  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.538400  8672 net.cpp:156] Memory required for data: 622497200
I1101 13:07:03.538400  8672 layer_factory.hpp:77] Creating layer bn3
I1101 13:07:03.538400  8672 net.cpp:91] Creating Layer bn3
I1101 13:07:03.538400  8672 net.cpp:425] bn3 <- conv3
I1101 13:07:03.538400  8672 net.cpp:399] bn3 -> bn3
I1101 13:07:03.538400  8672 net.cpp:141] Setting up bn3
I1101 13:07:03.538400  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.538400  8672 net.cpp:156] Memory required for data: 632532400
I1101 13:07:03.538400  8672 layer_factory.hpp:77] Creating layer scale3
I1101 13:07:03.538400  8672 net.cpp:91] Creating Layer scale3
I1101 13:07:03.538400  8672 net.cpp:425] scale3 <- bn3
I1101 13:07:03.538400  8672 net.cpp:399] scale3 -> scale3
I1101 13:07:03.538400  8672 layer_factory.hpp:77] Creating layer scale3
I1101 13:07:03.538400  8672 net.cpp:141] Setting up scale3
I1101 13:07:03.538400  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.538400  8672 net.cpp:156] Memory required for data: 642567600
I1101 13:07:03.538400  8672 layer_factory.hpp:77] Creating layer relu3
I1101 13:07:03.539402  8672 net.cpp:91] Creating Layer relu3
I1101 13:07:03.539402  8672 net.cpp:425] relu3 <- scale3
I1101 13:07:03.539402  8672 net.cpp:399] relu3 -> relu3
I1101 13:07:03.539402  8672 net.cpp:141] Setting up relu3
I1101 13:07:03.539402  8672 net.cpp:148] Top shape: 100 128 14 14 (2508800)
I1101 13:07:03.539402  8672 net.cpp:156] Memory required for data: 652602800
I1101 13:07:03.539402  8672 layer_factory.hpp:77] Creating layer conv4
I1101 13:07:03.539402  8672 net.cpp:91] Creating Layer conv4
I1101 13:07:03.539402  8672 net.cpp:425] conv4 <- relu3
I1101 13:07:03.539402  8672 net.cpp:399] conv4 -> conv4
I1101 13:07:03.544976  8672 net.cpp:141] Setting up conv4
I1101 13:07:03.544976  8672 net.cpp:148] Top shape: 100 256 14 14 (5017600)
I1101 13:07:03.544976  8672 net.cpp:156] Memory required for data: 672673200
I1101 13:07:03.544976  8672 layer_factory.hpp:77] Creating layer pool4
I1101 13:07:03.544976  8672 net.cpp:91] Creating Layer pool4
I1101 13:07:03.544976  8672 net.cpp:425] pool4 <- conv4
I1101 13:07:03.544976  8672 net.cpp:399] pool4 -> pool4
I1101 13:07:03.544976  8672 net.cpp:141] Setting up pool4
I1101 13:07:03.544976  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.544976  8672 net.cpp:156] Memory required for data: 677690800
I1101 13:07:03.544976  8672 layer_factory.hpp:77] Creating layer bn4
I1101 13:07:03.544976  8672 net.cpp:91] Creating Layer bn4
I1101 13:07:03.544976  8672 net.cpp:425] bn4 <- pool4
I1101 13:07:03.544976  8672 net.cpp:399] bn4 -> bn4
I1101 13:07:03.544976  8672 net.cpp:141] Setting up bn4
I1101 13:07:03.544976  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.544976  8672 net.cpp:156] Memory required for data: 682708400
I1101 13:07:03.544976  8672 layer_factory.hpp:77] Creating layer scale4
I1101 13:07:03.544976  8672 net.cpp:91] Creating Layer scale4
I1101 13:07:03.544976  8672 net.cpp:425] scale4 <- bn4
I1101 13:07:03.544976  8672 net.cpp:399] scale4 -> scale4
I1101 13:07:03.544976  8672 layer_factory.hpp:77] Creating layer scale4
I1101 13:07:03.544976  8672 net.cpp:141] Setting up scale4
I1101 13:07:03.544976  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.544976  8672 net.cpp:156] Memory required for data: 687726000
I1101 13:07:03.545979  8672 layer_factory.hpp:77] Creating layer relu4
I1101 13:07:03.545979  8672 net.cpp:91] Creating Layer relu4
I1101 13:07:03.545979  8672 net.cpp:425] relu4 <- scale4
I1101 13:07:03.545979  8672 net.cpp:399] relu4 -> relu4
I1101 13:07:03.545979  8672 net.cpp:141] Setting up relu4
I1101 13:07:03.545979  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.545979  8672 net.cpp:156] Memory required for data: 692743600
I1101 13:07:03.545979  8672 layer_factory.hpp:77] Creating layer conv4_1
I1101 13:07:03.545979  8672 net.cpp:91] Creating Layer conv4_1
I1101 13:07:03.545979  8672 net.cpp:425] conv4_1 <- relu4
I1101 13:07:03.545979  8672 net.cpp:399] conv4_1 -> conv4_1
I1101 13:07:03.552063  8672 net.cpp:141] Setting up conv4_1
I1101 13:07:03.552063  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.552063  8672 net.cpp:156] Memory required for data: 697761200
I1101 13:07:03.552063  8672 layer_factory.hpp:77] Creating layer bn4_1
I1101 13:07:03.552063  8672 net.cpp:91] Creating Layer bn4_1
I1101 13:07:03.552063  8672 net.cpp:425] bn4_1 <- conv4_1
I1101 13:07:03.552063  8672 net.cpp:399] bn4_1 -> bn4_1
I1101 13:07:03.553064  8672 net.cpp:141] Setting up bn4_1
I1101 13:07:03.553064  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.553064  8672 net.cpp:156] Memory required for data: 702778800
I1101 13:07:03.553064  8672 layer_factory.hpp:77] Creating layer scale4_1
I1101 13:07:03.553064  8672 net.cpp:91] Creating Layer scale4_1
I1101 13:07:03.553064  8672 net.cpp:425] scale4_1 <- bn4_1
I1101 13:07:03.553064  8672 net.cpp:399] scale4_1 -> scale4_1
I1101 13:07:03.553064  8672 layer_factory.hpp:77] Creating layer scale4_1
I1101 13:07:03.553064  8672 net.cpp:141] Setting up scale4_1
I1101 13:07:03.553064  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.553064  8672 net.cpp:156] Memory required for data: 707796400
I1101 13:07:03.553064  8672 layer_factory.hpp:77] Creating layer relu4_1
I1101 13:07:03.553064  8672 net.cpp:91] Creating Layer relu4_1
I1101 13:07:03.553064  8672 net.cpp:425] relu4_1 <- scale4_1
I1101 13:07:03.553064  8672 net.cpp:399] relu4_1 -> relu4_1
I1101 13:07:03.555066  8672 net.cpp:141] Setting up relu4_1
I1101 13:07:03.555066  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.555066  8672 net.cpp:156] Memory required for data: 712814000
I1101 13:07:03.555066  8672 layer_factory.hpp:77] Creating layer conv4_2
I1101 13:07:03.555066  8672 net.cpp:91] Creating Layer conv4_2
I1101 13:07:03.555066  8672 net.cpp:425] conv4_2 <- relu4_1
I1101 13:07:03.555066  8672 net.cpp:399] conv4_2 -> conv4_2
I1101 13:07:03.564940  8672 net.cpp:141] Setting up conv4_2
I1101 13:07:03.564940  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.564940  8672 net.cpp:156] Memory required for data: 717831600
I1101 13:07:03.564940  8672 layer_factory.hpp:77] Creating layer bn4_2
I1101 13:07:03.564940  8672 net.cpp:91] Creating Layer bn4_2
I1101 13:07:03.564940  8672 net.cpp:425] bn4_2 <- conv4_2
I1101 13:07:03.564940  8672 net.cpp:399] bn4_2 -> bn4_2
I1101 13:07:03.564940  8672 net.cpp:141] Setting up bn4_2
I1101 13:07:03.564940  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.564940  8672 net.cpp:156] Memory required for data: 722849200
I1101 13:07:03.564940  8672 layer_factory.hpp:77] Creating layer scale4_2
I1101 13:07:03.564940  8672 net.cpp:91] Creating Layer scale4_2
I1101 13:07:03.564940  8672 net.cpp:425] scale4_2 <- bn4_2
I1101 13:07:03.564940  8672 net.cpp:399] scale4_2 -> scale4_2
I1101 13:07:03.564940  8672 layer_factory.hpp:77] Creating layer scale4_2
I1101 13:07:03.564940  8672 net.cpp:141] Setting up scale4_2
I1101 13:07:03.564940  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.564940  8672 net.cpp:156] Memory required for data: 727866800
I1101 13:07:03.564940  8672 layer_factory.hpp:77] Creating layer relu4_2
I1101 13:07:03.564940  8672 net.cpp:91] Creating Layer relu4_2
I1101 13:07:03.564940  8672 net.cpp:425] relu4_2 <- scale4_2
I1101 13:07:03.564940  8672 net.cpp:399] relu4_2 -> relu4_2
I1101 13:07:03.565943  8672 net.cpp:141] Setting up relu4_2
I1101 13:07:03.565943  8672 net.cpp:148] Top shape: 100 256 7 7 (1254400)
I1101 13:07:03.565943  8672 net.cpp:156] Memory required for data: 732884400
I1101 13:07:03.565943  8672 layer_factory.hpp:77] Creating layer pool4_2
I1101 13:07:03.565943  8672 net.cpp:91] Creating Layer pool4_2
I1101 13:07:03.565943  8672 net.cpp:425] pool4_2 <- relu4_2
I1101 13:07:03.565943  8672 net.cpp:399] pool4_2 -> pool4_2
I1101 13:07:03.565943  8672 net.cpp:141] Setting up pool4_2
I1101 13:07:03.565943  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.565943  8672 net.cpp:156] Memory required for data: 734522800
I1101 13:07:03.565943  8672 layer_factory.hpp:77] Creating layer conv4_0
I1101 13:07:03.565943  8672 net.cpp:91] Creating Layer conv4_0
I1101 13:07:03.565943  8672 net.cpp:425] conv4_0 <- pool4_2
I1101 13:07:03.565943  8672 net.cpp:399] conv4_0 -> conv4_0
I1101 13:07:03.578851  8672 net.cpp:141] Setting up conv4_0
I1101 13:07:03.578851  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.578851  8672 net.cpp:156] Memory required for data: 737799600
I1101 13:07:03.578851  8672 layer_factory.hpp:77] Creating layer bn4_0
I1101 13:07:03.578851  8672 net.cpp:91] Creating Layer bn4_0
I1101 13:07:03.578851  8672 net.cpp:425] bn4_0 <- conv4_0
I1101 13:07:03.578851  8672 net.cpp:399] bn4_0 -> bn4_0
I1101 13:07:03.578851  8672 net.cpp:141] Setting up bn4_0
I1101 13:07:03.578851  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.578851  8672 net.cpp:156] Memory required for data: 741076400
I1101 13:07:03.578851  8672 layer_factory.hpp:77] Creating layer scale4_0
I1101 13:07:03.578851  8672 net.cpp:91] Creating Layer scale4_0
I1101 13:07:03.578851  8672 net.cpp:425] scale4_0 <- bn4_0
I1101 13:07:03.578851  8672 net.cpp:399] scale4_0 -> scale4_0
I1101 13:07:03.578851  8672 layer_factory.hpp:77] Creating layer scale4_0
I1101 13:07:03.578851  8672 net.cpp:141] Setting up scale4_0
I1101 13:07:03.578851  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.578851  8672 net.cpp:156] Memory required for data: 744353200
I1101 13:07:03.579854  8672 layer_factory.hpp:77] Creating layer relu4_0
I1101 13:07:03.579854  8672 net.cpp:91] Creating Layer relu4_0
I1101 13:07:03.579854  8672 net.cpp:425] relu4_0 <- scale4_0
I1101 13:07:03.579854  8672 net.cpp:399] relu4_0 -> relu4_0
I1101 13:07:03.579854  8672 net.cpp:141] Setting up relu4_0
I1101 13:07:03.579854  8672 net.cpp:148] Top shape: 100 512 4 4 (819200)
I1101 13:07:03.579854  8672 net.cpp:156] Memory required for data: 747630000
I1101 13:07:03.579854  8672 layer_factory.hpp:77] Creating layer cccp4
I1101 13:07:03.579854  8672 net.cpp:91] Creating Layer cccp4
I1101 13:07:03.579854  8672 net.cpp:425] cccp4 <- relu4_0
I1101 13:07:03.579854  8672 net.cpp:399] cccp4 -> cccp4
I1101 13:07:03.595439  8672 net.cpp:141] Setting up cccp4
I1101 13:07:03.595439  8672 net.cpp:148] Top shape: 100 2048 4 4 (3276800)
I1101 13:07:03.595439  8672 net.cpp:156] Memory required for data: 760737200
I1101 13:07:03.595439  8672 layer_factory.hpp:77] Creating layer relu_cccp4
I1101 13:07:03.595439  8672 net.cpp:91] Creating Layer relu_cccp4
I1101 13:07:03.595439  8672 net.cpp:425] relu_cccp4 <- cccp4
I1101 13:07:03.595439  8672 net.cpp:386] relu_cccp4 -> cccp4 (in-place)
I1101 13:07:03.596442  8672 net.cpp:141] Setting up relu_cccp4
I1101 13:07:03.596442  8672 net.cpp:148] Top shape: 100 2048 4 4 (3276800)
I1101 13:07:03.596442  8672 net.cpp:156] Memory required for data: 773844400
I1101 13:07:03.596442  8672 layer_factory.hpp:77] Creating layer cccp5
I1101 13:07:03.596442  8672 net.cpp:91] Creating Layer cccp5
I1101 13:07:03.596442  8672 net.cpp:425] cccp5 <- cccp4
I1101 13:07:03.596442  8672 net.cpp:399] cccp5 -> cccp5
I1101 13:07:03.602447  8672 net.cpp:141] Setting up cccp5
I1101 13:07:03.602447  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.602447  8672 net.cpp:156] Memory required for data: 775482800
I1101 13:07:03.602447  8672 layer_factory.hpp:77] Creating layer relu_cccp5
I1101 13:07:03.602447  8672 net.cpp:91] Creating Layer relu_cccp5
I1101 13:07:03.602447  8672 net.cpp:425] relu_cccp5 <- cccp5
I1101 13:07:03.602447  8672 net.cpp:386] relu_cccp5 -> cccp5 (in-place)
I1101 13:07:03.602447  8672 net.cpp:141] Setting up relu_cccp5
I1101 13:07:03.602447  8672 net.cpp:148] Top shape: 100 256 4 4 (409600)
I1101 13:07:03.602447  8672 net.cpp:156] Memory required for data: 777121200
I1101 13:07:03.602447  8672 layer_factory.hpp:77] Creating layer poolcp5
I1101 13:07:03.603447  8672 net.cpp:91] Creating Layer poolcp5
I1101 13:07:03.603447  8672 net.cpp:425] poolcp5 <- cccp5
I1101 13:07:03.603447  8672 net.cpp:399] poolcp5 -> poolcp5
I1101 13:07:03.603447  8672 net.cpp:141] Setting up poolcp5
I1101 13:07:03.603447  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.603447  8672 net.cpp:156] Memory required for data: 777530800
I1101 13:07:03.603447  8672 layer_factory.hpp:77] Creating layer cccp6
I1101 13:07:03.603447  8672 net.cpp:91] Creating Layer cccp6
I1101 13:07:03.603447  8672 net.cpp:425] cccp6 <- poolcp5
I1101 13:07:03.603447  8672 net.cpp:399] cccp6 -> cccp6
I1101 13:07:03.611951  8672 net.cpp:141] Setting up cccp6
I1101 13:07:03.612453  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.612453  8672 net.cpp:156] Memory required for data: 777940400
I1101 13:07:03.612453  8672 layer_factory.hpp:77] Creating layer relu_cccp6
I1101 13:07:03.612453  8672 net.cpp:91] Creating Layer relu_cccp6
I1101 13:07:03.612453  8672 net.cpp:425] relu_cccp6 <- cccp6
I1101 13:07:03.612453  8672 net.cpp:386] relu_cccp6 -> cccp6 (in-place)
I1101 13:07:03.612453  8672 net.cpp:141] Setting up relu_cccp6
I1101 13:07:03.612453  8672 net.cpp:148] Top shape: 100 256 2 2 (102400)
I1101 13:07:03.612453  8672 net.cpp:156] Memory required for data: 778350000
I1101 13:07:03.612453  8672 layer_factory.hpp:77] Creating layer poolcp6
I1101 13:07:03.612453  8672 net.cpp:91] Creating Layer poolcp6
I1101 13:07:03.612453  8672 net.cpp:425] poolcp6 <- cccp6
I1101 13:07:03.612453  8672 net.cpp:399] poolcp6 -> poolcp6
I1101 13:07:03.612453  8672 net.cpp:141] Setting up poolcp6
I1101 13:07:03.612453  8672 net.cpp:148] Top shape: 100 256 1 1 (25600)
I1101 13:07:03.612453  8672 net.cpp:156] Memory required for data: 778452400
I1101 13:07:03.612453  8672 layer_factory.hpp:77] Creating layer ip1
I1101 13:07:03.612953  8672 net.cpp:91] Creating Layer ip1
I1101 13:07:03.612953  8672 net.cpp:425] ip1 <- poolcp6
I1101 13:07:03.612953  8672 net.cpp:399] ip1 -> ip1
I1101 13:07:03.612953  8672 net.cpp:141] Setting up ip1
I1101 13:07:03.612953  8672 net.cpp:148] Top shape: 100 10 (1000)
I1101 13:07:03.612953  8672 net.cpp:156] Memory required for data: 778456400
I1101 13:07:03.612953  8672 layer_factory.hpp:77] Creating layer ip1_ip1_0_split
I1101 13:07:03.612953  8672 net.cpp:91] Creating Layer ip1_ip1_0_split
I1101 13:07:03.612953  8672 net.cpp:425] ip1_ip1_0_split <- ip1
I1101 13:07:03.612953  8672 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_0
I1101 13:07:03.612953  8672 net.cpp:399] ip1_ip1_0_split -> ip1_ip1_0_split_1
I1101 13:07:03.612953  8672 net.cpp:141] Setting up ip1_ip1_0_split
I1101 13:07:03.612953  8672 net.cpp:148] Top shape: 100 10 (1000)
I1101 13:07:03.612953  8672 net.cpp:148] Top shape: 100 10 (1000)
I1101 13:07:03.612953  8672 net.cpp:156] Memory required for data: 778464400
I1101 13:07:03.612953  8672 layer_factory.hpp:77] Creating layer accuracy
I1101 13:07:03.612953  8672 net.cpp:91] Creating Layer accuracy
I1101 13:07:03.612953  8672 net.cpp:425] accuracy <- ip1_ip1_0_split_0
I1101 13:07:03.612953  8672 net.cpp:425] accuracy <- label_mnist_1_split_0
I1101 13:07:03.612953  8672 net.cpp:399] accuracy -> accuracy
I1101 13:07:03.612953  8672 net.cpp:141] Setting up accuracy
I1101 13:07:03.612953  8672 net.cpp:148] Top shape: (1)
I1101 13:07:03.612953  8672 net.cpp:156] Memory required for data: 778464404
I1101 13:07:03.612953  8672 layer_factory.hpp:77] Creating layer loss
I1101 13:07:03.612953  8672 net.cpp:91] Creating Layer loss
I1101 13:07:03.612953  8672 net.cpp:425] loss <- ip1_ip1_0_split_1
I1101 13:07:03.612953  8672 net.cpp:425] loss <- label_mnist_1_split_1
I1101 13:07:03.612953  8672 net.cpp:399] loss -> loss
I1101 13:07:03.612953  8672 layer_factory.hpp:77] Creating layer loss
I1101 13:07:03.613955  8672 net.cpp:141] Setting up loss
I1101 13:07:03.613955  8672 net.cpp:148] Top shape: (1)
I1101 13:07:03.613955  8672 net.cpp:151]     with loss weight 1
I1101 13:07:03.613955  8672 net.cpp:156] Memory required for data: 778464408
I1101 13:07:03.613955  8672 net.cpp:217] loss needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:219] accuracy does not need backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] ip1_ip1_0_split needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] ip1 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] poolcp6 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu_cccp6 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] cccp6 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] poolcp5 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu_cccp5 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] cccp5 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu_cccp4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] cccp4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu4_0 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale4_0 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] bn4_0 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] conv4_0 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] pool4_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu4_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale4_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] bn4_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] conv4_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu4_1 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale4_1 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] bn4_1 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] conv4_1 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] bn4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] pool4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] conv4 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu3 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale3 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] bn3 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] conv3 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] relu2_2 needs backward computation.
I1101 13:07:03.613955  8672 net.cpp:217] scale2_2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] bn2_2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] conv2_2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] pool2_1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] relu2_1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] scale2_1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] bn2_1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] conv2_1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] relu2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] scale2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] bn2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] conv2 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] relu1_0 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] scale1_0 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] bn1_0 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] conv1_0 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] relu1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] scale1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] bn1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:217] conv1 needs backward computation.
I1101 13:07:03.614454  8672 net.cpp:219] label_mnist_1_split does not need backward computation.
I1101 13:07:03.614454  8672 net.cpp:219] mnist does not need backward computation.
I1101 13:07:03.614454  8672 net.cpp:261] This network produces output accuracy
I1101 13:07:03.614454  8672 net.cpp:261] This network produces output loss
I1101 13:07:03.614454  8672 net.cpp:274] Network initialization done.
I1101 13:07:03.614454  8672 solver.cpp:60] Solver scaffolding done.
I1101 13:07:03.617957  8672 caffe.cpp:129] Finetuning from examples/mnist/simpnet_nodrp_iter_6000.caffemodel
I1101 13:07:03.725033  8672 caffe.cpp:220] Starting Optimization
I1101 13:07:03.725033  8672 solver.cpp:279] Solving SimpNet
I1101 13:07:03.725033  8672 solver.cpp:280] Learning Rate Policy: poly
I1101 13:07:03.731271  8672 solver.cpp:337] Iteration 0, Testing net (#0)
I1101 13:07:08.909589  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:07:08.909589  8672 solver.cpp:404]     Test net output #1: loss = 0.0135872 (* 1 = 0.0135872 loss)
I1101 13:07:09.253682  8672 solver.cpp:228] Iteration 0, loss = 0.00401075
I1101 13:07:09.253682  8672 solver.cpp:244]     Train net output #0: loss = 0.00401075 (* 1 = 0.00401075 loss)
I1101 13:07:09.253682  8672 sgd_solver.cpp:106] Iteration 0, lr = 0.0198366
I1101 13:07:25.855804  8672 solver.cpp:228] Iteration 100, loss = 0.00287915
I1101 13:07:25.855804  8672 solver.cpp:244]     Train net output #0: loss = 0.00287915 (* 1 = 0.00287915 loss)
I1101 13:07:25.855804  8672 sgd_solver.cpp:106] Iteration 100, lr = 0.0198341
I1101 13:07:42.373963  8672 solver.cpp:228] Iteration 200, loss = 0.0120345
I1101 13:07:42.373963  8672 solver.cpp:244]     Train net output #0: loss = 0.0120345 (* 1 = 0.0120345 loss)
I1101 13:07:42.373963  8672 sgd_solver.cpp:106] Iteration 200, lr = 0.0198316
I1101 13:07:58.904788  8672 solver.cpp:228] Iteration 300, loss = 0.00917721
I1101 13:07:58.904788  8672 solver.cpp:244]     Train net output #0: loss = 0.0091772 (* 1 = 0.0091772 loss)
I1101 13:07:58.904788  8672 sgd_solver.cpp:106] Iteration 300, lr = 0.0198291
I1101 13:08:15.345957  8672 solver.cpp:228] Iteration 400, loss = 0.00268434
I1101 13:08:15.345957  8672 solver.cpp:244]     Train net output #0: loss = 0.00268433 (* 1 = 0.00268433 loss)
I1101 13:08:15.345957  8672 sgd_solver.cpp:106] Iteration 400, lr = 0.0198266
I1101 13:08:31.776778  8672 solver.cpp:228] Iteration 500, loss = 0.00464943
I1101 13:08:31.776778  8672 solver.cpp:244]     Train net output #0: loss = 0.00464941 (* 1 = 0.00464941 loss)
I1101 13:08:31.776778  8672 sgd_solver.cpp:106] Iteration 500, lr = 0.0198242
I1101 13:08:48.475807  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_600.caffemodel
I1101 13:08:48.629519  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_600.solverstate
I1101 13:08:48.686560  8672 solver.cpp:337] Iteration 600, Testing net (#0)
I1101 13:08:53.741294  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9956
I1101 13:08:53.741294  8672 solver.cpp:404]     Test net output #1: loss = 0.0145557 (* 1 = 0.0145557 loss)
I1101 13:08:53.811965  8672 solver.cpp:228] Iteration 600, loss = 0.000962175
I1101 13:08:53.811965  8672 solver.cpp:244]     Train net output #0: loss = 0.000962155 (* 1 = 0.000962155 loss)
I1101 13:08:53.811965  8672 sgd_solver.cpp:106] Iteration 600, lr = 0.0198217
I1101 13:09:10.536068  8672 solver.cpp:228] Iteration 700, loss = 0.00131751
I1101 13:09:10.536068  8672 solver.cpp:244]     Train net output #0: loss = 0.00131749 (* 1 = 0.00131749 loss)
I1101 13:09:10.536068  8672 sgd_solver.cpp:106] Iteration 700, lr = 0.0198192
I1101 13:09:26.957262  8672 solver.cpp:228] Iteration 800, loss = 0.00474573
I1101 13:09:26.957262  8672 solver.cpp:244]     Train net output #0: loss = 0.0047457 (* 1 = 0.0047457 loss)
I1101 13:09:26.957262  8672 sgd_solver.cpp:106] Iteration 800, lr = 0.0198167
I1101 13:09:44.149715  8672 solver.cpp:228] Iteration 900, loss = 0.00298042
I1101 13:09:44.149715  8672 solver.cpp:244]     Train net output #0: loss = 0.0029804 (* 1 = 0.0029804 loss)
I1101 13:09:44.149715  8672 sgd_solver.cpp:106] Iteration 900, lr = 0.0198142
I1101 13:10:01.321507  8672 solver.cpp:228] Iteration 1000, loss = 0.0024065
I1101 13:10:01.321507  8672 solver.cpp:244]     Train net output #0: loss = 0.00240648 (* 1 = 0.00240648 loss)
I1101 13:10:01.321507  8672 sgd_solver.cpp:106] Iteration 1000, lr = 0.0198118
I1101 13:10:17.901221  8672 solver.cpp:228] Iteration 1100, loss = 0.000608196
I1101 13:10:17.901221  8672 solver.cpp:244]     Train net output #0: loss = 0.000608171 (* 1 = 0.000608171 loss)
I1101 13:10:17.901221  8672 sgd_solver.cpp:106] Iteration 1100, lr = 0.0198093
I1101 13:10:34.348969  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_1200.caffemodel
I1101 13:10:34.468053  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_1200.solverstate
I1101 13:10:34.516088  8672 solver.cpp:337] Iteration 1200, Testing net (#0)
I1101 13:10:39.534562  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9958
I1101 13:10:39.534562  8672 solver.cpp:404]     Test net output #1: loss = 0.0132587 (* 1 = 0.0132587 loss)
I1101 13:10:39.606137  8672 solver.cpp:228] Iteration 1200, loss = 0.000571951
I1101 13:10:39.606137  8672 solver.cpp:244]     Train net output #0: loss = 0.000571923 (* 1 = 0.000571923 loss)
I1101 13:10:39.606137  8672 sgd_solver.cpp:106] Iteration 1200, lr = 0.0198068
I1101 13:10:56.120563  8672 solver.cpp:228] Iteration 1300, loss = 0.00117744
I1101 13:10:56.120563  8672 solver.cpp:244]     Train net output #0: loss = 0.00117741 (* 1 = 0.00117741 loss)
I1101 13:10:56.120563  8672 sgd_solver.cpp:106] Iteration 1300, lr = 0.0198043
I1101 13:11:12.794520  8672 solver.cpp:228] Iteration 1400, loss = 0.00136811
I1101 13:11:12.794520  8672 solver.cpp:244]     Train net output #0: loss = 0.00136808 (* 1 = 0.00136808 loss)
I1101 13:11:12.794520  8672 sgd_solver.cpp:106] Iteration 1400, lr = 0.0198018
I1101 13:11:29.561681  8672 solver.cpp:228] Iteration 1500, loss = 0.00475814
I1101 13:11:29.561681  8672 solver.cpp:244]     Train net output #0: loss = 0.00475811 (* 1 = 0.00475811 loss)
I1101 13:11:29.561681  8672 sgd_solver.cpp:106] Iteration 1500, lr = 0.0197994
I1101 13:11:46.269188  8672 solver.cpp:228] Iteration 1600, loss = 0.000799099
I1101 13:11:46.269188  8672 solver.cpp:244]     Train net output #0: loss = 0.000799069 (* 1 = 0.000799069 loss)
I1101 13:11:46.269188  8672 sgd_solver.cpp:106] Iteration 1600, lr = 0.0197969
I1101 13:12:03.000784  8672 solver.cpp:228] Iteration 1700, loss = 0.000267998
I1101 13:12:03.001286  8672 solver.cpp:244]     Train net output #0: loss = 0.000267968 (* 1 = 0.000267968 loss)
I1101 13:12:03.001286  8672 sgd_solver.cpp:106] Iteration 1700, lr = 0.0197944
I1101 13:12:19.755939  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_1800.caffemodel
I1101 13:12:19.870520  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_1800.solverstate
I1101 13:12:19.916553  8672 solver.cpp:337] Iteration 1800, Testing net (#0)
I1101 13:12:24.948802  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9956
I1101 13:12:24.949302  8672 solver.cpp:404]     Test net output #1: loss = 0.0134564 (* 1 = 0.0134564 loss)
I1101 13:12:25.020017  8672 solver.cpp:228] Iteration 1800, loss = 0.000754468
I1101 13:12:25.020017  8672 solver.cpp:244]     Train net output #0: loss = 0.000754439 (* 1 = 0.000754439 loss)
I1101 13:12:25.020017  8672 sgd_solver.cpp:106] Iteration 1800, lr = 0.0197919
I1101 13:12:41.799389  8672 solver.cpp:228] Iteration 1900, loss = 0.00175205
I1101 13:12:41.799389  8672 solver.cpp:244]     Train net output #0: loss = 0.00175202 (* 1 = 0.00175202 loss)
I1101 13:12:41.799389  8672 sgd_solver.cpp:106] Iteration 1900, lr = 0.0197894
I1101 13:12:58.538532  8672 solver.cpp:228] Iteration 2000, loss = 0.00107192
I1101 13:12:58.538532  8672 solver.cpp:244]     Train net output #0: loss = 0.00107188 (* 1 = 0.00107188 loss)
I1101 13:12:58.538532  8672 sgd_solver.cpp:106] Iteration 2000, lr = 0.019787
I1101 13:13:15.220613  8672 solver.cpp:228] Iteration 2100, loss = 0.000591954
I1101 13:13:15.220613  8672 solver.cpp:244]     Train net output #0: loss = 0.000591922 (* 1 = 0.000591922 loss)
I1101 13:13:15.220613  8672 sgd_solver.cpp:106] Iteration 2100, lr = 0.0197845
I1101 13:13:32.004896  8672 solver.cpp:228] Iteration 2200, loss = 0.000127315
I1101 13:13:32.004896  8672 solver.cpp:244]     Train net output #0: loss = 0.000127283 (* 1 = 0.000127283 loss)
I1101 13:13:32.004896  8672 sgd_solver.cpp:106] Iteration 2200, lr = 0.019782
I1101 13:13:48.716768  8672 solver.cpp:228] Iteration 2300, loss = 0.00027703
I1101 13:13:48.716768  8672 solver.cpp:244]     Train net output #0: loss = 0.000277 (* 1 = 0.000277 loss)
I1101 13:13:48.716768  8672 sgd_solver.cpp:106] Iteration 2300, lr = 0.0197795
I1101 13:14:05.466246  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_2400.caffemodel
I1101 13:14:05.601344  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_2400.solverstate
I1101 13:14:05.657384  8672 solver.cpp:337] Iteration 2400, Testing net (#0)
I1101 13:14:10.702451  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9966
I1101 13:14:10.702451  8672 solver.cpp:404]     Test net output #1: loss = 0.0121464 (* 1 = 0.0121464 loss)
I1101 13:14:10.773881  8672 solver.cpp:228] Iteration 2400, loss = 0.000228826
I1101 13:14:10.774382  8672 solver.cpp:244]     Train net output #0: loss = 0.000228791 (* 1 = 0.000228791 loss)
I1101 13:14:10.774382  8672 sgd_solver.cpp:106] Iteration 2400, lr = 0.0197771
I1101 13:14:27.585971  8672 solver.cpp:228] Iteration 2500, loss = 0.000236057
I1101 13:14:27.585971  8672 solver.cpp:244]     Train net output #0: loss = 0.000236022 (* 1 = 0.000236022 loss)
I1101 13:14:27.585971  8672 sgd_solver.cpp:106] Iteration 2500, lr = 0.0197746
I1101 13:14:44.382174  8672 solver.cpp:228] Iteration 2600, loss = 0.00065714
I1101 13:14:44.382174  8672 solver.cpp:244]     Train net output #0: loss = 0.000657106 (* 1 = 0.000657106 loss)
I1101 13:14:44.382174  8672 sgd_solver.cpp:106] Iteration 2600, lr = 0.0197721
I1101 13:15:01.147310  8672 solver.cpp:228] Iteration 2700, loss = 0.000304313
I1101 13:15:01.147310  8672 solver.cpp:244]     Train net output #0: loss = 0.000304278 (* 1 = 0.000304278 loss)
I1101 13:15:01.147310  8672 sgd_solver.cpp:106] Iteration 2700, lr = 0.0197696
I1101 13:15:17.882171  8672 solver.cpp:228] Iteration 2800, loss = 7.4511e-005
I1101 13:15:17.882171  8672 solver.cpp:244]     Train net output #0: loss = 7.44767e-005 (* 1 = 7.44767e-005 loss)
I1101 13:15:17.882171  8672 sgd_solver.cpp:106] Iteration 2800, lr = 0.0197671
I1101 13:15:34.628587  8672 solver.cpp:228] Iteration 2900, loss = 0.000472238
I1101 13:15:34.628587  8672 solver.cpp:244]     Train net output #0: loss = 0.000472203 (* 1 = 0.000472203 loss)
I1101 13:15:34.628587  8672 sgd_solver.cpp:106] Iteration 2900, lr = 0.0197647
I1101 13:15:51.575639  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_3000.caffemodel
I1101 13:15:51.702728  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_3000.solverstate
I1101 13:15:51.928305  8672 solver.cpp:337] Iteration 3000, Testing net (#0)
I1101 13:15:57.051158  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9971
I1101 13:15:57.051659  8672 solver.cpp:404]     Test net output #1: loss = 0.0114744 (* 1 = 0.0114744 loss)
I1101 13:15:57.121688  8672 solver.cpp:228] Iteration 3000, loss = 0.000161447
I1101 13:15:57.121688  8672 solver.cpp:244]     Train net output #0: loss = 0.000161412 (* 1 = 0.000161412 loss)
I1101 13:15:57.121688  8672 sgd_solver.cpp:106] Iteration 3000, lr = 0.0197622
I1101 13:16:14.119796  8672 solver.cpp:228] Iteration 3100, loss = 0.000645856
I1101 13:16:14.119796  8672 solver.cpp:244]     Train net output #0: loss = 0.000645821 (* 1 = 0.000645821 loss)
I1101 13:16:14.119796  8672 sgd_solver.cpp:106] Iteration 3100, lr = 0.0197597
I1101 13:16:29.696199  8672 solver.cpp:228] Iteration 3200, loss = 0.000313093
I1101 13:16:29.696199  8672 solver.cpp:244]     Train net output #0: loss = 0.000313058 (* 1 = 0.000313058 loss)
I1101 13:16:29.696199  8672 sgd_solver.cpp:106] Iteration 3200, lr = 0.0197572
I1101 13:16:45.481246  8672 solver.cpp:228] Iteration 3300, loss = 0.000173439
I1101 13:16:45.481246  8672 solver.cpp:244]     Train net output #0: loss = 0.000173405 (* 1 = 0.000173405 loss)
I1101 13:16:45.481246  8672 sgd_solver.cpp:106] Iteration 3300, lr = 0.0197547
I1101 13:17:02.896129  8672 solver.cpp:228] Iteration 3400, loss = 5.3008e-005
I1101 13:17:02.896129  8672 solver.cpp:244]     Train net output #0: loss = 5.29734e-005 (* 1 = 5.29734e-005 loss)
I1101 13:17:02.896129  8672 sgd_solver.cpp:106] Iteration 3400, lr = 0.0197523
I1101 13:17:19.416661  8672 solver.cpp:228] Iteration 3500, loss = 0.000200099
I1101 13:17:19.416661  8672 solver.cpp:244]     Train net output #0: loss = 0.000200065 (* 1 = 0.000200065 loss)
I1101 13:17:19.416661  8672 sgd_solver.cpp:106] Iteration 3500, lr = 0.0197498
I1101 13:17:36.168694  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_3600.caffemodel
I1101 13:17:36.298802  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_3600.solverstate
I1101 13:17:36.344820  8672 solver.cpp:337] Iteration 3600, Testing net (#0)
I1101 13:17:41.359340  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9967
I1101 13:17:41.359841  8672 solver.cpp:404]     Test net output #1: loss = 0.0116284 (* 1 = 0.0116284 loss)
I1101 13:17:41.428443  8672 solver.cpp:228] Iteration 3600, loss = 0.000126158
I1101 13:17:41.428443  8672 solver.cpp:244]     Train net output #0: loss = 0.000126124 (* 1 = 0.000126124 loss)
I1101 13:17:41.428443  8672 sgd_solver.cpp:106] Iteration 3600, lr = 0.0197473
I1101 13:17:58.027858  8672 solver.cpp:228] Iteration 3700, loss = 0.000342638
I1101 13:17:58.027858  8672 solver.cpp:244]     Train net output #0: loss = 0.000342604 (* 1 = 0.000342604 loss)
I1101 13:17:58.027858  8672 sgd_solver.cpp:106] Iteration 3700, lr = 0.0197448
I1101 13:18:14.580837  8672 solver.cpp:228] Iteration 3800, loss = 0.000255383
I1101 13:18:14.580837  8672 solver.cpp:244]     Train net output #0: loss = 0.000255348 (* 1 = 0.000255348 loss)
I1101 13:18:14.580837  8672 sgd_solver.cpp:106] Iteration 3800, lr = 0.0197423
I1101 13:18:31.098170  8672 solver.cpp:228] Iteration 3900, loss = 0.000137929
I1101 13:18:31.098170  8672 solver.cpp:244]     Train net output #0: loss = 0.000137895 (* 1 = 0.000137895 loss)
I1101 13:18:31.098170  8672 sgd_solver.cpp:106] Iteration 3900, lr = 0.0197399
I1101 13:18:47.517892  8672 solver.cpp:228] Iteration 4000, loss = 4.49099e-005
I1101 13:18:47.517892  8672 solver.cpp:244]     Train net output #0: loss = 4.48755e-005 (* 1 = 4.48755e-005 loss)
I1101 13:18:47.517892  8672 sgd_solver.cpp:106] Iteration 4000, lr = 0.0197374
I1101 13:19:03.971463  8672 solver.cpp:228] Iteration 4100, loss = 0.000145915
I1101 13:19:03.971463  8672 solver.cpp:244]     Train net output #0: loss = 0.00014588 (* 1 = 0.00014588 loss)
I1101 13:19:03.971463  8672 sgd_solver.cpp:106] Iteration 4100, lr = 0.0197349
I1101 13:19:20.303594  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_4200.caffemodel
I1101 13:19:20.418678  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_4200.solverstate
I1101 13:19:20.465710  8672 solver.cpp:337] Iteration 4200, Testing net (#0)
I1101 13:19:25.416306  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9968
I1101 13:19:25.416306  8672 solver.cpp:404]     Test net output #1: loss = 0.0117939 (* 1 = 0.0117939 loss)
I1101 13:19:25.485393  8672 solver.cpp:228] Iteration 4200, loss = 0.000113506
I1101 13:19:25.485393  8672 solver.cpp:244]     Train net output #0: loss = 0.000113471 (* 1 = 0.000113471 loss)
I1101 13:19:25.485393  8672 sgd_solver.cpp:106] Iteration 4200, lr = 0.0197324
I1101 13:19:41.914378  8672 solver.cpp:228] Iteration 4300, loss = 0.000203208
I1101 13:19:41.914378  8672 solver.cpp:244]     Train net output #0: loss = 0.000203174 (* 1 = 0.000203174 loss)
I1101 13:19:41.914378  8672 sgd_solver.cpp:106] Iteration 4300, lr = 0.0197299
I1101 13:19:58.343111  8672 solver.cpp:228] Iteration 4400, loss = 0.000208873
I1101 13:19:58.343111  8672 solver.cpp:244]     Train net output #0: loss = 0.000208839 (* 1 = 0.000208839 loss)
I1101 13:19:58.343111  8672 sgd_solver.cpp:106] Iteration 4400, lr = 0.0197275
I1101 13:20:14.856673  8672 solver.cpp:228] Iteration 4500, loss = 0.000126467
I1101 13:20:14.856673  8672 solver.cpp:244]     Train net output #0: loss = 0.000126432 (* 1 = 0.000126432 loss)
I1101 13:20:14.856673  8672 sgd_solver.cpp:106] Iteration 4500, lr = 0.019725
I1101 13:20:31.301470  8672 solver.cpp:228] Iteration 4600, loss = 4.03813e-005
I1101 13:20:31.301470  8672 solver.cpp:244]     Train net output #0: loss = 4.03468e-005 (* 1 = 4.03468e-005 loss)
I1101 13:20:31.301470  8672 sgd_solver.cpp:106] Iteration 4600, lr = 0.0197225
I1101 13:20:47.744423  8672 solver.cpp:228] Iteration 4700, loss = 0.000104205
I1101 13:20:47.744423  8672 solver.cpp:244]     Train net output #0: loss = 0.000104171 (* 1 = 0.000104171 loss)
I1101 13:20:47.744423  8672 sgd_solver.cpp:106] Iteration 4700, lr = 0.01972
I1101 13:21:04.086782  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_4800.caffemodel
I1101 13:21:04.227883  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_4800.solverstate
I1101 13:21:04.274916  8672 solver.cpp:337] Iteration 4800, Testing net (#0)
I1101 13:21:09.233305  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9968
I1101 13:21:09.233305  8672 solver.cpp:404]     Test net output #1: loss = 0.0119003 (* 1 = 0.0119003 loss)
I1101 13:21:09.303357  8672 solver.cpp:228] Iteration 4800, loss = 9.08497e-005
I1101 13:21:09.303357  8672 solver.cpp:244]     Train net output #0: loss = 9.08152e-005 (* 1 = 9.08152e-005 loss)
I1101 13:21:09.303357  8672 sgd_solver.cpp:106] Iteration 4800, lr = 0.0197175
I1101 13:21:25.753154  8672 solver.cpp:228] Iteration 4900, loss = 0.000142563
I1101 13:21:25.753154  8672 solver.cpp:244]     Train net output #0: loss = 0.000142528 (* 1 = 0.000142528 loss)
I1101 13:21:25.753154  8672 sgd_solver.cpp:106] Iteration 4900, lr = 0.0197151
I1101 13:21:42.223150  8672 solver.cpp:228] Iteration 5000, loss = 0.000179029
I1101 13:21:42.223150  8672 solver.cpp:244]     Train net output #0: loss = 0.000178994 (* 1 = 0.000178994 loss)
I1101 13:21:42.223150  8672 sgd_solver.cpp:106] Iteration 5000, lr = 0.0197126
I1101 13:21:58.690340  8672 solver.cpp:228] Iteration 5100, loss = 0.000109482
I1101 13:21:58.690340  8672 solver.cpp:244]     Train net output #0: loss = 0.000109447 (* 1 = 0.000109447 loss)
I1101 13:21:58.690340  8672 sgd_solver.cpp:106] Iteration 5100, lr = 0.0197101
I1101 13:22:15.136085  8672 solver.cpp:228] Iteration 5200, loss = 3.60815e-005
I1101 13:22:15.136085  8672 solver.cpp:244]     Train net output #0: loss = 3.60469e-005 (* 1 = 3.60469e-005 loss)
I1101 13:22:15.136085  8672 sgd_solver.cpp:106] Iteration 5200, lr = 0.0197076
I1101 13:22:31.582468  8672 solver.cpp:228] Iteration 5300, loss = 9.24159e-005
I1101 13:22:31.582468  8672 solver.cpp:244]     Train net output #0: loss = 9.23813e-005 (* 1 = 9.23813e-005 loss)
I1101 13:22:31.582468  8672 sgd_solver.cpp:106] Iteration 5300, lr = 0.0197051
I1101 13:22:47.922163  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_5400.caffemodel
I1101 13:22:48.037245  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_5400.solverstate
I1101 13:22:48.083277  8672 solver.cpp:337] Iteration 5400, Testing net (#0)
I1101 13:22:53.074957  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:22:53.074957  8672 solver.cpp:404]     Test net output #1: loss = 0.0119775 (* 1 = 0.0119775 loss)
I1101 13:22:53.144007  8672 solver.cpp:228] Iteration 5400, loss = 8.17905e-005
I1101 13:22:53.144007  8672 solver.cpp:244]     Train net output #0: loss = 8.17559e-005 (* 1 = 8.17559e-005 loss)
I1101 13:22:53.144007  8672 sgd_solver.cpp:106] Iteration 5400, lr = 0.0197027
I1101 13:23:09.628273  8672 solver.cpp:228] Iteration 5500, loss = 0.000125301
I1101 13:23:09.628273  8672 solver.cpp:244]     Train net output #0: loss = 0.000125267 (* 1 = 0.000125267 loss)
I1101 13:23:09.628273  8672 sgd_solver.cpp:106] Iteration 5500, lr = 0.0197002
I1101 13:23:26.064740  8672 solver.cpp:228] Iteration 5600, loss = 0.000159404
I1101 13:23:26.064740  8672 solver.cpp:244]     Train net output #0: loss = 0.000159369 (* 1 = 0.000159369 loss)
I1101 13:23:26.064740  8672 sgd_solver.cpp:106] Iteration 5600, lr = 0.0196977
I1101 13:23:42.541638  8672 solver.cpp:228] Iteration 5700, loss = 0.000102748
I1101 13:23:42.541638  8672 solver.cpp:244]     Train net output #0: loss = 0.000102714 (* 1 = 0.000102714 loss)
I1101 13:23:42.541638  8672 sgd_solver.cpp:106] Iteration 5700, lr = 0.0196952
I1101 13:23:59.009598  8672 solver.cpp:228] Iteration 5800, loss = 3.3218e-005
I1101 13:23:59.009598  8672 solver.cpp:244]     Train net output #0: loss = 3.31834e-005 (* 1 = 3.31834e-005 loss)
I1101 13:23:59.009598  8672 sgd_solver.cpp:106] Iteration 5800, lr = 0.0196927
I1101 13:24:15.582013  8672 solver.cpp:228] Iteration 5900, loss = 8.53274e-005
I1101 13:24:15.582013  8672 solver.cpp:244]     Train net output #0: loss = 8.52927e-005 (* 1 = 8.52927e-005 loss)
I1101 13:24:15.582013  8672 sgd_solver.cpp:106] Iteration 5900, lr = 0.0196903
I1101 13:24:32.446899  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_6000.caffemodel
I1101 13:24:32.607013  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_6000.solverstate
I1101 13:24:32.671525  8672 solver.cpp:337] Iteration 6000, Testing net (#0)
I1101 13:24:37.780454  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:24:37.780454  8672 solver.cpp:404]     Test net output #1: loss = 0.0120559 (* 1 = 0.0120559 loss)
I1101 13:24:37.852813  8672 solver.cpp:228] Iteration 6000, loss = 7.51707e-005
I1101 13:24:37.852813  8672 solver.cpp:244]     Train net output #0: loss = 7.5136e-005 (* 1 = 7.5136e-005 loss)
I1101 13:24:37.852813  8672 sgd_solver.cpp:106] Iteration 6000, lr = 0.0196878
I1101 13:24:54.722651  8672 solver.cpp:228] Iteration 6100, loss = 0.000111154
I1101 13:24:54.722651  8672 solver.cpp:244]     Train net output #0: loss = 0.000111119 (* 1 = 0.000111119 loss)
I1101 13:24:54.722651  8672 sgd_solver.cpp:106] Iteration 6100, lr = 0.0196853
I1101 13:25:11.631428  8672 solver.cpp:228] Iteration 6200, loss = 0.00014512
I1101 13:25:11.631428  8672 solver.cpp:244]     Train net output #0: loss = 0.000145085 (* 1 = 0.000145085 loss)
I1101 13:25:11.631428  8672 sgd_solver.cpp:106] Iteration 6200, lr = 0.0196828
I1101 13:25:28.482033  8672 solver.cpp:228] Iteration 6300, loss = 9.78009e-005
I1101 13:25:28.482033  8672 solver.cpp:244]     Train net output #0: loss = 9.77663e-005 (* 1 = 9.77663e-005 loss)
I1101 13:25:28.482033  8672 sgd_solver.cpp:106] Iteration 6300, lr = 0.0196803
I1101 13:25:45.385010  8672 solver.cpp:228] Iteration 6400, loss = 3.10275e-005
I1101 13:25:45.385010  8672 solver.cpp:244]     Train net output #0: loss = 3.09928e-005 (* 1 = 3.09928e-005 loss)
I1101 13:25:45.385010  8672 sgd_solver.cpp:106] Iteration 6400, lr = 0.0196779
I1101 13:26:02.273414  8672 solver.cpp:228] Iteration 6500, loss = 8.01582e-005
I1101 13:26:02.273414  8672 solver.cpp:244]     Train net output #0: loss = 8.01235e-005 (* 1 = 8.01235e-005 loss)
I1101 13:26:02.273414  8672 sgd_solver.cpp:106] Iteration 6500, lr = 0.0196754
I1101 13:26:19.087565  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_6600.caffemodel
I1101 13:26:19.227666  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_6600.solverstate
I1101 13:26:19.313230  8672 solver.cpp:337] Iteration 6600, Testing net (#0)
I1101 13:26:24.509088  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:26:24.509088  8672 solver.cpp:404]     Test net output #1: loss = 0.0121223 (* 1 = 0.0121223 loss)
I1101 13:26:24.579151  8672 solver.cpp:228] Iteration 6600, loss = 6.98763e-005
I1101 13:26:24.579151  8672 solver.cpp:244]     Train net output #0: loss = 6.98416e-005 (* 1 = 6.98416e-005 loss)
I1101 13:26:24.579151  8672 sgd_solver.cpp:106] Iteration 6600, lr = 0.0196729
I1101 13:26:41.089051  8672 solver.cpp:228] Iteration 6700, loss = 0.0001005
I1101 13:26:41.089051  8672 solver.cpp:244]     Train net output #0: loss = 0.000100465 (* 1 = 0.000100465 loss)
I1101 13:26:41.089051  8672 sgd_solver.cpp:106] Iteration 6700, lr = 0.0196704
I1101 13:26:57.831858  8672 solver.cpp:228] Iteration 6800, loss = 0.000134109
I1101 13:26:57.831858  8672 solver.cpp:244]     Train net output #0: loss = 0.000134075 (* 1 = 0.000134075 loss)
I1101 13:26:57.831858  8672 sgd_solver.cpp:106] Iteration 6800, lr = 0.0196679
I1101 13:27:14.582028  8672 solver.cpp:228] Iteration 6900, loss = 9.39486e-005
I1101 13:27:14.582028  8672 solver.cpp:244]     Train net output #0: loss = 9.39139e-005 (* 1 = 9.39139e-005 loss)
I1101 13:27:14.582028  8672 sgd_solver.cpp:106] Iteration 6900, lr = 0.0196655
I1101 13:27:31.236364  8672 solver.cpp:228] Iteration 7000, loss = 2.93896e-005
I1101 13:27:31.236364  8672 solver.cpp:244]     Train net output #0: loss = 2.93549e-005 (* 1 = 2.93549e-005 loss)
I1101 13:27:31.236364  8672 sgd_solver.cpp:106] Iteration 7000, lr = 0.019663
I1101 13:27:47.651573  8672 solver.cpp:228] Iteration 7100, loss = 7.58799e-005
I1101 13:27:47.651573  8672 solver.cpp:244]     Train net output #0: loss = 7.58451e-005 (* 1 = 7.58451e-005 loss)
I1101 13:27:47.651573  8672 sgd_solver.cpp:106] Iteration 7100, lr = 0.0196605
I1101 13:28:03.988451  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_7200.caffemodel
I1101 13:28:04.097817  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_7200.solverstate
I1101 13:28:04.144691  8672 solver.cpp:337] Iteration 7200, Testing net (#0)
I1101 13:28:09.098498  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:28:09.098498  8672 solver.cpp:404]     Test net output #1: loss = 0.0121804 (* 1 = 0.0121804 loss)
I1101 13:28:09.176612  8672 solver.cpp:228] Iteration 7200, loss = 6.57004e-005
I1101 13:28:09.176612  8672 solver.cpp:244]     Train net output #0: loss = 6.56656e-005 (* 1 = 6.56656e-005 loss)
I1101 13:28:09.176612  8672 sgd_solver.cpp:106] Iteration 7200, lr = 0.019658
I1101 13:28:25.631966  8672 solver.cpp:228] Iteration 7300, loss = 9.26075e-005
I1101 13:28:25.631966  8672 solver.cpp:244]     Train net output #0: loss = 9.25728e-005 (* 1 = 9.25728e-005 loss)
I1101 13:28:25.631966  8672 sgd_solver.cpp:106] Iteration 7300, lr = 0.0196556
I1101 13:28:42.294136  8672 solver.cpp:228] Iteration 7400, loss = 0.000125451
I1101 13:28:42.294136  8672 solver.cpp:244]     Train net output #0: loss = 0.000125416 (* 1 = 0.000125416 loss)
I1101 13:28:42.295135  8672 sgd_solver.cpp:106] Iteration 7400, lr = 0.0196531
I1101 13:28:58.903038  8672 solver.cpp:228] Iteration 7500, loss = 9.07907e-005
I1101 13:28:58.903038  8672 solver.cpp:244]     Train net output #0: loss = 9.0756e-005 (* 1 = 9.0756e-005 loss)
I1101 13:28:58.903038  8672 sgd_solver.cpp:106] Iteration 7500, lr = 0.0196506
I1101 13:29:15.606230  8672 solver.cpp:228] Iteration 7600, loss = 2.81138e-005
I1101 13:29:15.606230  8672 solver.cpp:244]     Train net output #0: loss = 2.8079e-005 (* 1 = 2.8079e-005 loss)
I1101 13:29:15.606230  8672 sgd_solver.cpp:106] Iteration 7600, lr = 0.0196481
I1101 13:29:32.122534  8672 solver.cpp:228] Iteration 7700, loss = 7.23408e-005
I1101 13:29:32.122534  8672 solver.cpp:244]     Train net output #0: loss = 7.2306e-005 (* 1 = 7.2306e-005 loss)
I1101 13:29:32.122534  8672 sgd_solver.cpp:106] Iteration 7700, lr = 0.0196456
I1101 13:29:48.513119  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_7800.caffemodel
I1101 13:29:48.630203  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_7800.solverstate
I1101 13:29:48.678236  8672 solver.cpp:337] Iteration 7800, Testing net (#0)
I1101 13:29:53.650923  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:29:53.650923  8672 solver.cpp:404]     Test net output #1: loss = 0.0122289 (* 1 = 0.0122289 loss)
I1101 13:29:53.744709  8672 solver.cpp:228] Iteration 7800, loss = 6.23735e-005
I1101 13:29:53.744709  8672 solver.cpp:244]     Train net output #0: loss = 6.23387e-005 (* 1 = 6.23387e-005 loss)
I1101 13:29:53.744709  8672 sgd_solver.cpp:106] Iteration 7800, lr = 0.0196432
I1101 13:30:10.257822  8672 solver.cpp:228] Iteration 7900, loss = 8.63413e-005
I1101 13:30:10.257822  8672 solver.cpp:244]     Train net output #0: loss = 8.63065e-005 (* 1 = 8.63065e-005 loss)
I1101 13:30:10.257822  8672 sgd_solver.cpp:106] Iteration 7900, lr = 0.0196407
I1101 13:30:26.808344  8672 solver.cpp:228] Iteration 8000, loss = 0.000118617
I1101 13:30:26.808344  8672 solver.cpp:244]     Train net output #0: loss = 0.000118582 (* 1 = 0.000118582 loss)
I1101 13:30:26.808344  8672 sgd_solver.cpp:106] Iteration 8000, lr = 0.0196382
I1101 13:30:43.486275  8672 solver.cpp:228] Iteration 8100, loss = 8.83913e-005
I1101 13:30:43.486275  8672 solver.cpp:244]     Train net output #0: loss = 8.83565e-005 (* 1 = 8.83565e-005 loss)
I1101 13:30:43.486275  8672 sgd_solver.cpp:106] Iteration 8100, lr = 0.0196357
I1101 13:31:00.424783  8672 solver.cpp:228] Iteration 8200, loss = 2.71093e-005
I1101 13:31:00.424783  8672 solver.cpp:244]     Train net output #0: loss = 2.70745e-005 (* 1 = 2.70745e-005 loss)
I1101 13:31:00.424783  8672 sgd_solver.cpp:106] Iteration 8200, lr = 0.0196332
I1101 13:31:15.999845  8672 solver.cpp:228] Iteration 8300, loss = 6.93018e-005
I1101 13:31:15.999845  8672 solver.cpp:244]     Train net output #0: loss = 6.92671e-005 (* 1 = 6.92671e-005 loss)
I1101 13:31:15.999845  8672 sgd_solver.cpp:106] Iteration 8300, lr = 0.0196308
I1101 13:31:31.639724  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_8400.caffemodel
I1101 13:31:31.749532  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_8400.solverstate
I1101 13:31:31.796408  8672 solver.cpp:337] Iteration 8400, Testing net (#0)
I1101 13:31:36.780213  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9969
I1101 13:31:36.780213  8672 solver.cpp:404]     Test net output #1: loss = 0.0122713 (* 1 = 0.0122713 loss)
I1101 13:31:36.864707  8672 solver.cpp:228] Iteration 8400, loss = 5.95481e-005
I1101 13:31:36.864707  8672 solver.cpp:244]     Train net output #0: loss = 5.95133e-005 (* 1 = 5.95133e-005 loss)
I1101 13:31:36.864707  8672 sgd_solver.cpp:106] Iteration 8400, lr = 0.0196283
I1101 13:31:53.325196  8672 solver.cpp:228] Iteration 8500, loss = 8.1385e-005
I1101 13:31:53.325196  8672 solver.cpp:244]     Train net output #0: loss = 8.13502e-005 (* 1 = 8.13502e-005 loss)
I1101 13:31:53.325196  8672 sgd_solver.cpp:106] Iteration 8500, lr = 0.0196258
I1101 13:32:09.817131  8672 solver.cpp:228] Iteration 8600, loss = 0.000112923
I1101 13:32:09.817131  8672 solver.cpp:244]     Train net output #0: loss = 0.000112889 (* 1 = 0.000112889 loss)
I1101 13:32:09.817131  8672 sgd_solver.cpp:106] Iteration 8600, lr = 0.0196233
I1101 13:32:26.359567  8672 solver.cpp:228] Iteration 8700, loss = 8.62639e-005
I1101 13:32:26.359567  8672 solver.cpp:244]     Train net output #0: loss = 8.62292e-005 (* 1 = 8.62292e-005 loss)
I1101 13:32:26.359567  8672 sgd_solver.cpp:106] Iteration 8700, lr = 0.0196208
I1101 13:32:42.877599  8672 solver.cpp:228] Iteration 8800, loss = 2.63303e-005
I1101 13:32:42.877599  8672 solver.cpp:244]     Train net output #0: loss = 2.62955e-005 (* 1 = 2.62955e-005 loss)
I1101 13:32:42.877599  8672 sgd_solver.cpp:106] Iteration 8800, lr = 0.0196184
I1101 13:32:59.361533  8672 solver.cpp:228] Iteration 8900, loss = 6.66461e-005
I1101 13:32:59.361533  8672 solver.cpp:244]     Train net output #0: loss = 6.66114e-005 (* 1 = 6.66114e-005 loss)
I1101 13:32:59.361533  8672 sgd_solver.cpp:106] Iteration 8900, lr = 0.0196159
I1101 13:33:15.803184  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_9000.caffemodel
I1101 13:33:15.928187  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_9000.solverstate
I1101 13:33:15.975075  8672 solver.cpp:337] Iteration 9000, Testing net (#0)
I1101 13:33:21.022830  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:33:21.022830  8672 solver.cpp:404]     Test net output #1: loss = 0.0123092 (* 1 = 0.0123092 loss)
I1101 13:33:21.091800  8672 solver.cpp:228] Iteration 9000, loss = 5.73416e-005
I1101 13:33:21.091800  8672 solver.cpp:244]     Train net output #0: loss = 5.73069e-005 (* 1 = 5.73069e-005 loss)
I1101 13:33:21.091800  8672 sgd_solver.cpp:106] Iteration 9000, lr = 0.0196134
I1101 13:33:37.539722  8672 solver.cpp:228] Iteration 9100, loss = 7.75898e-005
I1101 13:33:37.539722  8672 solver.cpp:244]     Train net output #0: loss = 7.75551e-005 (* 1 = 7.75551e-005 loss)
I1101 13:33:37.540244  8672 sgd_solver.cpp:106] Iteration 9100, lr = 0.0196109
I1101 13:33:54.254348  8672 solver.cpp:228] Iteration 9200, loss = 0.00010823
I1101 13:33:54.254348  8672 solver.cpp:244]     Train net output #0: loss = 0.000108195 (* 1 = 0.000108195 loss)
I1101 13:33:54.254348  8672 sgd_solver.cpp:106] Iteration 9200, lr = 0.0196084
I1101 13:34:10.853976  8672 solver.cpp:228] Iteration 9300, loss = 8.45098e-005
I1101 13:34:10.853976  8672 solver.cpp:244]     Train net output #0: loss = 8.44751e-005 (* 1 = 8.44751e-005 loss)
I1101 13:34:10.853976  8672 sgd_solver.cpp:106] Iteration 9300, lr = 0.019606
I1101 13:34:26.661563  8672 solver.cpp:228] Iteration 9400, loss = 2.56926e-005
I1101 13:34:26.661563  8672 solver.cpp:244]     Train net output #0: loss = 2.56579e-005 (* 1 = 2.56579e-005 loss)
I1101 13:34:26.661563  8672 sgd_solver.cpp:106] Iteration 9400, lr = 0.0196035
I1101 13:34:42.299335  8672 solver.cpp:228] Iteration 9500, loss = 6.4447e-005
I1101 13:34:42.299335  8672 solver.cpp:244]     Train net output #0: loss = 6.44123e-005 (* 1 = 6.44123e-005 loss)
I1101 13:34:42.299335  8672 sgd_solver.cpp:106] Iteration 9500, lr = 0.019601
I1101 13:34:58.137296  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_9600.caffemodel
I1101 13:34:58.259716  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_9600.solverstate
I1101 13:34:58.306603  8672 solver.cpp:337] Iteration 9600, Testing net (#0)
I1101 13:35:03.176178  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:35:03.176178  8672 solver.cpp:404]     Test net output #1: loss = 0.0123411 (* 1 = 0.0123411 loss)
I1101 13:35:03.254318  8672 solver.cpp:228] Iteration 9600, loss = 5.54701e-005
I1101 13:35:03.254318  8672 solver.cpp:244]     Train net output #0: loss = 5.54354e-005 (* 1 = 5.54354e-005 loss)
I1101 13:35:03.254318  8672 sgd_solver.cpp:106] Iteration 9600, lr = 0.0195985
I1101 13:35:18.964437  8672 solver.cpp:228] Iteration 9700, loss = 7.42987e-005
I1101 13:35:18.964437  8672 solver.cpp:244]     Train net output #0: loss = 7.42639e-005 (* 1 = 7.42639e-005 loss)
I1101 13:35:18.964437  8672 sgd_solver.cpp:106] Iteration 9700, lr = 0.019596
I1101 13:35:34.497629  8672 solver.cpp:228] Iteration 9800, loss = 0.000104293
I1101 13:35:34.497629  8672 solver.cpp:244]     Train net output #0: loss = 0.000104258 (* 1 = 0.000104258 loss)
I1101 13:35:34.497629  8672 sgd_solver.cpp:106] Iteration 9800, lr = 0.0195936
I1101 13:35:50.772724  8672 solver.cpp:228] Iteration 9900, loss = 8.30225e-005
I1101 13:35:50.772724  8672 solver.cpp:244]     Train net output #0: loss = 8.29878e-005 (* 1 = 8.29878e-005 loss)
I1101 13:35:50.772724  8672 sgd_solver.cpp:106] Iteration 9900, lr = 0.0195911
I1101 13:36:07.508239  8672 solver.cpp:228] Iteration 10000, loss = 2.51731e-005
I1101 13:36:07.508239  8672 solver.cpp:244]     Train net output #0: loss = 2.51384e-005 (* 1 = 2.51384e-005 loss)
I1101 13:36:07.508239  8672 sgd_solver.cpp:106] Iteration 10000, lr = 0.0195886
I1101 13:36:24.465945  8672 solver.cpp:228] Iteration 10100, loss = 6.24723e-005
I1101 13:36:24.466446  8672 solver.cpp:244]     Train net output #0: loss = 6.24376e-005 (* 1 = 6.24376e-005 loss)
I1101 13:36:24.466446  8672 sgd_solver.cpp:106] Iteration 10100, lr = 0.0195861
I1101 13:36:41.071241  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_10200.caffemodel
I1101 13:36:41.214331  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_10200.solverstate
I1101 13:36:41.275984  8672 solver.cpp:337] Iteration 10200, Testing net (#0)
I1101 13:36:46.293416  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:36:46.293416  8672 solver.cpp:404]     Test net output #1: loss = 0.0123697 (* 1 = 0.0123697 loss)
I1101 13:36:46.363992  8672 solver.cpp:228] Iteration 10200, loss = 5.38976e-005
I1101 13:36:46.363992  8672 solver.cpp:244]     Train net output #0: loss = 5.38629e-005 (* 1 = 5.38629e-005 loss)
I1101 13:36:46.363992  8672 sgd_solver.cpp:106] Iteration 10200, lr = 0.0195836
I1101 13:37:03.152446  8672 solver.cpp:228] Iteration 10300, loss = 7.14934e-005
I1101 13:37:03.152446  8672 solver.cpp:244]     Train net output #0: loss = 7.14587e-005 (* 1 = 7.14587e-005 loss)
I1101 13:37:03.152446  8672 sgd_solver.cpp:106] Iteration 10300, lr = 0.0195812
I1101 13:37:20.002400  8672 solver.cpp:228] Iteration 10400, loss = 0.000100903
I1101 13:37:20.002400  8672 solver.cpp:244]     Train net output #0: loss = 0.000100868 (* 1 = 0.000100868 loss)
I1101 13:37:20.002400  8672 sgd_solver.cpp:106] Iteration 10400, lr = 0.0195787
I1101 13:37:36.687106  8672 solver.cpp:228] Iteration 10500, loss = 8.17286e-005
I1101 13:37:36.687106  8672 solver.cpp:244]     Train net output #0: loss = 8.1694e-005 (* 1 = 8.1694e-005 loss)
I1101 13:37:36.687106  8672 sgd_solver.cpp:106] Iteration 10500, lr = 0.0195762
I1101 13:37:53.426707  8672 solver.cpp:228] Iteration 10600, loss = 2.47967e-005
I1101 13:37:53.426707  8672 solver.cpp:244]     Train net output #0: loss = 2.4762e-005 (* 1 = 2.4762e-005 loss)
I1101 13:37:53.426707  8672 sgd_solver.cpp:106] Iteration 10600, lr = 0.0195737
I1101 13:38:09.883819  8672 solver.cpp:228] Iteration 10700, loss = 6.08181e-005
I1101 13:38:09.883819  8672 solver.cpp:244]     Train net output #0: loss = 6.07834e-005 (* 1 = 6.07834e-005 loss)
I1101 13:38:09.883819  8672 sgd_solver.cpp:106] Iteration 10700, lr = 0.0195712
I1101 13:38:26.619715  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_10800.caffemodel
I1101 13:38:26.780333  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_10800.solverstate
I1101 13:38:26.855386  8672 solver.cpp:337] Iteration 10800, Testing net (#0)
I1101 13:38:31.939036  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:38:31.939036  8672 solver.cpp:404]     Test net output #1: loss = 0.0123935 (* 1 = 0.0123935 loss)
I1101 13:38:32.009227  8672 solver.cpp:228] Iteration 10800, loss = 5.25506e-005
I1101 13:38:32.009227  8672 solver.cpp:244]     Train net output #0: loss = 5.25159e-005 (* 1 = 5.25159e-005 loss)
I1101 13:38:32.009227  8672 sgd_solver.cpp:106] Iteration 10800, lr = 0.0195688
I1101 13:38:48.731837  8672 solver.cpp:228] Iteration 10900, loss = 6.92318e-005
I1101 13:38:48.731837  8672 solver.cpp:244]     Train net output #0: loss = 6.91972e-005 (* 1 = 6.91972e-005 loss)
I1101 13:38:48.731837  8672 sgd_solver.cpp:106] Iteration 10900, lr = 0.0195663
I1101 13:39:05.463613  8672 solver.cpp:228] Iteration 11000, loss = 9.79602e-005
I1101 13:39:05.463613  8672 solver.cpp:244]     Train net output #0: loss = 9.79255e-005 (* 1 = 9.79255e-005 loss)
I1101 13:39:05.463613  8672 sgd_solver.cpp:106] Iteration 11000, lr = 0.0195638
I1101 13:39:21.939949  8672 solver.cpp:228] Iteration 11100, loss = 8.06276e-005
I1101 13:39:21.939949  8672 solver.cpp:244]     Train net output #0: loss = 8.05929e-005 (* 1 = 8.05929e-005 loss)
I1101 13:39:21.939949  8672 sgd_solver.cpp:106] Iteration 11100, lr = 0.0195613
I1101 13:39:38.574177  8672 solver.cpp:228] Iteration 11200, loss = 2.45145e-005
I1101 13:39:38.574177  8672 solver.cpp:244]     Train net output #0: loss = 2.44798e-005 (* 1 = 2.44798e-005 loss)
I1101 13:39:38.574177  8672 sgd_solver.cpp:106] Iteration 11200, lr = 0.0195588
I1101 13:39:55.038959  8672 solver.cpp:228] Iteration 11300, loss = 5.934e-005
I1101 13:39:55.038959  8672 solver.cpp:244]     Train net output #0: loss = 5.93053e-005 (* 1 = 5.93053e-005 loss)
I1101 13:39:55.038959  8672 sgd_solver.cpp:106] Iteration 11300, lr = 0.0195564
I1101 13:40:11.441174  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_11400.caffemodel
I1101 13:40:11.553172  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_11400.solverstate
I1101 13:40:11.600047  8672 solver.cpp:337] Iteration 11400, Testing net (#0)
I1101 13:40:16.570868  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:40:16.570868  8672 solver.cpp:404]     Test net output #1: loss = 0.0124146 (* 1 = 0.0124146 loss)
I1101 13:40:16.639884  8672 solver.cpp:228] Iteration 11400, loss = 5.14126e-005
I1101 13:40:16.640386  8672 solver.cpp:244]     Train net output #0: loss = 5.13779e-005 (* 1 = 5.13779e-005 loss)
I1101 13:40:16.640386  8672 sgd_solver.cpp:106] Iteration 11400, lr = 0.0195539
I1101 13:40:33.183662  8672 solver.cpp:228] Iteration 11500, loss = 6.72243e-005
I1101 13:40:33.183662  8672 solver.cpp:244]     Train net output #0: loss = 6.71896e-005 (* 1 = 6.71896e-005 loss)
I1101 13:40:33.183662  8672 sgd_solver.cpp:106] Iteration 11500, lr = 0.0195514
I1101 13:40:49.681859  8672 solver.cpp:228] Iteration 11600, loss = 9.54173e-005
I1101 13:40:49.681859  8672 solver.cpp:244]     Train net output #0: loss = 9.53826e-005 (* 1 = 9.53826e-005 loss)
I1101 13:40:49.681859  8672 sgd_solver.cpp:106] Iteration 11600, lr = 0.0195489
I1101 13:41:06.254253  8672 solver.cpp:228] Iteration 11700, loss = 7.97152e-005
I1101 13:41:06.254253  8672 solver.cpp:244]     Train net output #0: loss = 7.96805e-005 (* 1 = 7.96805e-005 loss)
I1101 13:41:06.254253  8672 sgd_solver.cpp:106] Iteration 11700, lr = 0.0195464
I1101 13:41:22.769762  8672 solver.cpp:228] Iteration 11800, loss = 2.42741e-005
I1101 13:41:22.769762  8672 solver.cpp:244]     Train net output #0: loss = 2.42394e-005 (* 1 = 2.42394e-005 loss)
I1101 13:41:22.769762  8672 sgd_solver.cpp:106] Iteration 11800, lr = 0.019544
I1101 13:41:39.281004  8672 solver.cpp:228] Iteration 11900, loss = 5.81178e-005
I1101 13:41:39.281004  8672 solver.cpp:244]     Train net output #0: loss = 5.80832e-005 (* 1 = 5.80832e-005 loss)
I1101 13:41:39.281004  8672 sgd_solver.cpp:106] Iteration 11900, lr = 0.0195415
I1101 13:41:55.740173  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_12000.caffemodel
I1101 13:41:55.860157  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_12000.solverstate
I1101 13:41:55.898890  8672 solver.cpp:337] Iteration 12000, Testing net (#0)
I1101 13:42:00.841823  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:42:00.841823  8672 solver.cpp:404]     Test net output #1: loss = 0.0124332 (* 1 = 0.0124332 loss)
I1101 13:42:00.921210  8672 solver.cpp:228] Iteration 12000, loss = 5.04601e-005
I1101 13:42:00.921210  8672 solver.cpp:244]     Train net output #0: loss = 5.04254e-005 (* 1 = 5.04254e-005 loss)
I1101 13:42:00.921210  8672 sgd_solver.cpp:106] Iteration 12000, lr = 0.019539
I1101 13:42:17.374724  8672 solver.cpp:228] Iteration 12100, loss = 6.53791e-005
I1101 13:42:17.374724  8672 solver.cpp:244]     Train net output #0: loss = 6.53444e-005 (* 1 = 6.53444e-005 loss)
I1101 13:42:17.374724  8672 sgd_solver.cpp:106] Iteration 12100, lr = 0.0195365
I1101 13:42:33.833678  8672 solver.cpp:228] Iteration 12200, loss = 9.30595e-005
I1101 13:42:33.833678  8672 solver.cpp:244]     Train net output #0: loss = 9.30248e-005 (* 1 = 9.30248e-005 loss)
I1101 13:42:33.833678  8672 sgd_solver.cpp:106] Iteration 12200, lr = 0.0195341
I1101 13:42:50.248601  8672 solver.cpp:228] Iteration 12300, loss = 7.88672e-005
I1101 13:42:50.248601  8672 solver.cpp:244]     Train net output #0: loss = 7.88326e-005 (* 1 = 7.88326e-005 loss)
I1101 13:42:50.248601  8672 sgd_solver.cpp:106] Iteration 12300, lr = 0.0195316
I1101 13:43:06.669266  8672 solver.cpp:228] Iteration 12400, loss = 2.40909e-005
I1101 13:43:06.669266  8672 solver.cpp:244]     Train net output #0: loss = 2.40562e-005 (* 1 = 2.40562e-005 loss)
I1101 13:43:06.669266  8672 sgd_solver.cpp:106] Iteration 12400, lr = 0.0195291
I1101 13:43:23.094198  8672 solver.cpp:228] Iteration 12500, loss = 5.7067e-005
I1101 13:43:23.094198  8672 solver.cpp:244]     Train net output #0: loss = 5.70323e-005 (* 1 = 5.70323e-005 loss)
I1101 13:43:23.094198  8672 sgd_solver.cpp:106] Iteration 12500, lr = 0.0195266
I1101 13:43:39.527323  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_12600.caffemodel
I1101 13:43:39.643393  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_12600.solverstate
I1101 13:43:39.690425  8672 solver.cpp:337] Iteration 12600, Testing net (#0)
I1101 13:43:44.649582  8672 solver.cpp:404]     Test net output #0: accuracy = 0.997
I1101 13:43:44.649582  8672 solver.cpp:404]     Test net output #1: loss = 0.0124488 (* 1 = 0.0124488 loss)
I1101 13:43:44.720060  8672 solver.cpp:228] Iteration 12600, loss = 4.96561e-005
I1101 13:43:44.720060  8672 solver.cpp:244]     Train net output #0: loss = 4.96215e-005 (* 1 = 4.96215e-005 loss)
I1101 13:43:44.720060  8672 sgd_solver.cpp:106] Iteration 12600, lr = 0.0195241
I1101 13:44:01.128434  8672 solver.cpp:228] Iteration 12700, loss = 6.38189e-005
I1101 13:44:01.128434  8672 solver.cpp:244]     Train net output #0: loss = 6.37842e-005 (* 1 = 6.37842e-005 loss)
I1101 13:44:01.128434  8672 sgd_solver.cpp:106] Iteration 12700, lr = 0.0195217
I1101 13:44:17.586108  8672 solver.cpp:228] Iteration 12800, loss = 9.10854e-005
I1101 13:44:17.586108  8672 solver.cpp:244]     Train net output #0: loss = 9.10508e-005 (* 1 = 9.10508e-005 loss)
I1101 13:44:17.586108  8672 sgd_solver.cpp:106] Iteration 12800, lr = 0.0195192
I1101 13:44:34.197227  8672 solver.cpp:228] Iteration 12900, loss = 7.81255e-005
I1101 13:44:34.197227  8672 solver.cpp:244]     Train net output #0: loss = 7.80909e-005 (* 1 = 7.80909e-005 loss)
I1101 13:44:34.197227  8672 sgd_solver.cpp:106] Iteration 12900, lr = 0.0195167
I1101 13:44:50.707916  8672 solver.cpp:228] Iteration 13000, loss = 2.3956e-005
I1101 13:44:50.707916  8672 solver.cpp:244]     Train net output #0: loss = 2.39213e-005 (* 1 = 2.39213e-005 loss)
I1101 13:44:50.707916  8672 sgd_solver.cpp:106] Iteration 13000, lr = 0.0195142
I1101 13:45:07.198266  8672 solver.cpp:228] Iteration 13100, loss = 5.61533e-005
I1101 13:45:07.198266  8672 solver.cpp:244]     Train net output #0: loss = 5.61187e-005 (* 1 = 5.61187e-005 loss)
I1101 13:45:07.198266  8672 sgd_solver.cpp:106] Iteration 13100, lr = 0.0195117
I1101 13:45:23.438547  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_13200.caffemodel
I1101 13:45:23.557632  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_13200.solverstate
I1101 13:45:23.629806  8672 solver.cpp:337] Iteration 13200, Testing net (#0)
I1101 13:45:28.637641  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9971
I1101 13:45:28.638142  8672 solver.cpp:404]     Test net output #1: loss = 0.0124627 (* 1 = 0.0124627 loss)
I1101 13:45:28.707659  8672 solver.cpp:228] Iteration 13200, loss = 4.90175e-005
I1101 13:45:28.707659  8672 solver.cpp:244]     Train net output #0: loss = 4.89829e-005 (* 1 = 4.89829e-005 loss)
I1101 13:45:28.707659  8672 sgd_solver.cpp:106] Iteration 13200, lr = 0.0195093
I1101 13:45:45.241046  8672 solver.cpp:228] Iteration 13300, loss = 6.24175e-005
I1101 13:45:45.241046  8672 solver.cpp:244]     Train net output #0: loss = 6.23829e-005 (* 1 = 6.23829e-005 loss)
I1101 13:45:45.241046  8672 sgd_solver.cpp:106] Iteration 13300, lr = 0.0195068
I1101 13:46:01.713433  8672 solver.cpp:228] Iteration 13400, loss = 8.93459e-005
I1101 13:46:01.713433  8672 solver.cpp:244]     Train net output #0: loss = 8.93113e-005 (* 1 = 8.93113e-005 loss)
I1101 13:46:01.713433  8672 sgd_solver.cpp:106] Iteration 13400, lr = 0.0195043
I1101 13:46:18.500704  8672 solver.cpp:228] Iteration 13500, loss = 7.74495e-005
I1101 13:46:18.500704  8672 solver.cpp:244]     Train net output #0: loss = 7.74149e-005 (* 1 = 7.74149e-005 loss)
I1101 13:46:18.500704  8672 sgd_solver.cpp:106] Iteration 13500, lr = 0.0195018
I1101 13:46:35.497725  8672 solver.cpp:228] Iteration 13600, loss = 2.38503e-005
I1101 13:46:35.497725  8672 solver.cpp:244]     Train net output #0: loss = 2.38157e-005 (* 1 = 2.38157e-005 loss)
I1101 13:46:35.497725  8672 sgd_solver.cpp:106] Iteration 13600, lr = 0.0194993
I1101 13:46:52.005933  8672 solver.cpp:228] Iteration 13700, loss = 5.53644e-005
I1101 13:46:52.005933  8672 solver.cpp:244]     Train net output #0: loss = 5.53299e-005 (* 1 = 5.53299e-005 loss)
I1101 13:46:52.005933  8672 sgd_solver.cpp:106] Iteration 13700, lr = 0.0194969
I1101 13:47:07.920661  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_13800.caffemodel
I1101 13:47:08.045665  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_13800.solverstate
I1101 13:47:08.092540  8672 solver.cpp:337] Iteration 13800, Testing net (#0)
I1101 13:47:13.023880  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9971
I1101 13:47:13.023880  8672 solver.cpp:404]     Test net output #1: loss = 0.0124765 (* 1 = 0.0124765 loss)
I1101 13:47:13.105959  8672 solver.cpp:228] Iteration 13800, loss = 4.84952e-005
I1101 13:47:13.105959  8672 solver.cpp:244]     Train net output #0: loss = 4.84606e-005 (* 1 = 4.84606e-005 loss)
I1101 13:47:13.105959  8672 sgd_solver.cpp:106] Iteration 13800, lr = 0.0194944
I1101 13:47:29.882436  8672 solver.cpp:228] Iteration 13900, loss = 6.11953e-005
I1101 13:47:29.882436  8672 solver.cpp:244]     Train net output #0: loss = 6.11607e-005 (* 1 = 6.11607e-005 loss)
I1101 13:47:29.882436  8672 sgd_solver.cpp:106] Iteration 13900, lr = 0.0194919
I1101 13:47:46.353942  8672 solver.cpp:228] Iteration 14000, loss = 8.78338e-005
I1101 13:47:46.353942  8672 solver.cpp:244]     Train net output #0: loss = 8.77992e-005 (* 1 = 8.77992e-005 loss)
I1101 13:47:46.353942  8672 sgd_solver.cpp:106] Iteration 14000, lr = 0.0194894
I1101 13:48:02.841184  8672 solver.cpp:228] Iteration 14100, loss = 7.68786e-005
I1101 13:48:02.841184  8672 solver.cpp:244]     Train net output #0: loss = 7.6844e-005 (* 1 = 7.6844e-005 loss)
I1101 13:48:02.841184  8672 sgd_solver.cpp:106] Iteration 14100, lr = 0.0194869
I1101 13:48:19.327641  8672 solver.cpp:228] Iteration 14200, loss = 2.37787e-005
I1101 13:48:19.327641  8672 solver.cpp:244]     Train net output #0: loss = 2.3744e-005 (* 1 = 2.3744e-005 loss)
I1101 13:48:19.327641  8672 sgd_solver.cpp:106] Iteration 14200, lr = 0.0194845
I1101 13:48:36.345549  8672 solver.cpp:228] Iteration 14300, loss = 5.46013e-005
I1101 13:48:36.346050  8672 solver.cpp:244]     Train net output #0: loss = 5.45666e-005 (* 1 = 5.45666e-005 loss)
I1101 13:48:36.346050  8672 sgd_solver.cpp:106] Iteration 14300, lr = 0.019482
I1101 13:48:53.359508  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_14400.caffemodel
I1101 13:48:53.490602  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_14400.solverstate
I1101 13:48:53.541139  8672 solver.cpp:337] Iteration 14400, Testing net (#0)
I1101 13:48:58.683039  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9971
I1101 13:48:58.683039  8672 solver.cpp:404]     Test net output #1: loss = 0.0124877 (* 1 = 0.0124877 loss)
I1101 13:48:58.754317  8672 solver.cpp:228] Iteration 14400, loss = 4.80321e-005
I1101 13:48:58.754317  8672 solver.cpp:244]     Train net output #0: loss = 4.79975e-005 (* 1 = 4.79975e-005 loss)
I1101 13:48:58.754317  8672 sgd_solver.cpp:106] Iteration 14400, lr = 0.0194795
I1101 13:49:16.051370  8672 solver.cpp:228] Iteration 14500, loss = 6.01135e-005
I1101 13:49:16.051370  8672 solver.cpp:244]     Train net output #0: loss = 6.00789e-005 (* 1 = 6.00789e-005 loss)
I1101 13:49:16.051370  8672 sgd_solver.cpp:106] Iteration 14500, lr = 0.019477
I1101 13:49:33.217910  8672 solver.cpp:228] Iteration 14600, loss = 8.64554e-005
I1101 13:49:33.217910  8672 solver.cpp:244]     Train net output #0: loss = 8.64208e-005 (* 1 = 8.64208e-005 loss)
I1101 13:49:33.217910  8672 sgd_solver.cpp:106] Iteration 14600, lr = 0.0194745
I1101 13:49:50.439221  8672 solver.cpp:228] Iteration 14700, loss = 7.62766e-005
I1101 13:49:50.439221  8672 solver.cpp:244]     Train net output #0: loss = 7.6242e-005 (* 1 = 7.6242e-005 loss)
I1101 13:49:50.439221  8672 sgd_solver.cpp:106] Iteration 14700, lr = 0.0194721
I1101 13:50:08.194890  8672 solver.cpp:228] Iteration 14800, loss = 2.37541e-005
I1101 13:50:08.194890  8672 solver.cpp:244]     Train net output #0: loss = 2.37195e-005 (* 1 = 2.37195e-005 loss)
I1101 13:50:08.194890  8672 sgd_solver.cpp:106] Iteration 14800, lr = 0.0194696
I1101 13:50:25.255486  8672 solver.cpp:228] Iteration 14900, loss = 5.39603e-005
I1101 13:50:25.255985  8672 solver.cpp:244]     Train net output #0: loss = 5.39257e-005 (* 1 = 5.39257e-005 loss)
I1101 13:50:25.255985  8672 sgd_solver.cpp:106] Iteration 14900, lr = 0.0194671
I1101 13:50:42.248569  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_15000.caffemodel
I1101 13:50:42.389668  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_15000.solverstate
I1101 13:50:42.444710  8672 solver.cpp:337] Iteration 15000, Testing net (#0)
I1101 13:50:47.621387  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 13:50:47.621387  8672 solver.cpp:404]     Test net output #1: loss = 0.0124986 (* 1 = 0.0124986 loss)
I1101 13:50:47.696939  8672 solver.cpp:228] Iteration 15000, loss = 4.76441e-005
I1101 13:50:47.696939  8672 solver.cpp:244]     Train net output #0: loss = 4.76095e-005 (* 1 = 4.76095e-005 loss)
I1101 13:50:47.697440  8672 sgd_solver.cpp:106] Iteration 15000, lr = 0.0194646
I1101 13:51:04.734210  8672 solver.cpp:228] Iteration 15100, loss = 5.9221e-005
I1101 13:51:04.734210  8672 solver.cpp:244]     Train net output #0: loss = 5.91863e-005 (* 1 = 5.91863e-005 loss)
I1101 13:51:04.734210  8672 sgd_solver.cpp:106] Iteration 15100, lr = 0.0194621
I1101 13:51:21.767596  8672 solver.cpp:228] Iteration 15200, loss = 8.52292e-005
I1101 13:51:21.768095  8672 solver.cpp:244]     Train net output #0: loss = 8.51946e-005 (* 1 = 8.51946e-005 loss)
I1101 13:51:21.768095  8672 sgd_solver.cpp:106] Iteration 15200, lr = 0.0194597
I1101 13:51:38.751796  8672 solver.cpp:228] Iteration 15300, loss = 7.57134e-005
I1101 13:51:38.751796  8672 solver.cpp:244]     Train net output #0: loss = 7.56788e-005 (* 1 = 7.56788e-005 loss)
I1101 13:51:38.751796  8672 sgd_solver.cpp:106] Iteration 15300, lr = 0.0194572
I1101 13:51:55.760610  8672 solver.cpp:228] Iteration 15400, loss = 2.37577e-005
I1101 13:51:55.760610  8672 solver.cpp:244]     Train net output #0: loss = 2.3723e-005 (* 1 = 2.3723e-005 loss)
I1101 13:51:55.760610  8672 sgd_solver.cpp:106] Iteration 15400, lr = 0.0194547
I1101 13:52:13.484457  8672 solver.cpp:228] Iteration 15500, loss = 5.33845e-005
I1101 13:52:13.484457  8672 solver.cpp:244]     Train net output #0: loss = 5.33498e-005 (* 1 = 5.33498e-005 loss)
I1101 13:52:13.484457  8672 sgd_solver.cpp:106] Iteration 15500, lr = 0.0194522
I1101 13:52:30.970764  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_15600.caffemodel
I1101 13:52:31.275486  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_15600.solverstate
I1101 13:52:31.418586  8672 solver.cpp:337] Iteration 15600, Testing net (#0)
I1101 13:52:37.190207  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 13:52:37.191207  8672 solver.cpp:404]     Test net output #1: loss = 0.0125082 (* 1 = 0.0125082 loss)
I1101 13:52:37.294237  8672 solver.cpp:228] Iteration 15600, loss = 4.73003e-005
I1101 13:52:37.294739  8672 solver.cpp:244]     Train net output #0: loss = 4.72657e-005 (* 1 = 4.72657e-005 loss)
I1101 13:52:37.294739  8672 sgd_solver.cpp:106] Iteration 15600, lr = 0.0194497
I1101 13:52:55.338220  8672 solver.cpp:228] Iteration 15700, loss = 5.83881e-005
I1101 13:52:55.338220  8672 solver.cpp:244]     Train net output #0: loss = 5.83535e-005 (* 1 = 5.83535e-005 loss)
I1101 13:52:55.338220  8672 sgd_solver.cpp:106] Iteration 15700, lr = 0.0194473
I1101 13:53:12.720870  8672 solver.cpp:228] Iteration 15800, loss = 8.40823e-005
I1101 13:53:12.720870  8672 solver.cpp:244]     Train net output #0: loss = 8.40477e-005 (* 1 = 8.40477e-005 loss)
I1101 13:53:12.720870  8672 sgd_solver.cpp:106] Iteration 15800, lr = 0.0194448
I1101 13:53:30.045589  8672 solver.cpp:228] Iteration 15900, loss = 7.52839e-005
I1101 13:53:30.045589  8672 solver.cpp:244]     Train net output #0: loss = 7.52493e-005 (* 1 = 7.52493e-005 loss)
I1101 13:53:30.045589  8672 sgd_solver.cpp:106] Iteration 15900, lr = 0.0194423
I1101 13:53:47.417165  8672 solver.cpp:228] Iteration 16000, loss = 2.38124e-005
I1101 13:53:47.417165  8672 solver.cpp:244]     Train net output #0: loss = 2.37778e-005 (* 1 = 2.37778e-005 loss)
I1101 13:53:47.417165  8672 sgd_solver.cpp:106] Iteration 16000, lr = 0.0194398
I1101 13:54:03.937361  8672 solver.cpp:228] Iteration 16100, loss = 5.28492e-005
I1101 13:54:03.937361  8672 solver.cpp:244]     Train net output #0: loss = 5.28145e-005 (* 1 = 5.28145e-005 loss)
I1101 13:54:03.937361  8672 sgd_solver.cpp:106] Iteration 16100, lr = 0.0194374
I1101 13:54:20.347579  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_16200.caffemodel
I1101 13:54:20.464663  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_16200.solverstate
I1101 13:54:20.534713  8672 solver.cpp:337] Iteration 16200, Testing net (#0)
I1101 13:54:25.527272  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 13:54:25.527272  8672 solver.cpp:404]     Test net output #1: loss = 0.0125183 (* 1 = 0.0125183 loss)
I1101 13:54:25.597323  8672 solver.cpp:228] Iteration 16200, loss = 4.70287e-005
I1101 13:54:25.597323  8672 solver.cpp:244]     Train net output #0: loss = 4.6994e-005 (* 1 = 4.6994e-005 loss)
I1101 13:54:25.597323  8672 sgd_solver.cpp:106] Iteration 16200, lr = 0.0194349
I1101 13:54:42.084619  8672 solver.cpp:228] Iteration 16300, loss = 5.76741e-005
I1101 13:54:42.084619  8672 solver.cpp:244]     Train net output #0: loss = 5.76394e-005 (* 1 = 5.76394e-005 loss)
I1101 13:54:42.084619  8672 sgd_solver.cpp:106] Iteration 16300, lr = 0.0194324
I1101 13:54:58.555819  8672 solver.cpp:228] Iteration 16400, loss = 8.30619e-005
I1101 13:54:58.555819  8672 solver.cpp:244]     Train net output #0: loss = 8.30273e-005 (* 1 = 8.30273e-005 loss)
I1101 13:54:58.555819  8672 sgd_solver.cpp:106] Iteration 16400, lr = 0.0194299
I1101 13:55:15.012475  8672 solver.cpp:228] Iteration 16500, loss = 7.4747e-005
I1101 13:55:15.012475  8672 solver.cpp:244]     Train net output #0: loss = 7.47123e-005 (* 1 = 7.47123e-005 loss)
I1101 13:55:15.012475  8672 sgd_solver.cpp:106] Iteration 16500, lr = 0.0194274
I1101 13:55:31.477219  8672 solver.cpp:228] Iteration 16600, loss = 2.38565e-005
I1101 13:55:31.477219  8672 solver.cpp:244]     Train net output #0: loss = 2.38218e-005 (* 1 = 2.38218e-005 loss)
I1101 13:55:31.477219  8672 sgd_solver.cpp:106] Iteration 16600, lr = 0.019425
I1101 13:55:47.917011  8672 solver.cpp:228] Iteration 16700, loss = 5.23019e-005
I1101 13:55:47.917011  8672 solver.cpp:244]     Train net output #0: loss = 5.22672e-005 (* 1 = 5.22672e-005 loss)
I1101 13:55:47.917011  8672 sgd_solver.cpp:106] Iteration 16700, lr = 0.0194225
I1101 13:56:04.290355  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_16800.caffemodel
I1101 13:56:04.407429  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_16800.solverstate
I1101 13:56:04.455462  8672 solver.cpp:337] Iteration 16800, Testing net (#0)
I1101 13:56:09.428906  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 13:56:09.428906  8672 solver.cpp:404]     Test net output #1: loss = 0.0125266 (* 1 = 0.0125266 loss)
I1101 13:56:09.497944  8672 solver.cpp:228] Iteration 16800, loss = 4.68441e-005
I1101 13:56:09.497944  8672 solver.cpp:244]     Train net output #0: loss = 4.68095e-005 (* 1 = 4.68095e-005 loss)
I1101 13:56:09.497944  8672 sgd_solver.cpp:106] Iteration 16800, lr = 0.01942
I1101 13:56:25.935694  8672 solver.cpp:228] Iteration 16900, loss = 5.70514e-005
I1101 13:56:25.935694  8672 solver.cpp:244]     Train net output #0: loss = 5.70167e-005 (* 1 = 5.70167e-005 loss)
I1101 13:56:25.935694  8672 sgd_solver.cpp:106] Iteration 16900, lr = 0.0194175
I1101 13:56:42.385546  8672 solver.cpp:228] Iteration 17000, loss = 8.21299e-005
I1101 13:56:42.385546  8672 solver.cpp:244]     Train net output #0: loss = 8.20952e-005 (* 1 = 8.20952e-005 loss)
I1101 13:56:42.385546  8672 sgd_solver.cpp:106] Iteration 17000, lr = 0.019415
I1101 13:56:58.846290  8672 solver.cpp:228] Iteration 17100, loss = 7.43163e-005
I1101 13:56:58.846290  8672 solver.cpp:244]     Train net output #0: loss = 7.42816e-005 (* 1 = 7.42816e-005 loss)
I1101 13:56:58.846290  8672 sgd_solver.cpp:106] Iteration 17100, lr = 0.0194126
I1101 13:57:15.258500  8672 solver.cpp:228] Iteration 17200, loss = 2.39417e-005
I1101 13:57:15.258500  8672 solver.cpp:244]     Train net output #0: loss = 2.3907e-005 (* 1 = 2.3907e-005 loss)
I1101 13:57:15.258500  8672 sgd_solver.cpp:106] Iteration 17200, lr = 0.0194101
I1101 13:57:31.681205  8672 solver.cpp:228] Iteration 17300, loss = 5.1886e-005
I1101 13:57:31.681205  8672 solver.cpp:244]     Train net output #0: loss = 5.18513e-005 (* 1 = 5.18513e-005 loss)
I1101 13:57:31.681205  8672 sgd_solver.cpp:106] Iteration 17300, lr = 0.0194076
I1101 13:57:48.026546  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_17400.caffemodel
I1101 13:57:48.142629  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_17400.solverstate
I1101 13:57:48.199669  8672 solver.cpp:337] Iteration 17400, Testing net (#0)
I1101 13:57:53.180214  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 13:57:53.180214  8672 solver.cpp:404]     Test net output #1: loss = 0.0125332 (* 1 = 0.0125332 loss)
I1101 13:57:53.251301  8672 solver.cpp:228] Iteration 17400, loss = 4.67157e-005
I1101 13:57:53.251301  8672 solver.cpp:244]     Train net output #0: loss = 4.6681e-005 (* 1 = 4.6681e-005 loss)
I1101 13:57:53.251301  8672 sgd_solver.cpp:106] Iteration 17400, lr = 0.0194051
I1101 13:58:09.696270  8672 solver.cpp:228] Iteration 17500, loss = 5.65504e-005
I1101 13:58:09.696270  8672 solver.cpp:244]     Train net output #0: loss = 5.65158e-005 (* 1 = 5.65158e-005 loss)
I1101 13:58:09.696270  8672 sgd_solver.cpp:106] Iteration 17500, lr = 0.0194026
I1101 13:58:26.187897  8672 solver.cpp:228] Iteration 17600, loss = 8.12539e-005
I1101 13:58:26.187897  8672 solver.cpp:244]     Train net output #0: loss = 8.12193e-005 (* 1 = 8.12193e-005 loss)
I1101 13:58:26.187897  8672 sgd_solver.cpp:106] Iteration 17600, lr = 0.0194002
I1101 13:58:42.630746  8672 solver.cpp:228] Iteration 17700, loss = 7.38379e-005
I1101 13:58:42.630746  8672 solver.cpp:244]     Train net output #0: loss = 7.38032e-005 (* 1 = 7.38032e-005 loss)
I1101 13:58:42.630746  8672 sgd_solver.cpp:106] Iteration 17700, lr = 0.0193977
I1101 13:58:59.041126  8672 solver.cpp:228] Iteration 17800, loss = 2.40227e-005
I1101 13:58:59.041126  8672 solver.cpp:244]     Train net output #0: loss = 2.3988e-005 (* 1 = 2.3988e-005 loss)
I1101 13:58:59.041126  8672 sgd_solver.cpp:106] Iteration 17800, lr = 0.0193952
I1101 13:59:15.511020  8672 solver.cpp:228] Iteration 17900, loss = 5.15189e-005
I1101 13:59:15.511020  8672 solver.cpp:244]     Train net output #0: loss = 5.14842e-005 (* 1 = 5.14842e-005 loss)
I1101 13:59:15.511020  8672 sgd_solver.cpp:106] Iteration 17900, lr = 0.0193927
I1101 13:59:31.842803  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_18000.caffemodel
I1101 13:59:31.961902  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_18000.solverstate
I1101 13:59:32.008920  8672 solver.cpp:337] Iteration 18000, Testing net (#0)
I1101 13:59:36.960419  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 13:59:36.960419  8672 solver.cpp:404]     Test net output #1: loss = 0.0125399 (* 1 = 0.0125399 loss)
I1101 13:59:37.029469  8672 solver.cpp:228] Iteration 18000, loss = 4.65807e-005
I1101 13:59:37.029469  8672 solver.cpp:244]     Train net output #0: loss = 4.6546e-005 (* 1 = 4.6546e-005 loss)
I1101 13:59:37.029469  8672 sgd_solver.cpp:106] Iteration 18000, lr = 0.0193902
I1101 13:59:53.461472  8672 solver.cpp:228] Iteration 18100, loss = 5.60083e-005
I1101 13:59:53.461472  8672 solver.cpp:244]     Train net output #0: loss = 5.59737e-005 (* 1 = 5.59737e-005 loss)
I1101 13:59:53.461472  8672 sgd_solver.cpp:106] Iteration 18100, lr = 0.0193878
I1101 14:00:10.101869  8672 solver.cpp:228] Iteration 18200, loss = 8.05068e-005
I1101 14:00:10.102370  8672 solver.cpp:244]     Train net output #0: loss = 8.04722e-005 (* 1 = 8.04722e-005 loss)
I1101 14:00:10.102370  8672 sgd_solver.cpp:106] Iteration 18200, lr = 0.0193853
I1101 14:00:26.519701  8672 solver.cpp:228] Iteration 18300, loss = 7.33952e-005
I1101 14:00:26.519701  8672 solver.cpp:244]     Train net output #0: loss = 7.33605e-005 (* 1 = 7.33605e-005 loss)
I1101 14:00:26.519701  8672 sgd_solver.cpp:106] Iteration 18300, lr = 0.0193828
I1101 14:00:42.943725  8672 solver.cpp:228] Iteration 18400, loss = 2.41263e-005
I1101 14:00:42.943725  8672 solver.cpp:244]     Train net output #0: loss = 2.40917e-005 (* 1 = 2.40917e-005 loss)
I1101 14:00:42.943725  8672 sgd_solver.cpp:106] Iteration 18400, lr = 0.0193803
I1101 14:00:59.377168  8672 solver.cpp:228] Iteration 18500, loss = 5.11679e-005
I1101 14:00:59.377168  8672 solver.cpp:244]     Train net output #0: loss = 5.11333e-005 (* 1 = 5.11333e-005 loss)
I1101 14:00:59.377168  8672 sgd_solver.cpp:106] Iteration 18500, lr = 0.0193778
I1101 14:01:15.753506  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_18600.caffemodel
I1101 14:01:15.869590  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_18600.solverstate
I1101 14:01:15.916622  8672 solver.cpp:337] Iteration 18600, Testing net (#0)
I1101 14:01:20.873255  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 14:01:20.873255  8672 solver.cpp:404]     Test net output #1: loss = 0.0125449 (* 1 = 0.0125449 loss)
I1101 14:01:20.942339  8672 solver.cpp:228] Iteration 18600, loss = 4.64409e-005
I1101 14:01:20.942339  8672 solver.cpp:244]     Train net output #0: loss = 4.64062e-005 (* 1 = 4.64062e-005 loss)
I1101 14:01:20.942339  8672 sgd_solver.cpp:106] Iteration 18600, lr = 0.0193754
I1101 14:01:37.430188  8672 solver.cpp:228] Iteration 18700, loss = 5.55665e-005
I1101 14:01:37.430188  8672 solver.cpp:244]     Train net output #0: loss = 5.55318e-005 (* 1 = 5.55318e-005 loss)
I1101 14:01:37.430188  8672 sgd_solver.cpp:106] Iteration 18700, lr = 0.0193729
I1101 14:01:53.883946  8672 solver.cpp:228] Iteration 18800, loss = 7.97144e-005
I1101 14:01:53.883946  8672 solver.cpp:244]     Train net output #0: loss = 7.96797e-005 (* 1 = 7.96797e-005 loss)
I1101 14:01:53.883946  8672 sgd_solver.cpp:106] Iteration 18800, lr = 0.0193704
I1101 14:02:10.304678  8672 solver.cpp:228] Iteration 18900, loss = 7.3029e-005
I1101 14:02:10.304678  8672 solver.cpp:244]     Train net output #0: loss = 7.29943e-005 (* 1 = 7.29943e-005 loss)
I1101 14:02:10.304678  8672 sgd_solver.cpp:106] Iteration 18900, lr = 0.0193679
I1101 14:02:26.743453  8672 solver.cpp:228] Iteration 19000, loss = 2.42372e-005
I1101 14:02:26.743453  8672 solver.cpp:244]     Train net output #0: loss = 2.42025e-005 (* 1 = 2.42025e-005 loss)
I1101 14:02:26.743453  8672 sgd_solver.cpp:106] Iteration 19000, lr = 0.0193654
I1101 14:02:43.190948  8672 solver.cpp:228] Iteration 19100, loss = 5.08653e-005
I1101 14:02:43.190948  8672 solver.cpp:244]     Train net output #0: loss = 5.08307e-005 (* 1 = 5.08307e-005 loss)
I1101 14:02:43.190948  8672 sgd_solver.cpp:106] Iteration 19100, lr = 0.019363
I1101 14:02:59.573863  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_19200.caffemodel
I1101 14:02:59.689446  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_19200.solverstate
I1101 14:02:59.768462  8672 solver.cpp:337] Iteration 19200, Testing net (#0)
I1101 14:03:04.704851  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 14:03:04.704851  8672 solver.cpp:404]     Test net output #1: loss = 0.0125502 (* 1 = 0.0125502 loss)
I1101 14:03:04.774390  8672 solver.cpp:228] Iteration 19200, loss = 4.63942e-005
I1101 14:03:04.774390  8672 solver.cpp:244]     Train net output #0: loss = 4.63595e-005 (* 1 = 4.63595e-005 loss)
I1101 14:03:04.774390  8672 sgd_solver.cpp:106] Iteration 19200, lr = 0.0193605
I1101 14:03:21.260792  8672 solver.cpp:228] Iteration 19300, loss = 5.51718e-005
I1101 14:03:21.260792  8672 solver.cpp:244]     Train net output #0: loss = 5.51371e-005 (* 1 = 5.51371e-005 loss)
I1101 14:03:21.260792  8672 sgd_solver.cpp:106] Iteration 19300, lr = 0.019358
I1101 14:03:37.742624  8672 solver.cpp:228] Iteration 19400, loss = 7.90694e-005
I1101 14:03:37.742624  8672 solver.cpp:244]     Train net output #0: loss = 7.90347e-005 (* 1 = 7.90347e-005 loss)
I1101 14:03:37.742624  8672 sgd_solver.cpp:106] Iteration 19400, lr = 0.0193555
I1101 14:03:54.158294  8672 solver.cpp:228] Iteration 19500, loss = 7.2578e-005
I1101 14:03:54.158294  8672 solver.cpp:244]     Train net output #0: loss = 7.25433e-005 (* 1 = 7.25433e-005 loss)
I1101 14:03:54.158294  8672 sgd_solver.cpp:106] Iteration 19500, lr = 0.019353
I1101 14:04:10.585798  8672 solver.cpp:228] Iteration 19600, loss = 2.43611e-005
I1101 14:04:10.585798  8672 solver.cpp:244]     Train net output #0: loss = 2.43264e-005 (* 1 = 2.43264e-005 loss)
I1101 14:04:10.585798  8672 sgd_solver.cpp:106] Iteration 19600, lr = 0.0193506
I1101 14:04:27.022631  8672 solver.cpp:228] Iteration 19700, loss = 5.05657e-005
I1101 14:04:27.022631  8672 solver.cpp:244]     Train net output #0: loss = 5.0531e-005 (* 1 = 5.0531e-005 loss)
I1101 14:04:27.022631  8672 sgd_solver.cpp:106] Iteration 19700, lr = 0.0193481
I1101 14:04:43.374730  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_19800.caffemodel
I1101 14:04:43.489812  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_19800.solverstate
I1101 14:04:43.535845  8672 solver.cpp:337] Iteration 19800, Testing net (#0)
I1101 14:04:48.494674  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 14:04:48.494674  8672 solver.cpp:404]     Test net output #1: loss = 0.0125558 (* 1 = 0.0125558 loss)
I1101 14:04:48.565726  8672 solver.cpp:228] Iteration 19800, loss = 4.63475e-005
I1101 14:04:48.565726  8672 solver.cpp:244]     Train net output #0: loss = 4.63128e-005 (* 1 = 4.63128e-005 loss)
I1101 14:04:48.565726  8672 sgd_solver.cpp:106] Iteration 19800, lr = 0.0193456
I1101 14:05:05.002024  8672 solver.cpp:228] Iteration 19900, loss = 5.48482e-005
I1101 14:05:05.002024  8672 solver.cpp:244]     Train net output #0: loss = 5.48135e-005 (* 1 = 5.48135e-005 loss)
I1101 14:05:05.002024  8672 sgd_solver.cpp:106] Iteration 19900, lr = 0.0193431
I1101 14:05:21.441576  8672 solver.cpp:228] Iteration 20000, loss = 7.84064e-005
I1101 14:05:21.441576  8672 solver.cpp:244]     Train net output #0: loss = 7.83717e-005 (* 1 = 7.83717e-005 loss)
I1101 14:05:21.441576  8672 sgd_solver.cpp:106] Iteration 20000, lr = 0.0193406
I1101 14:05:37.866611  8672 solver.cpp:228] Iteration 20100, loss = 7.22398e-005
I1101 14:05:37.866611  8672 solver.cpp:244]     Train net output #0: loss = 7.22051e-005 (* 1 = 7.22051e-005 loss)
I1101 14:05:37.866611  8672 sgd_solver.cpp:106] Iteration 20100, lr = 0.0193382
I1101 14:05:54.308607  8672 solver.cpp:228] Iteration 20200, loss = 2.44821e-005
I1101 14:05:54.308607  8672 solver.cpp:244]     Train net output #0: loss = 2.44474e-005 (* 1 = 2.44474e-005 loss)
I1101 14:05:54.308607  8672 sgd_solver.cpp:106] Iteration 20200, lr = 0.0193357
I1101 14:06:10.716784  8672 solver.cpp:228] Iteration 20300, loss = 5.0266e-005
I1101 14:06:10.716784  8672 solver.cpp:244]     Train net output #0: loss = 5.02314e-005 (* 1 = 5.02314e-005 loss)
I1101 14:06:10.716784  8672 sgd_solver.cpp:106] Iteration 20300, lr = 0.0193332
I1101 14:06:27.083632  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_20400.caffemodel
I1101 14:06:27.213215  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_20400.solverstate
I1101 14:06:27.259248  8672 solver.cpp:337] Iteration 20400, Testing net (#0)
I1101 14:06:32.210938  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 14:06:32.210938  8672 solver.cpp:404]     Test net output #1: loss = 0.0125586 (* 1 = 0.0125586 loss)
I1101 14:06:32.281175  8672 solver.cpp:228] Iteration 20400, loss = 4.62972e-005
I1101 14:06:32.281175  8672 solver.cpp:244]     Train net output #0: loss = 4.62626e-005 (* 1 = 4.62626e-005 loss)
I1101 14:06:32.281175  8672 sgd_solver.cpp:106] Iteration 20400, lr = 0.0193307
I1101 14:06:48.745890  8672 solver.cpp:228] Iteration 20500, loss = 5.46129e-005
I1101 14:06:48.745890  8672 solver.cpp:244]     Train net output #0: loss = 5.45782e-005 (* 1 = 5.45782e-005 loss)
I1101 14:06:48.745890  8672 sgd_solver.cpp:106] Iteration 20500, lr = 0.0193282
I1101 14:07:05.211527  8672 solver.cpp:228] Iteration 20600, loss = 7.78509e-005
I1101 14:07:05.211527  8672 solver.cpp:244]     Train net output #0: loss = 7.78162e-005 (* 1 = 7.78162e-005 loss)
I1101 14:07:05.211527  8672 sgd_solver.cpp:106] Iteration 20600, lr = 0.0193258
I1101 14:07:21.646858  8672 solver.cpp:228] Iteration 20700, loss = 7.19225e-005
I1101 14:07:21.646858  8672 solver.cpp:244]     Train net output #0: loss = 7.18878e-005 (* 1 = 7.18878e-005 loss)
I1101 14:07:21.646858  8672 sgd_solver.cpp:106] Iteration 20700, lr = 0.0193233
I1101 14:07:38.101166  8672 solver.cpp:228] Iteration 20800, loss = 2.46168e-005
I1101 14:07:38.101166  8672 solver.cpp:244]     Train net output #0: loss = 2.45821e-005 (* 1 = 2.45821e-005 loss)
I1101 14:07:38.101166  8672 sgd_solver.cpp:106] Iteration 20800, lr = 0.0193208
I1101 14:07:54.526227  8672 solver.cpp:228] Iteration 20900, loss = 4.99652e-005
I1101 14:07:54.526227  8672 solver.cpp:244]     Train net output #0: loss = 4.99305e-005 (* 1 = 4.99305e-005 loss)
I1101 14:07:54.526227  8672 sgd_solver.cpp:106] Iteration 20900, lr = 0.0193183
I1101 14:08:11.113709  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_21000.caffemodel
I1101 14:08:11.251307  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_21000.solverstate
I1101 14:08:11.297839  8672 solver.cpp:337] Iteration 21000, Testing net (#0)
I1101 14:08:16.250421  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 14:08:16.250421  8672 solver.cpp:404]     Test net output #1: loss = 0.0125622 (* 1 = 0.0125622 loss)
I1101 14:08:16.319957  8672 solver.cpp:228] Iteration 21000, loss = 4.63096e-005
I1101 14:08:16.319957  8672 solver.cpp:244]     Train net output #0: loss = 4.62749e-005 (* 1 = 4.62749e-005 loss)
I1101 14:08:16.319957  8672 sgd_solver.cpp:106] Iteration 21000, lr = 0.0193158
I1101 14:08:32.892761  8672 solver.cpp:228] Iteration 21100, loss = 5.43907e-005
I1101 14:08:32.892761  8672 solver.cpp:244]     Train net output #0: loss = 5.4356e-005 (* 1 = 5.4356e-005 loss)
I1101 14:08:32.892761  8672 sgd_solver.cpp:106] Iteration 21100, lr = 0.0193134
I1101 14:08:49.569510  8672 solver.cpp:228] Iteration 21200, loss = 7.73401e-005
I1101 14:08:49.569510  8672 solver.cpp:244]     Train net output #0: loss = 7.73054e-005 (* 1 = 7.73054e-005 loss)
I1101 14:08:49.569510  8672 sgd_solver.cpp:106] Iteration 21200, lr = 0.0193109
I1101 14:09:05.513501  8672 solver.cpp:228] Iteration 21300, loss = 7.16482e-005
I1101 14:09:05.513501  8672 solver.cpp:244]     Train net output #0: loss = 7.16135e-005 (* 1 = 7.16135e-005 loss)
I1101 14:09:05.513501  8672 sgd_solver.cpp:106] Iteration 21300, lr = 0.0193084
I1101 14:09:21.098310  8672 solver.cpp:228] Iteration 21400, loss = 2.47622e-005
I1101 14:09:21.098310  8672 solver.cpp:244]     Train net output #0: loss = 2.47275e-005 (* 1 = 2.47275e-005 loss)
I1101 14:09:21.098310  8672 sgd_solver.cpp:106] Iteration 21400, lr = 0.0193059
I1101 14:09:36.690318  8672 solver.cpp:228] Iteration 21500, loss = 4.9739e-005
I1101 14:09:36.690318  8672 solver.cpp:244]     Train net output #0: loss = 4.97043e-005 (* 1 = 4.97043e-005 loss)
I1101 14:09:36.690318  8672 sgd_solver.cpp:106] Iteration 21500, lr = 0.0193035
I1101 14:09:52.140532  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_21600.caffemodel
I1101 14:09:52.265522  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_21600.solverstate
I1101 14:09:52.312409  8672 solver.cpp:337] Iteration 21600, Testing net (#0)
I1101 14:09:56.976270  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 14:09:56.976270  8672 solver.cpp:404]     Test net output #1: loss = 0.0125667 (* 1 = 0.0125667 loss)
I1101 14:09:57.054432  8672 solver.cpp:228] Iteration 21600, loss = 4.63375e-005
I1101 14:09:57.054432  8672 solver.cpp:244]     Train net output #0: loss = 4.63028e-005 (* 1 = 4.63028e-005 loss)
I1101 14:09:57.054432  8672 sgd_solver.cpp:106] Iteration 21600, lr = 0.019301
I1101 14:10:12.842697  8672 solver.cpp:228] Iteration 21700, loss = 5.41907e-005
I1101 14:10:12.842697  8672 solver.cpp:244]     Train net output #0: loss = 5.4156e-005 (* 1 = 5.4156e-005 loss)
I1101 14:10:12.842697  8672 sgd_solver.cpp:106] Iteration 21700, lr = 0.0192985
I1101 14:10:28.481153  8672 solver.cpp:228] Iteration 21800, loss = 7.69122e-005
I1101 14:10:28.481153  8672 solver.cpp:244]     Train net output #0: loss = 7.68775e-005 (* 1 = 7.68775e-005 loss)
I1101 14:10:28.481153  8672 sgd_solver.cpp:106] Iteration 21800, lr = 0.019296
I1101 14:10:44.632001  8672 solver.cpp:228] Iteration 21900, loss = 7.13166e-005
I1101 14:10:44.632001  8672 solver.cpp:244]     Train net output #0: loss = 7.12819e-005 (* 1 = 7.12819e-005 loss)
I1101 14:10:44.632001  8672 sgd_solver.cpp:106] Iteration 21900, lr = 0.0192935
I1101 14:11:00.499675  8672 solver.cpp:228] Iteration 22000, loss = 2.49314e-005
I1101 14:11:00.499675  8672 solver.cpp:244]     Train net output #0: loss = 2.48968e-005 (* 1 = 2.48968e-005 loss)
I1101 14:11:00.499675  8672 sgd_solver.cpp:106] Iteration 22000, lr = 0.0192911
I1101 14:11:16.288796  8672 solver.cpp:228] Iteration 22100, loss = 4.95486e-005
I1101 14:11:16.289296  8672 solver.cpp:244]     Train net output #0: loss = 4.95139e-005 (* 1 = 4.95139e-005 loss)
I1101 14:11:16.289296  8672 sgd_solver.cpp:106] Iteration 22100, lr = 0.0192886
I1101 14:11:32.090173  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_22200.caffemodel
I1101 14:11:32.220840  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_22200.solverstate
I1101 14:11:32.267715  8672 solver.cpp:337] Iteration 22200, Testing net (#0)
I1101 14:11:37.193181  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 14:11:37.193181  8672 solver.cpp:404]     Test net output #1: loss = 0.0125706 (* 1 = 0.0125706 loss)
I1101 14:11:37.259728  8672 solver.cpp:228] Iteration 22200, loss = 4.63403e-005
I1101 14:11:37.259728  8672 solver.cpp:244]     Train net output #0: loss = 4.63056e-005 (* 1 = 4.63056e-005 loss)
I1101 14:11:37.259728  8672 sgd_solver.cpp:106] Iteration 22200, lr = 0.0192861
I1101 14:11:53.230595  8672 solver.cpp:228] Iteration 22300, loss = 5.40198e-005
I1101 14:11:53.230595  8672 solver.cpp:244]     Train net output #0: loss = 5.39851e-005 (* 1 = 5.39851e-005 loss)
I1101 14:11:53.230595  8672 sgd_solver.cpp:106] Iteration 22300, lr = 0.0192836
I1101 14:12:08.946156  8672 solver.cpp:228] Iteration 22400, loss = 7.64885e-005
I1101 14:12:08.946156  8672 solver.cpp:244]     Train net output #0: loss = 7.64538e-005 (* 1 = 7.64538e-005 loss)
I1101 14:12:08.946156  8672 sgd_solver.cpp:106] Iteration 22400, lr = 0.0192811
I1101 14:12:24.695287  8672 solver.cpp:228] Iteration 22500, loss = 7.11211e-005
I1101 14:12:24.695287  8672 solver.cpp:244]     Train net output #0: loss = 7.10864e-005 (* 1 = 7.10864e-005 loss)
I1101 14:12:24.695287  8672 sgd_solver.cpp:106] Iteration 22500, lr = 0.0192787
I1101 14:12:40.481132  8672 solver.cpp:228] Iteration 22600, loss = 2.50685e-005
I1101 14:12:40.481132  8672 solver.cpp:244]     Train net output #0: loss = 2.50338e-005 (* 1 = 2.50338e-005 loss)
I1101 14:12:40.481132  8672 sgd_solver.cpp:106] Iteration 22600, lr = 0.0192762
I1101 14:12:56.329586  8672 solver.cpp:228] Iteration 22700, loss = 4.93444e-005
I1101 14:12:56.329586  8672 solver.cpp:244]     Train net output #0: loss = 4.93097e-005 (* 1 = 4.93097e-005 loss)
I1101 14:12:56.329586  8672 sgd_solver.cpp:106] Iteration 22700, lr = 0.0192737
I1101 14:13:12.079761  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_22800.caffemodel
I1101 14:13:12.220374  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_22800.solverstate
I1101 14:13:12.267251  8672 solver.cpp:337] Iteration 22800, Testing net (#0)
I1101 14:13:17.000378  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 14:13:17.000378  8672 solver.cpp:404]     Test net output #1: loss = 0.0125747 (* 1 = 0.0125747 loss)
I1101 14:13:17.071929  8672 solver.cpp:228] Iteration 22800, loss = 4.63795e-005
I1101 14:13:17.071929  8672 solver.cpp:244]     Train net output #0: loss = 4.63448e-005 (* 1 = 4.63448e-005 loss)
I1101 14:13:17.071929  8672 sgd_solver.cpp:106] Iteration 22800, lr = 0.0192712
I1101 14:13:33.560731  8672 solver.cpp:228] Iteration 22900, loss = 5.39325e-005
I1101 14:13:33.560731  8672 solver.cpp:244]     Train net output #0: loss = 5.38978e-005 (* 1 = 5.38978e-005 loss)
I1101 14:13:33.560731  8672 sgd_solver.cpp:106] Iteration 22900, lr = 0.0192687
I1101 14:13:50.017931  8672 solver.cpp:228] Iteration 23000, loss = 7.61108e-005
I1101 14:13:50.017931  8672 solver.cpp:244]     Train net output #0: loss = 7.60761e-005 (* 1 = 7.60761e-005 loss)
I1101 14:13:50.017931  8672 sgd_solver.cpp:106] Iteration 23000, lr = 0.0192663
I1101 14:14:06.464114  8672 solver.cpp:228] Iteration 23100, loss = 7.08521e-005
I1101 14:14:06.464114  8672 solver.cpp:244]     Train net output #0: loss = 7.08174e-005 (* 1 = 7.08174e-005 loss)
I1101 14:14:06.464114  8672 sgd_solver.cpp:106] Iteration 23100, lr = 0.0192638
I1101 14:14:22.902766  8672 solver.cpp:228] Iteration 23200, loss = 2.52402e-005
I1101 14:14:22.902766  8672 solver.cpp:244]     Train net output #0: loss = 2.52055e-005 (* 1 = 2.52055e-005 loss)
I1101 14:14:22.902766  8672 sgd_solver.cpp:106] Iteration 23200, lr = 0.0192613
I1101 14:14:39.373606  8672 solver.cpp:228] Iteration 23300, loss = 4.92226e-005
I1101 14:14:39.373606  8672 solver.cpp:244]     Train net output #0: loss = 4.91879e-005 (* 1 = 4.91879e-005 loss)
I1101 14:14:39.373606  8672 sgd_solver.cpp:106] Iteration 23300, lr = 0.0192588
I1101 14:14:55.740260  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_23400.caffemodel
I1101 14:14:55.848001  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_23400.solverstate
I1101 14:14:55.894876  8672 solver.cpp:337] Iteration 23400, Testing net (#0)
I1101 14:15:00.875118  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 14:15:00.875118  8672 solver.cpp:404]     Test net output #1: loss = 0.0125798 (* 1 = 0.0125798 loss)
I1101 14:15:00.953246  8672 solver.cpp:228] Iteration 23400, loss = 4.6445e-005
I1101 14:15:00.953246  8672 solver.cpp:244]     Train net output #0: loss = 4.64103e-005 (* 1 = 4.64103e-005 loss)
I1101 14:15:00.953246  8672 sgd_solver.cpp:106] Iteration 23400, lr = 0.0192563
I1101 14:15:17.379884  8672 solver.cpp:228] Iteration 23500, loss = 5.37611e-005
I1101 14:15:17.379884  8672 solver.cpp:244]     Train net output #0: loss = 5.37264e-005 (* 1 = 5.37264e-005 loss)
I1101 14:15:17.379884  8672 sgd_solver.cpp:106] Iteration 23500, lr = 0.0192539
I1101 14:15:33.823813  8672 solver.cpp:228] Iteration 23600, loss = 7.57426e-005
I1101 14:15:33.823813  8672 solver.cpp:244]     Train net output #0: loss = 7.57079e-005 (* 1 = 7.57079e-005 loss)
I1101 14:15:33.823813  8672 sgd_solver.cpp:106] Iteration 23600, lr = 0.0192514
I1101 14:15:50.279875  8672 solver.cpp:228] Iteration 23700, loss = 7.06113e-005
I1101 14:15:50.279875  8672 solver.cpp:244]     Train net output #0: loss = 7.05766e-005 (* 1 = 7.05766e-005 loss)
I1101 14:15:50.279875  8672 sgd_solver.cpp:106] Iteration 23700, lr = 0.0192489
I1101 14:16:06.712816  8672 solver.cpp:228] Iteration 23800, loss = 2.54029e-005
I1101 14:16:06.712816  8672 solver.cpp:244]     Train net output #0: loss = 2.53682e-005 (* 1 = 2.53682e-005 loss)
I1101 14:16:06.712816  8672 sgd_solver.cpp:106] Iteration 23800, lr = 0.0192464
I1101 14:16:23.189365  8672 solver.cpp:228] Iteration 23900, loss = 4.90524e-005
I1101 14:16:23.189365  8672 solver.cpp:244]     Train net output #0: loss = 4.90177e-005 (* 1 = 4.90177e-005 loss)
I1101 14:16:23.189365  8672 sgd_solver.cpp:106] Iteration 23900, lr = 0.0192439
I1101 14:16:39.518276  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_24000.caffemodel
I1101 14:16:39.643291  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_24000.solverstate
I1101 14:16:39.690155  8672 solver.cpp:337] Iteration 24000, Testing net (#0)
I1101 14:16:44.624215  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:16:44.624215  8672 solver.cpp:404]     Test net output #1: loss = 0.0125843 (* 1 = 0.0125843 loss)
I1101 14:16:44.718003  8672 solver.cpp:228] Iteration 24000, loss = 4.64961e-005
I1101 14:16:44.718003  8672 solver.cpp:244]     Train net output #0: loss = 4.64615e-005 (* 1 = 4.64615e-005 loss)
I1101 14:16:44.718003  8672 sgd_solver.cpp:106] Iteration 24000, lr = 0.0192415
I1101 14:17:01.141209  8672 solver.cpp:228] Iteration 24100, loss = 5.36714e-005
I1101 14:17:01.141209  8672 solver.cpp:244]     Train net output #0: loss = 5.36368e-005 (* 1 = 5.36368e-005 loss)
I1101 14:17:01.141209  8672 sgd_solver.cpp:106] Iteration 24100, lr = 0.019239
I1101 14:17:17.580149  8672 solver.cpp:228] Iteration 24200, loss = 7.53863e-005
I1101 14:17:17.580149  8672 solver.cpp:244]     Train net output #0: loss = 7.53516e-005 (* 1 = 7.53516e-005 loss)
I1101 14:17:17.580149  8672 sgd_solver.cpp:106] Iteration 24200, lr = 0.0192365
I1101 14:17:34.042896  8672 solver.cpp:228] Iteration 24300, loss = 7.03591e-005
I1101 14:17:34.042896  8672 solver.cpp:244]     Train net output #0: loss = 7.03244e-005 (* 1 = 7.03244e-005 loss)
I1101 14:17:34.042896  8672 sgd_solver.cpp:106] Iteration 24300, lr = 0.019234
I1101 14:17:50.445515  8672 solver.cpp:228] Iteration 24400, loss = 2.55626e-005
I1101 14:17:50.445515  8672 solver.cpp:244]     Train net output #0: loss = 2.55279e-005 (* 1 = 2.55279e-005 loss)
I1101 14:17:50.445515  8672 sgd_solver.cpp:106] Iteration 24400, lr = 0.0192315
I1101 14:18:06.857570  8672 solver.cpp:228] Iteration 24500, loss = 4.89073e-005
I1101 14:18:06.857570  8672 solver.cpp:244]     Train net output #0: loss = 4.88726e-005 (* 1 = 4.88726e-005 loss)
I1101 14:18:06.857570  8672 sgd_solver.cpp:106] Iteration 24500, lr = 0.0192291
I1101 14:18:23.228435  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_24600.caffemodel
I1101 14:18:23.353437  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_24600.solverstate
I1101 14:18:23.400313  8672 solver.cpp:337] Iteration 24600, Testing net (#0)
I1101 14:18:28.335620  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:18:28.335620  8672 solver.cpp:404]     Test net output #1: loss = 0.0125889 (* 1 = 0.0125889 loss)
I1101 14:18:28.429373  8672 solver.cpp:228] Iteration 24600, loss = 4.65909e-005
I1101 14:18:28.429373  8672 solver.cpp:244]     Train net output #0: loss = 4.65562e-005 (* 1 = 4.65562e-005 loss)
I1101 14:18:28.429373  8672 sgd_solver.cpp:106] Iteration 24600, lr = 0.0192266
I1101 14:18:44.867944  8672 solver.cpp:228] Iteration 24700, loss = 5.35938e-005
I1101 14:18:44.867944  8672 solver.cpp:244]     Train net output #0: loss = 5.35591e-005 (* 1 = 5.35591e-005 loss)
I1101 14:18:44.867944  8672 sgd_solver.cpp:106] Iteration 24700, lr = 0.0192241
I1101 14:19:01.304332  8672 solver.cpp:228] Iteration 24800, loss = 7.50712e-005
I1101 14:19:01.304332  8672 solver.cpp:244]     Train net output #0: loss = 7.50365e-005 (* 1 = 7.50365e-005 loss)
I1101 14:19:01.304332  8672 sgd_solver.cpp:106] Iteration 24800, lr = 0.0192216
I1101 14:19:17.781379  8672 solver.cpp:228] Iteration 24900, loss = 7.00437e-005
I1101 14:19:17.781379  8672 solver.cpp:244]     Train net output #0: loss = 7.0009e-005 (* 1 = 7.0009e-005 loss)
I1101 14:19:17.781379  8672 sgd_solver.cpp:106] Iteration 24900, lr = 0.0192191
I1101 14:19:34.189986  8672 solver.cpp:228] Iteration 25000, loss = 2.57438e-005
I1101 14:19:34.189986  8672 solver.cpp:244]     Train net output #0: loss = 2.57091e-005 (* 1 = 2.57091e-005 loss)
I1101 14:19:34.189986  8672 sgd_solver.cpp:106] Iteration 25000, lr = 0.0192167
I1101 14:19:50.649693  8672 solver.cpp:228] Iteration 25100, loss = 4.87783e-005
I1101 14:19:50.649693  8672 solver.cpp:244]     Train net output #0: loss = 4.87436e-005 (* 1 = 4.87436e-005 loss)
I1101 14:19:50.649693  8672 sgd_solver.cpp:106] Iteration 25100, lr = 0.0192142
I1101 14:20:07.005367  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_25200.caffemodel
I1101 14:20:07.125973  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_25200.solverstate
I1101 14:20:07.190181  8672 solver.cpp:337] Iteration 25200, Testing net (#0)
I1101 14:20:12.126433  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:20:12.126433  8672 solver.cpp:404]     Test net output #1: loss = 0.0125919 (* 1 = 0.0125919 loss)
I1101 14:20:12.204574  8672 solver.cpp:228] Iteration 25200, loss = 4.66486e-005
I1101 14:20:12.204574  8672 solver.cpp:244]     Train net output #0: loss = 4.66139e-005 (* 1 = 4.66139e-005 loss)
I1101 14:20:12.204574  8672 sgd_solver.cpp:106] Iteration 25200, lr = 0.0192117
I1101 14:20:28.613649  8672 solver.cpp:228] Iteration 25300, loss = 5.34676e-005
I1101 14:20:28.613649  8672 solver.cpp:244]     Train net output #0: loss = 5.34329e-005 (* 1 = 5.34329e-005 loss)
I1101 14:20:28.613649  8672 sgd_solver.cpp:106] Iteration 25300, lr = 0.0192092
I1101 14:20:45.082360  8672 solver.cpp:228] Iteration 25400, loss = 7.47059e-005
I1101 14:20:45.082360  8672 solver.cpp:244]     Train net output #0: loss = 7.46713e-005 (* 1 = 7.46713e-005 loss)
I1101 14:20:45.082360  8672 sgd_solver.cpp:106] Iteration 25400, lr = 0.0192067
I1101 14:21:01.488605  8672 solver.cpp:228] Iteration 25500, loss = 6.98309e-005
I1101 14:21:01.488605  8672 solver.cpp:244]     Train net output #0: loss = 6.97962e-005 (* 1 = 6.97962e-005 loss)
I1101 14:21:01.488605  8672 sgd_solver.cpp:106] Iteration 25500, lr = 0.0192043
I1101 14:21:17.911905  8672 solver.cpp:228] Iteration 25600, loss = 2.59131e-005
I1101 14:21:17.911905  8672 solver.cpp:244]     Train net output #0: loss = 2.58784e-005 (* 1 = 2.58784e-005 loss)
I1101 14:21:17.911905  8672 sgd_solver.cpp:106] Iteration 25600, lr = 0.0192018
I1101 14:21:34.335683  8672 solver.cpp:228] Iteration 25700, loss = 4.86249e-005
I1101 14:21:34.335683  8672 solver.cpp:244]     Train net output #0: loss = 4.85902e-005 (* 1 = 4.85902e-005 loss)
I1101 14:21:34.335683  8672 sgd_solver.cpp:106] Iteration 25700, lr = 0.0191993
I1101 14:21:50.678148  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_25800.caffemodel
I1101 14:21:50.787526  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_25800.solverstate
I1101 14:21:50.834401  8672 solver.cpp:337] Iteration 25800, Testing net (#0)
I1101 14:21:55.764972  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:21:55.764972  8672 solver.cpp:404]     Test net output #1: loss = 0.0125972 (* 1 = 0.0125972 loss)
I1101 14:21:55.843099  8672 solver.cpp:228] Iteration 25800, loss = 4.67689e-005
I1101 14:21:55.843099  8672 solver.cpp:244]     Train net output #0: loss = 4.67343e-005 (* 1 = 4.67343e-005 loss)
I1101 14:21:55.843099  8672 sgd_solver.cpp:106] Iteration 25800, lr = 0.0191968
I1101 14:22:12.263615  8672 solver.cpp:228] Iteration 25900, loss = 5.34275e-005
I1101 14:22:12.263615  8672 solver.cpp:244]     Train net output #0: loss = 5.33929e-005 (* 1 = 5.33929e-005 loss)
I1101 14:22:12.263615  8672 sgd_solver.cpp:106] Iteration 25900, lr = 0.0191944
I1101 14:22:28.706485  8672 solver.cpp:228] Iteration 26000, loss = 7.44045e-005
I1101 14:22:28.706485  8672 solver.cpp:244]     Train net output #0: loss = 7.43699e-005 (* 1 = 7.43699e-005 loss)
I1101 14:22:28.706485  8672 sgd_solver.cpp:106] Iteration 26000, lr = 0.0191919
I1101 14:22:45.137135  8672 solver.cpp:228] Iteration 26100, loss = 6.95681e-005
I1101 14:22:45.137135  8672 solver.cpp:244]     Train net output #0: loss = 6.95334e-005 (* 1 = 6.95334e-005 loss)
I1101 14:22:45.137135  8672 sgd_solver.cpp:106] Iteration 26100, lr = 0.0191894
I1101 14:23:01.573531  8672 solver.cpp:228] Iteration 26200, loss = 2.60853e-005
I1101 14:23:01.573531  8672 solver.cpp:244]     Train net output #0: loss = 2.60506e-005 (* 1 = 2.60506e-005 loss)
I1101 14:23:01.573531  8672 sgd_solver.cpp:106] Iteration 26200, lr = 0.0191869
I1101 14:23:17.959811  8672 solver.cpp:228] Iteration 26300, loss = 4.8475e-005
I1101 14:23:17.959811  8672 solver.cpp:244]     Train net output #0: loss = 4.84403e-005 (* 1 = 4.84403e-005 loss)
I1101 14:23:17.959811  8672 sgd_solver.cpp:106] Iteration 26300, lr = 0.0191844
I1101 14:23:34.320719  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_26400.caffemodel
I1101 14:23:34.430095  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_26400.solverstate
I1101 14:23:34.476971  8672 solver.cpp:337] Iteration 26400, Testing net (#0)
I1101 14:23:39.391074  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:23:39.391074  8672 solver.cpp:404]     Test net output #1: loss = 0.0126008 (* 1 = 0.0126008 loss)
I1101 14:23:39.484861  8672 solver.cpp:228] Iteration 26400, loss = 4.68183e-005
I1101 14:23:39.484861  8672 solver.cpp:244]     Train net output #0: loss = 4.67836e-005 (* 1 = 4.67836e-005 loss)
I1101 14:23:39.484861  8672 sgd_solver.cpp:106] Iteration 26400, lr = 0.019182
I1101 14:23:55.849503  8672 solver.cpp:228] Iteration 26500, loss = 5.33474e-005
I1101 14:23:55.849503  8672 solver.cpp:244]     Train net output #0: loss = 5.33128e-005 (* 1 = 5.33128e-005 loss)
I1101 14:23:55.849503  8672 sgd_solver.cpp:106] Iteration 26500, lr = 0.0191795
I1101 14:24:12.236603  8672 solver.cpp:228] Iteration 26600, loss = 7.40924e-005
I1101 14:24:12.236603  8672 solver.cpp:244]     Train net output #0: loss = 7.40578e-005 (* 1 = 7.40578e-005 loss)
I1101 14:24:12.236603  8672 sgd_solver.cpp:106] Iteration 26600, lr = 0.019177
I1101 14:24:28.623086  8672 solver.cpp:228] Iteration 26700, loss = 6.93541e-005
I1101 14:24:28.623086  8672 solver.cpp:244]     Train net output #0: loss = 6.93195e-005 (* 1 = 6.93195e-005 loss)
I1101 14:24:28.623086  8672 sgd_solver.cpp:106] Iteration 26700, lr = 0.0191745
I1101 14:24:45.034523  8672 solver.cpp:228] Iteration 26800, loss = 2.62546e-005
I1101 14:24:45.034523  8672 solver.cpp:244]     Train net output #0: loss = 2.62199e-005 (* 1 = 2.62199e-005 loss)
I1101 14:24:45.034523  8672 sgd_solver.cpp:106] Iteration 26800, lr = 0.019172
I1101 14:25:01.430349  8672 solver.cpp:228] Iteration 26900, loss = 4.83603e-005
I1101 14:25:01.430349  8672 solver.cpp:244]     Train net output #0: loss = 4.83257e-005 (* 1 = 4.83257e-005 loss)
I1101 14:25:01.430349  8672 sgd_solver.cpp:106] Iteration 26900, lr = 0.0191696
I1101 14:25:17.735622  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_27000.caffemodel
I1101 14:25:17.860625  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_27000.solverstate
I1101 14:25:17.907501  8672 solver.cpp:337] Iteration 27000, Testing net (#0)
I1101 14:25:22.843782  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:25:22.843782  8672 solver.cpp:404]     Test net output #1: loss = 0.0126069 (* 1 = 0.0126069 loss)
I1101 14:25:22.921911  8672 solver.cpp:228] Iteration 27000, loss = 4.69363e-005
I1101 14:25:22.921911  8672 solver.cpp:244]     Train net output #0: loss = 4.69016e-005 (* 1 = 4.69016e-005 loss)
I1101 14:25:22.921911  8672 sgd_solver.cpp:106] Iteration 27000, lr = 0.0191671
I1101 14:25:39.339807  8672 solver.cpp:228] Iteration 27100, loss = 5.3302e-005
I1101 14:25:39.339807  8672 solver.cpp:244]     Train net output #0: loss = 5.32673e-005 (* 1 = 5.32673e-005 loss)
I1101 14:25:39.339807  8672 sgd_solver.cpp:106] Iteration 27100, lr = 0.0191646
I1101 14:25:55.729533  8672 solver.cpp:228] Iteration 27200, loss = 7.37916e-005
I1101 14:25:55.729533  8672 solver.cpp:244]     Train net output #0: loss = 7.37569e-005 (* 1 = 7.37569e-005 loss)
I1101 14:25:55.729533  8672 sgd_solver.cpp:106] Iteration 27200, lr = 0.0191621
I1101 14:26:12.219293  8672 solver.cpp:228] Iteration 27300, loss = 6.91862e-005
I1101 14:26:12.219293  8672 solver.cpp:244]     Train net output #0: loss = 6.91515e-005 (* 1 = 6.91515e-005 loss)
I1101 14:26:12.219293  8672 sgd_solver.cpp:106] Iteration 27300, lr = 0.0191596
I1101 14:26:28.591671  8672 solver.cpp:228] Iteration 27400, loss = 2.6437e-005
I1101 14:26:28.591671  8672 solver.cpp:244]     Train net output #0: loss = 2.64023e-005 (* 1 = 2.64023e-005 loss)
I1101 14:26:28.591671  8672 sgd_solver.cpp:106] Iteration 27400, lr = 0.0191572
I1101 14:26:45.026136  8672 solver.cpp:228] Iteration 27500, loss = 4.82564e-005
I1101 14:26:45.026136  8672 solver.cpp:244]     Train net output #0: loss = 4.82218e-005 (* 1 = 4.82218e-005 loss)
I1101 14:26:45.026136  8672 sgd_solver.cpp:106] Iteration 27500, lr = 0.0191547
I1101 14:27:01.339954  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_27600.caffemodel
I1101 14:27:01.464972  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_27600.solverstate
I1101 14:27:01.511832  8672 solver.cpp:337] Iteration 27600, Testing net (#0)
I1101 14:27:06.432754  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:27:06.432754  8672 solver.cpp:404]     Test net output #1: loss = 0.0126124 (* 1 = 0.0126124 loss)
I1101 14:27:06.511411  8672 solver.cpp:228] Iteration 27600, loss = 4.70042e-005
I1101 14:27:06.511411  8672 solver.cpp:244]     Train net output #0: loss = 4.69695e-005 (* 1 = 4.69695e-005 loss)
I1101 14:27:06.511411  8672 sgd_solver.cpp:106] Iteration 27600, lr = 0.0191522
I1101 14:27:23.134353  8672 solver.cpp:228] Iteration 27700, loss = 5.32493e-005
I1101 14:27:23.134353  8672 solver.cpp:244]     Train net output #0: loss = 5.32146e-005 (* 1 = 5.32146e-005 loss)
I1101 14:27:23.134353  8672 sgd_solver.cpp:106] Iteration 27700, lr = 0.0191497
I1101 14:27:39.691005  8672 solver.cpp:228] Iteration 27800, loss = 7.35487e-005
I1101 14:27:39.691005  8672 solver.cpp:244]     Train net output #0: loss = 7.3514e-005 (* 1 = 7.3514e-005 loss)
I1101 14:27:39.691005  8672 sgd_solver.cpp:106] Iteration 27800, lr = 0.0191472
I1101 14:27:56.172873  8672 solver.cpp:228] Iteration 27900, loss = 6.89329e-005
I1101 14:27:56.172873  8672 solver.cpp:244]     Train net output #0: loss = 6.88982e-005 (* 1 = 6.88982e-005 loss)
I1101 14:27:56.172873  8672 sgd_solver.cpp:106] Iteration 27900, lr = 0.0191448
I1101 14:28:12.646194  8672 solver.cpp:228] Iteration 28000, loss = 2.65967e-005
I1101 14:28:12.646194  8672 solver.cpp:244]     Train net output #0: loss = 2.6562e-005 (* 1 = 2.6562e-005 loss)
I1101 14:28:12.646194  8672 sgd_solver.cpp:106] Iteration 28000, lr = 0.0191423
I1101 14:28:29.269755  8672 solver.cpp:228] Iteration 28100, loss = 4.81364e-005
I1101 14:28:29.269755  8672 solver.cpp:244]     Train net output #0: loss = 4.81017e-005 (* 1 = 4.81017e-005 loss)
I1101 14:28:29.269755  8672 sgd_solver.cpp:106] Iteration 28100, lr = 0.0191398
I1101 14:28:45.683432  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_28200.caffemodel
I1101 14:28:45.802017  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_28200.solverstate
I1101 14:28:45.848551  8672 solver.cpp:337] Iteration 28200, Testing net (#0)
I1101 14:28:50.807245  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:28:50.807245  8672 solver.cpp:404]     Test net output #1: loss = 0.0126185 (* 1 = 0.0126185 loss)
I1101 14:28:50.877657  8672 solver.cpp:228] Iteration 28200, loss = 4.71174e-005
I1101 14:28:50.877657  8672 solver.cpp:244]     Train net output #0: loss = 4.70827e-005 (* 1 = 4.70827e-005 loss)
I1101 14:28:50.877657  8672 sgd_solver.cpp:106] Iteration 28200, lr = 0.0191373
I1101 14:29:07.486269  8672 solver.cpp:228] Iteration 28300, loss = 5.32624e-005
I1101 14:29:07.486269  8672 solver.cpp:244]     Train net output #0: loss = 5.32277e-005 (* 1 = 5.32277e-005 loss)
I1101 14:29:07.486269  8672 sgd_solver.cpp:106] Iteration 28300, lr = 0.0191348
I1101 14:29:24.367914  8672 solver.cpp:228] Iteration 28400, loss = 7.32962e-005
I1101 14:29:24.367914  8672 solver.cpp:244]     Train net output #0: loss = 7.32616e-005 (* 1 = 7.32616e-005 loss)
I1101 14:29:24.367914  8672 sgd_solver.cpp:106] Iteration 28400, lr = 0.0191324
I1101 14:29:41.266281  8672 solver.cpp:228] Iteration 28500, loss = 6.86897e-005
I1101 14:29:41.266281  8672 solver.cpp:244]     Train net output #0: loss = 6.86551e-005 (* 1 = 6.86551e-005 loss)
I1101 14:29:41.266281  8672 sgd_solver.cpp:106] Iteration 28500, lr = 0.0191299
I1101 14:29:57.613226  8672 solver.cpp:228] Iteration 28600, loss = 2.67648e-005
I1101 14:29:57.613226  8672 solver.cpp:244]     Train net output #0: loss = 2.67301e-005 (* 1 = 2.67301e-005 loss)
I1101 14:29:57.613226  8672 sgd_solver.cpp:106] Iteration 28600, lr = 0.0191274
I1101 14:30:13.673543  8672 solver.cpp:228] Iteration 28700, loss = 4.80253e-005
I1101 14:30:13.673543  8672 solver.cpp:244]     Train net output #0: loss = 4.79907e-005 (* 1 = 4.79907e-005 loss)
I1101 14:30:13.673543  8672 sgd_solver.cpp:106] Iteration 28700, lr = 0.0191249
I1101 14:30:29.309548  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_28800.caffemodel
I1101 14:30:29.426631  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_28800.solverstate
I1101 14:30:29.473165  8672 solver.cpp:337] Iteration 28800, Testing net (#0)
I1101 14:30:34.136585  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:30:34.136585  8672 solver.cpp:404]     Test net output #1: loss = 0.012624 (* 1 = 0.012624 loss)
I1101 14:30:34.205634  8672 solver.cpp:228] Iteration 28800, loss = 4.7196e-005
I1101 14:30:34.205634  8672 solver.cpp:244]     Train net output #0: loss = 4.71614e-005 (* 1 = 4.71614e-005 loss)
I1101 14:30:34.205634  8672 sgd_solver.cpp:106] Iteration 28800, lr = 0.0191224
I1101 14:30:51.036456  8672 solver.cpp:228] Iteration 28900, loss = 5.3171e-005
I1101 14:30:51.036978  8672 solver.cpp:244]     Train net output #0: loss = 5.31363e-005 (* 1 = 5.31363e-005 loss)
I1101 14:30:51.036978  8672 sgd_solver.cpp:106] Iteration 28900, lr = 0.01912
I1101 14:31:07.522264  8672 solver.cpp:228] Iteration 29000, loss = 7.30098e-005
I1101 14:31:07.522264  8672 solver.cpp:244]     Train net output #0: loss = 7.29751e-005 (* 1 = 7.29751e-005 loss)
I1101 14:31:07.522264  8672 sgd_solver.cpp:106] Iteration 29000, lr = 0.0191175
I1101 14:31:24.264690  8672 solver.cpp:228] Iteration 29100, loss = 6.8437e-005
I1101 14:31:24.264690  8672 solver.cpp:244]     Train net output #0: loss = 6.84024e-005 (* 1 = 6.84024e-005 loss)
I1101 14:31:24.264690  8672 sgd_solver.cpp:106] Iteration 29100, lr = 0.019115
I1101 14:31:41.005480  8672 solver.cpp:228] Iteration 29200, loss = 2.69257e-005
I1101 14:31:41.005480  8672 solver.cpp:244]     Train net output #0: loss = 2.6891e-005 (* 1 = 2.6891e-005 loss)
I1101 14:31:41.005480  8672 sgd_solver.cpp:106] Iteration 29200, lr = 0.0191125
I1101 14:31:56.928061  8672 solver.cpp:228] Iteration 29300, loss = 4.79e-005
I1101 14:31:56.928061  8672 solver.cpp:244]     Train net output #0: loss = 4.78653e-005 (* 1 = 4.78653e-005 loss)
I1101 14:31:56.928061  8672 sgd_solver.cpp:106] Iteration 29300, lr = 0.01911
I1101 14:32:12.747844  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_29400.caffemodel
I1101 14:32:12.968504  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_29400.solverstate
I1101 14:32:13.021541  8672 solver.cpp:337] Iteration 29400, Testing net (#0)
I1101 14:32:17.869947  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:32:17.869947  8672 solver.cpp:404]     Test net output #1: loss = 0.0126301 (* 1 = 0.0126301 loss)
I1101 14:32:17.937165  8672 solver.cpp:228] Iteration 29400, loss = 4.7252e-005
I1101 14:32:17.937165  8672 solver.cpp:244]     Train net output #0: loss = 4.72173e-005 (* 1 = 4.72173e-005 loss)
I1101 14:32:17.937165  8672 sgd_solver.cpp:106] Iteration 29400, lr = 0.0191076
I1101 14:32:33.809684  8672 solver.cpp:228] Iteration 29500, loss = 5.31291e-005
I1101 14:32:33.809684  8672 solver.cpp:244]     Train net output #0: loss = 5.30944e-005 (* 1 = 5.30944e-005 loss)
I1101 14:32:33.809684  8672 sgd_solver.cpp:106] Iteration 29500, lr = 0.0191051
I1101 14:32:49.614296  8672 solver.cpp:228] Iteration 29600, loss = 7.27579e-005
I1101 14:32:49.614296  8672 solver.cpp:244]     Train net output #0: loss = 7.27233e-005 (* 1 = 7.27233e-005 loss)
I1101 14:32:49.614296  8672 sgd_solver.cpp:106] Iteration 29600, lr = 0.0191026
I1101 14:33:05.715674  8672 solver.cpp:228] Iteration 29700, loss = 6.81234e-005
I1101 14:33:05.715674  8672 solver.cpp:244]     Train net output #0: loss = 6.80887e-005 (* 1 = 6.80887e-005 loss)
I1101 14:33:05.715674  8672 sgd_solver.cpp:106] Iteration 29700, lr = 0.0191001
I1101 14:33:21.938843  8672 solver.cpp:228] Iteration 29800, loss = 2.71069e-005
I1101 14:33:21.939343  8672 solver.cpp:244]     Train net output #0: loss = 2.70722e-005 (* 1 = 2.70722e-005 loss)
I1101 14:33:21.939343  8672 sgd_solver.cpp:106] Iteration 29800, lr = 0.0190976
I1101 14:33:38.230774  8672 solver.cpp:228] Iteration 29900, loss = 4.78098e-005
I1101 14:33:38.230774  8672 solver.cpp:244]     Train net output #0: loss = 4.77751e-005 (* 1 = 4.77751e-005 loss)
I1101 14:33:38.230774  8672 sgd_solver.cpp:106] Iteration 29900, lr = 0.0190952
I1101 14:33:54.387136  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_30000.caffemodel
I1101 14:33:54.545251  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_30000.solverstate
I1101 14:33:54.616302  8672 solver.cpp:337] Iteration 30000, Testing net (#0)
I1101 14:33:59.532173  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:33:59.532173  8672 solver.cpp:404]     Test net output #1: loss = 0.0126351 (* 1 = 0.0126351 loss)
I1101 14:33:59.600817  8672 solver.cpp:228] Iteration 30000, loss = 4.7302e-005
I1101 14:33:59.600817  8672 solver.cpp:244]     Train net output #0: loss = 4.72673e-005 (* 1 = 4.72673e-005 loss)
I1101 14:33:59.600817  8672 sgd_solver.cpp:106] Iteration 30000, lr = 0.0190927
I1101 14:34:15.947748  8672 solver.cpp:228] Iteration 30100, loss = 5.30931e-005
I1101 14:34:15.947748  8672 solver.cpp:244]     Train net output #0: loss = 5.30585e-005 (* 1 = 5.30585e-005 loss)
I1101 14:34:15.947748  8672 sgd_solver.cpp:106] Iteration 30100, lr = 0.0190902
I1101 14:34:32.273777  8672 solver.cpp:228] Iteration 30200, loss = 7.2487e-005
I1101 14:34:32.273777  8672 solver.cpp:244]     Train net output #0: loss = 7.24523e-005 (* 1 = 7.24523e-005 loss)
I1101 14:34:32.273777  8672 sgd_solver.cpp:106] Iteration 30200, lr = 0.0190877
I1101 14:34:48.436185  8672 solver.cpp:228] Iteration 30300, loss = 6.78785e-005
I1101 14:34:48.436185  8672 solver.cpp:244]     Train net output #0: loss = 6.78438e-005 (* 1 = 6.78438e-005 loss)
I1101 14:34:48.436185  8672 sgd_solver.cpp:106] Iteration 30300, lr = 0.0190853
I1101 14:35:04.671185  8672 solver.cpp:228] Iteration 30400, loss = 2.72643e-005
I1101 14:35:04.671185  8672 solver.cpp:244]     Train net output #0: loss = 2.72296e-005 (* 1 = 2.72296e-005 loss)
I1101 14:35:04.671185  8672 sgd_solver.cpp:106] Iteration 30400, lr = 0.0190828
I1101 14:35:22.039959  8672 solver.cpp:228] Iteration 30500, loss = 4.77166e-005
I1101 14:35:22.039959  8672 solver.cpp:244]     Train net output #0: loss = 4.76819e-005 (* 1 = 4.76819e-005 loss)
I1101 14:35:22.039959  8672 sgd_solver.cpp:106] Iteration 30500, lr = 0.0190803
I1101 14:35:39.161244  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_30600.caffemodel
I1101 14:35:39.353168  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_30600.solverstate
I1101 14:35:39.418215  8672 solver.cpp:337] Iteration 30600, Testing net (#0)
I1101 14:35:44.515321  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:35:44.515321  8672 solver.cpp:404]     Test net output #1: loss = 0.0126414 (* 1 = 0.0126414 loss)
I1101 14:35:44.586514  8672 solver.cpp:228] Iteration 30600, loss = 4.7398e-005
I1101 14:35:44.586514  8672 solver.cpp:244]     Train net output #0: loss = 4.73633e-005 (* 1 = 4.73633e-005 loss)
I1101 14:35:44.586514  8672 sgd_solver.cpp:106] Iteration 30600, lr = 0.0190778
I1101 14:36:01.841169  8672 solver.cpp:228] Iteration 30700, loss = 5.30364e-005
I1101 14:36:01.841169  8672 solver.cpp:244]     Train net output #0: loss = 5.30017e-005 (* 1 = 5.30017e-005 loss)
I1101 14:36:01.841169  8672 sgd_solver.cpp:106] Iteration 30700, lr = 0.0190753
I1101 14:36:19.067160  8672 solver.cpp:228] Iteration 30800, loss = 7.21946e-005
I1101 14:36:19.067160  8672 solver.cpp:244]     Train net output #0: loss = 7.21599e-005 (* 1 = 7.21599e-005 loss)
I1101 14:36:19.067160  8672 sgd_solver.cpp:106] Iteration 30800, lr = 0.0190729
I1101 14:36:36.105993  8672 solver.cpp:228] Iteration 30900, loss = 6.76832e-005
I1101 14:36:36.105993  8672 solver.cpp:244]     Train net output #0: loss = 6.76484e-005 (* 1 = 6.76484e-005 loss)
I1101 14:36:36.105993  8672 sgd_solver.cpp:106] Iteration 30900, lr = 0.0190704
I1101 14:36:53.019065  8672 solver.cpp:228] Iteration 31000, loss = 2.74312e-005
I1101 14:36:53.019065  8672 solver.cpp:244]     Train net output #0: loss = 2.73965e-005 (* 1 = 2.73965e-005 loss)
I1101 14:36:53.019065  8672 sgd_solver.cpp:106] Iteration 31000, lr = 0.0190679
I1101 14:37:10.054185  8672 solver.cpp:228] Iteration 31100, loss = 4.76235e-005
I1101 14:37:10.054185  8672 solver.cpp:244]     Train net output #0: loss = 4.75887e-005 (* 1 = 4.75887e-005 loss)
I1101 14:37:10.054185  8672 sgd_solver.cpp:106] Iteration 31100, lr = 0.0190654
I1101 14:37:27.039314  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_31200.caffemodel
I1101 14:37:27.172513  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_31200.solverstate
I1101 14:37:27.240562  8672 solver.cpp:337] Iteration 31200, Testing net (#0)
I1101 14:37:32.407320  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:37:32.407320  8672 solver.cpp:404]     Test net output #1: loss = 0.0126472 (* 1 = 0.0126472 loss)
I1101 14:37:32.479607  8672 solver.cpp:228] Iteration 31200, loss = 4.74373e-005
I1101 14:37:32.479607  8672 solver.cpp:244]     Train net output #0: loss = 4.74026e-005 (* 1 = 4.74026e-005 loss)
I1101 14:37:32.479607  8672 sgd_solver.cpp:106] Iteration 31200, lr = 0.0190629
I1101 14:37:49.571835  8672 solver.cpp:228] Iteration 31300, loss = 5.29736e-005
I1101 14:37:49.571835  8672 solver.cpp:244]     Train net output #0: loss = 5.29389e-005 (* 1 = 5.29389e-005 loss)
I1101 14:37:49.571835  8672 sgd_solver.cpp:106] Iteration 31300, lr = 0.0190605
I1101 14:38:06.304237  8672 solver.cpp:228] Iteration 31400, loss = 7.19081e-005
I1101 14:38:06.304237  8672 solver.cpp:244]     Train net output #0: loss = 7.18734e-005 (* 1 = 7.18734e-005 loss)
I1101 14:38:06.304237  8672 sgd_solver.cpp:106] Iteration 31400, lr = 0.019058
I1101 14:38:22.612015  8672 solver.cpp:228] Iteration 31500, loss = 6.74884e-005
I1101 14:38:22.612015  8672 solver.cpp:244]     Train net output #0: loss = 6.74537e-005 (* 1 = 6.74537e-005 loss)
I1101 14:38:22.612015  8672 sgd_solver.cpp:106] Iteration 31500, lr = 0.0190555
I1101 14:38:39.117785  8672 solver.cpp:228] Iteration 31600, loss = 2.75862e-005
I1101 14:38:39.117785  8672 solver.cpp:244]     Train net output #0: loss = 2.75515e-005 (* 1 = 2.75515e-005 loss)
I1101 14:38:39.117785  8672 sgd_solver.cpp:106] Iteration 31600, lr = 0.019053
I1101 14:38:55.488915  8672 solver.cpp:228] Iteration 31700, loss = 4.75351e-005
I1101 14:38:55.488915  8672 solver.cpp:244]     Train net output #0: loss = 4.75004e-005 (* 1 = 4.75004e-005 loss)
I1101 14:38:55.488915  8672 sgd_solver.cpp:106] Iteration 31700, lr = 0.0190505
I1101 14:39:11.313834  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_31800.caffemodel
I1101 14:39:11.442931  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_31800.solverstate
I1101 14:39:11.493965  8672 solver.cpp:337] Iteration 31800, Testing net (#0)
I1101 14:39:16.298295  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:39:16.298295  8672 solver.cpp:404]     Test net output #1: loss = 0.0126534 (* 1 = 0.0126534 loss)
I1101 14:39:16.364825  8672 solver.cpp:228] Iteration 31800, loss = 4.75141e-005
I1101 14:39:16.364825  8672 solver.cpp:244]     Train net output #0: loss = 4.74794e-005 (* 1 = 4.74794e-005 loss)
I1101 14:39:16.364825  8672 sgd_solver.cpp:106] Iteration 31800, lr = 0.0190481
I1101 14:39:32.224934  8672 solver.cpp:228] Iteration 31900, loss = 5.29324e-005
I1101 14:39:32.224934  8672 solver.cpp:244]     Train net output #0: loss = 5.28977e-005 (* 1 = 5.28977e-005 loss)
I1101 14:39:32.224934  8672 sgd_solver.cpp:106] Iteration 31900, lr = 0.0190456
I1101 14:39:48.223628  8672 solver.cpp:228] Iteration 32000, loss = 7.16103e-005
I1101 14:39:48.224128  8672 solver.cpp:244]     Train net output #0: loss = 7.15756e-005 (* 1 = 7.15756e-005 loss)
I1101 14:39:48.224128  8672 sgd_solver.cpp:106] Iteration 32000, lr = 0.0190431
I1101 14:40:04.202314  8672 solver.cpp:228] Iteration 32100, loss = 6.73008e-005
I1101 14:40:04.202314  8672 solver.cpp:244]     Train net output #0: loss = 6.7266e-005 (* 1 = 6.7266e-005 loss)
I1101 14:40:04.202314  8672 sgd_solver.cpp:106] Iteration 32100, lr = 0.0190406
I1101 14:40:20.138388  8672 solver.cpp:228] Iteration 32200, loss = 2.77495e-005
I1101 14:40:20.138388  8672 solver.cpp:244]     Train net output #0: loss = 2.77148e-005 (* 1 = 2.77148e-005 loss)
I1101 14:40:20.138388  8672 sgd_solver.cpp:106] Iteration 32200, lr = 0.0190381
I1101 14:40:36.220414  8672 solver.cpp:228] Iteration 32300, loss = 4.74061e-005
I1101 14:40:36.220414  8672 solver.cpp:244]     Train net output #0: loss = 4.73714e-005 (* 1 = 4.73714e-005 loss)
I1101 14:40:36.220414  8672 sgd_solver.cpp:106] Iteration 32300, lr = 0.0190357
I1101 14:40:52.003041  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_32400.caffemodel
I1101 14:40:52.130631  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_32400.solverstate
I1101 14:40:52.192178  8672 solver.cpp:337] Iteration 32400, Testing net (#0)
I1101 14:40:57.002501  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:40:57.002501  8672 solver.cpp:404]     Test net output #1: loss = 0.0126585 (* 1 = 0.0126585 loss)
I1101 14:40:57.069689  8672 solver.cpp:228] Iteration 32400, loss = 4.75606e-005
I1101 14:40:57.069689  8672 solver.cpp:244]     Train net output #0: loss = 4.75259e-005 (* 1 = 4.75259e-005 loss)
I1101 14:40:57.069689  8672 sgd_solver.cpp:106] Iteration 32400, lr = 0.0190332
I1101 14:41:12.985245  8672 solver.cpp:228] Iteration 32500, loss = 5.29149e-005
I1101 14:41:12.985245  8672 solver.cpp:244]     Train net output #0: loss = 5.28802e-005 (* 1 = 5.28802e-005 loss)
I1101 14:41:12.985245  8672 sgd_solver.cpp:106] Iteration 32500, lr = 0.0190307
I1101 14:41:28.844310  8672 solver.cpp:228] Iteration 32600, loss = 7.13393e-005
I1101 14:41:28.844310  8672 solver.cpp:244]     Train net output #0: loss = 7.13046e-005 (* 1 = 7.13046e-005 loss)
I1101 14:41:28.844310  8672 sgd_solver.cpp:106] Iteration 32600, lr = 0.0190282
I1101 14:41:44.826083  8672 solver.cpp:228] Iteration 32700, loss = 6.70845e-005
I1101 14:41:44.826083  8672 solver.cpp:244]     Train net output #0: loss = 6.70498e-005 (* 1 = 6.70498e-005 loss)
I1101 14:41:44.826083  8672 sgd_solver.cpp:106] Iteration 32700, lr = 0.0190257
I1101 14:42:00.637281  8672 solver.cpp:228] Iteration 32800, loss = 2.79104e-005
I1101 14:42:00.637281  8672 solver.cpp:244]     Train net output #0: loss = 2.78757e-005 (* 1 = 2.78757e-005 loss)
I1101 14:42:00.637281  8672 sgd_solver.cpp:106] Iteration 32800, lr = 0.0190233
I1101 14:42:16.323693  8672 solver.cpp:228] Iteration 32900, loss = 4.7338e-005
I1101 14:42:16.323693  8672 solver.cpp:244]     Train net output #0: loss = 4.73033e-005 (* 1 = 4.73033e-005 loss)
I1101 14:42:16.323693  8672 sgd_solver.cpp:106] Iteration 32900, lr = 0.0190208
I1101 14:42:33.236904  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_33000.caffemodel
I1101 14:42:33.367997  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_33000.solverstate
I1101 14:42:33.419035  8672 solver.cpp:337] Iteration 33000, Testing net (#0)
I1101 14:42:38.559654  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:42:38.559654  8672 solver.cpp:404]     Test net output #1: loss = 0.0126646 (* 1 = 0.0126646 loss)
I1101 14:42:38.631273  8672 solver.cpp:228] Iteration 33000, loss = 4.76034e-005
I1101 14:42:38.631273  8672 solver.cpp:244]     Train net output #0: loss = 4.75687e-005 (* 1 = 4.75687e-005 loss)
I1101 14:42:38.631273  8672 sgd_solver.cpp:106] Iteration 33000, lr = 0.0190183
I1101 14:42:55.381705  8672 solver.cpp:228] Iteration 33100, loss = 5.2842e-005
I1101 14:42:55.381705  8672 solver.cpp:244]     Train net output #0: loss = 5.28073e-005 (* 1 = 5.28073e-005 loss)
I1101 14:42:55.381705  8672 sgd_solver.cpp:106] Iteration 33100, lr = 0.0190158
I1101 14:43:11.250548  8672 solver.cpp:228] Iteration 33200, loss = 7.10576e-005
I1101 14:43:11.250548  8672 solver.cpp:244]     Train net output #0: loss = 7.10229e-005 (* 1 = 7.10229e-005 loss)
I1101 14:43:11.250548  8672 sgd_solver.cpp:106] Iteration 33200, lr = 0.0190133
I1101 14:43:27.211313  8672 solver.cpp:228] Iteration 33300, loss = 6.68438e-005
I1101 14:43:27.211313  8672 solver.cpp:244]     Train net output #0: loss = 6.68091e-005 (* 1 = 6.68091e-005 loss)
I1101 14:43:27.211313  8672 sgd_solver.cpp:106] Iteration 33300, lr = 0.0190109
I1101 14:43:44.148439  8672 solver.cpp:228] Iteration 33400, loss = 2.80821e-005
I1101 14:43:44.148439  8672 solver.cpp:244]     Train net output #0: loss = 2.80474e-005 (* 1 = 2.80474e-005 loss)
I1101 14:43:44.148439  8672 sgd_solver.cpp:106] Iteration 33400, lr = 0.0190084
I1101 14:44:01.334653  8672 solver.cpp:228] Iteration 33500, loss = 4.72574e-005
I1101 14:44:01.334653  8672 solver.cpp:244]     Train net output #0: loss = 4.72227e-005 (* 1 = 4.72227e-005 loss)
I1101 14:44:01.334653  8672 sgd_solver.cpp:106] Iteration 33500, lr = 0.0190059
I1101 14:44:18.463752  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_33600.caffemodel
I1101 14:44:18.617687  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_33600.solverstate
I1101 14:44:18.696116  8672 solver.cpp:337] Iteration 33600, Testing net (#0)
I1101 14:44:23.773386  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:44:23.773386  8672 solver.cpp:404]     Test net output #1: loss = 0.0126703 (* 1 = 0.0126703 loss)
I1101 14:44:23.844259  8672 solver.cpp:228] Iteration 33600, loss = 4.7626e-005
I1101 14:44:23.844259  8672 solver.cpp:244]     Train net output #0: loss = 4.75913e-005 (* 1 = 4.75913e-005 loss)
I1101 14:44:23.844259  8672 sgd_solver.cpp:106] Iteration 33600, lr = 0.0190034
I1101 14:44:40.772248  8672 solver.cpp:228] Iteration 33700, loss = 5.28049e-005
I1101 14:44:40.772248  8672 solver.cpp:244]     Train net output #0: loss = 5.27702e-005 (* 1 = 5.27702e-005 loss)
I1101 14:44:40.772248  8672 sgd_solver.cpp:106] Iteration 33700, lr = 0.0190009
I1101 14:44:57.680151  8672 solver.cpp:228] Iteration 33800, loss = 7.08058e-005
I1101 14:44:57.680151  8672 solver.cpp:244]     Train net output #0: loss = 7.0771e-005 (* 1 = 7.0771e-005 loss)
I1101 14:44:57.680151  8672 sgd_solver.cpp:106] Iteration 33800, lr = 0.0189985
I1101 14:45:14.598244  8672 solver.cpp:228] Iteration 33900, loss = 6.66574e-005
I1101 14:45:14.598244  8672 solver.cpp:244]     Train net output #0: loss = 6.66227e-005 (* 1 = 6.66227e-005 loss)
I1101 14:45:14.598244  8672 sgd_solver.cpp:106] Iteration 33900, lr = 0.018996
I1101 14:45:31.487982  8672 solver.cpp:228] Iteration 34000, loss = 2.82717e-005
I1101 14:45:31.487982  8672 solver.cpp:244]     Train net output #0: loss = 2.82369e-005 (* 1 = 2.82369e-005 loss)
I1101 14:45:31.487982  8672 sgd_solver.cpp:106] Iteration 34000, lr = 0.0189935
I1101 14:45:48.390202  8672 solver.cpp:228] Iteration 34100, loss = 4.71732e-005
I1101 14:45:48.390202  8672 solver.cpp:244]     Train net output #0: loss = 4.71384e-005 (* 1 = 4.71384e-005 loss)
I1101 14:45:48.390202  8672 sgd_solver.cpp:106] Iteration 34100, lr = 0.018991
I1101 14:46:05.216303  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_34200.caffemodel
I1101 14:46:05.349398  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_34200.solverstate
I1101 14:46:05.401437  8672 solver.cpp:337] Iteration 34200, Testing net (#0)
I1101 14:46:10.490800  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:46:10.490800  8672 solver.cpp:404]     Test net output #1: loss = 0.0126763 (* 1 = 0.0126763 loss)
I1101 14:46:10.561898  8672 solver.cpp:228] Iteration 34200, loss = 4.7682e-005
I1101 14:46:10.561898  8672 solver.cpp:244]     Train net output #0: loss = 4.76473e-005 (* 1 = 4.76473e-005 loss)
I1101 14:46:10.561898  8672 sgd_solver.cpp:106] Iteration 34200, lr = 0.0189885
I1101 14:46:27.508725  8672 solver.cpp:228] Iteration 34300, loss = 5.27374e-005
I1101 14:46:27.508725  8672 solver.cpp:244]     Train net output #0: loss = 5.27027e-005 (* 1 = 5.27027e-005 loss)
I1101 14:46:27.508725  8672 sgd_solver.cpp:106] Iteration 34300, lr = 0.0189861
I1101 14:46:44.426153  8672 solver.cpp:228] Iteration 34400, loss = 7.05402e-005
I1101 14:46:44.426153  8672 solver.cpp:244]     Train net output #0: loss = 7.05055e-005 (* 1 = 7.05055e-005 loss)
I1101 14:46:44.426153  8672 sgd_solver.cpp:106] Iteration 34400, lr = 0.0189836
I1101 14:47:01.317904  8672 solver.cpp:228] Iteration 34500, loss = 6.6452e-005
I1101 14:47:01.317904  8672 solver.cpp:244]     Train net output #0: loss = 6.64173e-005 (* 1 = 6.64173e-005 loss)
I1101 14:47:01.317904  8672 sgd_solver.cpp:106] Iteration 34500, lr = 0.0189811
I1101 14:47:18.220062  8672 solver.cpp:228] Iteration 34600, loss = 2.84243e-005
I1101 14:47:18.220062  8672 solver.cpp:244]     Train net output #0: loss = 2.83895e-005 (* 1 = 2.83895e-005 loss)
I1101 14:47:18.220062  8672 sgd_solver.cpp:106] Iteration 34600, lr = 0.0189786
I1101 14:47:35.114475  8672 solver.cpp:228] Iteration 34700, loss = 4.70741e-005
I1101 14:47:35.114475  8672 solver.cpp:244]     Train net output #0: loss = 4.70393e-005 (* 1 = 4.70393e-005 loss)
I1101 14:47:35.114475  8672 sgd_solver.cpp:106] Iteration 34700, lr = 0.0189761
I1101 14:47:51.929921  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_34800.caffemodel
I1101 14:47:52.058014  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_34800.solverstate
I1101 14:47:52.111052  8672 solver.cpp:337] Iteration 34800, Testing net (#0)
I1101 14:47:57.194387  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:47:57.194387  8672 solver.cpp:404]     Test net output #1: loss = 0.0126811 (* 1 = 0.0126811 loss)
I1101 14:47:57.265950  8672 solver.cpp:228] Iteration 34800, loss = 4.76891e-005
I1101 14:47:57.265950  8672 solver.cpp:244]     Train net output #0: loss = 4.76544e-005 (* 1 = 4.76544e-005 loss)
I1101 14:47:57.265950  8672 sgd_solver.cpp:106] Iteration 34800, lr = 0.0189737
I1101 14:48:14.144495  8672 solver.cpp:228] Iteration 34900, loss = 5.268e-005
I1101 14:48:14.144495  8672 solver.cpp:244]     Train net output #0: loss = 5.26453e-005 (* 1 = 5.26453e-005 loss)
I1101 14:48:14.144495  8672 sgd_solver.cpp:106] Iteration 34900, lr = 0.0189712
I1101 14:48:31.022428  8672 solver.cpp:228] Iteration 35000, loss = 7.02603e-005
I1101 14:48:31.022428  8672 solver.cpp:244]     Train net output #0: loss = 7.02255e-005 (* 1 = 7.02255e-005 loss)
I1101 14:48:31.022428  8672 sgd_solver.cpp:106] Iteration 35000, lr = 0.0189687
I1101 14:48:48.214925  8672 solver.cpp:228] Iteration 35100, loss = 6.6191e-005
I1101 14:48:48.214925  8672 solver.cpp:244]     Train net output #0: loss = 6.61563e-005 (* 1 = 6.61563e-005 loss)
I1101 14:48:48.214925  8672 sgd_solver.cpp:106] Iteration 35100, lr = 0.0189662
I1101 14:49:05.323457  8672 solver.cpp:228] Iteration 35200, loss = 2.85971e-005
I1101 14:49:05.324457  8672 solver.cpp:244]     Train net output #0: loss = 2.85624e-005 (* 1 = 2.85624e-005 loss)
I1101 14:49:05.324457  8672 sgd_solver.cpp:106] Iteration 35200, lr = 0.0189638
I1101 14:49:22.835186  8672 solver.cpp:228] Iteration 35300, loss = 4.69934e-005
I1101 14:49:22.835186  8672 solver.cpp:244]     Train net output #0: loss = 4.69587e-005 (* 1 = 4.69587e-005 loss)
I1101 14:49:22.835186  8672 sgd_solver.cpp:106] Iteration 35300, lr = 0.0189613
I1101 14:49:39.490025  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_35400.caffemodel
I1101 14:49:39.612113  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_35400.solverstate
I1101 14:49:39.661147  8672 solver.cpp:337] Iteration 35400, Testing net (#0)
I1101 14:49:44.597208  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:49:44.597208  8672 solver.cpp:404]     Test net output #1: loss = 0.0126869 (* 1 = 0.0126869 loss)
I1101 14:49:44.665256  8672 solver.cpp:228] Iteration 35400, loss = 4.77326e-005
I1101 14:49:44.665256  8672 solver.cpp:244]     Train net output #0: loss = 4.76979e-005 (* 1 = 4.76979e-005 loss)
I1101 14:49:44.665256  8672 sgd_solver.cpp:106] Iteration 35400, lr = 0.0189588
I1101 14:50:01.116967  8672 solver.cpp:228] Iteration 35500, loss = 5.26394e-005
I1101 14:50:01.116967  8672 solver.cpp:244]     Train net output #0: loss = 5.26046e-005 (* 1 = 5.26046e-005 loss)
I1101 14:50:01.116967  8672 sgd_solver.cpp:106] Iteration 35500, lr = 0.0189563
I1101 14:50:17.800920  8672 solver.cpp:228] Iteration 35600, loss = 7.00215e-005
I1101 14:50:17.800920  8672 solver.cpp:244]     Train net output #0: loss = 6.99868e-005 (* 1 = 6.99868e-005 loss)
I1101 14:50:17.800920  8672 sgd_solver.cpp:106] Iteration 35600, lr = 0.0189538
I1101 14:50:34.465097  8672 solver.cpp:228] Iteration 35700, loss = 6.60661e-005
I1101 14:50:34.465097  8672 solver.cpp:244]     Train net output #0: loss = 6.60314e-005 (* 1 = 6.60314e-005 loss)
I1101 14:50:34.465097  8672 sgd_solver.cpp:106] Iteration 35700, lr = 0.0189514
I1101 14:50:50.916836  8672 solver.cpp:228] Iteration 35800, loss = 2.87569e-005
I1101 14:50:50.916836  8672 solver.cpp:244]     Train net output #0: loss = 2.87221e-005 (* 1 = 2.87221e-005 loss)
I1101 14:50:50.916836  8672 sgd_solver.cpp:106] Iteration 35800, lr = 0.0189489
I1101 14:51:07.328567  8672 solver.cpp:228] Iteration 35900, loss = 4.68764e-005
I1101 14:51:07.328567  8672 solver.cpp:244]     Train net output #0: loss = 4.68417e-005 (* 1 = 4.68417e-005 loss)
I1101 14:51:07.328567  8672 sgd_solver.cpp:106] Iteration 35900, lr = 0.0189464
I1101 14:51:23.708288  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_36000.caffemodel
I1101 14:51:23.876909  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_36000.solverstate
I1101 14:51:23.923442  8672 solver.cpp:337] Iteration 36000, Testing net (#0)
I1101 14:51:28.884152  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:51:28.884152  8672 solver.cpp:404]     Test net output #1: loss = 0.012691 (* 1 = 0.012691 loss)
I1101 14:51:28.955354  8672 solver.cpp:228] Iteration 36000, loss = 4.77206e-005
I1101 14:51:28.955853  8672 solver.cpp:244]     Train net output #0: loss = 4.76859e-005 (* 1 = 4.76859e-005 loss)
I1101 14:51:28.955853  8672 sgd_solver.cpp:106] Iteration 36000, lr = 0.0189439
I1101 14:51:45.217828  8672 solver.cpp:228] Iteration 36100, loss = 5.26071e-005
I1101 14:51:45.217828  8672 solver.cpp:244]     Train net output #0: loss = 5.25723e-005 (* 1 = 5.25723e-005 loss)
I1101 14:51:45.217828  8672 sgd_solver.cpp:106] Iteration 36100, lr = 0.0189414
I1101 14:52:00.745750  8672 solver.cpp:228] Iteration 36200, loss = 6.97714e-005
I1101 14:52:00.745750  8672 solver.cpp:244]     Train net output #0: loss = 6.97367e-005 (* 1 = 6.97367e-005 loss)
I1101 14:52:00.745750  8672 sgd_solver.cpp:106] Iteration 36200, lr = 0.018939
I1101 14:52:16.463090  8672 solver.cpp:228] Iteration 36300, loss = 6.5881e-005
I1101 14:52:16.463090  8672 solver.cpp:244]     Train net output #0: loss = 6.58462e-005 (* 1 = 6.58462e-005 loss)
I1101 14:52:16.463090  8672 sgd_solver.cpp:106] Iteration 36300, lr = 0.0189365
I1101 14:52:32.090262  8672 solver.cpp:228] Iteration 36400, loss = 2.89214e-005
I1101 14:52:32.090262  8672 solver.cpp:244]     Train net output #0: loss = 2.88866e-005 (* 1 = 2.88866e-005 loss)
I1101 14:52:32.090262  8672 sgd_solver.cpp:106] Iteration 36400, lr = 0.018934
I1101 14:52:47.872221  8672 solver.cpp:228] Iteration 36500, loss = 4.67922e-005
I1101 14:52:47.872221  8672 solver.cpp:244]     Train net output #0: loss = 4.67575e-005 (* 1 = 4.67575e-005 loss)
I1101 14:52:47.872221  8672 sgd_solver.cpp:106] Iteration 36500, lr = 0.0189315
I1101 14:53:03.561755  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_36600.caffemodel
I1101 14:53:03.686758  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_36600.solverstate
I1101 14:53:03.764884  8672 solver.cpp:337] Iteration 36600, Testing net (#0)
I1101 14:53:08.520069  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:53:08.520069  8672 solver.cpp:404]     Test net output #1: loss = 0.0126964 (* 1 = 0.0126964 loss)
I1101 14:53:08.587183  8672 solver.cpp:228] Iteration 36600, loss = 4.77354e-005
I1101 14:53:08.587183  8672 solver.cpp:244]     Train net output #0: loss = 4.77007e-005 (* 1 = 4.77007e-005 loss)
I1101 14:53:08.587183  8672 sgd_solver.cpp:106] Iteration 36600, lr = 0.018929
I1101 14:53:24.217629  8672 solver.cpp:228] Iteration 36700, loss = 5.25509e-005
I1101 14:53:24.217629  8672 solver.cpp:244]     Train net output #0: loss = 5.25162e-005 (* 1 = 5.25162e-005 loss)
I1101 14:53:24.217629  8672 sgd_solver.cpp:106] Iteration 36700, lr = 0.0189266
I1101 14:53:39.896884  8672 solver.cpp:228] Iteration 36800, loss = 6.95524e-005
I1101 14:53:39.896884  8672 solver.cpp:244]     Train net output #0: loss = 6.95176e-005 (* 1 = 6.95176e-005 loss)
I1101 14:53:39.896884  8672 sgd_solver.cpp:106] Iteration 36800, lr = 0.0189241
I1101 14:53:55.409951  8672 solver.cpp:228] Iteration 36900, loss = 6.56308e-005
I1101 14:53:55.409951  8672 solver.cpp:244]     Train net output #0: loss = 6.5596e-005 (* 1 = 6.5596e-005 loss)
I1101 14:53:55.409951  8672 sgd_solver.cpp:106] Iteration 36900, lr = 0.0189216
I1101 14:54:10.925897  8672 solver.cpp:228] Iteration 37000, loss = 2.90609e-005
I1101 14:54:10.925897  8672 solver.cpp:244]     Train net output #0: loss = 2.90261e-005 (* 1 = 2.90261e-005 loss)
I1101 14:54:10.925897  8672 sgd_solver.cpp:106] Iteration 37000, lr = 0.0189191
I1101 14:54:26.632383  8672 solver.cpp:228] Iteration 37100, loss = 4.66681e-005
I1101 14:54:26.632383  8672 solver.cpp:244]     Train net output #0: loss = 4.66333e-005 (* 1 = 4.66333e-005 loss)
I1101 14:54:26.632383  8672 sgd_solver.cpp:106] Iteration 37100, lr = 0.0189166
I1101 14:54:42.294445  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_37200.caffemodel
I1101 14:54:42.412029  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_37200.solverstate
I1101 14:54:42.463565  8672 solver.cpp:337] Iteration 37200, Testing net (#0)
I1101 14:54:47.395036  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:54:47.395036  8672 solver.cpp:404]     Test net output #1: loss = 0.0127016 (* 1 = 0.0127016 loss)
I1101 14:54:47.460583  8672 solver.cpp:228] Iteration 37200, loss = 4.77407e-005
I1101 14:54:47.460583  8672 solver.cpp:244]     Train net output #0: loss = 4.7706e-005 (* 1 = 4.7706e-005 loss)
I1101 14:54:47.460583  8672 sgd_solver.cpp:106] Iteration 37200, lr = 0.0189142
I1101 14:55:03.261975  8672 solver.cpp:228] Iteration 37300, loss = 5.24918e-005
I1101 14:55:03.261975  8672 solver.cpp:244]     Train net output #0: loss = 5.2457e-005 (* 1 = 5.2457e-005 loss)
I1101 14:55:03.261975  8672 sgd_solver.cpp:106] Iteration 37300, lr = 0.0189117
I1101 14:55:19.002720  8672 solver.cpp:228] Iteration 37400, loss = 6.93113e-005
I1101 14:55:19.002720  8672 solver.cpp:244]     Train net output #0: loss = 6.92765e-005 (* 1 = 6.92765e-005 loss)
I1101 14:55:19.002720  8672 sgd_solver.cpp:106] Iteration 37400, lr = 0.0189092
I1101 14:55:34.726097  8672 solver.cpp:228] Iteration 37500, loss = 6.54832e-005
I1101 14:55:34.726097  8672 solver.cpp:244]     Train net output #0: loss = 6.54485e-005 (* 1 = 6.54485e-005 loss)
I1101 14:55:34.726097  8672 sgd_solver.cpp:106] Iteration 37500, lr = 0.0189067
I1101 14:55:50.570808  8672 solver.cpp:228] Iteration 37600, loss = 2.92236e-005
I1101 14:55:50.570808  8672 solver.cpp:244]     Train net output #0: loss = 2.91889e-005 (* 1 = 2.91889e-005 loss)
I1101 14:55:50.570808  8672 sgd_solver.cpp:106] Iteration 37600, lr = 0.0189042
I1101 14:56:06.361594  8672 solver.cpp:228] Iteration 37700, loss = 4.66167e-005
I1101 14:56:06.361594  8672 solver.cpp:244]     Train net output #0: loss = 4.6582e-005 (* 1 = 4.6582e-005 loss)
I1101 14:56:06.361594  8672 sgd_solver.cpp:106] Iteration 37700, lr = 0.0189018
I1101 14:56:22.088057  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_37800.caffemodel
I1101 14:56:22.215800  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_37800.solverstate
I1101 14:56:22.262676  8672 solver.cpp:337] Iteration 37800, Testing net (#0)
I1101 14:56:27.055549  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:56:27.055549  8672 solver.cpp:404]     Test net output #1: loss = 0.0127055 (* 1 = 0.0127055 loss)
I1101 14:56:27.149291  8672 solver.cpp:228] Iteration 37800, loss = 4.77377e-005
I1101 14:56:27.149291  8672 solver.cpp:244]     Train net output #0: loss = 4.7703e-005 (* 1 = 4.7703e-005 loss)
I1101 14:56:27.149291  8672 sgd_solver.cpp:106] Iteration 37800, lr = 0.0188993
I1101 14:56:42.976402  8672 solver.cpp:228] Iteration 37900, loss = 5.24362e-005
I1101 14:56:42.976402  8672 solver.cpp:244]     Train net output #0: loss = 5.24015e-005 (* 1 = 5.24015e-005 loss)
I1101 14:56:42.976402  8672 sgd_solver.cpp:106] Iteration 37900, lr = 0.0188968
I1101 14:56:58.770169  8672 solver.cpp:228] Iteration 38000, loss = 6.91429e-005
I1101 14:56:58.770169  8672 solver.cpp:244]     Train net output #0: loss = 6.91082e-005 (* 1 = 6.91082e-005 loss)
I1101 14:56:58.770169  8672 sgd_solver.cpp:106] Iteration 38000, lr = 0.0188943
I1101 14:57:14.629384  8672 solver.cpp:228] Iteration 38100, loss = 6.52432e-005
I1101 14:57:14.629384  8672 solver.cpp:244]     Train net output #0: loss = 6.52084e-005 (* 1 = 6.52084e-005 loss)
I1101 14:57:14.629384  8672 sgd_solver.cpp:106] Iteration 38100, lr = 0.0188918
I1101 14:57:30.323146  8672 solver.cpp:228] Iteration 38200, loss = 2.93774e-005
I1101 14:57:30.323146  8672 solver.cpp:244]     Train net output #0: loss = 2.93426e-005 (* 1 = 2.93426e-005 loss)
I1101 14:57:30.323146  8672 sgd_solver.cpp:106] Iteration 38200, lr = 0.0188894
I1101 14:57:46.003123  8672 solver.cpp:228] Iteration 38300, loss = 4.6557e-005
I1101 14:57:46.003123  8672 solver.cpp:244]     Train net output #0: loss = 4.65222e-005 (* 1 = 4.65222e-005 loss)
I1101 14:57:46.003123  8672 sgd_solver.cpp:106] Iteration 38300, lr = 0.0188869
I1101 14:58:01.675536  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_38400.caffemodel
I1101 14:58:01.800552  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_38400.solverstate
I1101 14:58:01.840324  8672 solver.cpp:337] Iteration 38400, Testing net (#0)
I1101 14:58:06.566246  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:58:06.566246  8672 solver.cpp:404]     Test net output #1: loss = 0.0127109 (* 1 = 0.0127109 loss)
I1101 14:58:06.634546  8672 solver.cpp:228] Iteration 38400, loss = 4.77204e-005
I1101 14:58:06.634546  8672 solver.cpp:244]     Train net output #0: loss = 4.76856e-005 (* 1 = 4.76856e-005 loss)
I1101 14:58:06.634546  8672 sgd_solver.cpp:106] Iteration 38400, lr = 0.0188844
I1101 14:58:22.270903  8672 solver.cpp:228] Iteration 38500, loss = 5.23562e-005
I1101 14:58:22.270903  8672 solver.cpp:244]     Train net output #0: loss = 5.23214e-005 (* 1 = 5.23214e-005 loss)
I1101 14:58:22.270903  8672 sgd_solver.cpp:106] Iteration 38500, lr = 0.0188819
I1101 14:58:38.045030  8672 solver.cpp:228] Iteration 38600, loss = 6.89328e-005
I1101 14:58:38.045030  8672 solver.cpp:244]     Train net output #0: loss = 6.88981e-005 (* 1 = 6.88981e-005 loss)
I1101 14:58:38.045030  8672 sgd_solver.cpp:106] Iteration 38600, lr = 0.0188794
I1101 14:58:53.575160  8672 solver.cpp:228] Iteration 38700, loss = 6.50658e-005
I1101 14:58:53.575160  8672 solver.cpp:244]     Train net output #0: loss = 6.50311e-005 (* 1 = 6.50311e-005 loss)
I1101 14:58:53.575160  8672 sgd_solver.cpp:106] Iteration 38700, lr = 0.018877
I1101 14:59:09.216121  8672 solver.cpp:228] Iteration 38800, loss = 2.95181e-005
I1101 14:59:09.216121  8672 solver.cpp:244]     Train net output #0: loss = 2.94833e-005 (* 1 = 2.94833e-005 loss)
I1101 14:59:09.216121  8672 sgd_solver.cpp:106] Iteration 38800, lr = 0.0188745
I1101 14:59:24.939386  8672 solver.cpp:228] Iteration 38900, loss = 4.6443e-005
I1101 14:59:24.939386  8672 solver.cpp:244]     Train net output #0: loss = 4.64083e-005 (* 1 = 4.64083e-005 loss)
I1101 14:59:24.939386  8672 sgd_solver.cpp:106] Iteration 38900, lr = 0.018872
I1101 14:59:40.601469  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_39000.caffemodel
I1101 14:59:40.726501  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_39000.solverstate
I1101 14:59:40.789002  8672 solver.cpp:337] Iteration 39000, Testing net (#0)
I1101 14:59:45.484622  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 14:59:45.484622  8672 solver.cpp:404]     Test net output #1: loss = 0.0127161 (* 1 = 0.0127161 loss)
I1101 14:59:45.551705  8672 solver.cpp:228] Iteration 39000, loss = 4.77179e-005
I1101 14:59:45.551705  8672 solver.cpp:244]     Train net output #0: loss = 4.76832e-005 (* 1 = 4.76832e-005 loss)
I1101 14:59:45.551705  8672 sgd_solver.cpp:106] Iteration 39000, lr = 0.0188695
I1101 15:00:01.097879  8672 solver.cpp:228] Iteration 39100, loss = 5.23573e-005
I1101 15:00:01.097879  8672 solver.cpp:244]     Train net output #0: loss = 5.23226e-005 (* 1 = 5.23226e-005 loss)
I1101 15:00:01.097879  8672 sgd_solver.cpp:106] Iteration 39100, lr = 0.018867
I1101 15:00:16.827932  8672 solver.cpp:228] Iteration 39200, loss = 6.87925e-005
I1101 15:00:16.827932  8672 solver.cpp:244]     Train net output #0: loss = 6.87578e-005 (* 1 = 6.87578e-005 loss)
I1101 15:00:16.827932  8672 sgd_solver.cpp:106] Iteration 39200, lr = 0.0188646
I1101 15:00:32.611532  8672 solver.cpp:228] Iteration 39300, loss = 6.48681e-005
I1101 15:00:32.611532  8672 solver.cpp:244]     Train net output #0: loss = 6.48334e-005 (* 1 = 6.48334e-005 loss)
I1101 15:00:32.611532  8672 sgd_solver.cpp:106] Iteration 39300, lr = 0.0188621
I1101 15:00:48.365710  8672 solver.cpp:228] Iteration 39400, loss = 2.96611e-005
I1101 15:00:48.365710  8672 solver.cpp:244]     Train net output #0: loss = 2.96264e-005 (* 1 = 2.96264e-005 loss)
I1101 15:00:48.365710  8672 sgd_solver.cpp:106] Iteration 39400, lr = 0.0188596
I1101 15:01:04.126478  8672 solver.cpp:228] Iteration 39500, loss = 4.63785e-005
I1101 15:01:04.126478  8672 solver.cpp:244]     Train net output #0: loss = 4.63438e-005 (* 1 = 4.63438e-005 loss)
I1101 15:01:04.126478  8672 sgd_solver.cpp:106] Iteration 39500, lr = 0.0188571
I1101 15:01:19.757469  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_39600.caffemodel
I1101 15:01:19.891564  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_39600.solverstate
I1101 15:01:19.951607  8672 solver.cpp:337] Iteration 39600, Testing net (#0)
I1101 15:01:24.746322  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:01:24.746322  8672 solver.cpp:404]     Test net output #1: loss = 0.0127203 (* 1 = 0.0127203 loss)
I1101 15:01:24.813356  8672 solver.cpp:228] Iteration 39600, loss = 4.76916e-005
I1101 15:01:24.813356  8672 solver.cpp:244]     Train net output #0: loss = 4.76568e-005 (* 1 = 4.76568e-005 loss)
I1101 15:01:24.813356  8672 sgd_solver.cpp:106] Iteration 39600, lr = 0.0188546
I1101 15:01:40.603273  8672 solver.cpp:228] Iteration 39700, loss = 5.2257e-005
I1101 15:01:40.603273  8672 solver.cpp:244]     Train net output #0: loss = 5.22222e-005 (* 1 = 5.22222e-005 loss)
I1101 15:01:40.603273  8672 sgd_solver.cpp:106] Iteration 39700, lr = 0.0188522
I1101 15:01:56.476732  8672 solver.cpp:228] Iteration 39800, loss = 6.86045e-005
I1101 15:01:56.476732  8672 solver.cpp:244]     Train net output #0: loss = 6.85698e-005 (* 1 = 6.85698e-005 loss)
I1101 15:01:56.476732  8672 sgd_solver.cpp:106] Iteration 39800, lr = 0.0188497
I1101 15:02:12.139863  8672 solver.cpp:228] Iteration 39900, loss = 6.46931e-005
I1101 15:02:12.139863  8672 solver.cpp:244]     Train net output #0: loss = 6.46584e-005 (* 1 = 6.46584e-005 loss)
I1101 15:02:12.139863  8672 sgd_solver.cpp:106] Iteration 39900, lr = 0.0188472
I1101 15:02:27.756041  8672 solver.cpp:228] Iteration 40000, loss = 2.97911e-005
I1101 15:02:27.756041  8672 solver.cpp:244]     Train net output #0: loss = 2.97563e-005 (* 1 = 2.97563e-005 loss)
I1101 15:02:27.756041  8672 sgd_solver.cpp:106] Iteration 40000, lr = 0.0188447
I1101 15:02:43.406796  8672 solver.cpp:228] Iteration 40100, loss = 4.63009e-005
I1101 15:02:43.406796  8672 solver.cpp:244]     Train net output #0: loss = 4.62661e-005 (* 1 = 4.62661e-005 loss)
I1101 15:02:43.406796  8672 sgd_solver.cpp:106] Iteration 40100, lr = 0.0188423
I1101 15:02:59.034410  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_40200.caffemodel
I1101 15:02:59.143100  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_40200.solverstate
I1101 15:02:59.221225  8672 solver.cpp:337] Iteration 40200, Testing net (#0)
I1101 15:03:03.924815  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:03:03.924815  8672 solver.cpp:404]     Test net output #1: loss = 0.0127251 (* 1 = 0.0127251 loss)
I1101 15:03:04.002977  8672 solver.cpp:228] Iteration 40200, loss = 4.76581e-005
I1101 15:03:04.002977  8672 solver.cpp:244]     Train net output #0: loss = 4.76234e-005 (* 1 = 4.76234e-005 loss)
I1101 15:03:04.002977  8672 sgd_solver.cpp:106] Iteration 40200, lr = 0.0188398
I1101 15:03:19.491636  8672 solver.cpp:228] Iteration 40300, loss = 5.222e-005
I1101 15:03:19.491636  8672 solver.cpp:244]     Train net output #0: loss = 5.21852e-005 (* 1 = 5.21852e-005 loss)
I1101 15:03:19.491636  8672 sgd_solver.cpp:106] Iteration 40300, lr = 0.0188373
I1101 15:03:34.998648  8672 solver.cpp:228] Iteration 40400, loss = 6.84768e-005
I1101 15:03:34.998648  8672 solver.cpp:244]     Train net output #0: loss = 6.8442e-005 (* 1 = 6.8442e-005 loss)
I1101 15:03:34.998648  8672 sgd_solver.cpp:106] Iteration 40400, lr = 0.0188348
I1101 15:03:50.801843  8672 solver.cpp:228] Iteration 40500, loss = 6.45038e-005
I1101 15:03:50.801843  8672 solver.cpp:244]     Train net output #0: loss = 6.44691e-005 (* 1 = 6.44691e-005 loss)
I1101 15:03:50.801843  8672 sgd_solver.cpp:106] Iteration 40500, lr = 0.0188323
I1101 15:04:06.454434  8672 solver.cpp:228] Iteration 40600, loss = 2.99329e-005
I1101 15:04:06.454434  8672 solver.cpp:244]     Train net output #0: loss = 2.98982e-005 (* 1 = 2.98982e-005 loss)
I1101 15:04:06.454434  8672 sgd_solver.cpp:106] Iteration 40600, lr = 0.0188299
I1101 15:04:22.123029  8672 solver.cpp:228] Iteration 40700, loss = 4.62262e-005
I1101 15:04:22.123029  8672 solver.cpp:244]     Train net output #0: loss = 4.61915e-005 (* 1 = 4.61915e-005 loss)
I1101 15:04:22.123029  8672 sgd_solver.cpp:106] Iteration 40700, lr = 0.0188274
I1101 15:04:37.839082  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_40800.caffemodel
I1101 15:04:37.964100  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_40800.solverstate
I1101 15:04:38.010960  8672 solver.cpp:337] Iteration 40800, Testing net (#0)
I1101 15:04:42.706027  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:04:42.706027  8672 solver.cpp:404]     Test net output #1: loss = 0.0127301 (* 1 = 0.0127301 loss)
I1101 15:04:42.784159  8672 solver.cpp:228] Iteration 40800, loss = 4.76438e-005
I1101 15:04:42.784159  8672 solver.cpp:244]     Train net output #0: loss = 4.7609e-005 (* 1 = 4.7609e-005 loss)
I1101 15:04:42.784159  8672 sgd_solver.cpp:106] Iteration 40800, lr = 0.0188249
I1101 15:04:58.412691  8672 solver.cpp:228] Iteration 40900, loss = 5.22073e-005
I1101 15:04:58.412691  8672 solver.cpp:244]     Train net output #0: loss = 5.21726e-005 (* 1 = 5.21726e-005 loss)
I1101 15:04:58.412691  8672 sgd_solver.cpp:106] Iteration 40900, lr = 0.0188224
I1101 15:05:14.279428  8672 solver.cpp:228] Iteration 41000, loss = 6.82625e-005
I1101 15:05:14.279428  8672 solver.cpp:244]     Train net output #0: loss = 6.82278e-005 (* 1 = 6.82278e-005 loss)
I1101 15:05:14.279428  8672 sgd_solver.cpp:106] Iteration 41000, lr = 0.0188199
I1101 15:05:29.957375  8672 solver.cpp:228] Iteration 41100, loss = 6.43628e-005
I1101 15:05:29.957375  8672 solver.cpp:244]     Train net output #0: loss = 6.43281e-005 (* 1 = 6.43281e-005 loss)
I1101 15:05:29.957375  8672 sgd_solver.cpp:106] Iteration 41100, lr = 0.0188175
I1101 15:05:45.733099  8672 solver.cpp:228] Iteration 41200, loss = 3.00587e-005
I1101 15:05:45.733099  8672 solver.cpp:244]     Train net output #0: loss = 3.00239e-005 (* 1 = 3.00239e-005 loss)
I1101 15:05:45.733099  8672 sgd_solver.cpp:106] Iteration 41200, lr = 0.018815
I1101 15:06:01.638396  8672 solver.cpp:228] Iteration 41300, loss = 4.61713e-005
I1101 15:06:01.638396  8672 solver.cpp:244]     Train net output #0: loss = 4.61366e-005 (* 1 = 4.61366e-005 loss)
I1101 15:06:01.638396  8672 sgd_solver.cpp:106] Iteration 41300, lr = 0.0188125
I1101 15:06:17.305572  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_41400.caffemodel
I1101 15:06:17.455507  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_41400.solverstate
I1101 15:06:17.513550  8672 solver.cpp:337] Iteration 41400, Testing net (#0)
I1101 15:06:22.383836  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:06:22.383836  8672 solver.cpp:404]     Test net output #1: loss = 0.0127344 (* 1 = 0.0127344 loss)
I1101 15:06:22.451797  8672 solver.cpp:228] Iteration 41400, loss = 4.76336e-005
I1101 15:06:22.451797  8672 solver.cpp:244]     Train net output #0: loss = 4.75988e-005 (* 1 = 4.75988e-005 loss)
I1101 15:06:22.451797  8672 sgd_solver.cpp:106] Iteration 41400, lr = 0.01881
I1101 15:06:38.491487  8672 solver.cpp:228] Iteration 41500, loss = 5.21751e-005
I1101 15:06:38.491487  8672 solver.cpp:244]     Train net output #0: loss = 5.21403e-005 (* 1 = 5.21403e-005 loss)
I1101 15:06:38.491487  8672 sgd_solver.cpp:106] Iteration 41500, lr = 0.0188075
I1101 15:06:54.311450  8672 solver.cpp:228] Iteration 41600, loss = 6.80859e-005
I1101 15:06:54.311450  8672 solver.cpp:244]     Train net output #0: loss = 6.80511e-005 (* 1 = 6.80511e-005 loss)
I1101 15:06:54.311450  8672 sgd_solver.cpp:106] Iteration 41600, lr = 0.0188051
I1101 15:07:10.669886  8672 solver.cpp:228] Iteration 41700, loss = 6.41992e-005
I1101 15:07:10.669886  8672 solver.cpp:244]     Train net output #0: loss = 6.41644e-005 (* 1 = 6.41644e-005 loss)
I1101 15:07:10.669886  8672 sgd_solver.cpp:106] Iteration 41700, lr = 0.0188026
I1101 15:07:26.688053  8672 solver.cpp:228] Iteration 41800, loss = 3.01994e-005
I1101 15:07:26.688053  8672 solver.cpp:244]     Train net output #0: loss = 3.01646e-005 (* 1 = 3.01646e-005 loss)
I1101 15:07:26.688053  8672 sgd_solver.cpp:106] Iteration 41800, lr = 0.0188001
I1101 15:07:42.602808  8672 solver.cpp:228] Iteration 41900, loss = 4.61217e-005
I1101 15:07:42.602808  8672 solver.cpp:244]     Train net output #0: loss = 4.6087e-005 (* 1 = 4.6087e-005 loss)
I1101 15:07:42.603307  8672 sgd_solver.cpp:106] Iteration 41900, lr = 0.0187976
I1101 15:07:58.147917  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_42000.caffemodel
I1101 15:07:58.747154  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_42000.solverstate
I1101 15:07:58.856530  8672 solver.cpp:337] Iteration 42000, Testing net (#0)
I1101 15:08:04.040318  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:08:04.040318  8672 solver.cpp:404]     Test net output #1: loss = 0.0127402 (* 1 = 0.0127402 loss)
I1101 15:08:04.107607  8672 solver.cpp:228] Iteration 42000, loss = 4.75668e-005
I1101 15:08:04.107607  8672 solver.cpp:244]     Train net output #0: loss = 4.7532e-005 (* 1 = 4.7532e-005 loss)
I1101 15:08:04.107607  8672 sgd_solver.cpp:106] Iteration 42000, lr = 0.0187951
I1101 15:08:20.031299  8672 solver.cpp:228] Iteration 42100, loss = 5.21111e-005
I1101 15:08:20.031299  8672 solver.cpp:244]     Train net output #0: loss = 5.20764e-005 (* 1 = 5.20764e-005 loss)
I1101 15:08:20.031822  8672 sgd_solver.cpp:106] Iteration 42100, lr = 0.0187927
I1101 15:08:35.991096  8672 solver.cpp:228] Iteration 42200, loss = 6.78543e-005
I1101 15:08:35.991096  8672 solver.cpp:244]     Train net output #0: loss = 6.78196e-005 (* 1 = 6.78196e-005 loss)
I1101 15:08:35.991096  8672 sgd_solver.cpp:106] Iteration 42200, lr = 0.0187902
I1101 15:08:51.759929  8672 solver.cpp:228] Iteration 42300, loss = 6.40791e-005
I1101 15:08:51.759929  8672 solver.cpp:244]     Train net output #0: loss = 6.40444e-005 (* 1 = 6.40444e-005 loss)
I1101 15:08:51.759929  8672 sgd_solver.cpp:106] Iteration 42300, lr = 0.0187877
I1101 15:09:07.391757  8672 solver.cpp:228] Iteration 42400, loss = 3.0315e-005
I1101 15:09:07.391757  8672 solver.cpp:244]     Train net output #0: loss = 3.02802e-005 (* 1 = 3.02802e-005 loss)
I1101 15:09:07.391757  8672 sgd_solver.cpp:106] Iteration 42400, lr = 0.0187852
I1101 15:09:23.244009  8672 solver.cpp:228] Iteration 42500, loss = 4.60644e-005
I1101 15:09:23.244009  8672 solver.cpp:244]     Train net output #0: loss = 4.60297e-005 (* 1 = 4.60297e-005 loss)
I1101 15:09:23.244009  8672 sgd_solver.cpp:106] Iteration 42500, lr = 0.0187827
I1101 15:09:39.000036  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_42600.caffemodel
I1101 15:09:39.122124  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_42600.solverstate
I1101 15:09:39.184167  8672 solver.cpp:337] Iteration 42600, Testing net (#0)
I1101 15:09:43.922274  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:09:43.922274  8672 solver.cpp:404]     Test net output #1: loss = 0.0127448 (* 1 = 0.0127448 loss)
I1101 15:09:43.988323  8672 solver.cpp:228] Iteration 42600, loss = 4.75094e-005
I1101 15:09:43.988323  8672 solver.cpp:244]     Train net output #0: loss = 4.74747e-005 (* 1 = 4.74747e-005 loss)
I1101 15:09:43.988323  8672 sgd_solver.cpp:106] Iteration 42600, lr = 0.0187803
I1101 15:09:59.560844  8672 solver.cpp:228] Iteration 42700, loss = 5.21075e-005
I1101 15:09:59.560844  8672 solver.cpp:244]     Train net output #0: loss = 5.20727e-005 (* 1 = 5.20727e-005 loss)
I1101 15:09:59.560844  8672 sgd_solver.cpp:106] Iteration 42700, lr = 0.0187778
I1101 15:10:15.296712  8672 solver.cpp:228] Iteration 42800, loss = 6.76031e-005
I1101 15:10:15.296712  8672 solver.cpp:244]     Train net output #0: loss = 6.75683e-005 (* 1 = 6.75683e-005 loss)
I1101 15:10:15.296712  8672 sgd_solver.cpp:106] Iteration 42800, lr = 0.0187753
I1101 15:10:31.280416  8672 solver.cpp:228] Iteration 42900, loss = 6.38994e-005
I1101 15:10:31.280416  8672 solver.cpp:244]     Train net output #0: loss = 6.38646e-005 (* 1 = 6.38646e-005 loss)
I1101 15:10:31.280416  8672 sgd_solver.cpp:106] Iteration 42900, lr = 0.0187728
I1101 15:10:47.530623  8672 solver.cpp:228] Iteration 43000, loss = 3.04473e-005
I1101 15:10:47.530623  8672 solver.cpp:244]     Train net output #0: loss = 3.04126e-005 (* 1 = 3.04126e-005 loss)
I1101 15:10:47.530623  8672 sgd_solver.cpp:106] Iteration 43000, lr = 0.0187703
I1101 15:11:03.287734  8672 solver.cpp:228] Iteration 43100, loss = 4.60071e-005
I1101 15:11:03.287734  8672 solver.cpp:244]     Train net output #0: loss = 4.59723e-005 (* 1 = 4.59723e-005 loss)
I1101 15:11:03.287734  8672 sgd_solver.cpp:106] Iteration 43100, lr = 0.0187679
I1101 15:11:18.873694  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_43200.caffemodel
I1101 15:11:18.983059  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_43200.solverstate
I1101 15:11:19.076809  8672 solver.cpp:337] Iteration 43200, Testing net (#0)
I1101 15:11:23.830852  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:11:23.830852  8672 solver.cpp:404]     Test net output #1: loss = 0.0127505 (* 1 = 0.0127505 loss)
I1101 15:11:23.898566  8672 solver.cpp:228] Iteration 43200, loss = 4.74557e-005
I1101 15:11:23.898566  8672 solver.cpp:244]     Train net output #0: loss = 4.74209e-005 (* 1 = 4.74209e-005 loss)
I1101 15:11:23.898566  8672 sgd_solver.cpp:106] Iteration 43200, lr = 0.0187654
I1101 15:11:39.660676  8672 solver.cpp:228] Iteration 43300, loss = 5.20734e-005
I1101 15:11:39.660676  8672 solver.cpp:244]     Train net output #0: loss = 5.20386e-005 (* 1 = 5.20386e-005 loss)
I1101 15:11:39.660676  8672 sgd_solver.cpp:106] Iteration 43300, lr = 0.0187629
I1101 15:11:55.671483  8672 solver.cpp:228] Iteration 43400, loss = 6.73906e-005
I1101 15:11:55.671483  8672 solver.cpp:244]     Train net output #0: loss = 6.73559e-005 (* 1 = 6.73559e-005 loss)
I1101 15:11:55.671483  8672 sgd_solver.cpp:106] Iteration 43400, lr = 0.0187604
I1101 15:12:11.414502  8672 solver.cpp:228] Iteration 43500, loss = 6.37501e-005
I1101 15:12:11.414502  8672 solver.cpp:244]     Train net output #0: loss = 6.37153e-005 (* 1 = 6.37153e-005 loss)
I1101 15:12:11.414502  8672 sgd_solver.cpp:106] Iteration 43500, lr = 0.0187579
I1101 15:12:27.367929  8672 solver.cpp:228] Iteration 43600, loss = 3.05797e-005
I1101 15:12:27.367929  8672 solver.cpp:244]     Train net output #0: loss = 3.05449e-005 (* 1 = 3.05449e-005 loss)
I1101 15:12:27.367929  8672 sgd_solver.cpp:106] Iteration 43600, lr = 0.0187555
I1101 15:12:42.877542  8672 solver.cpp:228] Iteration 43700, loss = 4.59229e-005
I1101 15:12:42.877542  8672 solver.cpp:244]     Train net output #0: loss = 4.58882e-005 (* 1 = 4.58882e-005 loss)
I1101 15:12:42.877542  8672 sgd_solver.cpp:106] Iteration 43700, lr = 0.018753
I1101 15:12:58.501906  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_43800.caffemodel
I1101 15:12:58.624994  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_43800.solverstate
I1101 15:12:58.664253  8672 solver.cpp:337] Iteration 43800, Testing net (#0)
I1101 15:13:03.399478  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:13:03.399478  8672 solver.cpp:404]     Test net output #1: loss = 0.0127539 (* 1 = 0.0127539 loss)
I1101 15:13:03.464293  8672 solver.cpp:228] Iteration 43800, loss = 4.73805e-005
I1101 15:13:03.464293  8672 solver.cpp:244]     Train net output #0: loss = 4.73457e-005 (* 1 = 4.73457e-005 loss)
I1101 15:13:03.464293  8672 sgd_solver.cpp:106] Iteration 43800, lr = 0.0187505
I1101 15:13:19.098856  8672 solver.cpp:228] Iteration 43900, loss = 5.20154e-005
I1101 15:13:19.098856  8672 solver.cpp:244]     Train net output #0: loss = 5.19807e-005 (* 1 = 5.19807e-005 loss)
I1101 15:13:19.098856  8672 sgd_solver.cpp:106] Iteration 43900, lr = 0.018748
I1101 15:13:34.720465  8672 solver.cpp:228] Iteration 44000, loss = 6.71561e-005
I1101 15:13:34.720465  8672 solver.cpp:244]     Train net output #0: loss = 6.71213e-005 (* 1 = 6.71213e-005 loss)
I1101 15:13:34.720465  8672 sgd_solver.cpp:106] Iteration 44000, lr = 0.0187455
I1101 15:13:50.390108  8672 solver.cpp:228] Iteration 44100, loss = 6.36193e-005
I1101 15:13:50.390108  8672 solver.cpp:244]     Train net output #0: loss = 6.35845e-005 (* 1 = 6.35845e-005 loss)
I1101 15:13:50.390108  8672 sgd_solver.cpp:106] Iteration 44100, lr = 0.0187431
I1101 15:14:05.960469  8672 solver.cpp:228] Iteration 44200, loss = 3.07048e-005
I1101 15:14:05.960469  8672 solver.cpp:244]     Train net output #0: loss = 3.06701e-005 (* 1 = 3.06701e-005 loss)
I1101 15:14:05.960469  8672 sgd_solver.cpp:106] Iteration 44200, lr = 0.0187406
I1101 15:14:21.477601  8672 solver.cpp:228] Iteration 44300, loss = 4.58907e-005
I1101 15:14:21.477601  8672 solver.cpp:244]     Train net output #0: loss = 4.58559e-005 (* 1 = 4.58559e-005 loss)
I1101 15:14:21.477601  8672 sgd_solver.cpp:106] Iteration 44300, lr = 0.0187381
I1101 15:14:36.894345  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_44400.caffemodel
I1101 15:14:37.019350  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_44400.solverstate
I1101 15:14:37.081851  8672 solver.cpp:337] Iteration 44400, Testing net (#0)
I1101 15:14:41.797857  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:14:41.797857  8672 solver.cpp:404]     Test net output #1: loss = 0.0127589 (* 1 = 0.0127589 loss)
I1101 15:14:41.875985  8672 solver.cpp:228] Iteration 44400, loss = 4.73286e-005
I1101 15:14:41.875985  8672 solver.cpp:244]     Train net output #0: loss = 4.72938e-005 (* 1 = 4.72938e-005 loss)
I1101 15:14:41.875985  8672 sgd_solver.cpp:106] Iteration 44400, lr = 0.0187356
I1101 15:14:57.728175  8672 solver.cpp:228] Iteration 44500, loss = 5.197e-005
I1101 15:14:57.728175  8672 solver.cpp:244]     Train net output #0: loss = 5.19353e-005 (* 1 = 5.19353e-005 loss)
I1101 15:14:57.728175  8672 sgd_solver.cpp:106] Iteration 44500, lr = 0.0187332
I1101 15:15:13.506893  8672 solver.cpp:228] Iteration 44600, loss = 6.69252e-005
I1101 15:15:13.507393  8672 solver.cpp:244]     Train net output #0: loss = 6.68904e-005 (* 1 = 6.68904e-005 loss)
I1101 15:15:13.507393  8672 sgd_solver.cpp:106] Iteration 44600, lr = 0.0187307
I1101 15:15:29.201125  8672 solver.cpp:228] Iteration 44700, loss = 6.34724e-005
I1101 15:15:29.201625  8672 solver.cpp:244]     Train net output #0: loss = 6.34376e-005 (* 1 = 6.34376e-005 loss)
I1101 15:15:29.201625  8672 sgd_solver.cpp:106] Iteration 44700, lr = 0.0187282
I1101 15:15:44.897869  8672 solver.cpp:228] Iteration 44800, loss = 3.08336e-005
I1101 15:15:44.897869  8672 solver.cpp:244]     Train net output #0: loss = 3.07988e-005 (* 1 = 3.07988e-005 loss)
I1101 15:15:44.897869  8672 sgd_solver.cpp:106] Iteration 44800, lr = 0.0187257
I1101 15:16:00.623533  8672 solver.cpp:228] Iteration 44900, loss = 4.57844e-005
I1101 15:16:00.624034  8672 solver.cpp:244]     Train net output #0: loss = 4.57497e-005 (* 1 = 4.57497e-005 loss)
I1101 15:16:00.624034  8672 sgd_solver.cpp:106] Iteration 44900, lr = 0.0187232
I1101 15:16:16.251458  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_45000.caffemodel
I1101 15:16:16.362840  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_45000.solverstate
I1101 15:16:16.409715  8672 solver.cpp:337] Iteration 45000, Testing net (#0)
I1101 15:16:21.278178  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:16:21.278178  8672 solver.cpp:404]     Test net output #1: loss = 0.0127626 (* 1 = 0.0127626 loss)
I1101 15:16:21.343330  8672 solver.cpp:228] Iteration 45000, loss = 4.72785e-005
I1101 15:16:21.343330  8672 solver.cpp:244]     Train net output #0: loss = 4.72437e-005 (* 1 = 4.72437e-005 loss)
I1101 15:16:21.343330  8672 sgd_solver.cpp:106] Iteration 45000, lr = 0.0187208
I1101 15:16:37.184748  8672 solver.cpp:228] Iteration 45100, loss = 5.18757e-005
I1101 15:16:37.184748  8672 solver.cpp:244]     Train net output #0: loss = 5.18409e-005 (* 1 = 5.18409e-005 loss)
I1101 15:16:37.184748  8672 sgd_solver.cpp:106] Iteration 45100, lr = 0.0187183
I1101 15:16:53.017632  8672 solver.cpp:228] Iteration 45200, loss = 6.66668e-005
I1101 15:16:53.017632  8672 solver.cpp:244]     Train net output #0: loss = 6.6632e-005 (* 1 = 6.6632e-005 loss)
I1101 15:16:53.017632  8672 sgd_solver.cpp:106] Iteration 45200, lr = 0.0187158
I1101 15:17:08.596506  8672 solver.cpp:228] Iteration 45300, loss = 6.33458e-005
I1101 15:17:08.596506  8672 solver.cpp:244]     Train net output #0: loss = 6.3311e-005 (* 1 = 6.3311e-005 loss)
I1101 15:17:08.596506  8672 sgd_solver.cpp:106] Iteration 45300, lr = 0.0187133
I1101 15:17:24.282519  8672 solver.cpp:228] Iteration 45400, loss = 3.09504e-005
I1101 15:17:24.283020  8672 solver.cpp:244]     Train net output #0: loss = 3.09156e-005 (* 1 = 3.09156e-005 loss)
I1101 15:17:24.283020  8672 sgd_solver.cpp:106] Iteration 45400, lr = 0.0187108
I1101 15:17:40.330449  8672 solver.cpp:228] Iteration 45500, loss = 4.57182e-005
I1101 15:17:40.330449  8672 solver.cpp:244]     Train net output #0: loss = 4.56834e-005 (* 1 = 4.56834e-005 loss)
I1101 15:17:40.330449  8672 sgd_solver.cpp:106] Iteration 45500, lr = 0.0187084
I1101 15:17:56.413692  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_45600.caffemodel
I1101 15:17:56.540835  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_45600.solverstate
I1101 15:17:56.591372  8672 solver.cpp:337] Iteration 45600, Testing net (#0)
I1101 15:18:01.406884  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:18:01.406884  8672 solver.cpp:404]     Test net output #1: loss = 0.0127657 (* 1 = 0.0127657 loss)
I1101 15:18:01.471997  8672 solver.cpp:228] Iteration 45600, loss = 4.72283e-005
I1101 15:18:01.471997  8672 solver.cpp:244]     Train net output #0: loss = 4.71935e-005 (* 1 = 4.71935e-005 loss)
I1101 15:18:01.471997  8672 sgd_solver.cpp:106] Iteration 45600, lr = 0.0187059
I1101 15:18:17.220324  8672 solver.cpp:228] Iteration 45700, loss = 5.18524e-005
I1101 15:18:17.220324  8672 solver.cpp:244]     Train net output #0: loss = 5.18176e-005 (* 1 = 5.18176e-005 loss)
I1101 15:18:17.220324  8672 sgd_solver.cpp:106] Iteration 45700, lr = 0.0187034
I1101 15:18:33.135609  8672 solver.cpp:228] Iteration 45800, loss = 6.64556e-005
I1101 15:18:33.135609  8672 solver.cpp:244]     Train net output #0: loss = 6.64208e-005 (* 1 = 6.64208e-005 loss)
I1101 15:18:33.135609  8672 sgd_solver.cpp:106] Iteration 45800, lr = 0.0187009
I1101 15:18:49.465297  8672 solver.cpp:228] Iteration 45900, loss = 6.31875e-005
I1101 15:18:49.465297  8672 solver.cpp:244]     Train net output #0: loss = 6.31527e-005 (* 1 = 6.31527e-005 loss)
I1101 15:18:49.465297  8672 sgd_solver.cpp:106] Iteration 45900, lr = 0.0186984
I1101 15:19:05.466157  8672 solver.cpp:228] Iteration 46000, loss = 3.10553e-005
I1101 15:19:05.466157  8672 solver.cpp:244]     Train net output #0: loss = 3.10205e-005 (* 1 = 3.10205e-005 loss)
I1101 15:19:05.466157  8672 sgd_solver.cpp:106] Iteration 46000, lr = 0.018696
I1101 15:19:21.518129  8672 solver.cpp:228] Iteration 46100, loss = 4.56358e-005
I1101 15:19:21.518129  8672 solver.cpp:244]     Train net output #0: loss = 4.5601e-005 (* 1 = 4.5601e-005 loss)
I1101 15:19:21.518129  8672 sgd_solver.cpp:106] Iteration 46100, lr = 0.0186935
I1101 15:19:37.333292  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_46200.caffemodel
I1101 15:19:37.451376  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_46200.solverstate
I1101 15:19:37.499410  8672 solver.cpp:337] Iteration 46200, Testing net (#0)
I1101 15:19:42.225661  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:19:42.225661  8672 solver.cpp:404]     Test net output #1: loss = 0.0127682 (* 1 = 0.0127682 loss)
I1101 15:19:42.293701  8672 solver.cpp:228] Iteration 46200, loss = 4.71668e-005
I1101 15:19:42.293701  8672 solver.cpp:244]     Train net output #0: loss = 4.7132e-005 (* 1 = 4.7132e-005 loss)
I1101 15:19:42.294201  8672 sgd_solver.cpp:106] Iteration 46200, lr = 0.018691
I1101 15:19:58.009853  8672 solver.cpp:228] Iteration 46300, loss = 5.17675e-005
I1101 15:19:58.009853  8672 solver.cpp:244]     Train net output #0: loss = 5.17328e-005 (* 1 = 5.17328e-005 loss)
I1101 15:19:58.009853  8672 sgd_solver.cpp:106] Iteration 46300, lr = 0.0186885
I1101 15:20:13.562829  8672 solver.cpp:228] Iteration 46400, loss = 6.62348e-005
I1101 15:20:13.562829  8672 solver.cpp:244]     Train net output #0: loss = 6.62e-005 (* 1 = 6.62e-005 loss)
I1101 15:20:13.562829  8672 sgd_solver.cpp:106] Iteration 46400, lr = 0.018686
I1101 15:20:29.150708  8672 solver.cpp:228] Iteration 46500, loss = 6.30364e-005
I1101 15:20:29.150708  8672 solver.cpp:244]     Train net output #0: loss = 6.30016e-005 (* 1 = 6.30016e-005 loss)
I1101 15:20:29.150708  8672 sgd_solver.cpp:106] Iteration 46500, lr = 0.0186836
I1101 15:20:44.721352  8672 solver.cpp:228] Iteration 46600, loss = 3.11614e-005
I1101 15:20:44.721352  8672 solver.cpp:244]     Train net output #0: loss = 3.11266e-005 (* 1 = 3.11266e-005 loss)
I1101 15:20:44.721352  8672 sgd_solver.cpp:106] Iteration 46600, lr = 0.0186811
I1101 15:21:00.281796  8672 solver.cpp:228] Iteration 46700, loss = 4.55868e-005
I1101 15:21:00.281796  8672 solver.cpp:244]     Train net output #0: loss = 4.55521e-005 (* 1 = 4.55521e-005 loss)
I1101 15:21:00.281796  8672 sgd_solver.cpp:106] Iteration 46700, lr = 0.0186786
I1101 15:21:15.775781  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_46800.caffemodel
I1101 15:21:15.897423  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_46800.solverstate
I1101 15:21:15.943454  8672 solver.cpp:337] Iteration 46800, Testing net (#0)
I1101 15:21:20.626821  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:21:20.626821  8672 solver.cpp:404]     Test net output #1: loss = 0.0127717 (* 1 = 0.0127717 loss)
I1101 15:21:20.693404  8672 solver.cpp:228] Iteration 46800, loss = 4.71453e-005
I1101 15:21:20.693404  8672 solver.cpp:244]     Train net output #0: loss = 4.71105e-005 (* 1 = 4.71105e-005 loss)
I1101 15:21:20.693404  8672 sgd_solver.cpp:106] Iteration 46800, lr = 0.0186761
I1101 15:21:36.301645  8672 solver.cpp:228] Iteration 46900, loss = 5.1746e-005
I1101 15:21:36.301645  8672 solver.cpp:244]     Train net output #0: loss = 5.17112e-005 (* 1 = 5.17112e-005 loss)
I1101 15:21:36.301645  8672 sgd_solver.cpp:106] Iteration 46900, lr = 0.0186736
I1101 15:21:51.823875  8672 solver.cpp:228] Iteration 47000, loss = 6.60682e-005
I1101 15:21:51.823875  8672 solver.cpp:244]     Train net output #0: loss = 6.60335e-005 (* 1 = 6.60335e-005 loss)
I1101 15:21:51.823875  8672 sgd_solver.cpp:106] Iteration 47000, lr = 0.0186712
I1101 15:22:07.317806  8672 solver.cpp:228] Iteration 47100, loss = 6.28686e-005
I1101 15:22:07.317806  8672 solver.cpp:244]     Train net output #0: loss = 6.28338e-005 (* 1 = 6.28338e-005 loss)
I1101 15:22:07.317806  8672 sgd_solver.cpp:106] Iteration 47100, lr = 0.0186687
I1101 15:22:22.790217  8672 solver.cpp:228] Iteration 47200, loss = 3.12759e-005
I1101 15:22:22.790217  8672 solver.cpp:244]     Train net output #0: loss = 3.12411e-005 (* 1 = 3.12411e-005 loss)
I1101 15:22:22.790217  8672 sgd_solver.cpp:106] Iteration 47200, lr = 0.0186662
I1101 15:22:38.280766  8672 solver.cpp:228] Iteration 47300, loss = 4.55158e-005
I1101 15:22:38.280766  8672 solver.cpp:244]     Train net output #0: loss = 4.5481e-005 (* 1 = 4.5481e-005 loss)
I1101 15:22:38.280766  8672 sgd_solver.cpp:106] Iteration 47300, lr = 0.0186637
I1101 15:22:53.670970  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_47400.caffemodel
I1101 15:22:53.782610  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_47400.solverstate
I1101 15:22:53.829499  8672 solver.cpp:337] Iteration 47400, Testing net (#0)
I1101 15:22:58.521913  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:22:58.521913  8672 solver.cpp:404]     Test net output #1: loss = 0.0127757 (* 1 = 0.0127757 loss)
I1101 15:22:58.600039  8672 solver.cpp:228] Iteration 47400, loss = 4.70993e-005
I1101 15:22:58.600039  8672 solver.cpp:244]     Train net output #0: loss = 4.70646e-005 (* 1 = 4.70646e-005 loss)
I1101 15:22:58.600039  8672 sgd_solver.cpp:106] Iteration 47400, lr = 0.0186612
I1101 15:23:14.155537  8672 solver.cpp:228] Iteration 47500, loss = 5.16606e-005
I1101 15:23:14.155537  8672 solver.cpp:244]     Train net output #0: loss = 5.16258e-005 (* 1 = 5.16258e-005 loss)
I1101 15:23:14.155537  8672 sgd_solver.cpp:106] Iteration 47500, lr = 0.0186588
I1101 15:23:30.315511  8672 solver.cpp:228] Iteration 47600, loss = 6.5835e-005
I1101 15:23:30.315511  8672 solver.cpp:244]     Train net output #0: loss = 6.58002e-005 (* 1 = 6.58002e-005 loss)
I1101 15:23:30.315511  8672 sgd_solver.cpp:106] Iteration 47600, lr = 0.0186563
I1101 15:23:46.215723  8672 solver.cpp:228] Iteration 47700, loss = 6.26841e-005
I1101 15:23:46.215723  8672 solver.cpp:244]     Train net output #0: loss = 6.26493e-005 (* 1 = 6.26493e-005 loss)
I1101 15:23:46.215723  8672 sgd_solver.cpp:106] Iteration 47700, lr = 0.0186538
I1101 15:24:02.149286  8672 solver.cpp:228] Iteration 47800, loss = 3.13748e-005
I1101 15:24:02.149286  8672 solver.cpp:244]     Train net output #0: loss = 3.134e-005 (* 1 = 3.134e-005 loss)
I1101 15:24:02.149286  8672 sgd_solver.cpp:106] Iteration 47800, lr = 0.0186513
I1101 15:24:17.829901  8672 solver.cpp:228] Iteration 47900, loss = 4.54621e-005
I1101 15:24:17.829901  8672 solver.cpp:244]     Train net output #0: loss = 4.54273e-005 (* 1 = 4.54273e-005 loss)
I1101 15:24:17.829901  8672 sgd_solver.cpp:106] Iteration 47900, lr = 0.0186488
I1101 15:24:33.238212  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_48000.caffemodel
I1101 15:24:33.355764  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_48000.solverstate
I1101 15:24:33.499840  8672 solver.cpp:337] Iteration 48000, Testing net (#0)
I1101 15:24:38.220937  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:24:38.220937  8672 solver.cpp:404]     Test net output #1: loss = 0.0127801 (* 1 = 0.0127801 loss)
I1101 15:24:38.287004  8672 solver.cpp:228] Iteration 48000, loss = 4.70683e-005
I1101 15:24:38.287004  8672 solver.cpp:244]     Train net output #0: loss = 4.70335e-005 (* 1 = 4.70335e-005 loss)
I1101 15:24:38.287004  8672 sgd_solver.cpp:106] Iteration 48000, lr = 0.0186464
I1101 15:24:53.834444  8672 solver.cpp:228] Iteration 48100, loss = 5.16009e-005
I1101 15:24:53.834444  8672 solver.cpp:244]     Train net output #0: loss = 5.15661e-005 (* 1 = 5.15661e-005 loss)
I1101 15:24:53.834444  8672 sgd_solver.cpp:106] Iteration 48100, lr = 0.0186439
I1101 15:25:09.322933  8672 solver.cpp:228] Iteration 48200, loss = 6.56303e-005
I1101 15:25:09.322933  8672 solver.cpp:244]     Train net output #0: loss = 6.55955e-005 (* 1 = 6.55955e-005 loss)
I1101 15:25:09.322933  8672 sgd_solver.cpp:106] Iteration 48200, lr = 0.0186414
I1101 15:25:25.257098  8672 solver.cpp:228] Iteration 48300, loss = 6.24924e-005
I1101 15:25:25.257098  8672 solver.cpp:244]     Train net output #0: loss = 6.24576e-005 (* 1 = 6.24576e-005 loss)
I1101 15:25:25.257098  8672 sgd_solver.cpp:106] Iteration 48300, lr = 0.0186389
I1101 15:25:41.257226  8672 solver.cpp:228] Iteration 48400, loss = 3.14928e-005
I1101 15:25:41.257226  8672 solver.cpp:244]     Train net output #0: loss = 3.1458e-005 (* 1 = 3.1458e-005 loss)
I1101 15:25:41.257226  8672 sgd_solver.cpp:106] Iteration 48400, lr = 0.0186364
I1101 15:25:57.156770  8672 solver.cpp:228] Iteration 48500, loss = 4.54239e-005
I1101 15:25:57.156770  8672 solver.cpp:244]     Train net output #0: loss = 4.5389e-005 (* 1 = 4.5389e-005 loss)
I1101 15:25:57.156770  8672 sgd_solver.cpp:106] Iteration 48500, lr = 0.018634
I1101 15:26:13.036056  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_48600.caffemodel
I1101 15:26:13.200176  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_48600.solverstate
I1101 15:26:13.258215  8672 solver.cpp:337] Iteration 48600, Testing net (#0)
I1101 15:26:18.037576  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9974
I1101 15:26:18.037576  8672 solver.cpp:404]     Test net output #1: loss = 0.0127823 (* 1 = 0.0127823 loss)
I1101 15:26:18.104514  8672 solver.cpp:228] Iteration 48600, loss = 4.70271e-005
I1101 15:26:18.104514  8672 solver.cpp:244]     Train net output #0: loss = 4.69923e-005 (* 1 = 4.69923e-005 loss)
I1101 15:26:18.104514  8672 sgd_solver.cpp:106] Iteration 48600, lr = 0.0186315
I1101 15:26:33.882921  8672 solver.cpp:228] Iteration 48700, loss = 5.15226e-005
I1101 15:26:33.882921  8672 solver.cpp:244]     Train net output #0: loss = 5.14878e-005 (* 1 = 5.14878e-005 loss)
I1101 15:26:33.882921  8672 sgd_solver.cpp:106] Iteration 48700, lr = 0.018629
I1101 15:26:49.693112  8672 solver.cpp:228] Iteration 48800, loss = 6.54698e-005
I1101 15:26:49.693112  8672 solver.cpp:244]     Train net output #0: loss = 6.5435e-005 (* 1 = 6.5435e-005 loss)
I1101 15:26:49.693112  8672 sgd_solver.cpp:106] Iteration 48800, lr = 0.0186265
I1101 15:27:05.523864  8672 solver.cpp:228] Iteration 48900, loss = 6.23402e-005
I1101 15:27:05.523864  8672 solver.cpp:244]     Train net output #0: loss = 6.23054e-005 (* 1 = 6.23054e-005 loss)
I1101 15:27:05.523864  8672 sgd_solver.cpp:106] Iteration 48900, lr = 0.0186241
I1101 15:27:21.354526  8672 solver.cpp:228] Iteration 49000, loss = 3.16109e-005
I1101 15:27:21.354526  8672 solver.cpp:244]     Train net output #0: loss = 3.15761e-005 (* 1 = 3.15761e-005 loss)
I1101 15:27:21.354526  8672 sgd_solver.cpp:106] Iteration 49000, lr = 0.0186216
I1101 15:27:36.947947  8672 solver.cpp:228] Iteration 49100, loss = 4.53618e-005
I1101 15:27:36.947947  8672 solver.cpp:244]     Train net output #0: loss = 4.5327e-005 (* 1 = 4.5327e-005 loss)
I1101 15:27:36.947947  8672 sgd_solver.cpp:106] Iteration 49100, lr = 0.0186191
I1101 15:27:52.663990  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_49200.caffemodel
I1101 15:27:52.799590  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_49200.solverstate
I1101 15:27:52.848623  8672 solver.cpp:337] Iteration 49200, Testing net (#0)
I1101 15:27:57.615705  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 15:27:57.615705  8672 solver.cpp:404]     Test net output #1: loss = 0.0127862 (* 1 = 0.0127862 loss)
I1101 15:27:57.682762  8672 solver.cpp:228] Iteration 49200, loss = 4.70306e-005
I1101 15:27:57.682762  8672 solver.cpp:244]     Train net output #0: loss = 4.69958e-005 (* 1 = 4.69958e-005 loss)
I1101 15:27:57.682762  8672 sgd_solver.cpp:106] Iteration 49200, lr = 0.0186166
I1101 15:28:13.464762  8672 solver.cpp:228] Iteration 49300, loss = 5.15166e-005
I1101 15:28:13.465262  8672 solver.cpp:244]     Train net output #0: loss = 5.14818e-005 (* 1 = 5.14818e-005 loss)
I1101 15:28:13.465262  8672 sgd_solver.cpp:106] Iteration 49300, lr = 0.0186141
I1101 15:28:29.247527  8672 solver.cpp:228] Iteration 49400, loss = 6.52973e-005
I1101 15:28:29.247527  8672 solver.cpp:244]     Train net output #0: loss = 6.52625e-005 (* 1 = 6.52625e-005 loss)
I1101 15:28:29.247527  8672 sgd_solver.cpp:106] Iteration 49400, lr = 0.0186117
I1101 15:28:45.047935  8672 solver.cpp:228] Iteration 49500, loss = 6.21378e-005
I1101 15:28:45.047935  8672 solver.cpp:244]     Train net output #0: loss = 6.2103e-005 (* 1 = 6.2103e-005 loss)
I1101 15:28:45.047935  8672 sgd_solver.cpp:106] Iteration 49500, lr = 0.0186092
I1101 15:29:00.826266  8672 solver.cpp:228] Iteration 49600, loss = 3.17122e-005
I1101 15:29:00.826266  8672 solver.cpp:244]     Train net output #0: loss = 3.16774e-005 (* 1 = 3.16774e-005 loss)
I1101 15:29:00.826266  8672 sgd_solver.cpp:106] Iteration 49600, lr = 0.0186067
I1101 15:29:16.578635  8672 solver.cpp:228] Iteration 49700, loss = 4.52997e-005
I1101 15:29:16.578635  8672 solver.cpp:244]     Train net output #0: loss = 4.52649e-005 (* 1 = 4.52649e-005 loss)
I1101 15:29:16.578635  8672 sgd_solver.cpp:106] Iteration 49700, lr = 0.0186042
I1101 15:29:32.252756  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_49800.caffemodel
I1101 15:29:32.390354  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_49800.solverstate
I1101 15:29:32.441390  8672 solver.cpp:337] Iteration 49800, Testing net (#0)
I1101 15:29:37.195662  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:29:37.195662  8672 solver.cpp:404]     Test net output #1: loss = 0.0127884 (* 1 = 0.0127884 loss)
I1101 15:29:37.263206  8672 solver.cpp:228] Iteration 49800, loss = 4.69877e-005
I1101 15:29:37.263206  8672 solver.cpp:244]     Train net output #0: loss = 4.69528e-005 (* 1 = 4.69528e-005 loss)
I1101 15:29:37.263206  8672 sgd_solver.cpp:106] Iteration 49800, lr = 0.0186017
I1101 15:29:52.981411  8672 solver.cpp:228] Iteration 49900, loss = 5.14831e-005
I1101 15:29:52.981411  8672 solver.cpp:244]     Train net output #0: loss = 5.14483e-005 (* 1 = 5.14483e-005 loss)
I1101 15:29:52.981411  8672 sgd_solver.cpp:106] Iteration 49900, lr = 0.0185993
I1101 15:30:08.896036  8672 solver.cpp:228] Iteration 50000, loss = 6.51243e-005
I1101 15:30:08.896036  8672 solver.cpp:244]     Train net output #0: loss = 6.50895e-005 (* 1 = 6.50895e-005 loss)
I1101 15:30:08.896036  8672 sgd_solver.cpp:106] Iteration 50000, lr = 0.0185968
I1101 15:30:24.736685  8672 solver.cpp:228] Iteration 50100, loss = 6.19795e-005
I1101 15:30:24.736685  8672 solver.cpp:244]     Train net output #0: loss = 6.19447e-005 (* 1 = 6.19447e-005 loss)
I1101 15:30:24.736685  8672 sgd_solver.cpp:106] Iteration 50100, lr = 0.0185943
I1101 15:30:40.459811  8672 solver.cpp:228] Iteration 50200, loss = 3.18219e-005
I1101 15:30:40.459811  8672 solver.cpp:244]     Train net output #0: loss = 3.17871e-005 (* 1 = 3.17871e-005 loss)
I1101 15:30:40.459811  8672 sgd_solver.cpp:106] Iteration 50200, lr = 0.0185918
I1101 15:30:56.060559  8672 solver.cpp:228] Iteration 50300, loss = 4.52436e-005
I1101 15:30:56.060559  8672 solver.cpp:244]     Train net output #0: loss = 4.52088e-005 (* 1 = 4.52088e-005 loss)
I1101 15:30:56.060559  8672 sgd_solver.cpp:106] Iteration 50300, lr = 0.0185893
I1101 15:31:11.621774  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_50400.caffemodel
I1101 15:31:11.737857  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_50400.solverstate
I1101 15:31:11.785390  8672 solver.cpp:337] Iteration 50400, Testing net (#0)
I1101 15:31:16.472864  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:31:16.472864  8672 solver.cpp:404]     Test net output #1: loss = 0.0127934 (* 1 = 0.0127934 loss)
I1101 15:31:16.538684  8672 solver.cpp:228] Iteration 50400, loss = 4.69924e-005
I1101 15:31:16.538684  8672 solver.cpp:244]     Train net output #0: loss = 4.69576e-005 (* 1 = 4.69576e-005 loss)
I1101 15:31:16.538684  8672 sgd_solver.cpp:106] Iteration 50400, lr = 0.0185869
I1101 15:31:32.062366  8672 solver.cpp:228] Iteration 50500, loss = 5.14306e-005
I1101 15:31:32.062366  8672 solver.cpp:244]     Train net output #0: loss = 5.13957e-005 (* 1 = 5.13957e-005 loss)
I1101 15:31:32.062366  8672 sgd_solver.cpp:106] Iteration 50500, lr = 0.0185844
I1101 15:31:47.533576  8672 solver.cpp:228] Iteration 50600, loss = 6.49727e-005
I1101 15:31:47.533576  8672 solver.cpp:244]     Train net output #0: loss = 6.49379e-005 (* 1 = 6.49379e-005 loss)
I1101 15:31:47.533576  8672 sgd_solver.cpp:106] Iteration 50600, lr = 0.0185819
I1101 15:32:03.022764  8672 solver.cpp:228] Iteration 50700, loss = 6.1801e-005
I1101 15:32:03.022764  8672 solver.cpp:244]     Train net output #0: loss = 6.17662e-005 (* 1 = 6.17662e-005 loss)
I1101 15:32:03.022764  8672 sgd_solver.cpp:106] Iteration 50700, lr = 0.0185794
I1101 15:32:18.588704  8672 solver.cpp:228] Iteration 50800, loss = 3.19268e-005
I1101 15:32:18.588704  8672 solver.cpp:244]     Train net output #0: loss = 3.1892e-005 (* 1 = 3.1892e-005 loss)
I1101 15:32:18.588704  8672 sgd_solver.cpp:106] Iteration 50800, lr = 0.0185769
I1101 15:32:34.087376  8672 solver.cpp:228] Iteration 50900, loss = 4.51827e-005
I1101 15:32:34.087376  8672 solver.cpp:244]     Train net output #0: loss = 4.51479e-005 (* 1 = 4.51479e-005 loss)
I1101 15:32:34.087376  8672 sgd_solver.cpp:106] Iteration 50900, lr = 0.0185745
I1101 15:32:49.536990  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_51000.caffemodel
I1101 15:32:49.654574  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_51000.solverstate
I1101 15:32:49.701607  8672 solver.cpp:337] Iteration 51000, Testing net (#0)
I1101 15:32:54.381096  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:32:54.381096  8672 solver.cpp:404]     Test net output #1: loss = 0.0127963 (* 1 = 0.0127963 loss)
I1101 15:32:54.446671  8672 solver.cpp:228] Iteration 51000, loss = 4.69578e-005
I1101 15:32:54.446671  8672 solver.cpp:244]     Train net output #0: loss = 4.69229e-005 (* 1 = 4.69229e-005 loss)
I1101 15:32:54.446671  8672 sgd_solver.cpp:106] Iteration 51000, lr = 0.018572
I1101 15:33:09.980406  8672 solver.cpp:228] Iteration 51100, loss = 5.14013e-005
I1101 15:33:09.980406  8672 solver.cpp:244]     Train net output #0: loss = 5.13665e-005 (* 1 = 5.13665e-005 loss)
I1101 15:33:09.980406  8672 sgd_solver.cpp:106] Iteration 51100, lr = 0.0185695
I1101 15:33:25.495889  8672 solver.cpp:228] Iteration 51200, loss = 6.48128e-005
I1101 15:33:25.495889  8672 solver.cpp:244]     Train net output #0: loss = 6.4778e-005 (* 1 = 6.4778e-005 loss)
I1101 15:33:25.495889  8672 sgd_solver.cpp:106] Iteration 51200, lr = 0.018567
I1101 15:33:40.983116  8672 solver.cpp:228] Iteration 51300, loss = 6.16273e-005
I1101 15:33:40.983116  8672 solver.cpp:244]     Train net output #0: loss = 6.15924e-005 (* 1 = 6.15924e-005 loss)
I1101 15:33:40.983116  8672 sgd_solver.cpp:106] Iteration 51300, lr = 0.0185645
I1101 15:33:56.469952  8672 solver.cpp:228] Iteration 51400, loss = 3.20484e-005
I1101 15:33:56.469952  8672 solver.cpp:244]     Train net output #0: loss = 3.20136e-005 (* 1 = 3.20136e-005 loss)
I1101 15:33:56.469952  8672 sgd_solver.cpp:106] Iteration 51400, lr = 0.0185621
I1101 15:34:11.982717  8672 solver.cpp:228] Iteration 51500, loss = 4.5123e-005
I1101 15:34:11.982717  8672 solver.cpp:244]     Train net output #0: loss = 4.50882e-005 (* 1 = 4.50882e-005 loss)
I1101 15:34:11.982717  8672 sgd_solver.cpp:106] Iteration 51500, lr = 0.0185596
I1101 15:34:27.412062  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_51600.caffemodel
I1101 15:34:27.532148  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_51600.solverstate
I1101 15:34:27.579681  8672 solver.cpp:337] Iteration 51600, Testing net (#0)
I1101 15:34:32.257752  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:34:32.257752  8672 solver.cpp:404]     Test net output #1: loss = 0.0128001 (* 1 = 0.0128001 loss)
I1101 15:34:32.323799  8672 solver.cpp:228] Iteration 51600, loss = 4.69279e-005
I1101 15:34:32.323799  8672 solver.cpp:244]     Train net output #0: loss = 4.68931e-005 (* 1 = 4.68931e-005 loss)
I1101 15:34:32.323799  8672 sgd_solver.cpp:106] Iteration 51600, lr = 0.0185571
I1101 15:34:47.838124  8672 solver.cpp:228] Iteration 51700, loss = 5.13774e-005
I1101 15:34:47.838124  8672 solver.cpp:244]     Train net output #0: loss = 5.13425e-005 (* 1 = 5.13425e-005 loss)
I1101 15:34:47.838124  8672 sgd_solver.cpp:106] Iteration 51700, lr = 0.0185546
I1101 15:35:03.362387  8672 solver.cpp:228] Iteration 51800, loss = 6.46219e-005
I1101 15:35:03.362387  8672 solver.cpp:244]     Train net output #0: loss = 6.45871e-005 (* 1 = 6.45871e-005 loss)
I1101 15:35:03.362387  8672 sgd_solver.cpp:106] Iteration 51800, lr = 0.0185521
I1101 15:35:18.902127  8672 solver.cpp:228] Iteration 51900, loss = 6.14786e-005
I1101 15:35:18.902127  8672 solver.cpp:244]     Train net output #0: loss = 6.14438e-005 (* 1 = 6.14438e-005 loss)
I1101 15:35:18.902127  8672 sgd_solver.cpp:106] Iteration 51900, lr = 0.0185497
I1101 15:35:34.419164  8672 solver.cpp:228] Iteration 52000, loss = 3.21795e-005
I1101 15:35:34.419164  8672 solver.cpp:244]     Train net output #0: loss = 3.21447e-005 (* 1 = 3.21447e-005 loss)
I1101 15:35:34.419164  8672 sgd_solver.cpp:106] Iteration 52000, lr = 0.0185472
I1101 15:35:49.921825  8672 solver.cpp:228] Iteration 52100, loss = 4.50955e-005
I1101 15:35:49.921825  8672 solver.cpp:244]     Train net output #0: loss = 4.50607e-005 (* 1 = 4.50607e-005 loss)
I1101 15:35:49.921825  8672 sgd_solver.cpp:106] Iteration 52100, lr = 0.0185447
I1101 15:36:05.354313  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_52200.caffemodel
I1101 15:36:05.470396  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_52200.solverstate
I1101 15:36:05.518429  8672 solver.cpp:337] Iteration 52200, Testing net (#0)
I1101 15:36:10.180790  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:36:10.180790  8672 solver.cpp:404]     Test net output #1: loss = 0.0128053 (* 1 = 0.0128053 loss)
I1101 15:36:10.246840  8672 solver.cpp:228] Iteration 52200, loss = 4.6904e-005
I1101 15:36:10.246840  8672 solver.cpp:244]     Train net output #0: loss = 4.68692e-005 (* 1 = 4.68692e-005 loss)
I1101 15:36:10.246840  8672 sgd_solver.cpp:106] Iteration 52200, lr = 0.0185422
I1101 15:36:25.722640  8672 solver.cpp:228] Iteration 52300, loss = 5.12985e-005
I1101 15:36:25.722640  8672 solver.cpp:244]     Train net output #0: loss = 5.12637e-005 (* 1 = 5.12637e-005 loss)
I1101 15:36:25.722640  8672 sgd_solver.cpp:106] Iteration 52300, lr = 0.0185397
I1101 15:36:41.219912  8672 solver.cpp:228] Iteration 52400, loss = 6.44476e-005
I1101 15:36:41.219912  8672 solver.cpp:244]     Train net output #0: loss = 6.44128e-005 (* 1 = 6.44128e-005 loss)
I1101 15:36:41.219912  8672 sgd_solver.cpp:106] Iteration 52400, lr = 0.0185373
I1101 15:36:56.746414  8672 solver.cpp:228] Iteration 52500, loss = 6.12857e-005
I1101 15:36:56.746414  8672 solver.cpp:244]     Train net output #0: loss = 6.12509e-005 (* 1 = 6.12509e-005 loss)
I1101 15:36:56.746414  8672 sgd_solver.cpp:106] Iteration 52500, lr = 0.0185348
I1101 15:37:12.219631  8672 solver.cpp:228] Iteration 52600, loss = 3.23011e-005
I1101 15:37:12.219631  8672 solver.cpp:244]     Train net output #0: loss = 3.22663e-005 (* 1 = 3.22663e-005 loss)
I1101 15:37:12.219631  8672 sgd_solver.cpp:106] Iteration 52600, lr = 0.0185323
I1101 15:37:27.718348  8672 solver.cpp:228] Iteration 52700, loss = 4.50323e-005
I1101 15:37:27.718348  8672 solver.cpp:244]     Train net output #0: loss = 4.49974e-005 (* 1 = 4.49974e-005 loss)
I1101 15:37:27.718348  8672 sgd_solver.cpp:106] Iteration 52700, lr = 0.0185298
I1101 15:37:43.173856  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_52800.caffemodel
I1101 15:37:43.292440  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_52800.solverstate
I1101 15:37:43.342977  8672 solver.cpp:337] Iteration 52800, Testing net (#0)
I1101 15:37:48.024026  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:37:48.024026  8672 solver.cpp:404]     Test net output #1: loss = 0.0128093 (* 1 = 0.0128093 loss)
I1101 15:37:48.089742  8672 solver.cpp:228] Iteration 52800, loss = 4.68754e-005
I1101 15:37:48.089742  8672 solver.cpp:244]     Train net output #0: loss = 4.68405e-005 (* 1 = 4.68405e-005 loss)
I1101 15:37:48.089742  8672 sgd_solver.cpp:106] Iteration 52800, lr = 0.0185273
I1101 15:38:03.581882  8672 solver.cpp:228] Iteration 52900, loss = 5.1231e-005
I1101 15:38:03.581882  8672 solver.cpp:244]     Train net output #0: loss = 5.11962e-005 (* 1 = 5.11962e-005 loss)
I1101 15:38:03.581882  8672 sgd_solver.cpp:106] Iteration 52900, lr = 0.0185249
I1101 15:38:19.054486  8672 solver.cpp:228] Iteration 53000, loss = 6.42621e-005
I1101 15:38:19.054486  8672 solver.cpp:244]     Train net output #0: loss = 6.42273e-005 (* 1 = 6.42273e-005 loss)
I1101 15:38:19.054486  8672 sgd_solver.cpp:106] Iteration 53000, lr = 0.0185224
I1101 15:38:34.575388  8672 solver.cpp:228] Iteration 53100, loss = 6.1149e-005
I1101 15:38:34.575388  8672 solver.cpp:244]     Train net output #0: loss = 6.11142e-005 (* 1 = 6.11142e-005 loss)
I1101 15:38:34.575388  8672 sgd_solver.cpp:106] Iteration 53100, lr = 0.0185199
I1101 15:38:50.055105  8672 solver.cpp:228] Iteration 53200, loss = 3.24168e-005
I1101 15:38:50.055105  8672 solver.cpp:244]     Train net output #0: loss = 3.23819e-005 (* 1 = 3.23819e-005 loss)
I1101 15:38:50.055105  8672 sgd_solver.cpp:106] Iteration 53200, lr = 0.0185174
I1101 15:39:05.606307  8672 solver.cpp:228] Iteration 53300, loss = 4.4972e-005
I1101 15:39:05.606307  8672 solver.cpp:244]     Train net output #0: loss = 4.49371e-005 (* 1 = 4.49371e-005 loss)
I1101 15:39:05.606307  8672 sgd_solver.cpp:106] Iteration 53300, lr = 0.0185149
I1101 15:39:21.032635  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_53400.caffemodel
I1101 15:39:21.146718  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_53400.solverstate
I1101 15:39:21.215765  8672 solver.cpp:337] Iteration 53400, Testing net (#0)
I1101 15:39:25.898891  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:39:25.898891  8672 solver.cpp:404]     Test net output #1: loss = 0.0128139 (* 1 = 0.0128139 loss)
I1101 15:39:25.964505  8672 solver.cpp:228] Iteration 53400, loss = 4.68586e-005
I1101 15:39:25.964505  8672 solver.cpp:244]     Train net output #0: loss = 4.68238e-005 (* 1 = 4.68238e-005 loss)
I1101 15:39:25.964505  8672 sgd_solver.cpp:106] Iteration 53400, lr = 0.0185125
I1101 15:39:41.426043  8672 solver.cpp:228] Iteration 53500, loss = 5.11761e-005
I1101 15:39:41.426043  8672 solver.cpp:244]     Train net output #0: loss = 5.11413e-005 (* 1 = 5.11413e-005 loss)
I1101 15:39:41.426043  8672 sgd_solver.cpp:106] Iteration 53500, lr = 0.01851
I1101 15:39:56.917824  8672 solver.cpp:228] Iteration 53600, loss = 6.41075e-005
I1101 15:39:56.917824  8672 solver.cpp:244]     Train net output #0: loss = 6.40727e-005 (* 1 = 6.40727e-005 loss)
I1101 15:39:56.917824  8672 sgd_solver.cpp:106] Iteration 53600, lr = 0.0185075
I1101 15:40:12.452265  8672 solver.cpp:228] Iteration 53700, loss = 6.098e-005
I1101 15:40:12.452265  8672 solver.cpp:244]     Train net output #0: loss = 6.09452e-005 (* 1 = 6.09452e-005 loss)
I1101 15:40:12.452265  8672 sgd_solver.cpp:106] Iteration 53700, lr = 0.018505
I1101 15:40:28.148226  8672 solver.cpp:228] Iteration 53800, loss = 3.25467e-005
I1101 15:40:28.148226  8672 solver.cpp:244]     Train net output #0: loss = 3.25119e-005 (* 1 = 3.25119e-005 loss)
I1101 15:40:28.148226  8672 sgd_solver.cpp:106] Iteration 53800, lr = 0.0185026
I1101 15:40:43.752526  8672 solver.cpp:228] Iteration 53900, loss = 4.49027e-005
I1101 15:40:43.752526  8672 solver.cpp:244]     Train net output #0: loss = 4.48679e-005 (* 1 = 4.48679e-005 loss)
I1101 15:40:43.752526  8672 sgd_solver.cpp:106] Iteration 53900, lr = 0.0185001
I1101 15:40:59.400313  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_54000.caffemodel
I1101 15:40:59.514408  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_54000.solverstate
I1101 15:40:59.561427  8672 solver.cpp:337] Iteration 54000, Testing net (#0)
I1101 15:41:04.239599  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:41:04.239599  8672 solver.cpp:404]     Test net output #1: loss = 0.0128192 (* 1 = 0.0128192 loss)
I1101 15:41:04.309651  8672 solver.cpp:228] Iteration 54000, loss = 4.68204e-005
I1101 15:41:04.309651  8672 solver.cpp:244]     Train net output #0: loss = 4.67856e-005 (* 1 = 4.67856e-005 loss)
I1101 15:41:04.309651  8672 sgd_solver.cpp:106] Iteration 54000, lr = 0.0184976
I1101 15:41:19.839915  8672 solver.cpp:228] Iteration 54100, loss = 5.11038e-005
I1101 15:41:19.839915  8672 solver.cpp:244]     Train net output #0: loss = 5.1069e-005 (* 1 = 5.1069e-005 loss)
I1101 15:41:19.839915  8672 sgd_solver.cpp:106] Iteration 54100, lr = 0.0184951
I1101 15:41:35.447188  8672 solver.cpp:228] Iteration 54200, loss = 6.38868e-005
I1101 15:41:35.447188  8672 solver.cpp:244]     Train net output #0: loss = 6.38519e-005 (* 1 = 6.38519e-005 loss)
I1101 15:41:35.447188  8672 sgd_solver.cpp:106] Iteration 54200, lr = 0.0184926
I1101 15:41:50.909193  8672 solver.cpp:228] Iteration 54300, loss = 6.08749e-005
I1101 15:41:50.909193  8672 solver.cpp:244]     Train net output #0: loss = 6.08401e-005 (* 1 = 6.08401e-005 loss)
I1101 15:41:50.909193  8672 sgd_solver.cpp:106] Iteration 54300, lr = 0.0184902
I1101 15:42:06.421362  8672 solver.cpp:228] Iteration 54400, loss = 3.26695e-005
I1101 15:42:06.421362  8672 solver.cpp:244]     Train net output #0: loss = 3.26347e-005 (* 1 = 3.26347e-005 loss)
I1101 15:42:06.421362  8672 sgd_solver.cpp:106] Iteration 54400, lr = 0.0184877
I1101 15:42:21.924307  8672 solver.cpp:228] Iteration 54500, loss = 4.48085e-005
I1101 15:42:21.924307  8672 solver.cpp:244]     Train net output #0: loss = 4.47736e-005 (* 1 = 4.47736e-005 loss)
I1101 15:42:21.924307  8672 sgd_solver.cpp:106] Iteration 54500, lr = 0.0184852
I1101 15:42:37.364754  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_54600.caffemodel
I1101 15:42:37.478835  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_54600.solverstate
I1101 15:42:37.524868  8672 solver.cpp:337] Iteration 54600, Testing net (#0)
I1101 15:42:42.201958  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:42:42.201958  8672 solver.cpp:404]     Test net output #1: loss = 0.0128255 (* 1 = 0.0128255 loss)
I1101 15:42:42.267004  8672 solver.cpp:228] Iteration 54600, loss = 4.67744e-005
I1101 15:42:42.267004  8672 solver.cpp:244]     Train net output #0: loss = 4.67396e-005 (* 1 = 4.67396e-005 loss)
I1101 15:42:42.267004  8672 sgd_solver.cpp:106] Iteration 54600, lr = 0.0184827
I1101 15:42:57.786778  8672 solver.cpp:228] Iteration 54700, loss = 5.1062e-005
I1101 15:42:57.786778  8672 solver.cpp:244]     Train net output #0: loss = 5.10272e-005 (* 1 = 5.10272e-005 loss)
I1101 15:42:57.786778  8672 sgd_solver.cpp:106] Iteration 54700, lr = 0.0184802
I1101 15:43:13.321944  8672 solver.cpp:228] Iteration 54800, loss = 6.37453e-005
I1101 15:43:13.321944  8672 solver.cpp:244]     Train net output #0: loss = 6.37105e-005 (* 1 = 6.37105e-005 loss)
I1101 15:43:13.321944  8672 sgd_solver.cpp:106] Iteration 54800, lr = 0.0184778
I1101 15:43:28.888785  8672 solver.cpp:228] Iteration 54900, loss = 6.06898e-005
I1101 15:43:28.888785  8672 solver.cpp:244]     Train net output #0: loss = 6.0655e-005 (* 1 = 6.0655e-005 loss)
I1101 15:43:28.888785  8672 sgd_solver.cpp:106] Iteration 54900, lr = 0.0184753
I1101 15:43:44.408814  8672 solver.cpp:228] Iteration 55000, loss = 3.2772e-005
I1101 15:43:44.408814  8672 solver.cpp:244]     Train net output #0: loss = 3.27372e-005 (* 1 = 3.27372e-005 loss)
I1101 15:43:44.408814  8672 sgd_solver.cpp:106] Iteration 55000, lr = 0.0184728
I1101 15:43:59.916122  8672 solver.cpp:228] Iteration 55100, loss = 4.47571e-005
I1101 15:43:59.916122  8672 solver.cpp:244]     Train net output #0: loss = 4.47223e-005 (* 1 = 4.47223e-005 loss)
I1101 15:43:59.916122  8672 sgd_solver.cpp:106] Iteration 55100, lr = 0.0184703
I1101 15:44:15.355775  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_55200.caffemodel
I1101 15:44:15.468343  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_55200.solverstate
I1101 15:44:15.529377  8672 solver.cpp:337] Iteration 55200, Testing net (#0)
I1101 15:44:20.219072  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:44:20.219573  8672 solver.cpp:404]     Test net output #1: loss = 0.0128302 (* 1 = 0.0128302 loss)
I1101 15:44:20.285682  8672 solver.cpp:228] Iteration 55200, loss = 4.67458e-005
I1101 15:44:20.285682  8672 solver.cpp:244]     Train net output #0: loss = 4.6711e-005 (* 1 = 4.6711e-005 loss)
I1101 15:44:20.285682  8672 sgd_solver.cpp:106] Iteration 55200, lr = 0.0184678
I1101 15:44:35.898087  8672 solver.cpp:228] Iteration 55300, loss = 5.09844e-005
I1101 15:44:35.898087  8672 solver.cpp:244]     Train net output #0: loss = 5.09495e-005 (* 1 = 5.09495e-005 loss)
I1101 15:44:35.898087  8672 sgd_solver.cpp:106] Iteration 55300, lr = 0.0184654
I1101 15:44:51.545151  8672 solver.cpp:228] Iteration 55400, loss = 6.35747e-005
I1101 15:44:51.545151  8672 solver.cpp:244]     Train net output #0: loss = 6.35399e-005 (* 1 = 6.35399e-005 loss)
I1101 15:44:51.545151  8672 sgd_solver.cpp:106] Iteration 55400, lr = 0.0184629
I1101 15:45:07.422909  8672 solver.cpp:228] Iteration 55500, loss = 6.0562e-005
I1101 15:45:07.422909  8672 solver.cpp:244]     Train net output #0: loss = 6.05272e-005 (* 1 = 6.05272e-005 loss)
I1101 15:45:07.422909  8672 sgd_solver.cpp:106] Iteration 55500, lr = 0.0184604
I1101 15:45:23.233360  8672 solver.cpp:228] Iteration 55600, loss = 3.28745e-005
I1101 15:45:23.233360  8672 solver.cpp:244]     Train net output #0: loss = 3.28397e-005 (* 1 = 3.28397e-005 loss)
I1101 15:45:23.233360  8672 sgd_solver.cpp:106] Iteration 55600, lr = 0.0184579
I1101 15:45:38.965620  8672 solver.cpp:228] Iteration 55700, loss = 4.47117e-005
I1101 15:45:38.965620  8672 solver.cpp:244]     Train net output #0: loss = 4.46769e-005 (* 1 = 4.46769e-005 loss)
I1101 15:45:38.965620  8672 sgd_solver.cpp:106] Iteration 55700, lr = 0.0184554
I1101 15:45:54.606931  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_55800.caffemodel
I1101 15:45:54.727016  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_55800.solverstate
I1101 15:45:54.775050  8672 solver.cpp:337] Iteration 55800, Testing net (#0)
I1101 15:45:59.517071  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:45:59.517071  8672 solver.cpp:404]     Test net output #1: loss = 0.0128361 (* 1 = 0.0128361 loss)
I1101 15:45:59.583642  8672 solver.cpp:228] Iteration 55800, loss = 4.67201e-005
I1101 15:45:59.583642  8672 solver.cpp:244]     Train net output #0: loss = 4.66853e-005 (* 1 = 4.66853e-005 loss)
I1101 15:45:59.583642  8672 sgd_solver.cpp:106] Iteration 55800, lr = 0.018453
I1101 15:46:15.395805  8672 solver.cpp:228] Iteration 55900, loss = 5.09413e-005
I1101 15:46:15.395805  8672 solver.cpp:244]     Train net output #0: loss = 5.09065e-005 (* 1 = 5.09065e-005 loss)
I1101 15:46:15.395805  8672 sgd_solver.cpp:106] Iteration 55900, lr = 0.0184505
I1101 15:46:31.465593  8672 solver.cpp:228] Iteration 56000, loss = 6.3453e-005
I1101 15:46:31.465593  8672 solver.cpp:244]     Train net output #0: loss = 6.34181e-005 (* 1 = 6.34181e-005 loss)
I1101 15:46:31.465593  8672 sgd_solver.cpp:106] Iteration 56000, lr = 0.018448
I1101 15:46:47.314518  8672 solver.cpp:228] Iteration 56100, loss = 6.04337e-005
I1101 15:46:47.314518  8672 solver.cpp:244]     Train net output #0: loss = 6.03988e-005 (* 1 = 6.03988e-005 loss)
I1101 15:46:47.314518  8672 sgd_solver.cpp:106] Iteration 56100, lr = 0.0184455
I1101 15:47:03.263797  8672 solver.cpp:228] Iteration 56200, loss = 3.29961e-005
I1101 15:47:03.263797  8672 solver.cpp:244]     Train net output #0: loss = 3.29613e-005 (* 1 = 3.29613e-005 loss)
I1101 15:47:03.263797  8672 sgd_solver.cpp:106] Iteration 56200, lr = 0.018443
I1101 15:47:19.213068  8672 solver.cpp:228] Iteration 56300, loss = 4.46783e-005
I1101 15:47:19.213068  8672 solver.cpp:244]     Train net output #0: loss = 4.46435e-005 (* 1 = 4.46435e-005 loss)
I1101 15:47:19.213068  8672 sgd_solver.cpp:106] Iteration 56300, lr = 0.0184406
I1101 15:47:34.874526  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_56400.caffemodel
I1101 15:47:35.080899  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_56400.solverstate
I1101 15:47:35.142945  8672 solver.cpp:337] Iteration 56400, Testing net (#0)
I1101 15:47:40.072549  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:47:40.072549  8672 solver.cpp:404]     Test net output #1: loss = 0.0128424 (* 1 = 0.0128424 loss)
I1101 15:47:40.140379  8672 solver.cpp:228] Iteration 56400, loss = 4.66795e-005
I1101 15:47:40.140379  8672 solver.cpp:244]     Train net output #0: loss = 4.66447e-005 (* 1 = 4.66447e-005 loss)
I1101 15:47:40.142380  8672 sgd_solver.cpp:106] Iteration 56400, lr = 0.0184381
I1101 15:47:56.641257  8672 solver.cpp:228] Iteration 56500, loss = 5.08685e-005
I1101 15:47:56.641257  8672 solver.cpp:244]     Train net output #0: loss = 5.08336e-005 (* 1 = 5.08336e-005 loss)
I1101 15:47:56.641257  8672 sgd_solver.cpp:106] Iteration 56500, lr = 0.0184356
I1101 15:48:12.566722  8672 solver.cpp:228] Iteration 56600, loss = 6.3296e-005
I1101 15:48:12.566722  8672 solver.cpp:244]     Train net output #0: loss = 6.32612e-005 (* 1 = 6.32612e-005 loss)
I1101 15:48:12.566722  8672 sgd_solver.cpp:106] Iteration 56600, lr = 0.0184331
I1101 15:48:28.603664  8672 solver.cpp:228] Iteration 56700, loss = 6.03017e-005
I1101 15:48:28.603664  8672 solver.cpp:244]     Train net output #0: loss = 6.02669e-005 (* 1 = 6.02669e-005 loss)
I1101 15:48:28.603664  8672 sgd_solver.cpp:106] Iteration 56700, lr = 0.0184306
I1101 15:48:44.347260  8672 solver.cpp:228] Iteration 56800, loss = 3.30927e-005
I1101 15:48:44.347260  8672 solver.cpp:244]     Train net output #0: loss = 3.30579e-005 (* 1 = 3.30579e-005 loss)
I1101 15:48:44.347260  8672 sgd_solver.cpp:106] Iteration 56800, lr = 0.0184282
I1101 15:48:59.883083  8672 solver.cpp:228] Iteration 56900, loss = 4.46126e-005
I1101 15:48:59.883083  8672 solver.cpp:244]     Train net output #0: loss = 4.45778e-005 (* 1 = 4.45778e-005 loss)
I1101 15:48:59.883083  8672 sgd_solver.cpp:106] Iteration 56900, lr = 0.0184257
I1101 15:49:15.285792  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_57000.caffemodel
I1101 15:49:15.403877  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_57000.solverstate
I1101 15:49:15.449909  8672 solver.cpp:337] Iteration 57000, Testing net (#0)
I1101 15:49:20.109238  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:49:20.109238  8672 solver.cpp:404]     Test net output #1: loss = 0.0128488 (* 1 = 0.0128488 loss)
I1101 15:49:20.182277  8672 solver.cpp:228] Iteration 57000, loss = 4.66527e-005
I1101 15:49:20.182277  8672 solver.cpp:244]     Train net output #0: loss = 4.66178e-005 (* 1 = 4.66178e-005 loss)
I1101 15:49:20.182277  8672 sgd_solver.cpp:106] Iteration 57000, lr = 0.0184232
I1101 15:49:35.657335  8672 solver.cpp:228] Iteration 57100, loss = 5.0832e-005
I1101 15:49:35.657335  8672 solver.cpp:244]     Train net output #0: loss = 5.07972e-005 (* 1 = 5.07972e-005 loss)
I1101 15:49:35.657335  8672 sgd_solver.cpp:106] Iteration 57100, lr = 0.0184207
I1101 15:49:51.133416  8672 solver.cpp:228] Iteration 57200, loss = 6.3154e-005
I1101 15:49:51.133416  8672 solver.cpp:244]     Train net output #0: loss = 6.31192e-005 (* 1 = 6.31192e-005 loss)
I1101 15:49:51.133416  8672 sgd_solver.cpp:106] Iteration 57200, lr = 0.0184182
I1101 15:50:06.614946  8672 solver.cpp:228] Iteration 57300, loss = 6.02097e-005
I1101 15:50:06.614946  8672 solver.cpp:244]     Train net output #0: loss = 6.01749e-005 (* 1 = 6.01749e-005 loss)
I1101 15:50:06.614946  8672 sgd_solver.cpp:106] Iteration 57300, lr = 0.0184158
I1101 15:50:22.102074  8672 solver.cpp:228] Iteration 57400, loss = 3.32036e-005
I1101 15:50:22.102074  8672 solver.cpp:244]     Train net output #0: loss = 3.31688e-005 (* 1 = 3.31688e-005 loss)
I1101 15:50:22.102074  8672 sgd_solver.cpp:106] Iteration 57400, lr = 0.0184133
I1101 15:50:37.569047  8672 solver.cpp:228] Iteration 57500, loss = 4.45792e-005
I1101 15:50:37.569047  8672 solver.cpp:244]     Train net output #0: loss = 4.45444e-005 (* 1 = 4.45444e-005 loss)
I1101 15:50:37.569047  8672 sgd_solver.cpp:106] Iteration 57500, lr = 0.0184108
I1101 15:50:52.961743  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_57600.caffemodel
I1101 15:50:53.076814  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_57600.solverstate
I1101 15:50:53.123845  8672 solver.cpp:337] Iteration 57600, Testing net (#0)
I1101 15:50:57.785179  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:50:57.785179  8672 solver.cpp:404]     Test net output #1: loss = 0.0128548 (* 1 = 0.0128548 loss)
I1101 15:50:57.850211  8672 solver.cpp:228] Iteration 57600, loss = 4.66288e-005
I1101 15:50:57.850211  8672 solver.cpp:244]     Train net output #0: loss = 4.65939e-005 (* 1 = 4.65939e-005 loss)
I1101 15:50:57.850211  8672 sgd_solver.cpp:106] Iteration 57600, lr = 0.0184083
I1101 15:51:13.309654  8672 solver.cpp:228] Iteration 57700, loss = 5.07669e-005
I1101 15:51:13.309654  8672 solver.cpp:244]     Train net output #0: loss = 5.07321e-005 (* 1 = 5.07321e-005 loss)
I1101 15:51:13.309654  8672 sgd_solver.cpp:106] Iteration 57700, lr = 0.0184058
I1101 15:51:28.763684  8672 solver.cpp:228] Iteration 57800, loss = 6.29834e-005
I1101 15:51:28.763684  8672 solver.cpp:244]     Train net output #0: loss = 6.29486e-005 (* 1 = 6.29486e-005 loss)
I1101 15:51:28.763684  8672 sgd_solver.cpp:106] Iteration 57800, lr = 0.0184034
I1101 15:51:44.263749  8672 solver.cpp:228] Iteration 57900, loss = 6.00718e-005
I1101 15:51:44.263749  8672 solver.cpp:244]     Train net output #0: loss = 6.0037e-005 (* 1 = 6.0037e-005 loss)
I1101 15:51:44.263749  8672 sgd_solver.cpp:106] Iteration 57900, lr = 0.0184009
I1101 15:51:59.825147  8672 solver.cpp:228] Iteration 58000, loss = 3.33132e-005
I1101 15:51:59.825147  8672 solver.cpp:244]     Train net output #0: loss = 3.32784e-005 (* 1 = 3.32784e-005 loss)
I1101 15:51:59.825147  8672 sgd_solver.cpp:106] Iteration 58000, lr = 0.0183984
I1101 15:52:15.297230  8672 solver.cpp:228] Iteration 58100, loss = 4.45249e-005
I1101 15:52:15.297230  8672 solver.cpp:244]     Train net output #0: loss = 4.449e-005 (* 1 = 4.449e-005 loss)
I1101 15:52:15.297230  8672 sgd_solver.cpp:106] Iteration 58100, lr = 0.0183959
I1101 15:52:30.722211  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_58200.caffemodel
I1101 15:52:30.836292  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_58200.solverstate
I1101 15:52:30.882825  8672 solver.cpp:337] Iteration 58200, Testing net (#0)
I1101 15:52:35.560923  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:52:35.560923  8672 solver.cpp:404]     Test net output #1: loss = 0.0128596 (* 1 = 0.0128596 loss)
I1101 15:52:35.639050  8672 solver.cpp:228] Iteration 58200, loss = 4.6562e-005
I1101 15:52:35.639050  8672 solver.cpp:244]     Train net output #0: loss = 4.65271e-005 (* 1 = 4.65271e-005 loss)
I1101 15:52:35.639050  8672 sgd_solver.cpp:106] Iteration 58200, lr = 0.0183935
I1101 15:52:51.139149  8672 solver.cpp:228] Iteration 58300, loss = 5.07203e-005
I1101 15:52:51.139149  8672 solver.cpp:244]     Train net output #0: loss = 5.06855e-005 (* 1 = 5.06855e-005 loss)
I1101 15:52:51.139149  8672 sgd_solver.cpp:106] Iteration 58300, lr = 0.018391
I1101 15:53:06.621640  8672 solver.cpp:228] Iteration 58400, loss = 6.28897e-005
I1101 15:53:06.621640  8672 solver.cpp:244]     Train net output #0: loss = 6.28549e-005 (* 1 = 6.28549e-005 loss)
I1101 15:53:06.621640  8672 sgd_solver.cpp:106] Iteration 58400, lr = 0.0183885
I1101 15:53:22.129776  8672 solver.cpp:228] Iteration 58500, loss = 5.99256e-005
I1101 15:53:22.129776  8672 solver.cpp:244]     Train net output #0: loss = 5.98907e-005 (* 1 = 5.98907e-005 loss)
I1101 15:53:22.129776  8672 sgd_solver.cpp:106] Iteration 58500, lr = 0.018386
I1101 15:53:37.609670  8672 solver.cpp:228] Iteration 58600, loss = 3.3417e-005
I1101 15:53:37.609670  8672 solver.cpp:244]     Train net output #0: loss = 3.33821e-005 (* 1 = 3.33821e-005 loss)
I1101 15:53:37.609670  8672 sgd_solver.cpp:106] Iteration 58600, lr = 0.0183835
I1101 15:53:53.115298  8672 solver.cpp:228] Iteration 58700, loss = 4.44867e-005
I1101 15:53:53.115298  8672 solver.cpp:244]     Train net output #0: loss = 4.44518e-005 (* 1 = 4.44518e-005 loss)
I1101 15:53:53.115298  8672 sgd_solver.cpp:106] Iteration 58700, lr = 0.0183811
I1101 15:54:08.677858  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_58800.caffemodel
I1101 15:54:08.788451  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_58800.solverstate
I1101 15:54:08.835326  8672 solver.cpp:337] Iteration 58800, Testing net (#0)
I1101 15:54:13.504988  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:54:13.504988  8672 solver.cpp:404]     Test net output #1: loss = 0.0128665 (* 1 = 0.0128665 loss)
I1101 15:54:13.583137  8672 solver.cpp:228] Iteration 58800, loss = 4.6525e-005
I1101 15:54:13.583137  8672 solver.cpp:244]     Train net output #0: loss = 4.64901e-005 (* 1 = 4.64901e-005 loss)
I1101 15:54:13.583137  8672 sgd_solver.cpp:106] Iteration 58800, lr = 0.0183786
I1101 15:54:29.144390  8672 solver.cpp:228] Iteration 58900, loss = 5.06427e-005
I1101 15:54:29.144390  8672 solver.cpp:244]     Train net output #0: loss = 5.06079e-005 (* 1 = 5.06079e-005 loss)
I1101 15:54:29.144390  8672 sgd_solver.cpp:106] Iteration 58900, lr = 0.0183761
I1101 15:54:44.792305  8672 solver.cpp:228] Iteration 59000, loss = 6.27674e-005
I1101 15:54:44.792305  8672 solver.cpp:244]     Train net output #0: loss = 6.27325e-005 (* 1 = 6.27325e-005 loss)
I1101 15:54:44.792305  8672 sgd_solver.cpp:106] Iteration 59000, lr = 0.0183736
I1101 15:55:00.291980  8672 solver.cpp:228] Iteration 59100, loss = 5.97883e-005
I1101 15:55:00.291980  8672 solver.cpp:244]     Train net output #0: loss = 5.97534e-005 (* 1 = 5.97534e-005 loss)
I1101 15:55:00.291980  8672 sgd_solver.cpp:106] Iteration 59100, lr = 0.0183711
I1101 15:55:15.841403  8672 solver.cpp:228] Iteration 59200, loss = 3.35135e-005
I1101 15:55:15.841403  8672 solver.cpp:244]     Train net output #0: loss = 3.34787e-005 (* 1 = 3.34787e-005 loss)
I1101 15:55:15.841403  8672 sgd_solver.cpp:106] Iteration 59200, lr = 0.0183687
I1101 15:55:31.531913  8672 solver.cpp:228] Iteration 59300, loss = 4.44324e-005
I1101 15:55:31.531913  8672 solver.cpp:244]     Train net output #0: loss = 4.43975e-005 (* 1 = 4.43975e-005 loss)
I1101 15:55:31.531913  8672 sgd_solver.cpp:106] Iteration 59300, lr = 0.0183662
I1101 15:55:48.046104  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_59400.caffemodel
I1101 15:55:48.268422  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_59400.solverstate
I1101 15:55:48.371949  8672 solver.cpp:337] Iteration 59400, Testing net (#0)
I1101 15:55:53.305748  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:55:53.305748  8672 solver.cpp:404]     Test net output #1: loss = 0.0128701 (* 1 = 0.0128701 loss)
I1101 15:55:53.373077  8672 solver.cpp:228] Iteration 59400, loss = 4.64796e-005
I1101 15:55:53.373077  8672 solver.cpp:244]     Train net output #0: loss = 4.64448e-005 (* 1 = 4.64448e-005 loss)
I1101 15:55:53.373077  8672 sgd_solver.cpp:106] Iteration 59400, lr = 0.0183637
I1101 15:56:09.784235  8672 solver.cpp:228] Iteration 59500, loss = 5.05621e-005
I1101 15:56:09.784235  8672 solver.cpp:244]     Train net output #0: loss = 5.05273e-005 (* 1 = 5.05273e-005 loss)
I1101 15:56:09.784235  8672 sgd_solver.cpp:106] Iteration 59500, lr = 0.0183612
I1101 15:56:25.876421  8672 solver.cpp:228] Iteration 59600, loss = 6.2657e-005
I1101 15:56:25.876421  8672 solver.cpp:244]     Train net output #0: loss = 6.26221e-005 (* 1 = 6.26221e-005 loss)
I1101 15:56:25.876421  8672 sgd_solver.cpp:106] Iteration 59600, lr = 0.0183587
I1101 15:56:41.739946  8672 solver.cpp:228] Iteration 59700, loss = 5.96336e-005
I1101 15:56:41.739946  8672 solver.cpp:244]     Train net output #0: loss = 5.95988e-005 (* 1 = 5.95988e-005 loss)
I1101 15:56:41.739946  8672 sgd_solver.cpp:106] Iteration 59700, lr = 0.0183563
I1101 15:56:57.616780  8672 solver.cpp:228] Iteration 59800, loss = 3.36077e-005
I1101 15:56:57.616780  8672 solver.cpp:244]     Train net output #0: loss = 3.35729e-005 (* 1 = 3.35729e-005 loss)
I1101 15:56:57.616780  8672 sgd_solver.cpp:106] Iteration 59800, lr = 0.0183538
I1101 15:57:13.456149  8672 solver.cpp:228] Iteration 59900, loss = 4.44037e-005
I1101 15:57:13.456149  8672 solver.cpp:244]     Train net output #0: loss = 4.43689e-005 (* 1 = 4.43689e-005 loss)
I1101 15:57:13.456149  8672 sgd_solver.cpp:106] Iteration 59900, lr = 0.0183513
I1101 15:57:29.251641  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_60000.caffemodel
I1101 15:57:29.369225  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_60000.solverstate
I1101 15:57:29.415757  8672 solver.cpp:337] Iteration 60000, Testing net (#0)
I1101 15:57:34.199249  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:57:34.199249  8672 solver.cpp:404]     Test net output #1: loss = 0.0128753 (* 1 = 0.0128753 loss)
I1101 15:57:34.267572  8672 solver.cpp:228] Iteration 60000, loss = 4.64521e-005
I1101 15:57:34.267572  8672 solver.cpp:244]     Train net output #0: loss = 4.64173e-005 (* 1 = 4.64173e-005 loss)
I1101 15:57:34.267572  8672 sgd_solver.cpp:106] Iteration 60000, lr = 0.0183488
I1101 15:57:50.149291  8672 solver.cpp:228] Iteration 60100, loss = 5.05364e-005
I1101 15:57:50.149291  8672 solver.cpp:244]     Train net output #0: loss = 5.05015e-005 (* 1 = 5.05015e-005 loss)
I1101 15:57:50.149291  8672 sgd_solver.cpp:106] Iteration 60100, lr = 0.0183463
I1101 15:58:06.016968  8672 solver.cpp:228] Iteration 60200, loss = 6.25931e-005
I1101 15:58:06.016968  8672 solver.cpp:244]     Train net output #0: loss = 6.25583e-005 (* 1 = 6.25583e-005 loss)
I1101 15:58:06.016968  8672 sgd_solver.cpp:106] Iteration 60200, lr = 0.0183439
I1101 15:58:21.902250  8672 solver.cpp:228] Iteration 60300, loss = 5.94719e-005
I1101 15:58:21.902250  8672 solver.cpp:244]     Train net output #0: loss = 5.9437e-005 (* 1 = 5.9437e-005 loss)
I1101 15:58:21.902250  8672 sgd_solver.cpp:106] Iteration 60300, lr = 0.0183414
I1101 15:58:37.730325  8672 solver.cpp:228] Iteration 60400, loss = 3.37198e-005
I1101 15:58:37.730325  8672 solver.cpp:244]     Train net output #0: loss = 3.36849e-005 (* 1 = 3.36849e-005 loss)
I1101 15:58:37.730325  8672 sgd_solver.cpp:106] Iteration 60400, lr = 0.0183389
I1101 15:58:53.653404  8672 solver.cpp:228] Iteration 60500, loss = 4.43726e-005
I1101 15:58:53.653404  8672 solver.cpp:244]     Train net output #0: loss = 4.43378e-005 (* 1 = 4.43378e-005 loss)
I1101 15:58:53.653404  8672 sgd_solver.cpp:106] Iteration 60500, lr = 0.0183364
I1101 15:59:09.439968  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_60600.caffemodel
I1101 15:59:09.561053  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_60600.solverstate
I1101 15:59:09.610090  8672 solver.cpp:337] Iteration 60600, Testing net (#0)
I1101 15:59:14.475378  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 15:59:14.475378  8672 solver.cpp:404]     Test net output #1: loss = 0.0128791 (* 1 = 0.0128791 loss)
I1101 15:59:14.542455  8672 solver.cpp:228] Iteration 60600, loss = 4.63925e-005
I1101 15:59:14.542455  8672 solver.cpp:244]     Train net output #0: loss = 4.63576e-005 (* 1 = 4.63576e-005 loss)
I1101 15:59:14.542455  8672 sgd_solver.cpp:106] Iteration 60600, lr = 0.0183339
I1101 15:59:30.373420  8672 solver.cpp:228] Iteration 60700, loss = 5.04963e-005
I1101 15:59:30.373420  8672 solver.cpp:244]     Train net output #0: loss = 5.04615e-005 (* 1 = 5.04615e-005 loss)
I1101 15:59:30.373420  8672 sgd_solver.cpp:106] Iteration 60700, lr = 0.0183315
I1101 15:59:46.305824  8672 solver.cpp:228] Iteration 60800, loss = 6.24749e-005
I1101 15:59:46.305824  8672 solver.cpp:244]     Train net output #0: loss = 6.24401e-005 (* 1 = 6.24401e-005 loss)
I1101 15:59:46.305824  8672 sgd_solver.cpp:106] Iteration 60800, lr = 0.018329
I1101 16:00:02.215086  8672 solver.cpp:228] Iteration 60900, loss = 5.94097e-005
I1101 16:00:02.215086  8672 solver.cpp:244]     Train net output #0: loss = 5.93749e-005 (* 1 = 5.93749e-005 loss)
I1101 16:00:02.215086  8672 sgd_solver.cpp:106] Iteration 60900, lr = 0.0183265
I1101 16:00:18.121202  8672 solver.cpp:228] Iteration 61000, loss = 3.37972e-005
I1101 16:00:18.121202  8672 solver.cpp:244]     Train net output #0: loss = 3.37624e-005 (* 1 = 3.37624e-005 loss)
I1101 16:00:18.121202  8672 sgd_solver.cpp:106] Iteration 61000, lr = 0.018324
I1101 16:00:34.090893  8672 solver.cpp:228] Iteration 61100, loss = 4.43487e-005
I1101 16:00:34.090893  8672 solver.cpp:244]     Train net output #0: loss = 4.43139e-005 (* 1 = 4.43139e-005 loss)
I1101 16:00:34.090893  8672 sgd_solver.cpp:106] Iteration 61100, lr = 0.0183215
I1101 16:00:49.993352  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_61200.caffemodel
I1101 16:00:50.177487  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_61200.solverstate
I1101 16:00:50.298970  8672 solver.cpp:337] Iteration 61200, Testing net (#0)
I1101 16:00:55.063407  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:00:55.063407  8672 solver.cpp:404]     Test net output #1: loss = 0.0128826 (* 1 = 0.0128826 loss)
I1101 16:00:55.132457  8672 solver.cpp:228] Iteration 61200, loss = 4.63596e-005
I1101 16:00:55.132957  8672 solver.cpp:244]     Train net output #0: loss = 4.63248e-005 (* 1 = 4.63248e-005 loss)
I1101 16:00:55.132957  8672 sgd_solver.cpp:106] Iteration 61200, lr = 0.0183191
I1101 16:01:11.287677  8672 solver.cpp:228] Iteration 61300, loss = 5.04712e-005
I1101 16:01:11.287677  8672 solver.cpp:244]     Train net output #0: loss = 5.04364e-005 (* 1 = 5.04364e-005 loss)
I1101 16:01:11.287677  8672 sgd_solver.cpp:106] Iteration 61300, lr = 0.0183166
I1101 16:01:27.956374  8672 solver.cpp:228] Iteration 61400, loss = 6.2358e-005
I1101 16:01:27.956374  8672 solver.cpp:244]     Train net output #0: loss = 6.23231e-005 (* 1 = 6.23231e-005 loss)
I1101 16:01:27.956374  8672 sgd_solver.cpp:106] Iteration 61400, lr = 0.0183141
I1101 16:01:44.588824  8672 solver.cpp:228] Iteration 61500, loss = 5.92694e-005
I1101 16:01:44.588824  8672 solver.cpp:244]     Train net output #0: loss = 5.92346e-005 (* 1 = 5.92346e-005 loss)
I1101 16:01:44.588824  8672 sgd_solver.cpp:106] Iteration 61500, lr = 0.0183116
I1101 16:02:00.981405  8672 solver.cpp:228] Iteration 61600, loss = 3.38831e-005
I1101 16:02:00.981405  8672 solver.cpp:244]     Train net output #0: loss = 3.38482e-005 (* 1 = 3.38482e-005 loss)
I1101 16:02:00.981405  8672 sgd_solver.cpp:106] Iteration 61600, lr = 0.0183091
I1101 16:02:17.389333  8672 solver.cpp:228] Iteration 61700, loss = 4.4295e-005
I1101 16:02:17.389333  8672 solver.cpp:244]     Train net output #0: loss = 4.42602e-005 (* 1 = 4.42602e-005 loss)
I1101 16:02:17.389333  8672 sgd_solver.cpp:106] Iteration 61700, lr = 0.0183067
I1101 16:02:33.688408  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_61800.caffemodel
I1101 16:02:33.828508  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_61800.solverstate
I1101 16:02:33.889050  8672 solver.cpp:337] Iteration 61800, Testing net (#0)
I1101 16:02:38.809926  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:02:38.809926  8672 solver.cpp:404]     Test net output #1: loss = 0.0128872 (* 1 = 0.0128872 loss)
I1101 16:02:38.878849  8672 solver.cpp:228] Iteration 61800, loss = 4.63167e-005
I1101 16:02:38.878849  8672 solver.cpp:244]     Train net output #0: loss = 4.62818e-005 (* 1 = 4.62818e-005 loss)
I1101 16:02:38.878849  8672 sgd_solver.cpp:106] Iteration 61800, lr = 0.0183042
I1101 16:02:55.261186  8672 solver.cpp:228] Iteration 61900, loss = 5.04353e-005
I1101 16:02:55.261186  8672 solver.cpp:244]     Train net output #0: loss = 5.04005e-005 (* 1 = 5.04005e-005 loss)
I1101 16:02:55.261186  8672 sgd_solver.cpp:106] Iteration 61900, lr = 0.0183017
I1101 16:03:11.602320  8672 solver.cpp:228] Iteration 62000, loss = 6.22506e-005
I1101 16:03:11.602320  8672 solver.cpp:244]     Train net output #0: loss = 6.22157e-005 (* 1 = 6.22157e-005 loss)
I1101 16:03:11.602320  8672 sgd_solver.cpp:106] Iteration 62000, lr = 0.0182992
I1101 16:03:27.975963  8672 solver.cpp:228] Iteration 62100, loss = 5.91888e-005
I1101 16:03:27.975963  8672 solver.cpp:244]     Train net output #0: loss = 5.9154e-005 (* 1 = 5.9154e-005 loss)
I1101 16:03:27.975963  8672 sgd_solver.cpp:106] Iteration 62100, lr = 0.0182967
I1101 16:03:44.376929  8672 solver.cpp:228] Iteration 62200, loss = 3.39892e-005
I1101 16:03:44.376929  8672 solver.cpp:244]     Train net output #0: loss = 3.39543e-005 (* 1 = 3.39543e-005 loss)
I1101 16:03:44.376929  8672 sgd_solver.cpp:106] Iteration 62200, lr = 0.0182943
I1101 16:04:00.751797  8672 solver.cpp:228] Iteration 62300, loss = 4.42938e-005
I1101 16:04:00.751797  8672 solver.cpp:244]     Train net output #0: loss = 4.4259e-005 (* 1 = 4.4259e-005 loss)
I1101 16:04:00.751797  8672 sgd_solver.cpp:106] Iteration 62300, lr = 0.0182918
I1101 16:04:17.111088  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_62400.caffemodel
I1101 16:04:17.350258  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_62400.solverstate
I1101 16:04:17.408802  8672 solver.cpp:337] Iteration 62400, Testing net (#0)
I1101 16:04:22.346057  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:04:22.346057  8672 solver.cpp:404]     Test net output #1: loss = 0.0128906 (* 1 = 0.0128906 loss)
I1101 16:04:22.415472  8672 solver.cpp:228] Iteration 62400, loss = 4.63143e-005
I1101 16:04:22.415472  8672 solver.cpp:244]     Train net output #0: loss = 4.62794e-005 (* 1 = 4.62794e-005 loss)
I1101 16:04:22.415472  8672 sgd_solver.cpp:106] Iteration 62400, lr = 0.0182893
I1101 16:04:38.788379  8672 solver.cpp:228] Iteration 62500, loss = 5.04209e-005
I1101 16:04:38.788379  8672 solver.cpp:244]     Train net output #0: loss = 5.03861e-005 (* 1 = 5.03861e-005 loss)
I1101 16:04:38.788379  8672 sgd_solver.cpp:106] Iteration 62500, lr = 0.0182868
I1101 16:04:55.149806  8672 solver.cpp:228] Iteration 62600, loss = 6.21455e-005
I1101 16:04:55.149806  8672 solver.cpp:244]     Train net output #0: loss = 6.21107e-005 (* 1 = 6.21107e-005 loss)
I1101 16:04:55.149806  8672 sgd_solver.cpp:106] Iteration 62600, lr = 0.0182843
I1101 16:05:11.487568  8672 solver.cpp:228] Iteration 62700, loss = 5.90444e-005
I1101 16:05:11.487568  8672 solver.cpp:244]     Train net output #0: loss = 5.90095e-005 (* 1 = 5.90095e-005 loss)
I1101 16:05:11.487568  8672 sgd_solver.cpp:106] Iteration 62700, lr = 0.0182819
I1101 16:05:27.815671  8672 solver.cpp:228] Iteration 62800, loss = 3.40881e-005
I1101 16:05:27.815671  8672 solver.cpp:244]     Train net output #0: loss = 3.40533e-005 (* 1 = 3.40533e-005 loss)
I1101 16:05:27.815671  8672 sgd_solver.cpp:106] Iteration 62800, lr = 0.0182794
I1101 16:05:44.200510  8672 solver.cpp:228] Iteration 62900, loss = 4.4246e-005
I1101 16:05:44.200510  8672 solver.cpp:244]     Train net output #0: loss = 4.42112e-005 (* 1 = 4.42112e-005 loss)
I1101 16:05:44.200510  8672 sgd_solver.cpp:106] Iteration 62900, lr = 0.0182769
I1101 16:06:00.464661  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_63000.caffemodel
I1101 16:06:00.597256  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_63000.solverstate
I1101 16:06:00.651295  8672 solver.cpp:337] Iteration 63000, Testing net (#0)
I1101 16:06:05.491430  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:06:05.491430  8672 solver.cpp:404]     Test net output #1: loss = 0.0128951 (* 1 = 0.0128951 loss)
I1101 16:06:05.559408  8672 solver.cpp:228] Iteration 63000, loss = 4.62629e-005
I1101 16:06:05.559908  8672 solver.cpp:244]     Train net output #0: loss = 4.62281e-005 (* 1 = 4.62281e-005 loss)
I1101 16:06:05.559908  8672 sgd_solver.cpp:106] Iteration 63000, lr = 0.0182744
I1101 16:06:21.911379  8672 solver.cpp:228] Iteration 63100, loss = 5.0363e-005
I1101 16:06:21.911379  8672 solver.cpp:244]     Train net output #0: loss = 5.03282e-005 (* 1 = 5.03282e-005 loss)
I1101 16:06:21.911379  8672 sgd_solver.cpp:106] Iteration 63100, lr = 0.018272
I1101 16:06:38.259814  8672 solver.cpp:228] Iteration 63200, loss = 6.20363e-005
I1101 16:06:38.259814  8672 solver.cpp:244]     Train net output #0: loss = 6.20015e-005 (* 1 = 6.20015e-005 loss)
I1101 16:06:38.259814  8672 sgd_solver.cpp:106] Iteration 63200, lr = 0.0182695
I1101 16:06:54.638171  8672 solver.cpp:228] Iteration 63300, loss = 5.89214e-005
I1101 16:06:54.638171  8672 solver.cpp:244]     Train net output #0: loss = 5.88866e-005 (* 1 = 5.88866e-005 loss)
I1101 16:06:54.638171  8672 sgd_solver.cpp:106] Iteration 63300, lr = 0.018267
I1101 16:07:10.965327  8672 solver.cpp:228] Iteration 63400, loss = 3.41656e-005
I1101 16:07:10.965327  8672 solver.cpp:244]     Train net output #0: loss = 3.41308e-005 (* 1 = 3.41308e-005 loss)
I1101 16:07:10.965327  8672 sgd_solver.cpp:106] Iteration 63400, lr = 0.0182645
I1101 16:07:27.292543  8672 solver.cpp:228] Iteration 63500, loss = 4.41822e-005
I1101 16:07:27.292543  8672 solver.cpp:244]     Train net output #0: loss = 4.41474e-005 (* 1 = 4.41474e-005 loss)
I1101 16:07:27.292543  8672 sgd_solver.cpp:106] Iteration 63500, lr = 0.018262
I1101 16:07:43.596422  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_63600.caffemodel
I1101 16:07:43.743027  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_63600.solverstate
I1101 16:07:43.800067  8672 solver.cpp:337] Iteration 63600, Testing net (#0)
I1101 16:07:48.716876  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:07:48.716876  8672 solver.cpp:404]     Test net output #1: loss = 0.0128986 (* 1 = 0.0128986 loss)
I1101 16:07:48.785300  8672 solver.cpp:228] Iteration 63600, loss = 4.62498e-005
I1101 16:07:48.785300  8672 solver.cpp:244]     Train net output #0: loss = 4.6215e-005 (* 1 = 4.6215e-005 loss)
I1101 16:07:48.785300  8672 sgd_solver.cpp:106] Iteration 63600, lr = 0.0182596
I1101 16:08:05.098434  8672 solver.cpp:228] Iteration 63700, loss = 5.03832e-005
I1101 16:08:05.098434  8672 solver.cpp:244]     Train net output #0: loss = 5.03484e-005 (* 1 = 5.03484e-005 loss)
I1101 16:08:05.098434  8672 sgd_solver.cpp:106] Iteration 63700, lr = 0.0182571
I1101 16:08:21.307849  8672 solver.cpp:228] Iteration 63800, loss = 6.19164e-005
I1101 16:08:21.307849  8672 solver.cpp:244]     Train net output #0: loss = 6.18816e-005 (* 1 = 6.18816e-005 loss)
I1101 16:08:21.307849  8672 sgd_solver.cpp:106] Iteration 63800, lr = 0.0182546
I1101 16:08:37.332969  8672 solver.cpp:228] Iteration 63900, loss = 5.87901e-005
I1101 16:08:37.332969  8672 solver.cpp:244]     Train net output #0: loss = 5.87552e-005 (* 1 = 5.87552e-005 loss)
I1101 16:08:37.332969  8672 sgd_solver.cpp:106] Iteration 63900, lr = 0.0182521
I1101 16:08:53.751410  8672 solver.cpp:228] Iteration 64000, loss = 3.42646e-005
I1101 16:08:53.751410  8672 solver.cpp:244]     Train net output #0: loss = 3.42297e-005 (* 1 = 3.42297e-005 loss)
I1101 16:08:53.751410  8672 sgd_solver.cpp:106] Iteration 64000, lr = 0.0182496
I1101 16:09:10.138658  8672 solver.cpp:228] Iteration 64100, loss = 4.41524e-005
I1101 16:09:10.138658  8672 solver.cpp:244]     Train net output #0: loss = 4.41175e-005 (* 1 = 4.41175e-005 loss)
I1101 16:09:10.138658  8672 sgd_solver.cpp:106] Iteration 64100, lr = 0.0182472
I1101 16:09:26.050822  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_64200.caffemodel
I1101 16:09:26.206933  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_64200.solverstate
I1101 16:09:26.271978  8672 solver.cpp:337] Iteration 64200, Testing net (#0)
I1101 16:09:31.182956  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:09:31.182956  8672 solver.cpp:404]     Test net output #1: loss = 0.0129016 (* 1 = 0.0129016 loss)
I1101 16:09:31.252373  8672 solver.cpp:228] Iteration 64200, loss = 4.62223e-005
I1101 16:09:31.252373  8672 solver.cpp:244]     Train net output #0: loss = 4.61875e-005 (* 1 = 4.61875e-005 loss)
I1101 16:09:31.252373  8672 sgd_solver.cpp:106] Iteration 64200, lr = 0.0182447
I1101 16:09:47.408689  8672 solver.cpp:228] Iteration 64300, loss = 5.03623e-005
I1101 16:09:47.408689  8672 solver.cpp:244]     Train net output #0: loss = 5.03274e-005 (* 1 = 5.03274e-005 loss)
I1101 16:09:47.408689  8672 sgd_solver.cpp:106] Iteration 64300, lr = 0.0182422
I1101 16:10:03.450220  8672 solver.cpp:228] Iteration 64400, loss = 6.17887e-005
I1101 16:10:03.450220  8672 solver.cpp:244]     Train net output #0: loss = 6.17539e-005 (* 1 = 6.17539e-005 loss)
I1101 16:10:03.450220  8672 sgd_solver.cpp:106] Iteration 64400, lr = 0.0182397
I1101 16:10:19.441138  8672 solver.cpp:228] Iteration 64500, loss = 5.87148e-005
I1101 16:10:19.441138  8672 solver.cpp:244]     Train net output #0: loss = 5.868e-005 (* 1 = 5.868e-005 loss)
I1101 16:10:19.441138  8672 sgd_solver.cpp:106] Iteration 64500, lr = 0.0182372
I1101 16:10:35.365322  8672 solver.cpp:228] Iteration 64600, loss = 3.43432e-005
I1101 16:10:35.365322  8672 solver.cpp:244]     Train net output #0: loss = 3.43084e-005 (* 1 = 3.43084e-005 loss)
I1101 16:10:35.365322  8672 sgd_solver.cpp:106] Iteration 64600, lr = 0.0182348
I1101 16:10:51.398360  8672 solver.cpp:228] Iteration 64700, loss = 4.41177e-005
I1101 16:10:51.398860  8672 solver.cpp:244]     Train net output #0: loss = 4.40829e-005 (* 1 = 4.40829e-005 loss)
I1101 16:10:51.398860  8672 sgd_solver.cpp:106] Iteration 64700, lr = 0.0182323
I1101 16:11:07.208380  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_64800.caffemodel
I1101 16:11:07.332469  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_64800.solverstate
I1101 16:11:07.387008  8672 solver.cpp:337] Iteration 64800, Testing net (#0)
I1101 16:11:12.261988  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:11:12.261988  8672 solver.cpp:404]     Test net output #1: loss = 0.012905 (* 1 = 0.012905 loss)
I1101 16:11:12.329133  8672 solver.cpp:228] Iteration 64800, loss = 4.62068e-005
I1101 16:11:12.329133  8672 solver.cpp:244]     Train net output #0: loss = 4.6172e-005 (* 1 = 4.6172e-005 loss)
I1101 16:11:12.329133  8672 sgd_solver.cpp:106] Iteration 64800, lr = 0.0182298
I1101 16:11:28.211035  8672 solver.cpp:228] Iteration 64900, loss = 5.03264e-005
I1101 16:11:28.211035  8672 solver.cpp:244]     Train net output #0: loss = 5.02916e-005 (* 1 = 5.02916e-005 loss)
I1101 16:11:28.211035  8672 sgd_solver.cpp:106] Iteration 64900, lr = 0.0182273
I1101 16:11:44.118217  8672 solver.cpp:228] Iteration 65000, loss = 6.16586e-005
I1101 16:11:44.118217  8672 solver.cpp:244]     Train net output #0: loss = 6.16238e-005 (* 1 = 6.16238e-005 loss)
I1101 16:11:44.118217  8672 sgd_solver.cpp:106] Iteration 65000, lr = 0.0182248
I1101 16:12:00.052996  8672 solver.cpp:228] Iteration 65100, loss = 5.85429e-005
I1101 16:12:00.053498  8672 solver.cpp:244]     Train net output #0: loss = 5.85081e-005 (* 1 = 5.85081e-005 loss)
I1101 16:12:00.053498  8672 sgd_solver.cpp:106] Iteration 65100, lr = 0.0182224
I1101 16:12:16.009496  8672 solver.cpp:228] Iteration 65200, loss = 3.44255e-005
I1101 16:12:16.009496  8672 solver.cpp:244]     Train net output #0: loss = 3.43907e-005 (* 1 = 3.43907e-005 loss)
I1101 16:12:16.009496  8672 sgd_solver.cpp:106] Iteration 65200, lr = 0.0182199
I1101 16:12:32.343055  8672 solver.cpp:228] Iteration 65300, loss = 4.40736e-005
I1101 16:12:32.343055  8672 solver.cpp:244]     Train net output #0: loss = 4.40387e-005 (* 1 = 4.40387e-005 loss)
I1101 16:12:32.343055  8672 sgd_solver.cpp:106] Iteration 65300, lr = 0.0182174
I1101 16:12:48.134768  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_65400.caffemodel
I1101 16:12:48.283083  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_65400.solverstate
I1101 16:12:48.328936  8672 solver.cpp:337] Iteration 65400, Testing net (#0)
I1101 16:12:52.978229  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:12:52.978229  8672 solver.cpp:404]     Test net output #1: loss = 0.0129081 (* 1 = 0.0129081 loss)
I1101 16:12:53.056391  8672 solver.cpp:228] Iteration 65400, loss = 4.61686e-005
I1101 16:12:53.056391  8672 solver.cpp:244]     Train net output #0: loss = 4.61338e-005 (* 1 = 4.61338e-005 loss)
I1101 16:12:53.056391  8672 sgd_solver.cpp:106] Iteration 65400, lr = 0.0182149
I1101 16:13:08.890869  8672 solver.cpp:228] Iteration 65500, loss = 5.03174e-005
I1101 16:13:08.890869  8672 solver.cpp:244]     Train net output #0: loss = 5.02826e-005 (* 1 = 5.02826e-005 loss)
I1101 16:13:08.890869  8672 sgd_solver.cpp:106] Iteration 65500, lr = 0.0182124
I1101 16:13:24.589821  8672 solver.cpp:228] Iteration 65600, loss = 6.15512e-005
I1101 16:13:24.589821  8672 solver.cpp:244]     Train net output #0: loss = 6.15164e-005 (* 1 = 6.15164e-005 loss)
I1101 16:13:24.589821  8672 sgd_solver.cpp:106] Iteration 65600, lr = 0.01821
I1101 16:13:40.232775  8672 solver.cpp:228] Iteration 65700, loss = 5.84349e-005
I1101 16:13:40.232775  8672 solver.cpp:244]     Train net output #0: loss = 5.84001e-005 (* 1 = 5.84001e-005 loss)
I1101 16:13:40.232775  8672 sgd_solver.cpp:106] Iteration 65700, lr = 0.0182075
I1101 16:13:55.773958  8672 solver.cpp:228] Iteration 65800, loss = 3.45042e-005
I1101 16:13:55.773958  8672 solver.cpp:244]     Train net output #0: loss = 3.44693e-005 (* 1 = 3.44693e-005 loss)
I1101 16:13:55.773958  8672 sgd_solver.cpp:106] Iteration 65800, lr = 0.018205
I1101 16:14:11.298985  8672 solver.cpp:228] Iteration 65900, loss = 4.40258e-005
I1101 16:14:11.298985  8672 solver.cpp:244]     Train net output #0: loss = 4.3991e-005 (* 1 = 4.3991e-005 loss)
I1101 16:14:11.298985  8672 sgd_solver.cpp:106] Iteration 65900, lr = 0.0182025
I1101 16:14:26.759086  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_66000.caffemodel
I1101 16:14:26.884088  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_66000.solverstate
I1101 16:14:26.933202  8672 solver.cpp:337] Iteration 66000, Testing net (#0)
I1101 16:14:31.628604  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:14:31.628604  8672 solver.cpp:404]     Test net output #1: loss = 0.0129122 (* 1 = 0.0129122 loss)
I1101 16:14:31.706903  8672 solver.cpp:228] Iteration 66000, loss = 4.61549e-005
I1101 16:14:31.706903  8672 solver.cpp:244]     Train net output #0: loss = 4.612e-005 (* 1 = 4.612e-005 loss)
I1101 16:14:31.706903  8672 sgd_solver.cpp:106] Iteration 66000, lr = 0.0182
I1101 16:14:47.262845  8672 solver.cpp:228] Iteration 66100, loss = 5.03126e-005
I1101 16:14:47.262845  8672 solver.cpp:244]     Train net output #0: loss = 5.02778e-005 (* 1 = 5.02778e-005 loss)
I1101 16:14:47.262845  8672 sgd_solver.cpp:106] Iteration 66100, lr = 0.0181976
I1101 16:15:03.038509  8672 solver.cpp:228] Iteration 66200, loss = 6.14653e-005
I1101 16:15:03.038509  8672 solver.cpp:244]     Train net output #0: loss = 6.14305e-005 (* 1 = 6.14305e-005 loss)
I1101 16:15:03.038509  8672 sgd_solver.cpp:106] Iteration 66200, lr = 0.0181951
I1101 16:15:18.627154  8672 solver.cpp:228] Iteration 66300, loss = 5.83101e-005
I1101 16:15:18.627154  8672 solver.cpp:244]     Train net output #0: loss = 5.82753e-005 (* 1 = 5.82753e-005 loss)
I1101 16:15:18.627154  8672 sgd_solver.cpp:106] Iteration 66300, lr = 0.0181926
I1101 16:15:34.229141  8672 solver.cpp:228] Iteration 66400, loss = 3.4584e-005
I1101 16:15:34.229141  8672 solver.cpp:244]     Train net output #0: loss = 3.45492e-005 (* 1 = 3.45492e-005 loss)
I1101 16:15:34.229141  8672 sgd_solver.cpp:106] Iteration 66400, lr = 0.0181901
I1101 16:15:49.772694  8672 solver.cpp:228] Iteration 66500, loss = 4.39888e-005
I1101 16:15:49.772694  8672 solver.cpp:244]     Train net output #0: loss = 4.3954e-005 (* 1 = 4.3954e-005 loss)
I1101 16:15:49.772694  8672 sgd_solver.cpp:106] Iteration 66500, lr = 0.0181876
I1101 16:16:05.343432  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_66600.caffemodel
I1101 16:16:05.465533  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_66600.solverstate
I1101 16:16:05.512552  8672 solver.cpp:337] Iteration 66600, Testing net (#0)
I1101 16:16:10.213739  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:16:10.214241  8672 solver.cpp:404]     Test net output #1: loss = 0.0129147 (* 1 = 0.0129147 loss)
I1101 16:16:10.279577  8672 solver.cpp:228] Iteration 66600, loss = 4.61358e-005
I1101 16:16:10.279577  8672 solver.cpp:244]     Train net output #0: loss = 4.61009e-005 (* 1 = 4.61009e-005 loss)
I1101 16:16:10.279577  8672 sgd_solver.cpp:106] Iteration 66600, lr = 0.0181852
I1101 16:16:25.920712  8672 solver.cpp:228] Iteration 66700, loss = 5.02636e-005
I1101 16:16:25.920712  8672 solver.cpp:244]     Train net output #0: loss = 5.02288e-005 (* 1 = 5.02288e-005 loss)
I1101 16:16:25.920712  8672 sgd_solver.cpp:106] Iteration 66700, lr = 0.0181827
I1101 16:16:41.463449  8672 solver.cpp:228] Iteration 66800, loss = 6.13507e-005
I1101 16:16:41.463449  8672 solver.cpp:244]     Train net output #0: loss = 6.13159e-005 (* 1 = 6.13159e-005 loss)
I1101 16:16:41.463449  8672 sgd_solver.cpp:106] Iteration 66800, lr = 0.0181802
I1101 16:16:57.210198  8672 solver.cpp:228] Iteration 66900, loss = 5.82206e-005
I1101 16:16:57.210198  8672 solver.cpp:244]     Train net output #0: loss = 5.81857e-005 (* 1 = 5.81857e-005 loss)
I1101 16:16:57.210198  8672 sgd_solver.cpp:106] Iteration 66900, lr = 0.0181777
I1101 16:17:12.971251  8672 solver.cpp:228] Iteration 67000, loss = 3.46603e-005
I1101 16:17:12.971251  8672 solver.cpp:244]     Train net output #0: loss = 3.46255e-005 (* 1 = 3.46255e-005 loss)
I1101 16:17:12.971251  8672 sgd_solver.cpp:106] Iteration 67000, lr = 0.0181752
I1101 16:17:28.958096  8672 solver.cpp:228] Iteration 67100, loss = 4.3947e-005
I1101 16:17:28.958096  8672 solver.cpp:244]     Train net output #0: loss = 4.39122e-005 (* 1 = 4.39122e-005 loss)
I1101 16:17:28.958096  8672 sgd_solver.cpp:106] Iteration 67100, lr = 0.0181728
I1101 16:17:44.674108  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_67200.caffemodel
I1101 16:17:44.799098  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_67200.solverstate
I1101 16:17:44.845973  8672 solver.cpp:337] Iteration 67200, Testing net (#0)
I1101 16:17:49.528261  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:17:49.528261  8672 solver.cpp:404]     Test net output #1: loss = 0.0129185 (* 1 = 0.0129185 loss)
I1101 16:17:49.606400  8672 solver.cpp:228] Iteration 67200, loss = 4.6119e-005
I1101 16:17:49.606400  8672 solver.cpp:244]     Train net output #0: loss = 4.60842e-005 (* 1 = 4.60842e-005 loss)
I1101 16:17:49.606400  8672 sgd_solver.cpp:106] Iteration 67200, lr = 0.0181703
I1101 16:18:05.158849  8672 solver.cpp:228] Iteration 67300, loss = 5.02433e-005
I1101 16:18:05.158849  8672 solver.cpp:244]     Train net output #0: loss = 5.02085e-005 (* 1 = 5.02085e-005 loss)
I1101 16:18:05.158849  8672 sgd_solver.cpp:106] Iteration 67300, lr = 0.0181678
I1101 16:18:20.746167  8672 solver.cpp:228] Iteration 67400, loss = 6.12451e-005
I1101 16:18:20.746167  8672 solver.cpp:244]     Train net output #0: loss = 6.12103e-005 (* 1 = 6.12103e-005 loss)
I1101 16:18:20.746167  8672 sgd_solver.cpp:106] Iteration 67400, lr = 0.0181653
I1101 16:18:36.364047  8672 solver.cpp:228] Iteration 67500, loss = 5.80761e-005
I1101 16:18:36.364047  8672 solver.cpp:244]     Train net output #0: loss = 5.80413e-005 (* 1 = 5.80413e-005 loss)
I1101 16:18:36.364047  8672 sgd_solver.cpp:106] Iteration 67500, lr = 0.0181629
I1101 16:18:51.942621  8672 solver.cpp:228] Iteration 67600, loss = 3.4739e-005
I1101 16:18:51.942621  8672 solver.cpp:244]     Train net output #0: loss = 3.47042e-005 (* 1 = 3.47042e-005 loss)
I1101 16:18:51.942621  8672 sgd_solver.cpp:106] Iteration 67600, lr = 0.0181604
I1101 16:19:07.728508  8672 solver.cpp:228] Iteration 67700, loss = 4.39076e-005
I1101 16:19:07.728508  8672 solver.cpp:244]     Train net output #0: loss = 4.38728e-005 (* 1 = 4.38728e-005 loss)
I1101 16:19:07.728508  8672 sgd_solver.cpp:106] Iteration 67700, lr = 0.0181579
I1101 16:19:23.534384  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_67800.caffemodel
I1101 16:19:23.656591  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_67800.solverstate
I1101 16:19:23.705545  8672 solver.cpp:337] Iteration 67800, Testing net (#0)
I1101 16:19:28.515538  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9973
I1101 16:19:28.516039  8672 solver.cpp:404]     Test net output #1: loss = 0.0129216 (* 1 = 0.0129216 loss)
I1101 16:19:28.582291  8672 solver.cpp:228] Iteration 67800, loss = 4.61035e-005
I1101 16:19:28.582291  8672 solver.cpp:244]     Train net output #0: loss = 4.60687e-005 (* 1 = 4.60687e-005 loss)
I1101 16:19:28.582291  8672 sgd_solver.cpp:106] Iteration 67800, lr = 0.0181554
I1101 16:19:44.150315  8672 solver.cpp:228] Iteration 67900, loss = 5.02372e-005
I1101 16:19:44.150315  8672 solver.cpp:244]     Train net output #0: loss = 5.02024e-005 (* 1 = 5.02024e-005 loss)
I1101 16:19:44.150315  8672 sgd_solver.cpp:106] Iteration 67900, lr = 0.0181529
I1101 16:19:59.664755  8672 solver.cpp:228] Iteration 68000, loss = 6.11431e-005
I1101 16:19:59.664755  8672 solver.cpp:244]     Train net output #0: loss = 6.11082e-005 (* 1 = 6.11082e-005 loss)
I1101 16:19:59.664755  8672 sgd_solver.cpp:106] Iteration 68000, lr = 0.0181505
I1101 16:20:15.201759  8672 solver.cpp:228] Iteration 68100, loss = 5.798e-005
I1101 16:20:15.201759  8672 solver.cpp:244]     Train net output #0: loss = 5.79452e-005 (* 1 = 5.79452e-005 loss)
I1101 16:20:15.201759  8672 sgd_solver.cpp:106] Iteration 68100, lr = 0.018148
I1101 16:20:30.676026  8672 solver.cpp:228] Iteration 68200, loss = 3.48022e-005
I1101 16:20:30.676026  8672 solver.cpp:244]     Train net output #0: loss = 3.47673e-005 (* 1 = 3.47673e-005 loss)
I1101 16:20:30.676026  8672 sgd_solver.cpp:106] Iteration 68200, lr = 0.0181455
I1101 16:20:46.161761  8672 solver.cpp:228] Iteration 68300, loss = 4.38629e-005
I1101 16:20:46.161761  8672 solver.cpp:244]     Train net output #0: loss = 4.38281e-005 (* 1 = 4.38281e-005 loss)
I1101 16:20:46.161761  8672 sgd_solver.cpp:106] Iteration 68300, lr = 0.018143
I1101 16:21:01.556596  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_68400.caffemodel
I1101 16:21:01.672066  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_68400.solverstate
I1101 16:21:01.718941  8672 solver.cpp:337] Iteration 68400, Testing net (#0)
I1101 16:21:06.391525  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:21:06.391525  8672 solver.cpp:404]     Test net output #1: loss = 0.0129246 (* 1 = 0.0129246 loss)
I1101 16:21:06.469655  8672 solver.cpp:228] Iteration 68400, loss = 4.61047e-005
I1101 16:21:06.469655  8672 solver.cpp:244]     Train net output #0: loss = 4.60698e-005 (* 1 = 4.60698e-005 loss)
I1101 16:21:06.469655  8672 sgd_solver.cpp:106] Iteration 68400, lr = 0.0181405
I1101 16:21:21.995292  8672 solver.cpp:228] Iteration 68500, loss = 5.02623e-005
I1101 16:21:21.995292  8672 solver.cpp:244]     Train net output #0: loss = 5.02274e-005 (* 1 = 5.02274e-005 loss)
I1101 16:21:21.995292  8672 sgd_solver.cpp:106] Iteration 68500, lr = 0.0181381
I1101 16:21:37.530436  8672 solver.cpp:228] Iteration 68600, loss = 6.10523e-005
I1101 16:21:37.530436  8672 solver.cpp:244]     Train net output #0: loss = 6.10175e-005 (* 1 = 6.10175e-005 loss)
I1101 16:21:37.530436  8672 sgd_solver.cpp:106] Iteration 68600, lr = 0.0181356
I1101 16:21:53.041754  8672 solver.cpp:228] Iteration 68700, loss = 5.78749e-005
I1101 16:21:53.041754  8672 solver.cpp:244]     Train net output #0: loss = 5.78401e-005 (* 1 = 5.78401e-005 loss)
I1101 16:21:53.041754  8672 sgd_solver.cpp:106] Iteration 68700, lr = 0.0181331
I1101 16:22:08.530939  8672 solver.cpp:228] Iteration 68800, loss = 3.48689e-005
I1101 16:22:08.530939  8672 solver.cpp:244]     Train net output #0: loss = 3.48341e-005 (* 1 = 3.48341e-005 loss)
I1101 16:22:08.530939  8672 sgd_solver.cpp:106] Iteration 68800, lr = 0.0181306
I1101 16:22:24.002744  8672 solver.cpp:228] Iteration 68900, loss = 4.38384e-005
I1101 16:22:24.002744  8672 solver.cpp:244]     Train net output #0: loss = 4.38036e-005 (* 1 = 4.38036e-005 loss)
I1101 16:22:24.002744  8672 sgd_solver.cpp:106] Iteration 68900, lr = 0.0181281
I1101 16:22:39.389302  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_69000.caffemodel
I1101 16:22:39.514292  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_69000.solverstate
I1101 16:22:39.565346  8672 solver.cpp:337] Iteration 69000, Testing net (#0)
I1101 16:22:44.237471  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:22:44.237471  8672 solver.cpp:404]     Test net output #1: loss = 0.0129291 (* 1 = 0.0129291 loss)
I1101 16:22:44.302047  8672 solver.cpp:228] Iteration 69000, loss = 4.60569e-005
I1101 16:22:44.302047  8672 solver.cpp:244]     Train net output #0: loss = 4.60221e-005 (* 1 = 4.60221e-005 loss)
I1101 16:22:44.302047  8672 sgd_solver.cpp:106] Iteration 69000, lr = 0.0181257
I1101 16:22:59.816500  8672 solver.cpp:228] Iteration 69100, loss = 5.0221e-005
I1101 16:22:59.816500  8672 solver.cpp:244]     Train net output #0: loss = 5.01862e-005 (* 1 = 5.01862e-005 loss)
I1101 16:22:59.816500  8672 sgd_solver.cpp:106] Iteration 69100, lr = 0.0181232
I1101 16:23:15.308338  8672 solver.cpp:228] Iteration 69200, loss = 6.09223e-005
I1101 16:23:15.308338  8672 solver.cpp:244]     Train net output #0: loss = 6.08875e-005 (* 1 = 6.08875e-005 loss)
I1101 16:23:15.308338  8672 sgd_solver.cpp:106] Iteration 69200, lr = 0.0181207
I1101 16:23:30.792757  8672 solver.cpp:228] Iteration 69300, loss = 5.78129e-005
I1101 16:23:30.792757  8672 solver.cpp:244]     Train net output #0: loss = 5.7778e-005 (* 1 = 5.7778e-005 loss)
I1101 16:23:30.792757  8672 sgd_solver.cpp:106] Iteration 69300, lr = 0.0181182
I1101 16:23:46.298568  8672 solver.cpp:228] Iteration 69400, loss = 3.49547e-005
I1101 16:23:46.298568  8672 solver.cpp:244]     Train net output #0: loss = 3.49199e-005 (* 1 = 3.49199e-005 loss)
I1101 16:23:46.298568  8672 sgd_solver.cpp:106] Iteration 69400, lr = 0.0181157
I1101 16:24:01.768882  8672 solver.cpp:228] Iteration 69500, loss = 4.37996e-005
I1101 16:24:01.768882  8672 solver.cpp:244]     Train net output #0: loss = 4.37648e-005 (* 1 = 4.37648e-005 loss)
I1101 16:24:01.768882  8672 sgd_solver.cpp:106] Iteration 69500, lr = 0.0181133
I1101 16:24:17.192759  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_69600.caffemodel
I1101 16:24:17.317761  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_69600.solverstate
I1101 16:24:17.364636  8672 solver.cpp:337] Iteration 69600, Testing net (#0)
I1101 16:24:22.009840  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:24:22.009840  8672 solver.cpp:404]     Test net output #1: loss = 0.0129316 (* 1 = 0.0129316 loss)
I1101 16:24:22.104202  8672 solver.cpp:228] Iteration 69600, loss = 4.60378e-005
I1101 16:24:22.104202  8672 solver.cpp:244]     Train net output #0: loss = 4.6003e-005 (* 1 = 4.6003e-005 loss)
I1101 16:24:22.104202  8672 sgd_solver.cpp:106] Iteration 69600, lr = 0.0181108
I1101 16:24:37.596329  8672 solver.cpp:228] Iteration 69700, loss = 5.02461e-005
I1101 16:24:37.596329  8672 solver.cpp:244]     Train net output #0: loss = 5.02112e-005 (* 1 = 5.02112e-005 loss)
I1101 16:24:37.596329  8672 sgd_solver.cpp:106] Iteration 69700, lr = 0.0181083
I1101 16:24:53.075819  8672 solver.cpp:228] Iteration 69800, loss = 6.08256e-005
I1101 16:24:53.075819  8672 solver.cpp:244]     Train net output #0: loss = 6.07908e-005 (* 1 = 6.07908e-005 loss)
I1101 16:24:53.075819  8672 sgd_solver.cpp:106] Iteration 69800, lr = 0.0181058
I1101 16:25:08.561014  8672 solver.cpp:228] Iteration 69900, loss = 5.76785e-005
I1101 16:25:08.561014  8672 solver.cpp:244]     Train net output #0: loss = 5.76437e-005 (* 1 = 5.76437e-005 loss)
I1101 16:25:08.561014  8672 sgd_solver.cpp:106] Iteration 69900, lr = 0.0181033
I1101 16:25:24.040302  8672 solver.cpp:228] Iteration 70000, loss = 3.50298e-005
I1101 16:25:24.040302  8672 solver.cpp:244]     Train net output #0: loss = 3.4995e-005 (* 1 = 3.4995e-005 loss)
I1101 16:25:24.040302  8672 sgd_solver.cpp:106] Iteration 70000, lr = 0.0181009
I1101 16:25:39.513653  8672 solver.cpp:228] Iteration 70100, loss = 4.37638e-005
I1101 16:25:39.513653  8672 solver.cpp:244]     Train net output #0: loss = 4.3729e-005 (* 1 = 4.3729e-005 loss)
I1101 16:25:39.513653  8672 sgd_solver.cpp:106] Iteration 70100, lr = 0.0180984
I1101 16:25:54.897042  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_70200.caffemodel
I1101 16:25:55.022032  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_70200.solverstate
I1101 16:25:55.068907  8672 solver.cpp:337] Iteration 70200, Testing net (#0)
I1101 16:25:59.769021  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:25:59.769021  8672 solver.cpp:404]     Test net output #1: loss = 0.0129349 (* 1 = 0.0129349 loss)
I1101 16:25:59.847149  8672 solver.cpp:228] Iteration 70200, loss = 4.59948e-005
I1101 16:25:59.847149  8672 solver.cpp:244]     Train net output #0: loss = 4.596e-005 (* 1 = 4.596e-005 loss)
I1101 16:25:59.847149  8672 sgd_solver.cpp:106] Iteration 70200, lr = 0.0180959
I1101 16:26:15.318019  8672 solver.cpp:228] Iteration 70300, loss = 5.02018e-005
I1101 16:26:15.318019  8672 solver.cpp:244]     Train net output #0: loss = 5.0167e-005 (* 1 = 5.0167e-005 loss)
I1101 16:26:15.318019  8672 sgd_solver.cpp:106] Iteration 70300, lr = 0.0180934
I1101 16:26:30.786814  8672 solver.cpp:228] Iteration 70400, loss = 6.06705e-005
I1101 16:26:30.786814  8672 solver.cpp:244]     Train net output #0: loss = 6.06357e-005 (* 1 = 6.06357e-005 loss)
I1101 16:26:30.786814  8672 sgd_solver.cpp:106] Iteration 70400, lr = 0.0180909
I1101 16:26:46.296450  8672 solver.cpp:228] Iteration 70500, loss = 5.76642e-005
I1101 16:26:46.296450  8672 solver.cpp:244]     Train net output #0: loss = 5.76294e-005 (* 1 = 5.76294e-005 loss)
I1101 16:26:46.296450  8672 sgd_solver.cpp:106] Iteration 70500, lr = 0.0180885
I1101 16:27:01.765321  8672 solver.cpp:228] Iteration 70600, loss = 3.50966e-005
I1101 16:27:01.765321  8672 solver.cpp:244]     Train net output #0: loss = 3.50618e-005 (* 1 = 3.50618e-005 loss)
I1101 16:27:01.765321  8672 sgd_solver.cpp:106] Iteration 70600, lr = 0.018086
I1101 16:27:17.212654  8672 solver.cpp:228] Iteration 70700, loss = 4.37172e-005
I1101 16:27:17.212654  8672 solver.cpp:244]     Train net output #0: loss = 4.36824e-005 (* 1 = 4.36824e-005 loss)
I1101 16:27:17.212654  8672 sgd_solver.cpp:106] Iteration 70700, lr = 0.0180835
I1101 16:27:32.615981  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_70800.caffemodel
I1101 16:27:32.740970  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_70800.solverstate
I1101 16:27:32.791121  8672 solver.cpp:337] Iteration 70800, Testing net (#0)
I1101 16:27:37.472201  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:27:37.472201  8672 solver.cpp:404]     Test net output #1: loss = 0.0129383 (* 1 = 0.0129383 loss)
I1101 16:27:37.554654  8672 solver.cpp:228] Iteration 70800, loss = 4.59579e-005
I1101 16:27:37.554654  8672 solver.cpp:244]     Train net output #0: loss = 4.59231e-005 (* 1 = 4.59231e-005 loss)
I1101 16:27:37.554654  8672 sgd_solver.cpp:106] Iteration 70800, lr = 0.018081
I1101 16:27:53.040266  8672 solver.cpp:228] Iteration 70900, loss = 5.02209e-005
I1101 16:27:53.040266  8672 solver.cpp:244]     Train net output #0: loss = 5.01861e-005 (* 1 = 5.01861e-005 loss)
I1101 16:27:53.040266  8672 sgd_solver.cpp:106] Iteration 70900, lr = 0.0180785
I1101 16:28:08.619137  8672 solver.cpp:228] Iteration 71000, loss = 6.05917e-005
I1101 16:28:08.619137  8672 solver.cpp:244]     Train net output #0: loss = 6.05569e-005 (* 1 = 6.05569e-005 loss)
I1101 16:28:08.619137  8672 sgd_solver.cpp:106] Iteration 71000, lr = 0.0180761
I1101 16:28:24.103086  8672 solver.cpp:228] Iteration 71100, loss = 5.75532e-005
I1101 16:28:24.103086  8672 solver.cpp:244]     Train net output #0: loss = 5.75184e-005 (* 1 = 5.75184e-005 loss)
I1101 16:28:24.103086  8672 sgd_solver.cpp:106] Iteration 71100, lr = 0.0180736
I1101 16:28:39.570974  8672 solver.cpp:228] Iteration 71200, loss = 3.51669e-005
I1101 16:28:39.570974  8672 solver.cpp:244]     Train net output #0: loss = 3.51321e-005 (* 1 = 3.51321e-005 loss)
I1101 16:28:39.570974  8672 sgd_solver.cpp:106] Iteration 71200, lr = 0.0180711
I1101 16:28:55.076360  8672 solver.cpp:228] Iteration 71300, loss = 4.36635e-005
I1101 16:28:55.076360  8672 solver.cpp:244]     Train net output #0: loss = 4.36287e-005 (* 1 = 4.36287e-005 loss)
I1101 16:28:55.076360  8672 sgd_solver.cpp:106] Iteration 71300, lr = 0.0180686
I1101 16:29:10.473213  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_71400.caffemodel
I1101 16:29:10.582592  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_71400.solverstate
I1101 16:29:10.645092  8672 solver.cpp:337] Iteration 71400, Testing net (#0)
I1101 16:29:15.313637  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:29:15.313637  8672 solver.cpp:404]     Test net output #1: loss = 0.0129405 (* 1 = 0.0129405 loss)
I1101 16:29:15.391765  8672 solver.cpp:228] Iteration 71400, loss = 4.59113e-005
I1101 16:29:15.391765  8672 solver.cpp:244]     Train net output #0: loss = 4.58765e-005 (* 1 = 4.58765e-005 loss)
I1101 16:29:15.391765  8672 sgd_solver.cpp:106] Iteration 71400, lr = 0.0180661
I1101 16:29:30.892303  8672 solver.cpp:228] Iteration 71500, loss = 5.02154e-005
I1101 16:29:30.892303  8672 solver.cpp:244]     Train net output #0: loss = 5.01806e-005 (* 1 = 5.01806e-005 loss)
I1101 16:29:30.892303  8672 sgd_solver.cpp:106] Iteration 71500, lr = 0.0180637
I1101 16:29:46.408896  8672 solver.cpp:228] Iteration 71600, loss = 6.04539e-005
I1101 16:29:46.408896  8672 solver.cpp:244]     Train net output #0: loss = 6.04191e-005 (* 1 = 6.04191e-005 loss)
I1101 16:29:46.408896  8672 sgd_solver.cpp:106] Iteration 71600, lr = 0.0180612
I1101 16:30:01.835566  8672 solver.cpp:228] Iteration 71700, loss = 5.75054e-005
I1101 16:30:01.835566  8672 solver.cpp:244]     Train net output #0: loss = 5.74706e-005 (* 1 = 5.74706e-005 loss)
I1101 16:30:01.835566  8672 sgd_solver.cpp:106] Iteration 71700, lr = 0.0180587
I1101 16:30:17.266683  8672 solver.cpp:228] Iteration 71800, loss = 3.52396e-005
I1101 16:30:17.266683  8672 solver.cpp:244]     Train net output #0: loss = 3.52048e-005 (* 1 = 3.52048e-005 loss)
I1101 16:30:17.266683  8672 sgd_solver.cpp:106] Iteration 71800, lr = 0.0180562
I1101 16:30:32.722589  8672 solver.cpp:228] Iteration 71900, loss = 4.36289e-005
I1101 16:30:32.722589  8672 solver.cpp:244]     Train net output #0: loss = 4.35941e-005 (* 1 = 4.35941e-005 loss)
I1101 16:30:32.722589  8672 sgd_solver.cpp:106] Iteration 71900, lr = 0.0180537
I1101 16:30:48.108141  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_72000.caffemodel
I1101 16:30:48.235400  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_72000.solverstate
I1101 16:30:48.282275  8672 solver.cpp:337] Iteration 72000, Testing net (#0)
I1101 16:30:52.945312  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:30:52.945312  8672 solver.cpp:404]     Test net output #1: loss = 0.0129449 (* 1 = 0.0129449 loss)
I1101 16:30:53.023437  8672 solver.cpp:228] Iteration 72000, loss = 4.58851e-005
I1101 16:30:53.023437  8672 solver.cpp:244]     Train net output #0: loss = 4.58503e-005 (* 1 = 4.58503e-005 loss)
I1101 16:30:53.023437  8672 sgd_solver.cpp:106] Iteration 72000, lr = 0.0180513
I1101 16:31:08.470832  8672 solver.cpp:228] Iteration 72100, loss = 5.02178e-005
I1101 16:31:08.470832  8672 solver.cpp:244]     Train net output #0: loss = 5.0183e-005 (* 1 = 5.0183e-005 loss)
I1101 16:31:08.470832  8672 sgd_solver.cpp:106] Iteration 72100, lr = 0.0180488
I1101 16:31:23.918648  8672 solver.cpp:228] Iteration 72200, loss = 6.03578e-005
I1101 16:31:23.918648  8672 solver.cpp:244]     Train net output #0: loss = 6.0323e-005 (* 1 = 6.0323e-005 loss)
I1101 16:31:23.918648  8672 sgd_solver.cpp:106] Iteration 72200, lr = 0.0180463
I1101 16:31:39.391381  8672 solver.cpp:228] Iteration 72300, loss = 5.74117e-005
I1101 16:31:39.391381  8672 solver.cpp:244]     Train net output #0: loss = 5.73769e-005 (* 1 = 5.73769e-005 loss)
I1101 16:31:39.391381  8672 sgd_solver.cpp:106] Iteration 72300, lr = 0.0180438
I1101 16:31:54.845530  8672 solver.cpp:228] Iteration 72400, loss = 3.53123e-005
I1101 16:31:54.845530  8672 solver.cpp:244]     Train net output #0: loss = 3.52775e-005 (* 1 = 3.52775e-005 loss)
I1101 16:31:54.845530  8672 sgd_solver.cpp:106] Iteration 72400, lr = 0.0180414
I1101 16:32:10.335753  8672 solver.cpp:228] Iteration 72500, loss = 4.35883e-005
I1101 16:32:10.335753  8672 solver.cpp:244]     Train net output #0: loss = 4.35535e-005 (* 1 = 4.35535e-005 loss)
I1101 16:32:10.335753  8672 sgd_solver.cpp:106] Iteration 72500, lr = 0.0180389
I1101 16:32:25.717173  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_72600.caffemodel
I1101 16:32:25.826552  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_72600.solverstate
I1101 16:32:25.873426  8672 solver.cpp:337] Iteration 72600, Testing net (#0)
I1101 16:32:30.531311  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:32:30.531311  8672 solver.cpp:404]     Test net output #1: loss = 0.0129486 (* 1 = 0.0129486 loss)
I1101 16:32:30.609459  8672 solver.cpp:228] Iteration 72600, loss = 4.58576e-005
I1101 16:32:30.609459  8672 solver.cpp:244]     Train net output #0: loss = 4.58228e-005 (* 1 = 4.58228e-005 loss)
I1101 16:32:30.609459  8672 sgd_solver.cpp:106] Iteration 72600, lr = 0.0180364
I1101 16:32:46.063290  8672 solver.cpp:228] Iteration 72700, loss = 5.02237e-005
I1101 16:32:46.063290  8672 solver.cpp:244]     Train net output #0: loss = 5.01889e-005 (* 1 = 5.01889e-005 loss)
I1101 16:32:46.063290  8672 sgd_solver.cpp:106] Iteration 72700, lr = 0.0180339
I1101 16:33:01.530652  8672 solver.cpp:228] Iteration 72800, loss = 6.02397e-005
I1101 16:33:01.530652  8672 solver.cpp:244]     Train net output #0: loss = 6.02049e-005 (* 1 = 6.02049e-005 loss)
I1101 16:33:01.530652  8672 sgd_solver.cpp:106] Iteration 72800, lr = 0.0180314
I1101 16:33:16.980618  8672 solver.cpp:228] Iteration 72900, loss = 5.73365e-005
I1101 16:33:16.980618  8672 solver.cpp:244]     Train net output #0: loss = 5.73017e-005 (* 1 = 5.73017e-005 loss)
I1101 16:33:16.980618  8672 sgd_solver.cpp:106] Iteration 72900, lr = 0.018029
I1101 16:33:32.390198  8672 solver.cpp:228] Iteration 73000, loss = 3.53815e-005
I1101 16:33:32.390198  8672 solver.cpp:244]     Train net output #0: loss = 3.53467e-005 (* 1 = 3.53467e-005 loss)
I1101 16:33:32.390198  8672 sgd_solver.cpp:106] Iteration 73000, lr = 0.0180265
I1101 16:33:47.841717  8672 solver.cpp:228] Iteration 73100, loss = 4.35609e-005
I1101 16:33:47.841717  8672 solver.cpp:244]     Train net output #0: loss = 4.35261e-005 (* 1 = 4.35261e-005 loss)
I1101 16:33:47.841717  8672 sgd_solver.cpp:106] Iteration 73100, lr = 0.018024
I1101 16:34:03.225934  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_73200.caffemodel
I1101 16:34:03.350936  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_73200.solverstate
I1101 16:34:03.386760  8672 solver.cpp:337] Iteration 73200, Testing net (#0)
I1101 16:34:08.043982  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:34:08.043982  8672 solver.cpp:404]     Test net output #1: loss = 0.0129514 (* 1 = 0.0129514 loss)
I1101 16:34:08.130326  8672 solver.cpp:228] Iteration 73200, loss = 4.58278e-005
I1101 16:34:08.130326  8672 solver.cpp:244]     Train net output #0: loss = 4.5793e-005 (* 1 = 4.5793e-005 loss)
I1101 16:34:08.130326  8672 sgd_solver.cpp:106] Iteration 73200, lr = 0.0180215
I1101 16:34:23.610560  8672 solver.cpp:228] Iteration 73300, loss = 5.02356e-005
I1101 16:34:23.610560  8672 solver.cpp:244]     Train net output #0: loss = 5.02008e-005 (* 1 = 5.02008e-005 loss)
I1101 16:34:23.610560  8672 sgd_solver.cpp:106] Iteration 73300, lr = 0.018019
I1101 16:34:39.041996  8672 solver.cpp:228] Iteration 73400, loss = 6.01203e-005
I1101 16:34:39.041996  8672 solver.cpp:244]     Train net output #0: loss = 6.00855e-005 (* 1 = 6.00855e-005 loss)
I1101 16:34:39.041996  8672 sgd_solver.cpp:106] Iteration 73400, lr = 0.0180166
I1101 16:34:54.530066  8672 solver.cpp:228] Iteration 73500, loss = 5.72344e-005
I1101 16:34:54.530066  8672 solver.cpp:244]     Train net output #0: loss = 5.71996e-005 (* 1 = 5.71996e-005 loss)
I1101 16:34:54.530066  8672 sgd_solver.cpp:106] Iteration 73500, lr = 0.0180141
I1101 16:35:09.946112  8672 solver.cpp:228] Iteration 73600, loss = 3.54506e-005
I1101 16:35:09.946112  8672 solver.cpp:244]     Train net output #0: loss = 3.54158e-005 (* 1 = 3.54158e-005 loss)
I1101 16:35:09.946112  8672 sgd_solver.cpp:106] Iteration 73600, lr = 0.0180116
I1101 16:35:25.392915  8672 solver.cpp:228] Iteration 73700, loss = 4.35501e-005
I1101 16:35:25.392915  8672 solver.cpp:244]     Train net output #0: loss = 4.35153e-005 (* 1 = 4.35153e-005 loss)
I1101 16:35:25.392915  8672 sgd_solver.cpp:106] Iteration 73700, lr = 0.0180091
I1101 16:35:40.766554  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_73800.caffemodel
I1101 16:35:40.874330  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_73800.solverstate
I1101 16:35:40.921205  8672 solver.cpp:337] Iteration 73800, Testing net (#0)
I1101 16:35:45.571660  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:35:45.571660  8672 solver.cpp:404]     Test net output #1: loss = 0.0129554 (* 1 = 0.0129554 loss)
I1101 16:35:45.665402  8672 solver.cpp:228] Iteration 73800, loss = 4.57991e-005
I1101 16:35:45.665402  8672 solver.cpp:244]     Train net output #0: loss = 4.57643e-005 (* 1 = 4.57643e-005 loss)
I1101 16:35:45.665402  8672 sgd_solver.cpp:106] Iteration 73800, lr = 0.0180066
I1101 16:36:01.081362  8672 solver.cpp:228] Iteration 73900, loss = 5.02415e-005
I1101 16:36:01.081362  8672 solver.cpp:244]     Train net output #0: loss = 5.02067e-005 (* 1 = 5.02067e-005 loss)
I1101 16:36:01.081362  8672 sgd_solver.cpp:106] Iteration 73900, lr = 0.0180042
I1101 16:36:16.549957  8672 solver.cpp:228] Iteration 74000, loss = 6.00141e-005
I1101 16:36:16.549957  8672 solver.cpp:244]     Train net output #0: loss = 5.99793e-005 (* 1 = 5.99793e-005 loss)
I1101 16:36:16.549957  8672 sgd_solver.cpp:106] Iteration 74000, lr = 0.0180017
I1101 16:36:32.044744  8672 solver.cpp:228] Iteration 74100, loss = 5.71676e-005
I1101 16:36:32.044744  8672 solver.cpp:244]     Train net output #0: loss = 5.71328e-005 (* 1 = 5.71328e-005 loss)
I1101 16:36:32.044744  8672 sgd_solver.cpp:106] Iteration 74100, lr = 0.0179992
I1101 16:36:47.524531  8672 solver.cpp:228] Iteration 74200, loss = 3.55364e-005
I1101 16:36:47.524531  8672 solver.cpp:244]     Train net output #0: loss = 3.55016e-005 (* 1 = 3.55016e-005 loss)
I1101 16:36:47.524531  8672 sgd_solver.cpp:106] Iteration 74200, lr = 0.0179967
I1101 16:37:02.929781  8672 solver.cpp:228] Iteration 74300, loss = 4.35423e-005
I1101 16:37:02.929781  8672 solver.cpp:244]     Train net output #0: loss = 4.35075e-005 (* 1 = 4.35075e-005 loss)
I1101 16:37:02.929781  8672 sgd_solver.cpp:106] Iteration 74300, lr = 0.0179942
I1101 16:37:18.308802  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_74400.caffemodel
I1101 16:37:18.429392  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_74400.solverstate
I1101 16:37:18.476269  8672 solver.cpp:337] Iteration 74400, Testing net (#0)
I1101 16:37:23.127454  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:37:23.127454  8672 solver.cpp:404]     Test net output #1: loss = 0.0129586 (* 1 = 0.0129586 loss)
I1101 16:37:23.205581  8672 solver.cpp:228] Iteration 74400, loss = 4.57693e-005
I1101 16:37:23.205581  8672 solver.cpp:244]     Train net output #0: loss = 4.57345e-005 (* 1 = 4.57345e-005 loss)
I1101 16:37:23.205581  8672 sgd_solver.cpp:106] Iteration 74400, lr = 0.0179918
I1101 16:37:38.652464  8672 solver.cpp:228] Iteration 74500, loss = 5.02772e-005
I1101 16:37:38.652464  8672 solver.cpp:244]     Train net output #0: loss = 5.02424e-005 (* 1 = 5.02424e-005 loss)
I1101 16:37:38.652464  8672 sgd_solver.cpp:106] Iteration 74500, lr = 0.0179893
I1101 16:37:54.085914  8672 solver.cpp:228] Iteration 74600, loss = 5.99163e-005
I1101 16:37:54.085914  8672 solver.cpp:244]     Train net output #0: loss = 5.98815e-005 (* 1 = 5.98815e-005 loss)
I1101 16:37:54.085914  8672 sgd_solver.cpp:106] Iteration 74600, lr = 0.0179868
I1101 16:38:09.530779  8672 solver.cpp:228] Iteration 74700, loss = 5.70947e-005
I1101 16:38:09.530779  8672 solver.cpp:244]     Train net output #0: loss = 5.70599e-005 (* 1 = 5.70599e-005 loss)
I1101 16:38:09.530779  8672 sgd_solver.cpp:106] Iteration 74700, lr = 0.0179843
I1101 16:38:24.990689  8672 solver.cpp:228] Iteration 74800, loss = 3.56092e-005
I1101 16:38:24.990689  8672 solver.cpp:244]     Train net output #0: loss = 3.55744e-005 (* 1 = 3.55744e-005 loss)
I1101 16:38:24.990689  8672 sgd_solver.cpp:106] Iteration 74800, lr = 0.0179818
I1101 16:38:40.421612  8672 solver.cpp:228] Iteration 74900, loss = 4.35149e-005
I1101 16:38:40.421612  8672 solver.cpp:244]     Train net output #0: loss = 4.34801e-005 (* 1 = 4.34801e-005 loss)
I1101 16:38:40.421612  8672 sgd_solver.cpp:106] Iteration 74900, lr = 0.0179794
I1101 16:38:55.786943  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_75000.caffemodel
I1101 16:38:55.893894  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_75000.solverstate
I1101 16:38:55.940783  8672 solver.cpp:337] Iteration 75000, Testing net (#0)
I1101 16:39:00.618994  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:39:00.618994  8672 solver.cpp:404]     Test net output #1: loss = 0.0129603 (* 1 = 0.0129603 loss)
I1101 16:39:00.697156  8672 solver.cpp:228] Iteration 75000, loss = 4.57084e-005
I1101 16:39:00.697156  8672 solver.cpp:244]     Train net output #0: loss = 4.56736e-005 (* 1 = 4.56736e-005 loss)
I1101 16:39:00.697156  8672 sgd_solver.cpp:106] Iteration 75000, lr = 0.0179769
I1101 16:39:16.167034  8672 solver.cpp:228] Iteration 75100, loss = 5.02748e-005
I1101 16:39:16.167034  8672 solver.cpp:244]     Train net output #0: loss = 5.024e-005 (* 1 = 5.024e-005 loss)
I1101 16:39:16.167034  8672 sgd_solver.cpp:106] Iteration 75100, lr = 0.0179744
I1101 16:39:31.622690  8672 solver.cpp:228] Iteration 75200, loss = 5.98131e-005
I1101 16:39:31.622690  8672 solver.cpp:244]     Train net output #0: loss = 5.97782e-005 (* 1 = 5.97782e-005 loss)
I1101 16:39:31.622690  8672 sgd_solver.cpp:106] Iteration 75200, lr = 0.0179719
I1101 16:39:47.074405  8672 solver.cpp:228] Iteration 75300, loss = 5.70315e-005
I1101 16:39:47.074405  8672 solver.cpp:244]     Train net output #0: loss = 5.69967e-005 (* 1 = 5.69967e-005 loss)
I1101 16:39:47.074405  8672 sgd_solver.cpp:106] Iteration 75300, lr = 0.0179694
I1101 16:40:02.531395  8672 solver.cpp:228] Iteration 75400, loss = 3.567e-005
I1101 16:40:02.531395  8672 solver.cpp:244]     Train net output #0: loss = 3.56352e-005 (* 1 = 3.56352e-005 loss)
I1101 16:40:02.531395  8672 sgd_solver.cpp:106] Iteration 75400, lr = 0.017967
I1101 16:40:17.976375  8672 solver.cpp:228] Iteration 75500, loss = 4.35041e-005
I1101 16:40:17.976375  8672 solver.cpp:244]     Train net output #0: loss = 4.34693e-005 (* 1 = 4.34693e-005 loss)
I1101 16:40:17.976375  8672 sgd_solver.cpp:106] Iteration 75500, lr = 0.0179645
I1101 16:40:33.312721  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_75600.caffemodel
I1101 16:40:33.427319  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_75600.solverstate
I1101 16:40:33.474179  8672 solver.cpp:337] Iteration 75600, Testing net (#0)
I1101 16:40:38.136973  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:40:38.136973  8672 solver.cpp:404]     Test net output #1: loss = 0.0129607 (* 1 = 0.0129607 loss)
I1101 16:40:38.215102  8672 solver.cpp:228] Iteration 75600, loss = 4.57025e-005
I1101 16:40:38.215102  8672 solver.cpp:244]     Train net output #0: loss = 4.56677e-005 (* 1 = 4.56677e-005 loss)
I1101 16:40:38.215102  8672 sgd_solver.cpp:106] Iteration 75600, lr = 0.017962
I1101 16:40:53.624748  8672 solver.cpp:228] Iteration 75700, loss = 5.02891e-005
I1101 16:40:53.624748  8672 solver.cpp:244]     Train net output #0: loss = 5.02543e-005 (* 1 = 5.02543e-005 loss)
I1101 16:40:53.624748  8672 sgd_solver.cpp:106] Iteration 75700, lr = 0.0179595
I1101 16:41:09.077194  8672 solver.cpp:228] Iteration 75800, loss = 5.97396e-005
I1101 16:41:09.077194  8672 solver.cpp:244]     Train net output #0: loss = 5.97048e-005 (* 1 = 5.97048e-005 loss)
I1101 16:41:09.077194  8672 sgd_solver.cpp:106] Iteration 75800, lr = 0.017957
I1101 16:41:24.523934  8672 solver.cpp:228] Iteration 75900, loss = 5.69801e-005
I1101 16:41:24.523934  8672 solver.cpp:244]     Train net output #0: loss = 5.69453e-005 (* 1 = 5.69453e-005 loss)
I1101 16:41:24.523934  8672 sgd_solver.cpp:106] Iteration 75900, lr = 0.0179546
I1101 16:41:39.970434  8672 solver.cpp:228] Iteration 76000, loss = 3.57534e-005
I1101 16:41:39.970434  8672 solver.cpp:244]     Train net output #0: loss = 3.57186e-005 (* 1 = 3.57186e-005 loss)
I1101 16:41:39.970434  8672 sgd_solver.cpp:106] Iteration 76000, lr = 0.0179521
I1101 16:41:55.872995  8672 solver.cpp:228] Iteration 76100, loss = 4.34898e-005
I1101 16:41:55.872995  8672 solver.cpp:244]     Train net output #0: loss = 4.3455e-005 (* 1 = 4.3455e-005 loss)
I1101 16:41:55.872995  8672 sgd_solver.cpp:106] Iteration 76100, lr = 0.0179496
I1101 16:42:11.396877  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_76200.caffemodel
I1101 16:42:11.515427  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_76200.solverstate
I1101 16:42:11.562304  8672 solver.cpp:337] Iteration 76200, Testing net (#0)
I1101 16:42:16.301601  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:42:16.301601  8672 solver.cpp:404]     Test net output #1: loss = 0.0129612 (* 1 = 0.0129612 loss)
I1101 16:42:16.379765  8672 solver.cpp:228] Iteration 76200, loss = 4.56536e-005
I1101 16:42:16.379765  8672 solver.cpp:244]     Train net output #0: loss = 4.56188e-005 (* 1 = 4.56188e-005 loss)
I1101 16:42:16.379765  8672 sgd_solver.cpp:106] Iteration 76200, lr = 0.0179471
I1101 16:42:31.957018  8672 solver.cpp:228] Iteration 76300, loss = 5.0286e-005
I1101 16:42:31.957018  8672 solver.cpp:244]     Train net output #0: loss = 5.02512e-005 (* 1 = 5.02512e-005 loss)
I1101 16:42:31.957018  8672 sgd_solver.cpp:106] Iteration 76300, lr = 0.0179446
I1101 16:42:47.718125  8672 solver.cpp:228] Iteration 76400, loss = 5.96489e-005
I1101 16:42:47.718125  8672 solver.cpp:244]     Train net output #0: loss = 5.96141e-005 (* 1 = 5.96141e-005 loss)
I1101 16:42:47.718125  8672 sgd_solver.cpp:106] Iteration 76400, lr = 0.0179422
I1101 16:43:03.544361  8672 solver.cpp:228] Iteration 76500, loss = 5.69228e-005
I1101 16:43:03.544361  8672 solver.cpp:244]     Train net output #0: loss = 5.6888e-005 (* 1 = 5.6888e-005 loss)
I1101 16:43:03.544361  8672 sgd_solver.cpp:106] Iteration 76500, lr = 0.0179397
I1101 16:43:19.287716  8672 solver.cpp:228] Iteration 76600, loss = 3.57939e-005
I1101 16:43:19.287716  8672 solver.cpp:244]     Train net output #0: loss = 3.57591e-005 (* 1 = 3.57591e-005 loss)
I1101 16:43:19.287716  8672 sgd_solver.cpp:106] Iteration 76600, lr = 0.0179372
I1101 16:43:35.030580  8672 solver.cpp:228] Iteration 76700, loss = 4.34802e-005
I1101 16:43:35.030580  8672 solver.cpp:244]     Train net output #0: loss = 4.34454e-005 (* 1 = 4.34454e-005 loss)
I1101 16:43:35.030580  8672 sgd_solver.cpp:106] Iteration 76700, lr = 0.0179347
I1101 16:43:50.608484  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_76800.caffemodel
I1101 16:43:50.726068  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_76800.solverstate
I1101 16:43:50.871430  8672 solver.cpp:337] Iteration 76800, Testing net (#0)
I1101 16:43:55.578425  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:43:55.578425  8672 solver.cpp:404]     Test net output #1: loss = 0.0129642 (* 1 = 0.0129642 loss)
I1101 16:43:55.645973  8672 solver.cpp:228] Iteration 76800, loss = 4.56523e-005
I1101 16:43:55.645973  8672 solver.cpp:244]     Train net output #0: loss = 4.56175e-005 (* 1 = 4.56175e-005 loss)
I1101 16:43:55.645973  8672 sgd_solver.cpp:106] Iteration 76800, lr = 0.0179322
I1101 16:44:11.188391  8672 solver.cpp:228] Iteration 76900, loss = 5.02968e-005
I1101 16:44:11.188391  8672 solver.cpp:244]     Train net output #0: loss = 5.02619e-005 (* 1 = 5.02619e-005 loss)
I1101 16:44:11.188391  8672 sgd_solver.cpp:106] Iteration 76900, lr = 0.0179298
I1101 16:44:26.775149  8672 solver.cpp:228] Iteration 77000, loss = 5.95869e-005
I1101 16:44:26.775149  8672 solver.cpp:244]     Train net output #0: loss = 5.95521e-005 (* 1 = 5.95521e-005 loss)
I1101 16:44:26.775149  8672 sgd_solver.cpp:106] Iteration 77000, lr = 0.0179273
I1101 16:44:42.361585  8672 solver.cpp:228] Iteration 77100, loss = 5.68554e-005
I1101 16:44:42.361585  8672 solver.cpp:244]     Train net output #0: loss = 5.68206e-005 (* 1 = 5.68206e-005 loss)
I1101 16:44:42.361585  8672 sgd_solver.cpp:106] Iteration 77100, lr = 0.0179248
I1101 16:44:57.928230  8672 solver.cpp:228] Iteration 77200, loss = 3.58667e-005
I1101 16:44:57.928230  8672 solver.cpp:244]     Train net output #0: loss = 3.58319e-005 (* 1 = 3.58319e-005 loss)
I1101 16:44:57.928230  8672 sgd_solver.cpp:106] Iteration 77200, lr = 0.0179223
I1101 16:45:13.458735  8672 solver.cpp:228] Iteration 77300, loss = 4.34683e-005
I1101 16:45:13.458735  8672 solver.cpp:244]     Train net output #0: loss = 4.34334e-005 (* 1 = 4.34334e-005 loss)
I1101 16:45:13.458735  8672 sgd_solver.cpp:106] Iteration 77300, lr = 0.0179199
I1101 16:45:28.910917  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_77400.caffemodel
I1101 16:45:29.021996  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_77400.solverstate
I1101 16:45:29.068886  8672 solver.cpp:337] Iteration 77400, Testing net (#0)
I1101 16:45:33.760058  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:45:33.760058  8672 solver.cpp:404]     Test net output #1: loss = 0.0129656 (* 1 = 0.0129656 loss)
I1101 16:45:33.825973  8672 solver.cpp:228] Iteration 77400, loss = 4.55796e-005
I1101 16:45:33.825973  8672 solver.cpp:244]     Train net output #0: loss = 4.55448e-005 (* 1 = 4.55448e-005 loss)
I1101 16:45:33.825973  8672 sgd_solver.cpp:106] Iteration 77400, lr = 0.0179174
I1101 16:45:49.338791  8672 solver.cpp:228] Iteration 77500, loss = 5.02502e-005
I1101 16:45:49.338791  8672 solver.cpp:244]     Train net output #0: loss = 5.02154e-005 (* 1 = 5.02154e-005 loss)
I1101 16:45:49.338791  8672 sgd_solver.cpp:106] Iteration 77500, lr = 0.0179149
I1101 16:46:04.854744  8672 solver.cpp:228] Iteration 77600, loss = 5.94765e-005
I1101 16:46:04.854744  8672 solver.cpp:244]     Train net output #0: loss = 5.94417e-005 (* 1 = 5.94417e-005 loss)
I1101 16:46:04.854744  8672 sgd_solver.cpp:106] Iteration 77600, lr = 0.0179124
I1101 16:46:20.355051  8672 solver.cpp:228] Iteration 77700, loss = 5.68124e-005
I1101 16:46:20.355051  8672 solver.cpp:244]     Train net output #0: loss = 5.67776e-005 (* 1 = 5.67776e-005 loss)
I1101 16:46:20.355051  8672 sgd_solver.cpp:106] Iteration 77700, lr = 0.0179099
I1101 16:46:35.906108  8672 solver.cpp:228] Iteration 77800, loss = 3.59298e-005
I1101 16:46:35.906108  8672 solver.cpp:244]     Train net output #0: loss = 3.5895e-005 (* 1 = 3.5895e-005 loss)
I1101 16:46:35.906108  8672 sgd_solver.cpp:106] Iteration 77800, lr = 0.0179075
I1101 16:46:51.458806  8672 solver.cpp:228] Iteration 77900, loss = 4.34706e-005
I1101 16:46:51.458806  8672 solver.cpp:244]     Train net output #0: loss = 4.34358e-005 (* 1 = 4.34358e-005 loss)
I1101 16:46:51.458806  8672 sgd_solver.cpp:106] Iteration 77900, lr = 0.017905
I1101 16:47:06.987579  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_78000.caffemodel
I1101 16:47:07.110752  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_78000.solverstate
I1101 16:47:07.158287  8672 solver.cpp:337] Iteration 78000, Testing net (#0)
I1101 16:47:11.848340  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:47:11.848340  8672 solver.cpp:404]     Test net output #1: loss = 0.0129695 (* 1 = 0.0129695 loss)
I1101 16:47:11.914013  8672 solver.cpp:228] Iteration 78000, loss = 4.55682e-005
I1101 16:47:11.914013  8672 solver.cpp:244]     Train net output #0: loss = 4.55334e-005 (* 1 = 4.55334e-005 loss)
I1101 16:47:11.914013  8672 sgd_solver.cpp:106] Iteration 78000, lr = 0.0179025
I1101 16:47:27.462790  8672 solver.cpp:228] Iteration 78100, loss = 5.02847e-005
I1101 16:47:27.462790  8672 solver.cpp:244]     Train net output #0: loss = 5.02499e-005 (* 1 = 5.02499e-005 loss)
I1101 16:47:27.462790  8672 sgd_solver.cpp:106] Iteration 78100, lr = 0.0179
I1101 16:47:43.047112  8672 solver.cpp:228] Iteration 78200, loss = 5.943e-005
I1101 16:47:43.047112  8672 solver.cpp:244]     Train net output #0: loss = 5.93952e-005 (* 1 = 5.93952e-005 loss)
I1101 16:47:43.047112  8672 sgd_solver.cpp:106] Iteration 78200, lr = 0.0178975
I1101 16:47:58.621445  8672 solver.cpp:228] Iteration 78300, loss = 5.66829e-005
I1101 16:47:58.621445  8672 solver.cpp:244]     Train net output #0: loss = 5.66481e-005 (* 1 = 5.66481e-005 loss)
I1101 16:47:58.621445  8672 sgd_solver.cpp:106] Iteration 78300, lr = 0.0178951
I1101 16:48:14.198045  8672 solver.cpp:228] Iteration 78400, loss = 3.59787e-005
I1101 16:48:14.198045  8672 solver.cpp:244]     Train net output #0: loss = 3.59439e-005 (* 1 = 3.59439e-005 loss)
I1101 16:48:14.198045  8672 sgd_solver.cpp:106] Iteration 78400, lr = 0.0178926
I1101 16:48:29.788610  8672 solver.cpp:228] Iteration 78500, loss = 4.34658e-005
I1101 16:48:29.788610  8672 solver.cpp:244]     Train net output #0: loss = 4.3431e-005 (* 1 = 4.3431e-005 loss)
I1101 16:48:29.788610  8672 sgd_solver.cpp:106] Iteration 78500, lr = 0.0178901
I1101 16:48:45.311525  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_78600.caffemodel
I1101 16:48:45.427608  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_78600.solverstate
I1101 16:48:45.480145  8672 solver.cpp:337] Iteration 78600, Testing net (#0)
I1101 16:48:50.179466  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:48:50.179466  8672 solver.cpp:404]     Test net output #1: loss = 0.0129716 (* 1 = 0.0129716 loss)
I1101 16:48:50.244658  8672 solver.cpp:228] Iteration 78600, loss = 4.55282e-005
I1101 16:48:50.244658  8672 solver.cpp:244]     Train net output #0: loss = 4.54934e-005 (* 1 = 4.54934e-005 loss)
I1101 16:48:50.244658  8672 sgd_solver.cpp:106] Iteration 78600, lr = 0.0178876
I1101 16:49:05.801923  8672 solver.cpp:228] Iteration 78700, loss = 5.02644e-005
I1101 16:49:05.801923  8672 solver.cpp:244]     Train net output #0: loss = 5.02296e-005 (* 1 = 5.02296e-005 loss)
I1101 16:49:05.801923  8672 sgd_solver.cpp:106] Iteration 78700, lr = 0.0178851
I1101 16:49:21.416430  8672 solver.cpp:228] Iteration 78800, loss = 5.93273e-005
I1101 16:49:21.416430  8672 solver.cpp:244]     Train net output #0: loss = 5.92925e-005 (* 1 = 5.92925e-005 loss)
I1101 16:49:21.416430  8672 sgd_solver.cpp:106] Iteration 78800, lr = 0.0178827
I1101 16:49:37.085877  8672 solver.cpp:228] Iteration 78900, loss = 5.66936e-005
I1101 16:49:37.085877  8672 solver.cpp:244]     Train net output #0: loss = 5.66588e-005 (* 1 = 5.66588e-005 loss)
I1101 16:49:37.085877  8672 sgd_solver.cpp:106] Iteration 78900, lr = 0.0178802
I1101 16:49:52.653528  8672 solver.cpp:228] Iteration 79000, loss = 3.60467e-005
I1101 16:49:52.653528  8672 solver.cpp:244]     Train net output #0: loss = 3.60119e-005 (* 1 = 3.60119e-005 loss)
I1101 16:49:52.653528  8672 sgd_solver.cpp:106] Iteration 79000, lr = 0.0178777
I1101 16:50:08.211354  8672 solver.cpp:228] Iteration 79100, loss = 4.34396e-005
I1101 16:50:08.211354  8672 solver.cpp:244]     Train net output #0: loss = 4.34048e-005 (* 1 = 4.34048e-005 loss)
I1101 16:50:08.211354  8672 sgd_solver.cpp:106] Iteration 79100, lr = 0.0178752
I1101 16:50:23.697197  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_79200.caffemodel
I1101 16:50:23.818778  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_79200.solverstate
I1101 16:50:23.873317  8672 solver.cpp:337] Iteration 79200, Testing net (#0)
I1101 16:50:28.567701  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:50:28.567701  8672 solver.cpp:404]     Test net output #1: loss = 0.0129756 (* 1 = 0.0129756 loss)
I1101 16:50:28.634202  8672 solver.cpp:228] Iteration 79200, loss = 4.55115e-005
I1101 16:50:28.634202  8672 solver.cpp:244]     Train net output #0: loss = 4.54767e-005 (* 1 = 4.54767e-005 loss)
I1101 16:50:28.634202  8672 sgd_solver.cpp:106] Iteration 79200, lr = 0.0178727
I1101 16:50:44.204530  8672 solver.cpp:228] Iteration 79300, loss = 5.02572e-005
I1101 16:50:44.204530  8672 solver.cpp:244]     Train net output #0: loss = 5.02224e-005 (* 1 = 5.02224e-005 loss)
I1101 16:50:44.204530  8672 sgd_solver.cpp:106] Iteration 79300, lr = 0.0178703
I1101 16:50:59.768317  8672 solver.cpp:228] Iteration 79400, loss = 5.92927e-005
I1101 16:50:59.768317  8672 solver.cpp:244]     Train net output #0: loss = 5.92579e-005 (* 1 = 5.92579e-005 loss)
I1101 16:50:59.768317  8672 sgd_solver.cpp:106] Iteration 79400, lr = 0.0178678
I1101 16:51:15.334097  8672 solver.cpp:228] Iteration 79500, loss = 5.65838e-005
I1101 16:51:15.334097  8672 solver.cpp:244]     Train net output #0: loss = 5.6549e-005 (* 1 = 5.6549e-005 loss)
I1101 16:51:15.334097  8672 sgd_solver.cpp:106] Iteration 79500, lr = 0.0178653
I1101 16:51:30.876358  8672 solver.cpp:228] Iteration 79600, loss = 3.61098e-005
I1101 16:51:30.876358  8672 solver.cpp:244]     Train net output #0: loss = 3.6075e-005 (* 1 = 3.6075e-005 loss)
I1101 16:51:30.876358  8672 sgd_solver.cpp:106] Iteration 79600, lr = 0.0178628
I1101 16:51:46.404918  8672 solver.cpp:228] Iteration 79700, loss = 4.34336e-005
I1101 16:51:46.404918  8672 solver.cpp:244]     Train net output #0: loss = 4.33988e-005 (* 1 = 4.33988e-005 loss)
I1101 16:51:46.404918  8672 sgd_solver.cpp:106] Iteration 79700, lr = 0.0178603
I1101 16:52:01.847987  8672 solver.cpp:454] Snapshotting to binary proto file examples/mnist/simpnet_nodrp_iter_79800.caffemodel
I1101 16:52:01.971074  8672 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/mnist/simpnet_nodrp_iter_79800.solverstate
I1101 16:52:02.022110  8672 solver.cpp:337] Iteration 79800, Testing net (#0)
I1101 16:52:06.713198  8672 solver.cpp:404]     Test net output #0: accuracy = 0.9972
I1101 16:52:06.713198  8672 solver.cpp:404]     Test net output #1: loss = 0.0129769 (* 1 = 0.0129769 loss)
I1101 16:52:06.780056  8672 solver.cpp:228] Iteration 79800, loss = 4.54578e-005
I1101 16:52:06.780056  8672 solver.cpp:244]     Train net output #0: loss = 4.54231e-005 (* 1 = 4.54231e-005 loss)
I1101 16:52:06.780056  8672 sgd_solver.cpp:106] Iteration 79800, lr = 0.0178579
I1101 16:52:22.372028  8672 solver.cpp:228] Iteration 79900, loss = 5.02446e-005
I1101 16:52:22.372028  8672 solver.cpp:244]     Train net output #0: loss = 5.02098e-005 (* 1 = 5.02098e-005 loss)
I1101 16:52:22.372028  8672 sgd_solver.cpp:106] Iteration 79900, lr = 0.0178554
I1101 16:52:37.861352  8672 solver.cpp:228] Iteration 80000, loss = 5.92151e-005
I1101 16:52:37.861352  8672 solver.cpp:244]     Train net output #0: loss = 5.91803e-005 (* 1 = 5.91803e-005 loss)
I1101 16:52:37.861352  8672 sgd_solver.cpp:106] Iteration 80000, lr = 0.0178529
I1101 16:52:53.429941  8672 solver.cpp:228] Iteration 80100, los^C