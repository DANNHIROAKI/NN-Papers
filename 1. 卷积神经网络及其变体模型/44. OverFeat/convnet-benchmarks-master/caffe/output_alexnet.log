I0228 23:01:58.835140 24487 caffe.cpp:308] Use GPU with device ID 0
I0228 23:01:59.105986 24487 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/alexnet.prototxt
I0228 23:01:59.106055 24487 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0228 23:01:59.106077 24487 upgrade_proto.cpp:65] Attempting to upgrade input file specified using deprecated input fields: ./imagenet_winners/alexnet.prototxt
I0228 23:01:59.106086 24487 upgrade_proto.cpp:68] Successfully upgraded file specified using deprecated input fields.
W0228 23:01:59.106089 24487 upgrade_proto.cpp:70] Note that future Caffe releases will only support input layers and not input fields.
I0228 23:01:59.106209 24487 net.cpp:49] Initializing net from parameters: 
name: "alexnet"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 128
      dim: 3
      dim: 224
      dim: 224
    }
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/11x11_s4"
  top: "conv1/11x11_s4"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/11x11_s4"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2/5x5_s1"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2/5x5_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/5x5_s1"
  top: "conv2/5x5_s1"
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/5x5_s1"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "conv4/3x3_s1"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "pool5/3x3_s2"
  type: "Pooling"
  bottom: "conv5/3x3_s1"
  top: "pool5/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5/3x3_s2"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
I0228 23:01:59.106274 24487 layer_factory.hpp:77] Creating layer input
I0228 23:01:59.106305 24487 net.cpp:91] Creating Layer input
I0228 23:01:59.106310 24487 net.cpp:399] input -> data
I0228 23:01:59.112552 24487 net.cpp:141] Setting up input
I0228 23:01:59.112576 24487 net.cpp:148] Top shape: 128 3 224 224 (19267584)
I0228 23:01:59.112578 24487 net.cpp:156] Memory required for data: 77070336
I0228 23:01:59.112586 24487 layer_factory.hpp:77] Creating layer conv1
I0228 23:01:59.112601 24487 net.cpp:91] Creating Layer conv1
I0228 23:01:59.112606 24487 net.cpp:425] conv1 <- data
I0228 23:01:59.112612 24487 net.cpp:399] conv1 -> conv1/11x11_s4
I0228 23:01:59.254693 24487 net.cpp:141] Setting up conv1
I0228 23:01:59.254719 24487 net.cpp:148] Top shape: 128 64 55 55 (24780800)
I0228 23:01:59.254722 24487 net.cpp:156] Memory required for data: 176193536
I0228 23:01:59.254739 24487 layer_factory.hpp:77] Creating layer conv1/relu
I0228 23:01:59.254748 24487 net.cpp:91] Creating Layer conv1/relu
I0228 23:01:59.254753 24487 net.cpp:425] conv1/relu <- conv1/11x11_s4
I0228 23:01:59.254757 24487 net.cpp:386] conv1/relu -> conv1/11x11_s4 (in-place)
I0228 23:01:59.255596 24487 net.cpp:141] Setting up conv1/relu
I0228 23:01:59.255606 24487 net.cpp:148] Top shape: 128 64 55 55 (24780800)
I0228 23:01:59.255609 24487 net.cpp:156] Memory required for data: 275316736
I0228 23:01:59.255612 24487 layer_factory.hpp:77] Creating layer pool1/3x3_s2
I0228 23:01:59.255620 24487 net.cpp:91] Creating Layer pool1/3x3_s2
I0228 23:01:59.255622 24487 net.cpp:425] pool1/3x3_s2 <- conv1/11x11_s4
I0228 23:01:59.255626 24487 net.cpp:399] pool1/3x3_s2 -> pool1/3x3_s2
I0228 23:01:59.255674 24487 net.cpp:141] Setting up pool1/3x3_s2
I0228 23:01:59.255679 24487 net.cpp:148] Top shape: 128 64 27 27 (5971968)
I0228 23:01:59.255682 24487 net.cpp:156] Memory required for data: 299204608
I0228 23:01:59.255686 24487 layer_factory.hpp:77] Creating layer conv2/5x5_s1
I0228 23:01:59.255695 24487 net.cpp:91] Creating Layer conv2/5x5_s1
I0228 23:01:59.255698 24487 net.cpp:425] conv2/5x5_s1 <- pool1/3x3_s2
I0228 23:01:59.255702 24487 net.cpp:399] conv2/5x5_s1 -> conv2/5x5_s1
I0228 23:01:59.259663 24487 net.cpp:141] Setting up conv2/5x5_s1
I0228 23:01:59.259675 24487 net.cpp:148] Top shape: 128 192 27 27 (17915904)
I0228 23:01:59.259680 24487 net.cpp:156] Memory required for data: 370868224
I0228 23:01:59.259687 24487 layer_factory.hpp:77] Creating layer conv2/relu
I0228 23:01:59.259692 24487 net.cpp:91] Creating Layer conv2/relu
I0228 23:01:59.259696 24487 net.cpp:425] conv2/relu <- conv2/5x5_s1
I0228 23:01:59.259699 24487 net.cpp:386] conv2/relu -> conv2/5x5_s1 (in-place)
I0228 23:01:59.260179 24487 net.cpp:141] Setting up conv2/relu
I0228 23:01:59.260190 24487 net.cpp:148] Top shape: 128 192 27 27 (17915904)
I0228 23:01:59.260192 24487 net.cpp:156] Memory required for data: 442531840
I0228 23:01:59.260195 24487 layer_factory.hpp:77] Creating layer pool2/3x3_s2
I0228 23:01:59.260201 24487 net.cpp:91] Creating Layer pool2/3x3_s2
I0228 23:01:59.260205 24487 net.cpp:425] pool2/3x3_s2 <- conv2/5x5_s1
I0228 23:01:59.260208 24487 net.cpp:399] pool2/3x3_s2 -> pool2/3x3_s2
I0228 23:01:59.260239 24487 net.cpp:141] Setting up pool2/3x3_s2
I0228 23:01:59.260244 24487 net.cpp:148] Top shape: 128 192 13 13 (4153344)
I0228 23:01:59.260247 24487 net.cpp:156] Memory required for data: 459145216
I0228 23:01:59.260251 24487 layer_factory.hpp:77] Creating layer conv3/3x3_s1
I0228 23:01:59.260257 24487 net.cpp:91] Creating Layer conv3/3x3_s1
I0228 23:01:59.260260 24487 net.cpp:425] conv3/3x3_s1 <- pool2/3x3_s2
I0228 23:01:59.260264 24487 net.cpp:399] conv3/3x3_s1 -> conv3/3x3_s1
I0228 23:01:59.267001 24487 net.cpp:141] Setting up conv3/3x3_s1
I0228 23:01:59.267020 24487 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0228 23:01:59.267024 24487 net.cpp:156] Memory required for data: 492371968
I0228 23:01:59.267031 24487 layer_factory.hpp:77] Creating layer conv3/relu
I0228 23:01:59.267038 24487 net.cpp:91] Creating Layer conv3/relu
I0228 23:01:59.267041 24487 net.cpp:425] conv3/relu <- conv3/3x3_s1
I0228 23:01:59.267045 24487 net.cpp:386] conv3/relu -> conv3/3x3_s1 (in-place)
I0228 23:01:59.267168 24487 net.cpp:141] Setting up conv3/relu
I0228 23:01:59.267175 24487 net.cpp:148] Top shape: 128 384 13 13 (8306688)
I0228 23:01:59.267179 24487 net.cpp:156] Memory required for data: 525598720
I0228 23:01:59.267181 24487 layer_factory.hpp:77] Creating layer conv4/3x3_s1
I0228 23:01:59.267189 24487 net.cpp:91] Creating Layer conv4/3x3_s1
I0228 23:01:59.267192 24487 net.cpp:425] conv4/3x3_s1 <- conv3/3x3_s1
I0228 23:01:59.267196 24487 net.cpp:399] conv4/3x3_s1 -> conv4/3x3_s1
I0228 23:01:59.274763 24487 net.cpp:141] Setting up conv4/3x3_s1
I0228 23:01:59.274775 24487 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0228 23:01:59.274778 24487 net.cpp:156] Memory required for data: 547749888
I0228 23:01:59.274783 24487 layer_factory.hpp:77] Creating layer conv4/relu
I0228 23:01:59.274790 24487 net.cpp:91] Creating Layer conv4/relu
I0228 23:01:59.274792 24487 net.cpp:425] conv4/relu <- conv4/3x3_s1
I0228 23:01:59.274797 24487 net.cpp:386] conv4/relu -> conv4/3x3_s1 (in-place)
I0228 23:01:59.275074 24487 net.cpp:141] Setting up conv4/relu
I0228 23:01:59.275084 24487 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0228 23:01:59.275087 24487 net.cpp:156] Memory required for data: 569901056
I0228 23:01:59.275090 24487 layer_factory.hpp:77] Creating layer conv5/3x3_s1
I0228 23:01:59.275099 24487 net.cpp:91] Creating Layer conv5/3x3_s1
I0228 23:01:59.275102 24487 net.cpp:425] conv5/3x3_s1 <- conv4/3x3_s1
I0228 23:01:59.275109 24487 net.cpp:399] conv5/3x3_s1 -> conv5/3x3_s1
I0228 23:01:59.279484 24487 net.cpp:141] Setting up conv5/3x3_s1
I0228 23:01:59.279496 24487 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0228 23:01:59.279500 24487 net.cpp:156] Memory required for data: 592052224
I0228 23:01:59.279507 24487 layer_factory.hpp:77] Creating layer conv5/relu
I0228 23:01:59.279512 24487 net.cpp:91] Creating Layer conv5/relu
I0228 23:01:59.279516 24487 net.cpp:425] conv5/relu <- conv5/3x3_s1
I0228 23:01:59.279520 24487 net.cpp:386] conv5/relu -> conv5/3x3_s1 (in-place)
I0228 23:01:59.279769 24487 net.cpp:141] Setting up conv5/relu
I0228 23:01:59.279778 24487 net.cpp:148] Top shape: 128 256 13 13 (5537792)
I0228 23:01:59.279781 24487 net.cpp:156] Memory required for data: 614203392
I0228 23:01:59.279784 24487 layer_factory.hpp:77] Creating layer pool5/3x3_s2
I0228 23:01:59.279790 24487 net.cpp:91] Creating Layer pool5/3x3_s2
I0228 23:01:59.279793 24487 net.cpp:425] pool5/3x3_s2 <- conv5/3x3_s1
I0228 23:01:59.279799 24487 net.cpp:399] pool5/3x3_s2 -> pool5/3x3_s2
I0228 23:01:59.279834 24487 net.cpp:141] Setting up pool5/3x3_s2
I0228 23:01:59.279839 24487 net.cpp:148] Top shape: 128 256 6 6 (1179648)
I0228 23:01:59.279840 24487 net.cpp:156] Memory required for data: 618921984
I0228 23:01:59.279844 24487 layer_factory.hpp:77] Creating layer fc6
I0228 23:01:59.279850 24487 net.cpp:91] Creating Layer fc6
I0228 23:01:59.279852 24487 net.cpp:425] fc6 <- pool5/3x3_s2
I0228 23:01:59.279857 24487 net.cpp:399] fc6 -> fc6
I0228 23:01:59.346503 24487 net.cpp:141] Setting up fc6
I0228 23:01:59.346530 24487 net.cpp:148] Top shape: 128 4096 (524288)
I0228 23:01:59.346534 24487 net.cpp:156] Memory required for data: 621019136
I0228 23:01:59.346544 24487 layer_factory.hpp:77] Creating layer fc7
I0228 23:01:59.346551 24487 net.cpp:91] Creating Layer fc7
I0228 23:01:59.346556 24487 net.cpp:425] fc7 <- fc6
I0228 23:01:59.346562 24487 net.cpp:399] fc7 -> fc7
I0228 23:01:59.376416 24487 net.cpp:141] Setting up fc7
I0228 23:01:59.376454 24487 net.cpp:148] Top shape: 128 4096 (524288)
I0228 23:01:59.376457 24487 net.cpp:156] Memory required for data: 623116288
I0228 23:01:59.376466 24487 layer_factory.hpp:77] Creating layer fc8
I0228 23:01:59.376487 24487 net.cpp:91] Creating Layer fc8
I0228 23:01:59.376492 24487 net.cpp:425] fc8 <- fc7
I0228 23:01:59.376497 24487 net.cpp:399] fc8 -> fc8
I0228 23:01:59.383560 24487 net.cpp:141] Setting up fc8
I0228 23:01:59.383586 24487 net.cpp:148] Top shape: 128 1000 (128000)
I0228 23:01:59.383590 24487 net.cpp:156] Memory required for data: 623628288
I0228 23:01:59.383599 24487 net.cpp:219] fc8 does not need backward computation.
I0228 23:01:59.383604 24487 net.cpp:219] fc7 does not need backward computation.
I0228 23:01:59.383606 24487 net.cpp:219] fc6 does not need backward computation.
I0228 23:01:59.383610 24487 net.cpp:219] pool5/3x3_s2 does not need backward computation.
I0228 23:01:59.383612 24487 net.cpp:219] conv5/relu does not need backward computation.
I0228 23:01:59.383615 24487 net.cpp:219] conv5/3x3_s1 does not need backward computation.
I0228 23:01:59.383618 24487 net.cpp:219] conv4/relu does not need backward computation.
I0228 23:01:59.383621 24487 net.cpp:219] conv4/3x3_s1 does not need backward computation.
I0228 23:01:59.383625 24487 net.cpp:219] conv3/relu does not need backward computation.
I0228 23:01:59.383627 24487 net.cpp:219] conv3/3x3_s1 does not need backward computation.
I0228 23:01:59.383630 24487 net.cpp:219] pool2/3x3_s2 does not need backward computation.
I0228 23:01:59.383633 24487 net.cpp:219] conv2/relu does not need backward computation.
I0228 23:01:59.383636 24487 net.cpp:219] conv2/5x5_s1 does not need backward computation.
I0228 23:01:59.383640 24487 net.cpp:219] pool1/3x3_s2 does not need backward computation.
I0228 23:01:59.383642 24487 net.cpp:219] conv1/relu does not need backward computation.
I0228 23:01:59.383644 24487 net.cpp:219] conv1 does not need backward computation.
I0228 23:01:59.383648 24487 net.cpp:219] input does not need backward computation.
I0228 23:01:59.383651 24487 net.cpp:261] This network produces output fc8
I0228 23:01:59.383666 24487 net.cpp:274] Network initialization done.
I0228 23:01:59.383720 24487 caffe.cpp:320] Performing Forward
I0228 23:01:59.456549 24487 caffe.cpp:325] Initial loss: 0
I0228 23:01:59.456580 24487 caffe.cpp:326] Performing Backward
I0228 23:01:59.459419 24487 caffe.cpp:334] *** Benchmark begins ***
I0228 23:01:59.459429 24487 caffe.cpp:335] Testing for 10 iterations.
I0228 23:01:59.697926 24487 caffe.cpp:363] Iteration: 1 forward-backward time: 136.04 ms.
I0228 23:01:59.828011 24487 caffe.cpp:363] Iteration: 2 forward-backward time: 130.048 ms.
I0228 23:01:59.955576 24487 caffe.cpp:363] Iteration: 3 forward-backward time: 127.527 ms.
I0228 23:02:00.082654 24487 caffe.cpp:363] Iteration: 4 forward-backward time: 127.05 ms.
I0228 23:02:00.210253 24487 caffe.cpp:363] Iteration: 5 forward-backward time: 127.564 ms.
I0228 23:02:00.337790 24487 caffe.cpp:363] Iteration: 6 forward-backward time: 127.497 ms.
I0228 23:02:00.465500 24487 caffe.cpp:363] Iteration: 7 forward-backward time: 127.675 ms.
I0228 23:02:00.593641 24487 caffe.cpp:363] Iteration: 8 forward-backward time: 128.1 ms.
I0228 23:02:00.721340 24487 caffe.cpp:363] Iteration: 9 forward-backward time: 127.672 ms.
I0228 23:02:00.849045 24487 caffe.cpp:363] Iteration: 10 forward-backward time: 127.675 ms.
I0228 23:02:00.849069 24487 caffe.cpp:366] Average time per layer: 
I0228 23:02:00.849072 24487 caffe.cpp:369]      input	forward: 0.0019584 ms.
I0228 23:02:00.849079 24487 caffe.cpp:372]      input	backward: 0.0019456 ms.
I0228 23:02:00.849082 24487 caffe.cpp:369]      conv1	forward: 4.6583 ms.
I0228 23:02:00.849086 24487 caffe.cpp:372]      conv1	backward: 14.4471 ms.
I0228 23:02:00.849088 24487 caffe.cpp:369] conv1/relu	forward: 0.859251 ms.
I0228 23:02:00.849092 24487 caffe.cpp:372] conv1/relu	backward: 1.26321 ms.
I0228 23:02:00.849094 24487 caffe.cpp:369] pool1/3x3_s2	forward: 0.869603 ms.
I0228 23:02:00.849097 24487 caffe.cpp:372] pool1/3x3_s2	backward: 3.43378 ms.
I0228 23:02:00.849100 24487 caffe.cpp:369] conv2/5x5_s1	forward: 11.562 ms.
I0228 23:02:00.849103 24487 caffe.cpp:372] conv2/5x5_s1	backward: 22.2473 ms.
I0228 23:02:00.849107 24487 caffe.cpp:369] conv2/relu	forward: 0.604659 ms.
I0228 23:02:00.849119 24487 caffe.cpp:372] conv2/relu	backward: 0.905738 ms.
I0228 23:02:00.849123 24487 caffe.cpp:369] pool2/3x3_s2	forward: 0.632957 ms.
I0228 23:02:00.849125 24487 caffe.cpp:372] pool2/3x3_s2	backward: 2.52765 ms.
I0228 23:02:00.849128 24487 caffe.cpp:369] conv3/3x3_s1	forward: 5.48363 ms.
I0228 23:02:00.849131 24487 caffe.cpp:372] conv3/3x3_s1	backward: 10.7821 ms.
I0228 23:02:00.849134 24487 caffe.cpp:369] conv3/relu	forward: 0.298499 ms.
I0228 23:02:00.849138 24487 caffe.cpp:372] conv3/relu	backward: 0.451782 ms.
I0228 23:02:00.849139 24487 caffe.cpp:369] conv4/3x3_s1	forward: 7.21521 ms.
I0228 23:02:00.849143 24487 caffe.cpp:372] conv4/3x3_s1	backward: 13.5 ms.
I0228 23:02:00.849145 24487 caffe.cpp:369] conv4/relu	forward: 0.203267 ms.
I0228 23:02:00.849148 24487 caffe.cpp:372] conv4/relu	backward: 0.306096 ms.
I0228 23:02:00.849151 24487 caffe.cpp:369] conv5/3x3_s1	forward: 4.91163 ms.
I0228 23:02:00.849154 24487 caffe.cpp:372] conv5/3x3_s1	backward: 9.03352 ms.
I0228 23:02:00.849156 24487 caffe.cpp:369] conv5/relu	forward: 0.201331 ms.
I0228 23:02:00.849159 24487 caffe.cpp:372] conv5/relu	backward: 0.305062 ms.
I0228 23:02:00.849162 24487 caffe.cpp:369] pool5/3x3_s2	forward: 0.220278 ms.
I0228 23:02:00.849165 24487 caffe.cpp:372] pool5/3x3_s2	backward: 0.834374 ms.
I0228 23:02:00.849169 24487 caffe.cpp:369]        fc6	forward: 3.02144 ms.
I0228 23:02:00.849170 24487 caffe.cpp:372]        fc6	backward: 3.81615 ms.
I0228 23:02:00.849174 24487 caffe.cpp:369]        fc7	forward: 0.996445 ms.
I0228 23:02:00.849176 24487 caffe.cpp:372]        fc7	backward: 1.68725 ms.
I0228 23:02:00.849179 24487 caffe.cpp:369]        fc8	forward: 0.548045 ms.
I0228 23:02:00.849181 24487 caffe.cpp:372]        fc8	backward: 0.596589 ms.
I0228 23:02:00.849194 24487 caffe.cpp:377] Average Forward pass: 42.405 ms.
I0228 23:02:00.849197 24487 caffe.cpp:379] Average Backward pass: 86.2657 ms.
I0228 23:02:00.849201 24487 caffe.cpp:381] Average Forward-Backward: 128.729 ms.
I0228 23:02:00.849206 24487 caffe.cpp:383] Total Time: 1287.29 ms.
I0228 23:02:00.849210 24487 caffe.cpp:384] *** Benchmark ends ***
