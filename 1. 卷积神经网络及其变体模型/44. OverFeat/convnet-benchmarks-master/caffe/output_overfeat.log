I0228 23:02:00.996084 24534 caffe.cpp:308] Use GPU with device ID 0
I0228 23:02:01.243448 24534 upgrade_proto.cpp:51] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/overfeat.prototxt
I0228 23:02:01.243518 24534 upgrade_proto.cpp:59] Successfully upgraded file specified using deprecated V1LayerParameter
I0228 23:02:01.243541 24534 upgrade_proto.cpp:65] Attempting to upgrade input file specified using deprecated input fields: ./imagenet_winners/overfeat.prototxt
I0228 23:02:01.243548 24534 upgrade_proto.cpp:68] Successfully upgraded file specified using deprecated input fields.
W0228 23:02:01.243551 24534 upgrade_proto.cpp:70] Note that future Caffe releases will only support input layers and not input fields.
I0228 23:02:01.243683 24534 net.cpp:49] Initializing net from parameters: 
name: "overfeat"
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 128
      dim: 3
      dim: 231
      dim: 231
    }
  }
}
layer {
  name: "conv1/11x11_s4"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 96
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/11x11_s4"
  top: "conv1/11x11_s4"
}
layer {
  name: "pool1/2x2_s2"
  type: "Pooling"
  bottom: "conv1/11x11_s4"
  top: "pool1/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2/5x5_s1"
  type: "Convolution"
  bottom: "pool1/2x2_s2"
  top: "conv2/5x5_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv2/relu"
  type: "ReLU"
  bottom: "conv2/5x5_s1"
  top: "conv2/5x5_s1"
}
layer {
  name: "pool2/2x2_s2"
  type: "Pooling"
  bottom: "conv2/5x5_s1"
  top: "pool2/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/2x2_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "conv4/3x3_s1"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 1024
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "pool5/2x2_s2"
  type: "Pooling"
  bottom: "conv5/3x3_s1"
  top: "pool5/2x2_s2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5/2x2_s2"
  top: "fc6"
  inner_product_param {
    num_output: 3072
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
I0228 23:02:01.243755 24534 layer_factory.hpp:77] Creating layer input
I0228 23:02:01.243775 24534 net.cpp:91] Creating Layer input
I0228 23:02:01.243779 24534 net.cpp:399] input -> data
I0228 23:02:01.249866 24534 net.cpp:141] Setting up input
I0228 23:02:01.249888 24534 net.cpp:148] Top shape: 128 3 231 231 (20490624)
I0228 23:02:01.249892 24534 net.cpp:156] Memory required for data: 81962496
I0228 23:02:01.249898 24534 layer_factory.hpp:77] Creating layer conv1/11x11_s4
I0228 23:02:01.249915 24534 net.cpp:91] Creating Layer conv1/11x11_s4
I0228 23:02:01.249920 24534 net.cpp:425] conv1/11x11_s4 <- data
I0228 23:02:01.249927 24534 net.cpp:399] conv1/11x11_s4 -> conv1/11x11_s4
I0228 23:02:01.386718 24534 net.cpp:141] Setting up conv1/11x11_s4
I0228 23:02:01.386745 24534 net.cpp:148] Top shape: 128 96 56 56 (38535168)
I0228 23:02:01.386749 24534 net.cpp:156] Memory required for data: 236103168
I0228 23:02:01.386765 24534 layer_factory.hpp:77] Creating layer conv1/relu
I0228 23:02:01.386775 24534 net.cpp:91] Creating Layer conv1/relu
I0228 23:02:01.386780 24534 net.cpp:425] conv1/relu <- conv1/11x11_s4
I0228 23:02:01.386783 24534 net.cpp:386] conv1/relu -> conv1/11x11_s4 (in-place)
I0228 23:02:01.387037 24534 net.cpp:141] Setting up conv1/relu
I0228 23:02:01.387048 24534 net.cpp:148] Top shape: 128 96 56 56 (38535168)
I0228 23:02:01.387050 24534 net.cpp:156] Memory required for data: 390243840
I0228 23:02:01.387053 24534 layer_factory.hpp:77] Creating layer pool1/2x2_s2
I0228 23:02:01.387060 24534 net.cpp:91] Creating Layer pool1/2x2_s2
I0228 23:02:01.387063 24534 net.cpp:425] pool1/2x2_s2 <- conv1/11x11_s4
I0228 23:02:01.387068 24534 net.cpp:399] pool1/2x2_s2 -> pool1/2x2_s2
I0228 23:02:01.387104 24534 net.cpp:141] Setting up pool1/2x2_s2
I0228 23:02:01.387110 24534 net.cpp:148] Top shape: 128 96 28 28 (9633792)
I0228 23:02:01.387114 24534 net.cpp:156] Memory required for data: 428779008
I0228 23:02:01.387115 24534 layer_factory.hpp:77] Creating layer conv2/5x5_s1
I0228 23:02:01.387125 24534 net.cpp:91] Creating Layer conv2/5x5_s1
I0228 23:02:01.387128 24534 net.cpp:425] conv2/5x5_s1 <- pool1/2x2_s2
I0228 23:02:01.387132 24534 net.cpp:399] conv2/5x5_s1 -> conv2/5x5_s1
I0228 23:02:01.391953 24534 net.cpp:141] Setting up conv2/5x5_s1
I0228 23:02:01.391965 24534 net.cpp:148] Top shape: 128 256 24 24 (18874368)
I0228 23:02:01.391968 24534 net.cpp:156] Memory required for data: 504276480
I0228 23:02:01.391975 24534 layer_factory.hpp:77] Creating layer conv2/relu
I0228 23:02:01.391983 24534 net.cpp:91] Creating Layer conv2/relu
I0228 23:02:01.391985 24534 net.cpp:425] conv2/relu <- conv2/5x5_s1
I0228 23:02:01.391989 24534 net.cpp:386] conv2/relu -> conv2/5x5_s1 (in-place)
I0228 23:02:01.392232 24534 net.cpp:141] Setting up conv2/relu
I0228 23:02:01.392242 24534 net.cpp:148] Top shape: 128 256 24 24 (18874368)
I0228 23:02:01.392246 24534 net.cpp:156] Memory required for data: 579773952
I0228 23:02:01.392248 24534 layer_factory.hpp:77] Creating layer pool2/2x2_s2
I0228 23:02:01.392254 24534 net.cpp:91] Creating Layer pool2/2x2_s2
I0228 23:02:01.392257 24534 net.cpp:425] pool2/2x2_s2 <- conv2/5x5_s1
I0228 23:02:01.392262 24534 net.cpp:399] pool2/2x2_s2 -> pool2/2x2_s2
I0228 23:02:01.392293 24534 net.cpp:141] Setting up pool2/2x2_s2
I0228 23:02:01.392298 24534 net.cpp:148] Top shape: 128 256 12 12 (4718592)
I0228 23:02:01.392302 24534 net.cpp:156] Memory required for data: 598648320
I0228 23:02:01.392305 24534 layer_factory.hpp:77] Creating layer conv3/3x3_s1
I0228 23:02:01.392312 24534 net.cpp:91] Creating Layer conv3/3x3_s1
I0228 23:02:01.392314 24534 net.cpp:425] conv3/3x3_s1 <- pool2/2x2_s2
I0228 23:02:01.392319 24534 net.cpp:399] conv3/3x3_s1 -> conv3/3x3_s1
I0228 23:02:01.400120 24534 net.cpp:141] Setting up conv3/3x3_s1
I0228 23:02:01.400141 24534 net.cpp:148] Top shape: 128 512 12 12 (9437184)
I0228 23:02:01.400144 24534 net.cpp:156] Memory required for data: 636397056
I0228 23:02:01.400151 24534 layer_factory.hpp:77] Creating layer conv3/relu
I0228 23:02:01.400157 24534 net.cpp:91] Creating Layer conv3/relu
I0228 23:02:01.400161 24534 net.cpp:425] conv3/relu <- conv3/3x3_s1
I0228 23:02:01.400167 24534 net.cpp:386] conv3/relu -> conv3/3x3_s1 (in-place)
I0228 23:02:01.400307 24534 net.cpp:141] Setting up conv3/relu
I0228 23:02:01.400315 24534 net.cpp:148] Top shape: 128 512 12 12 (9437184)
I0228 23:02:01.400317 24534 net.cpp:156] Memory required for data: 674145792
I0228 23:02:01.400321 24534 layer_factory.hpp:77] Creating layer conv4/3x3_s1
I0228 23:02:01.400328 24534 net.cpp:91] Creating Layer conv4/3x3_s1
I0228 23:02:01.400331 24534 net.cpp:425] conv4/3x3_s1 <- conv3/3x3_s1
I0228 23:02:01.400336 24534 net.cpp:399] conv4/3x3_s1 -> conv4/3x3_s1
I0228 23:02:01.429241 24534 net.cpp:141] Setting up conv4/3x3_s1
I0228 23:02:01.429275 24534 net.cpp:148] Top shape: 128 1024 12 12 (18874368)
I0228 23:02:01.429282 24534 net.cpp:156] Memory required for data: 749643264
I0228 23:02:01.429292 24534 layer_factory.hpp:77] Creating layer conv4/relu
I0228 23:02:01.429306 24534 net.cpp:91] Creating Layer conv4/relu
I0228 23:02:01.429312 24534 net.cpp:425] conv4/relu <- conv4/3x3_s1
I0228 23:02:01.429321 24534 net.cpp:386] conv4/relu -> conv4/3x3_s1 (in-place)
I0228 23:02:01.429625 24534 net.cpp:141] Setting up conv4/relu
I0228 23:02:01.429636 24534 net.cpp:148] Top shape: 128 1024 12 12 (18874368)
I0228 23:02:01.429639 24534 net.cpp:156] Memory required for data: 825140736
I0228 23:02:01.429642 24534 layer_factory.hpp:77] Creating layer conv5/3x3_s1
I0228 23:02:01.429652 24534 net.cpp:91] Creating Layer conv5/3x3_s1
I0228 23:02:01.429656 24534 net.cpp:425] conv5/3x3_s1 <- conv4/3x3_s1
I0228 23:02:01.429661 24534 net.cpp:399] conv5/3x3_s1 -> conv5/3x3_s1
I0228 23:02:01.486037 24534 net.cpp:141] Setting up conv5/3x3_s1
I0228 23:02:01.486064 24534 net.cpp:148] Top shape: 128 1024 12 12 (18874368)
I0228 23:02:01.486068 24534 net.cpp:156] Memory required for data: 900638208
I0228 23:02:01.486081 24534 layer_factory.hpp:77] Creating layer conv5/relu
I0228 23:02:01.486090 24534 net.cpp:91] Creating Layer conv5/relu
I0228 23:02:01.486094 24534 net.cpp:425] conv5/relu <- conv5/3x3_s1
I0228 23:02:01.486099 24534 net.cpp:386] conv5/relu -> conv5/3x3_s1 (in-place)
I0228 23:02:01.486372 24534 net.cpp:141] Setting up conv5/relu
I0228 23:02:01.486383 24534 net.cpp:148] Top shape: 128 1024 12 12 (18874368)
I0228 23:02:01.486387 24534 net.cpp:156] Memory required for data: 976135680
I0228 23:02:01.486390 24534 layer_factory.hpp:77] Creating layer pool5/2x2_s2
I0228 23:02:01.486397 24534 net.cpp:91] Creating Layer pool5/2x2_s2
I0228 23:02:01.486399 24534 net.cpp:425] pool5/2x2_s2 <- conv5/3x3_s1
I0228 23:02:01.486403 24534 net.cpp:399] pool5/2x2_s2 -> pool5/2x2_s2
I0228 23:02:01.486441 24534 net.cpp:141] Setting up pool5/2x2_s2
I0228 23:02:01.486446 24534 net.cpp:148] Top shape: 128 1024 6 6 (4718592)
I0228 23:02:01.486449 24534 net.cpp:156] Memory required for data: 995010048
I0228 23:02:01.486451 24534 layer_factory.hpp:77] Creating layer fc6
I0228 23:02:01.486457 24534 net.cpp:91] Creating Layer fc6
I0228 23:02:01.486459 24534 net.cpp:425] fc6 <- pool5/2x2_s2
I0228 23:02:01.486464 24534 net.cpp:399] fc6 -> fc6
I0228 23:02:01.685596 24534 net.cpp:141] Setting up fc6
I0228 23:02:01.685626 24534 net.cpp:148] Top shape: 128 3072 (393216)
I0228 23:02:01.685629 24534 net.cpp:156] Memory required for data: 996582912
I0228 23:02:01.685638 24534 layer_factory.hpp:77] Creating layer fc7
I0228 23:02:01.685647 24534 net.cpp:91] Creating Layer fc7
I0228 23:02:01.685652 24534 net.cpp:425] fc7 <- fc6
I0228 23:02:01.685657 24534 net.cpp:399] fc7 -> fc7
I0228 23:02:01.707695 24534 net.cpp:141] Setting up fc7
I0228 23:02:01.707725 24534 net.cpp:148] Top shape: 128 4096 (524288)
I0228 23:02:01.707727 24534 net.cpp:156] Memory required for data: 998680064
I0228 23:02:01.707744 24534 layer_factory.hpp:77] Creating layer fc8
I0228 23:02:01.707757 24534 net.cpp:91] Creating Layer fc8
I0228 23:02:01.707762 24534 net.cpp:425] fc8 <- fc7
I0228 23:02:01.707767 24534 net.cpp:399] fc8 -> fc8
I0228 23:02:01.714983 24534 net.cpp:141] Setting up fc8
I0228 23:02:01.715009 24534 net.cpp:148] Top shape: 128 1000 (128000)
I0228 23:02:01.715013 24534 net.cpp:156] Memory required for data: 999192064
I0228 23:02:01.715021 24534 net.cpp:219] fc8 does not need backward computation.
I0228 23:02:01.715025 24534 net.cpp:219] fc7 does not need backward computation.
I0228 23:02:01.715029 24534 net.cpp:219] fc6 does not need backward computation.
I0228 23:02:01.715031 24534 net.cpp:219] pool5/2x2_s2 does not need backward computation.
I0228 23:02:01.715034 24534 net.cpp:219] conv5/relu does not need backward computation.
I0228 23:02:01.715037 24534 net.cpp:219] conv5/3x3_s1 does not need backward computation.
I0228 23:02:01.715040 24534 net.cpp:219] conv4/relu does not need backward computation.
I0228 23:02:01.715042 24534 net.cpp:219] conv4/3x3_s1 does not need backward computation.
I0228 23:02:01.715045 24534 net.cpp:219] conv3/relu does not need backward computation.
I0228 23:02:01.715049 24534 net.cpp:219] conv3/3x3_s1 does not need backward computation.
I0228 23:02:01.715051 24534 net.cpp:219] pool2/2x2_s2 does not need backward computation.
I0228 23:02:01.715054 24534 net.cpp:219] conv2/relu does not need backward computation.
I0228 23:02:01.715057 24534 net.cpp:219] conv2/5x5_s1 does not need backward computation.
I0228 23:02:01.715060 24534 net.cpp:219] pool1/2x2_s2 does not need backward computation.
I0228 23:02:01.715065 24534 net.cpp:219] conv1/relu does not need backward computation.
I0228 23:02:01.715067 24534 net.cpp:219] conv1/11x11_s4 does not need backward computation.
I0228 23:02:01.715070 24534 net.cpp:219] input does not need backward computation.
I0228 23:02:01.715075 24534 net.cpp:261] This network produces output fc8
I0228 23:02:01.715087 24534 net.cpp:274] Network initialization done.
I0228 23:02:01.715144 24534 caffe.cpp:320] Performing Forward
I0228 23:02:01.907001 24534 caffe.cpp:325] Initial loss: 0
I0228 23:02:01.907030 24534 caffe.cpp:326] Performing Backward
I0228 23:02:01.910131 24534 caffe.cpp:334] *** Benchmark begins ***
I0228 23:02:01.910141 24534 caffe.cpp:335] Testing for 10 iterations.
I0228 23:02:02.624702 24534 caffe.cpp:363] Iteration: 1 forward-backward time: 426.361 ms.
I0228 23:02:03.056290 24534 caffe.cpp:363] Iteration: 2 forward-backward time: 431.521 ms.
I0228 23:02:03.482328 24534 caffe.cpp:363] Iteration: 3 forward-backward time: 425.986 ms.
I0228 23:02:03.911427 24534 caffe.cpp:363] Iteration: 4 forward-backward time: 429.046 ms.
I0228 23:02:04.344964 24534 caffe.cpp:363] Iteration: 5 forward-backward time: 433.483 ms.
I0228 23:02:04.775502 24534 caffe.cpp:363] Iteration: 6 forward-backward time: 430.476 ms.
I0228 23:02:05.206106 24534 caffe.cpp:363] Iteration: 7 forward-backward time: 430.55 ms.
I0228 23:02:05.637663 24534 caffe.cpp:363] Iteration: 8 forward-backward time: 431.398 ms.
I0228 23:02:06.068687 24534 caffe.cpp:363] Iteration: 9 forward-backward time: 430.961 ms.
I0228 23:02:06.499398 24534 caffe.cpp:363] Iteration: 10 forward-backward time: 430.659 ms.
I0228 23:02:06.499428 24534 caffe.cpp:366] Average time per layer: 
I0228 23:02:06.499431 24534 caffe.cpp:369]      input	forward: 0.0018432 ms.
I0228 23:02:06.499439 24534 caffe.cpp:372]      input	backward: 0.0020576 ms.
I0228 23:02:06.499441 24534 caffe.cpp:369] conv1/11x11_s4	forward: 7.81988 ms.
I0228 23:02:06.499444 24534 caffe.cpp:372] conv1/11x11_s4	backward: 19.4583 ms.
I0228 23:02:06.499447 24534 caffe.cpp:369] conv1/relu	forward: 1.37973 ms.
I0228 23:02:06.499450 24534 caffe.cpp:372] conv1/relu	backward: 2.04701 ms.
I0228 23:02:06.499454 24534 caffe.cpp:369] pool1/2x2_s2	forward: 0.867136 ms.
I0228 23:02:06.499456 24534 caffe.cpp:372] pool1/2x2_s2	backward: 4.60472 ms.
I0228 23:02:06.499459 24534 caffe.cpp:369] conv2/5x5_s1	forward: 16.2551 ms.
I0228 23:02:06.499461 24534 caffe.cpp:372] conv2/5x5_s1	backward: 46.0019 ms.
I0228 23:02:06.499475 24534 caffe.cpp:369] conv2/relu	forward: 0.640413 ms.
I0228 23:02:06.499477 24534 caffe.cpp:372] conv2/relu	backward: 0.956422 ms.
I0228 23:02:06.499480 24534 caffe.cpp:369] pool2/2x2_s2	forward: 0.433555 ms.
I0228 23:02:06.499483 24534 caffe.cpp:372] pool2/2x2_s2	backward: 2.25986 ms.
I0228 23:02:06.499485 24534 caffe.cpp:369] conv3/3x3_s1	forward: 8.06175 ms.
I0228 23:02:06.499488 24534 caffe.cpp:372] conv3/3x3_s1	backward: 15.2926 ms.
I0228 23:02:06.499491 24534 caffe.cpp:369] conv3/relu	forward: 0.326141 ms.
I0228 23:02:06.499495 24534 caffe.cpp:372] conv3/relu	backward: 0.482512 ms.
I0228 23:02:06.499497 24534 caffe.cpp:369] conv4/3x3_s1	forward: 31.1493 ms.
I0228 23:02:06.499500 24534 caffe.cpp:372] conv4/3x3_s1	backward: 60.424 ms.
I0228 23:02:06.499503 24534 caffe.cpp:369] conv4/relu	forward: 0.639104 ms.
I0228 23:02:06.499506 24534 caffe.cpp:372] conv4/relu	backward: 0.960726 ms.
I0228 23:02:06.499510 24534 caffe.cpp:369] conv5/3x3_s1	forward: 61.3352 ms.
I0228 23:02:06.499512 24534 caffe.cpp:372] conv5/3x3_s1	backward: 119.721 ms.
I0228 23:02:06.499516 24534 caffe.cpp:369] conv5/relu	forward: 0.641437 ms.
I0228 23:02:06.499518 24534 caffe.cpp:372] conv5/relu	backward: 0.958163 ms.
I0228 23:02:06.499521 24534 caffe.cpp:369] pool5/2x2_s2	forward: 0.435315 ms.
I0228 23:02:06.499523 24534 caffe.cpp:372] pool5/2x2_s2	backward: 2.2782 ms.
I0228 23:02:06.499526 24534 caffe.cpp:369]        fc6	forward: 10.3745 ms.
I0228 23:02:06.499529 24534 caffe.cpp:372]        fc6	backward: 10.5616 ms.
I0228 23:02:06.499532 24534 caffe.cpp:369]        fc7	forward: 1.01981 ms.
I0228 23:02:06.499536 24534 caffe.cpp:372]        fc7	backward: 1.23862 ms.
I0228 23:02:06.499538 24534 caffe.cpp:369]        fc8	forward: 0.539984 ms.
I0228 23:02:06.499541 24534 caffe.cpp:372]        fc8	backward: 0.596582 ms.
I0228 23:02:06.499552 24534 caffe.cpp:377] Average Forward pass: 142.054 ms.
I0228 23:02:06.499557 24534 caffe.cpp:379] Average Backward pass: 287.975 ms.
I0228 23:02:06.499562 24534 caffe.cpp:381] Average Forward-Backward: 430.114 ms.
I0228 23:02:06.499565 24534 caffe.cpp:383] Total Time: 4301.14 ms.
I0228 23:02:06.499568 24534 caffe.cpp:384] *** Benchmark ends ***
