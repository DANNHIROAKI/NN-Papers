I0822 16:50:40.169147  9913 caffe.cpp:291] Use GPU with device ID 0
I0822 16:50:40.679966  9913 upgrade_proto.cpp:641] Attempting to upgrade input file specified using deprecated V1LayerParameter: ./imagenet_winners/alexnet.prototxt
I0822 16:50:40.680040  9913 upgrade_proto.cpp:649] Successfully upgraded file specified using deprecated V1LayerParameter
I0822 16:50:40.680186  9913 net.cpp:51] Initializing net from parameters: 
name: "alexnet"
input: "data"
input_dim: 128
input_dim: 3
input_dim: 224
input_dim: 224
force_backward: true
state {
  phase: TRAIN
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1/11x11_s4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 2
    kernel_size: 11
    stride: 4
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv1/relu"
  type: "ReLU"
  bottom: "conv1/11x11_s4"
  top: "conv1/11x11_s4"
}
layer {
  name: "pool1/3x3_s2"
  type: "Pooling"
  bottom: "conv1/11x11_s4"
  top: "pool1/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv2/5x5_s1"
  type: "Convolution"
  bottom: "pool1/3x3_s2"
  top: "conv2/5x5_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 192
    pad: 2
    kernel_size: 5
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "cpnv2/relu"
  type: "ReLU"
  bottom: "conv2/5x5_s1"
  top: "conv2/5x5_s1"
}
layer {
  name: "pool2/3x3_s2"
  type: "Pooling"
  bottom: "conv2/5x5_s1"
  top: "pool2/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "conv3/3x3_s1"
  type: "Convolution"
  bottom: "pool2/3x3_s2"
  top: "conv3/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 384
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv3/relu"
  type: "ReLU"
  bottom: "conv3/3x3_s1"
  top: "conv3/3x3_s1"
}
layer {
  name: "conv4/3x3_s1"
  type: "Convolution"
  bottom: "conv3/3x3_s1"
  top: "conv4/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv4/relu"
  type: "ReLU"
  bottom: "conv4/3x3_s1"
  top: "conv4/3x3_s1"
}
layer {
  name: "conv5/3x3_s1"
  type: "Convolution"
  bottom: "conv4/3x3_s1"
  top: "conv5/3x3_s1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
      std: 0.1
    }
    bias_filler {
      type: "constant"
      value: 0.2
    }
  }
}
layer {
  name: "conv5/relu"
  type: "ReLU"
  bottom: "conv5/3x3_s1"
  top: "conv5/3x3_s1"
}
layer {
  name: "pool5/3x3_s2"
  type: "Pooling"
  bottom: "conv5/3x3_s1"
  top: "pool5/3x3_s2"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
  }
}
layer {
  name: "fc6"
  type: "InnerProduct"
  bottom: "pool5/3x3_s2"
  top: "fc6"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc7"
  type: "InnerProduct"
  bottom: "fc6"
  top: "fc7"
  inner_product_param {
    num_output: 4096
  }
}
layer {
  name: "fc8"
  type: "InnerProduct"
  bottom: "fc7"
  top: "fc8"
  inner_product_param {
    num_output: 1000
  }
}
I0822 16:50:40.680248  9913 net.cpp:440] Input 0 -> data
I0822 16:50:40.680284  9913 layer_factory.hpp:76] Creating layer conv1
I0822 16:50:40.680297  9913 net.cpp:110] Creating Layer conv1
I0822 16:50:40.680306  9913 net.cpp:485] conv1 <- data
I0822 16:50:40.680313  9913 net.cpp:438] conv1 -> conv1/11x11_s4
I0822 16:50:40.680809  9913 net.cpp:155] Setting up conv1
I0822 16:50:40.680819  9913 net.cpp:163] Top shape: 128 64 55 55 (24780800)
I0822 16:50:40.680835  9913 layer_factory.hpp:76] Creating layer conv1/relu
I0822 16:50:40.680842  9913 net.cpp:110] Creating Layer conv1/relu
I0822 16:50:40.680845  9913 net.cpp:485] conv1/relu <- conv1/11x11_s4
I0822 16:50:40.680850  9913 net.cpp:425] conv1/relu -> conv1/11x11_s4 (in-place)
I0822 16:50:40.680858  9913 net.cpp:155] Setting up conv1/relu
I0822 16:50:40.680862  9913 net.cpp:163] Top shape: 128 64 55 55 (24780800)
I0822 16:50:40.680866  9913 layer_factory.hpp:76] Creating layer pool1/3x3_s2
I0822 16:50:40.680871  9913 net.cpp:110] Creating Layer pool1/3x3_s2
I0822 16:50:40.680873  9913 net.cpp:485] pool1/3x3_s2 <- conv1/11x11_s4
I0822 16:50:40.680877  9913 net.cpp:438] pool1/3x3_s2 -> pool1/3x3_s2
I0822 16:50:40.680891  9913 net.cpp:155] Setting up pool1/3x3_s2
I0822 16:50:40.680896  9913 net.cpp:163] Top shape: 128 64 27 27 (5971968)
I0822 16:50:40.680898  9913 layer_factory.hpp:76] Creating layer conv2/5x5_s1
I0822 16:50:40.680903  9913 net.cpp:110] Creating Layer conv2/5x5_s1
I0822 16:50:40.680907  9913 net.cpp:485] conv2/5x5_s1 <- pool1/3x3_s2
I0822 16:50:40.680912  9913 net.cpp:438] conv2/5x5_s1 -> conv2/5x5_s1
I0822 16:50:40.682770  9913 net.cpp:155] Setting up conv2/5x5_s1
I0822 16:50:40.682778  9913 net.cpp:163] Top shape: 128 192 27 27 (17915904)
I0822 16:50:40.682785  9913 layer_factory.hpp:76] Creating layer cpnv2/relu
I0822 16:50:40.682790  9913 net.cpp:110] Creating Layer cpnv2/relu
I0822 16:50:40.682795  9913 net.cpp:485] cpnv2/relu <- conv2/5x5_s1
I0822 16:50:40.682798  9913 net.cpp:425] cpnv2/relu -> conv2/5x5_s1 (in-place)
I0822 16:50:40.682804  9913 net.cpp:155] Setting up cpnv2/relu
I0822 16:50:40.682807  9913 net.cpp:163] Top shape: 128 192 27 27 (17915904)
I0822 16:50:40.682811  9913 layer_factory.hpp:76] Creating layer pool2/3x3_s2
I0822 16:50:40.682816  9913 net.cpp:110] Creating Layer pool2/3x3_s2
I0822 16:50:40.682817  9913 net.cpp:485] pool2/3x3_s2 <- conv2/5x5_s1
I0822 16:50:40.682822  9913 net.cpp:438] pool2/3x3_s2 -> pool2/3x3_s2
I0822 16:50:40.682832  9913 net.cpp:155] Setting up pool2/3x3_s2
I0822 16:50:40.682837  9913 net.cpp:163] Top shape: 128 192 13 13 (4153344)
I0822 16:50:40.682840  9913 layer_factory.hpp:76] Creating layer conv3/3x3_s1
I0822 16:50:40.682845  9913 net.cpp:110] Creating Layer conv3/3x3_s1
I0822 16:50:40.682848  9913 net.cpp:485] conv3/3x3_s1 <- pool2/3x3_s2
I0822 16:50:40.682853  9913 net.cpp:438] conv3/3x3_s1 -> conv3/3x3_s1
I0822 16:50:40.686522  9913 net.cpp:155] Setting up conv3/3x3_s1
I0822 16:50:40.686529  9913 net.cpp:163] Top shape: 128 384 13 13 (8306688)
I0822 16:50:40.686537  9913 layer_factory.hpp:76] Creating layer conv3/relu
I0822 16:50:40.686540  9913 net.cpp:110] Creating Layer conv3/relu
I0822 16:50:40.686543  9913 net.cpp:485] conv3/relu <- conv3/3x3_s1
I0822 16:50:40.686548  9913 net.cpp:425] conv3/relu -> conv3/3x3_s1 (in-place)
I0822 16:50:40.686553  9913 net.cpp:155] Setting up conv3/relu
I0822 16:50:40.686558  9913 net.cpp:163] Top shape: 128 384 13 13 (8306688)
I0822 16:50:40.686560  9913 layer_factory.hpp:76] Creating layer conv4/3x3_s1
I0822 16:50:40.686566  9913 net.cpp:110] Creating Layer conv4/3x3_s1
I0822 16:50:40.686569  9913 net.cpp:485] conv4/3x3_s1 <- conv3/3x3_s1
I0822 16:50:40.686573  9913 net.cpp:438] conv4/3x3_s1 -> conv4/3x3_s1
I0822 16:50:40.691813  9913 net.cpp:155] Setting up conv4/3x3_s1
I0822 16:50:40.691823  9913 net.cpp:163] Top shape: 128 256 13 13 (5537792)
I0822 16:50:40.691828  9913 layer_factory.hpp:76] Creating layer conv4/relu
I0822 16:50:40.691833  9913 net.cpp:110] Creating Layer conv4/relu
I0822 16:50:40.691835  9913 net.cpp:485] conv4/relu <- conv4/3x3_s1
I0822 16:50:40.691840  9913 net.cpp:425] conv4/relu -> conv4/3x3_s1 (in-place)
I0822 16:50:40.691845  9913 net.cpp:155] Setting up conv4/relu
I0822 16:50:40.691854  9913 net.cpp:163] Top shape: 128 256 13 13 (5537792)
I0822 16:50:40.691858  9913 layer_factory.hpp:76] Creating layer conv5/3x3_s1
I0822 16:50:40.691862  9913 net.cpp:110] Creating Layer conv5/3x3_s1
I0822 16:50:40.691865  9913 net.cpp:485] conv5/3x3_s1 <- conv4/3x3_s1
I0822 16:50:40.691870  9913 net.cpp:438] conv5/3x3_s1 -> conv5/3x3_s1
I0822 16:50:40.695372  9913 net.cpp:155] Setting up conv5/3x3_s1
I0822 16:50:40.695380  9913 net.cpp:163] Top shape: 128 256 13 13 (5537792)
I0822 16:50:40.695387  9913 layer_factory.hpp:76] Creating layer conv5/relu
I0822 16:50:40.695392  9913 net.cpp:110] Creating Layer conv5/relu
I0822 16:50:40.695395  9913 net.cpp:485] conv5/relu <- conv5/3x3_s1
I0822 16:50:40.695399  9913 net.cpp:425] conv5/relu -> conv5/3x3_s1 (in-place)
I0822 16:50:40.695405  9913 net.cpp:155] Setting up conv5/relu
I0822 16:50:40.695410  9913 net.cpp:163] Top shape: 128 256 13 13 (5537792)
I0822 16:50:40.695412  9913 layer_factory.hpp:76] Creating layer pool5/3x3_s2
I0822 16:50:40.695416  9913 net.cpp:110] Creating Layer pool5/3x3_s2
I0822 16:50:40.695420  9913 net.cpp:485] pool5/3x3_s2 <- conv5/3x3_s1
I0822 16:50:40.695423  9913 net.cpp:438] pool5/3x3_s2 -> pool5/3x3_s2
I0822 16:50:40.695431  9913 net.cpp:155] Setting up pool5/3x3_s2
I0822 16:50:40.695436  9913 net.cpp:163] Top shape: 128 256 6 6 (1179648)
I0822 16:50:40.695440  9913 layer_factory.hpp:76] Creating layer fc6
I0822 16:50:40.695448  9913 net.cpp:110] Creating Layer fc6
I0822 16:50:40.695451  9913 net.cpp:485] fc6 <- pool5/3x3_s2
I0822 16:50:40.695456  9913 net.cpp:438] fc6 -> fc6
I0822 16:50:40.724627  9913 net.cpp:155] Setting up fc6
I0822 16:50:40.724647  9913 net.cpp:163] Top shape: 128 4096 (524288)
I0822 16:50:40.724655  9913 layer_factory.hpp:76] Creating layer fc7
I0822 16:50:40.724663  9913 net.cpp:110] Creating Layer fc7
I0822 16:50:40.724666  9913 net.cpp:485] fc7 <- fc6
I0822 16:50:40.724673  9913 net.cpp:438] fc7 -> fc7
I0822 16:50:40.737881  9913 net.cpp:155] Setting up fc7
I0822 16:50:40.737903  9913 net.cpp:163] Top shape: 128 4096 (524288)
I0822 16:50:40.737912  9913 layer_factory.hpp:76] Creating layer fc8
I0822 16:50:40.737920  9913 net.cpp:110] Creating Layer fc8
I0822 16:50:40.737925  9913 net.cpp:485] fc8 <- fc7
I0822 16:50:40.737931  9913 net.cpp:438] fc8 -> fc8
I0822 16:50:40.741376  9913 net.cpp:155] Setting up fc8
I0822 16:50:40.741395  9913 net.cpp:163] Top shape: 128 1000 (128000)
I0822 16:50:40.741403  9913 net.cpp:244] fc8 does not need backward computation.
I0822 16:50:40.741407  9913 net.cpp:244] fc7 does not need backward computation.
I0822 16:50:40.741411  9913 net.cpp:244] fc6 does not need backward computation.
I0822 16:50:40.741415  9913 net.cpp:244] pool5/3x3_s2 does not need backward computation.
I0822 16:50:40.741417  9913 net.cpp:244] conv5/relu does not need backward computation.
I0822 16:50:40.741420  9913 net.cpp:244] conv5/3x3_s1 does not need backward computation.
I0822 16:50:40.741423  9913 net.cpp:244] conv4/relu does not need backward computation.
I0822 16:50:40.741427  9913 net.cpp:244] conv4/3x3_s1 does not need backward computation.
I0822 16:50:40.741430  9913 net.cpp:244] conv3/relu does not need backward computation.
I0822 16:50:40.741433  9913 net.cpp:244] conv3/3x3_s1 does not need backward computation.
I0822 16:50:40.741437  9913 net.cpp:244] pool2/3x3_s2 does not need backward computation.
I0822 16:50:40.741441  9913 net.cpp:244] cpnv2/relu does not need backward computation.
I0822 16:50:40.741443  9913 net.cpp:244] conv2/5x5_s1 does not need backward computation.
I0822 16:50:40.741446  9913 net.cpp:244] pool1/3x3_s2 does not need backward computation.
I0822 16:50:40.741451  9913 net.cpp:244] conv1/relu does not need backward computation.
I0822 16:50:40.741453  9913 net.cpp:244] conv1 does not need backward computation.
I0822 16:50:40.741458  9913 net.cpp:287] This network produces output fc8
I0822 16:50:40.741474  9913 net.cpp:301] Network initialization done.
I0822 16:50:40.741477  9913 net.cpp:302] Memory required for data: 546557952
I0822 16:50:40.741547  9913 caffe.cpp:305] Performing Forward
I0822 16:50:40.956858  9913 caffe.cpp:310] Initial loss: 0
I0822 16:50:40.956898  9913 caffe.cpp:311] Performing Backward
I0822 16:50:41.829725  9913 caffe.cpp:319] *** Benchmark begins ***
I0822 16:50:41.829736  9913 caffe.cpp:320] Testing for 10 iterations.
I0822 16:50:43.598851  9913 caffe.cpp:350] Iteration: 1 forward-backward time: 1769 ms.
I0822 16:50:44.995029  9913 caffe.cpp:350] Iteration: 2 forward-backward time: 1396 ms.
I0822 16:50:46.391796  9913 caffe.cpp:350] Iteration: 3 forward-backward time: 1396 ms.
I0822 16:50:47.788988  9913 caffe.cpp:350] Iteration: 4 forward-backward time: 1397 ms.
I0822 16:50:49.199331  9913 caffe.cpp:350] Iteration: 5 forward-backward time: 1410 ms.
I0822 16:50:50.610597  9913 caffe.cpp:350] Iteration: 6 forward-backward time: 1411 ms.
I0822 16:50:52.022483  9913 caffe.cpp:350] Iteration: 7 forward-backward time: 1411 ms.
I0822 16:50:53.433804  9913 caffe.cpp:350] Iteration: 8 forward-backward time: 1411 ms.
I0822 16:50:54.845808  9913 caffe.cpp:350] Iteration: 9 forward-backward time: 1411 ms.
I0822 16:50:56.257473  9913 caffe.cpp:350] Iteration: 10 forward-backward time: 1411 ms.
I0822 16:50:56.257485  9913 caffe.cpp:353] Average time per layer: 
I0822 16:50:56.257488  9913 caffe.cpp:356]      conv1	forward: 57.8561 ms.
I0822 16:50:56.257493  9913 caffe.cpp:359]      conv1	backward: 399.725 ms.
I0822 16:50:56.257496  9913 caffe.cpp:356] conv1/relu	forward: 0.9209 ms.
I0822 16:50:56.257500  9913 caffe.cpp:359] conv1/relu	backward: 1.3274 ms.
I0822 16:50:56.257503  9913 caffe.cpp:356] pool1/3x3_s2	forward: 1.3224 ms.
I0822 16:50:56.257506  9913 caffe.cpp:359] pool1/3x3_s2	backward: 5.3766 ms.
I0822 16:50:56.257508  9913 caffe.cpp:356] conv2/5x5_s1	forward: 36.8325 ms.
I0822 16:50:56.257513  9913 caffe.cpp:359] conv2/5x5_s1	backward: 212.519 ms.
I0822 16:50:56.257515  9913 caffe.cpp:356] cpnv2/relu	forward: 0.6585 ms.
I0822 16:50:56.257519  9913 caffe.cpp:359] cpnv2/relu	backward: 0.9457 ms.
I0822 16:50:56.257521  9913 caffe.cpp:356] pool2/3x3_s2	forward: 0.9486 ms.
I0822 16:50:56.257524  9913 caffe.cpp:359] pool2/3x3_s2	backward: 4.1699 ms.
I0822 16:50:56.257527  9913 caffe.cpp:356] conv3/3x3_s1	forward: 22.5768 ms.
I0822 16:50:56.257530  9913 caffe.cpp:359] conv3/3x3_s1	backward: 254.945 ms.
I0822 16:50:56.257534  9913 caffe.cpp:356] conv3/relu	forward: 0.3114 ms.
I0822 16:50:56.257536  9913 caffe.cpp:359] conv3/relu	backward: 0.4273 ms.
I0822 16:50:56.257539  9913 caffe.cpp:356] conv4/3x3_s1	forward: 39.5137 ms.
I0822 16:50:56.257542  9913 caffe.cpp:359] conv4/3x3_s1	backward: 186.081 ms.
I0822 16:50:56.257545  9913 caffe.cpp:356] conv4/relu	forward: 0.2142 ms.
I0822 16:50:56.257549  9913 caffe.cpp:359] conv4/relu	backward: 0.2831 ms.
I0822 16:50:56.257551  9913 caffe.cpp:356] conv5/3x3_s1	forward: 26.8439 ms.
I0822 16:50:56.257555  9913 caffe.cpp:359] conv5/3x3_s1	backward: 142.852 ms.
I0822 16:50:56.257557  9913 caffe.cpp:356] conv5/relu	forward: 0.2145 ms.
I0822 16:50:56.257560  9913 caffe.cpp:359] conv5/relu	backward: 0.2849 ms.
I0822 16:50:56.257563  9913 caffe.cpp:356] pool5/3x3_s2	forward: 0.2958 ms.
I0822 16:50:56.257566  9913 caffe.cpp:359] pool5/3x3_s2	backward: 1.3278 ms.
I0822 16:50:56.257570  9913 caffe.cpp:356]        fc6	forward: 13.1232 ms.
I0822 16:50:56.257572  9913 caffe.cpp:359]        fc6	backward: 13.0686 ms.
I0822 16:50:56.257575  9913 caffe.cpp:356]        fc7	forward: 5.8826 ms.
I0822 16:50:56.257578  9913 caffe.cpp:359]        fc7	backward: 6.6231 ms.
I0822 16:50:56.257581  9913 caffe.cpp:356]        fc8	forward: 2.9204 ms.
I0822 16:50:56.257585  9913 caffe.cpp:359]        fc8	backward: 2.3444 ms.
I0822 16:50:56.257588  9913 caffe.cpp:364] Average Forward pass: 210.443 ms.
I0822 16:50:56.257592  9913 caffe.cpp:366] Average Backward pass: 1232.31 ms.
I0822 16:50:56.257596  9913 caffe.cpp:368] Average Forward-Backward: 1442.7 ms.
I0822 16:50:56.257599  9913 caffe.cpp:370] Total Time: 14427 ms.
I0822 16:50:56.257602  9913 caffe.cpp:371] *** Benchmark ends ***
